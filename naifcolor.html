



<!DOCTYPE html>
<html lang="en">
  
  <head>
    
      <meta charset="utf-8">
      <title>Bokeh Plot</title>
      
      
        
          
        <link rel="stylesheet" href="http://localhost:5006/static/extensions/panel/css/alerts.css" type="text/css" />
        <link rel="stylesheet" href="http://localhost:5006/static/extensions/panel/css/card.css" type="text/css" />
        <link rel="stylesheet" href="http://localhost:5006/static/extensions/panel/css/dataframe.css" type="text/css" />
        <link rel="stylesheet" href="http://localhost:5006/static/extensions/panel/css/json.css" type="text/css" />
        <link rel="stylesheet" href="http://localhost:5006/static/extensions/panel/css/markdown.css" type="text/css" />
        <link rel="stylesheet" href="http://localhost:5006/static/extensions/panel/css/widgets.css" type="text/css" />
        
        
          
        <script type="text/javascript" src="https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js" integrity="sha384-T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM" crossorigin="anonymous"></script>
        <script type="text/javascript">
            Bokeh.set_log_level("info");
        </script>
        
      
      
    
  </head>
  
  
  <body>
    
      
        
          
          
            
              <div class="bk-root" id="62ea5ea9-79ac-4d9a-a7a6-ddb12b567757" data-root-id="2172"></div>
            
          
        
      
      
        <script type="application/json" id="2300">
          {"17a79a35-419e-4724-b8dd-45a6605298e2":{"roots":{"references":[{"attributes":{},"id":"2179","type":"LinearScale"},{"attributes":{"formatter":{"id":"2214"},"ticker":{"id":"2186"},"visible":false},"id":"2185","type":"LinearAxis"},{"attributes":{},"id":"2193","type":"ResetTool"},{"attributes":{"overlay":{"id":"2195"}},"id":"2191","type":"BoxZoomTool"},{"attributes":{"callback":null,"tooltips":[["label","@label"],["text","@text"]]},"id":"2196","type":"HoverTool"},{"attributes":{"data":{"alpha":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"color":["#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#e2514a","#e2514a","#9e0142","#9e0142","#9e0142","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#5e4fa2","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#fee999","#9e0142","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#fca55d","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#9e0142","#e2514a","#edf8a3","#e2514a","#fee999","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#fca55d","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#e2514a","#edf8a3","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#9e0142","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#fca55d","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#9e0142","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#9e0142","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#fca55d","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#9e0142","#edf8a3","#9e0142","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#fca55d","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#fee999","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#e2514a","#9e0142","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#a2d9a4","#edf8a3","#fee999","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#fca55d","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fee999","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#9e0142","#9e0142","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#fca55d","#fca55d","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fee999","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#9e0142","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#fca55d","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#e2514a","#9e0142","#e2514a","#e2514a","#e2514a","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#e2514a","#47a0b3","#fca55d","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#e2514a","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#e2514a","#edf8a3","#edf8a3","#a2d9a4","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#e2514a","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#fca55d","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#a2d9a4","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fee999","#9e0142","#edf8a3","#e2514a","#a2d9a4","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#a2d9a4","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#9e0142","#fca55d","#edf8a3","#e2514a","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#9e0142","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#a2d9a4","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#a2d9a4","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fee999","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#47a0b3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#fca55d","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#47a0b3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#e2514a","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#fca55d","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#a2d9a4","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#47a0b3","#47a0b3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#fee999","#edf8a3","#edf8a3","#fca55d","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#fca55d","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#47a0b3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#9e0142","#9e0142","#e2514a","#edf8a3","#5e4fa2","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fee999","#edf8a3","#e2514a","#edf8a3","#fca55d","#edf8a3","#e2514a","#edf8a3","#47a0b3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#e2514a","#edf8a3","#e2514a","#9e0142","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fee999","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fee999","#e2514a","#edf8a3","#fee999","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#e2514a","#edf8a3","#9e0142","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#9e0142","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#47a0b3","#e2514a","#e2514a","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fee999","#e2514a","#edf8a3","#9e0142","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#47a0b3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#fca55d","#edf8a3","#9e0142","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#fee999","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#fee999","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#fee999","#edf8a3","#e2514a","#fee999","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#9e0142","#edf8a3","#edf8a3","#e2514a","#fee999","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#9e0142","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#9e0142","#edf8a3","#9e0142","#e2514a","#e2514a","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#47a0b3","#47a0b3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#9e0142","#e2514a","#e2514a","#edf8a3","#9e0142","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#9e0142","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#fee999","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#47a0b3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#e2514a","#edf8a3","#e2514a","#fca55d","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#fca55d","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#a2d9a4","#edf8a3","#e2514a","#edf8a3","#fee999","#edf8a3","#9e0142","#9e0142","#9e0142","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#fee999","#e2514a","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#fca55d","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#fca55d","#edf8a3","#9e0142","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#9e0142","#fca55d","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#e2514a","#fca55d","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#fca55d","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#fca55d","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#fca55d","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#edf8a3","#9e0142","#e2514a","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#9e0142","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#47a0b3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#47a0b3","#9e0142","#e2514a","#edf8a3","#e2514a","#9e0142","#edf8a3","#e2514a","#9e0142","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fee999","#e2514a","#fee999","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#e2514a","#edf8a3","#9e0142","#9e0142","#edf8a3","#e2514a","#9e0142","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#47a0b3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#fca55d","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#fca55d","#edf8a3","#edf8a3","#fee999","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#e2514a","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#e2514a","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#9e0142","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#fca55d","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#47a0b3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#a2d9a4","#9e0142","#edf8a3","#e2514a","#fca55d","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#fca55d","#edf8a3","#e2514a","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#9e0142","#e2514a","#fca55d","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#9e0142","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#fca55d","#edf8a3","#edf8a3","#fca55d","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#9e0142","#edf8a3","#edf8a3","#47a0b3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#a2d9a4","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#9e0142","#edf8a3","#fca55d","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#e2514a","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fee999","#9e0142","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#fca55d","#edf8a3","#e2514a","#9e0142","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#9e0142","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#a2d9a4","#9e0142","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#9e0142","#edf8a3","#9e0142","#edf8a3","#edf8a3","#a2d9a4","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#fca55d","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fee999","#edf8a3","#e2514a","#edf8a3","#9e0142","#a2d9a4","#edf8a3","#e2514a","#edf8a3","#9e0142","#9e0142","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#9e0142","#9e0142","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#fca55d","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#fca55d","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#fca55d","#9e0142","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#fca55d","#fca55d","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#fca55d","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#9e0142","#e2514a","#e2514a","#9e0142","#edf8a3","#edf8a3","#fca55d","#e2514a","#edf8a3","#edf8a3","#9e0142","#9e0142","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#e2514a","#edf8a3","#fca55d","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#e2514a","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#fca55d","#e2514a","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#a2d9a4","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#fee999","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#fee999","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fee999","#e2514a","#9e0142","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#a2d9a4","#e2514a","#edf8a3","#e2514a","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#9e0142","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#5e4fa2","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#47a0b3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#e2514a","#e2514a","#fee999","#edf8a3","#fee999","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#5e4fa2","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#9e0142","#9e0142","#9e0142","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#fca55d","#e2514a","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#e2514a","#e2514a","#e2514a","#9e0142","#edf8a3","#e2514a","#e2514a","#e2514a","#edf8a3","#e2514a","#edf8a3","#edf8a3","#fca55d","#9e0142","#edf8a3","#fee999","#edf8a3","#e2514a","#9e0142","#edf8a3","#edf8a3","#e2514a","#9e0142","#edf8a3","#e2514a","#edf8a3","#e2514a","#e2514a","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3","#edf8a3"],"index":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999,3000,3001,3002,3003,3004,3005,3006,3007,3008,3009,3010,3011,3012,3013,3014,3015,3016,3017,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3033,3034,3035,3036,3037,3038,3039,3040,3041,3042,3043,3044,3045,3046,3047,3048,3049,3050,3051,3052,3053,3054,3055,3056,3057,3058,3059,3060,3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,3071,3072,3073,3074,3075,3076,3077,3078,3079,3080,3081,3082,3083,3084,3085,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,3101,3102,3103,3104,3105,3106,3107,3108,3109,3110,3111,3112,3113,3114,3115,3116,3117,3118,3119,3120,3121,3122,3123,3124,3125,3126,3127,3128,3129,3130,3131,3132,3133,3134,3135,3136,3137,3138,3139,3140,3141,3142,3143,3144,3145,3146,3147,3148,3149,3150,3151,3152,3153,3154,3155,3156,3157,3158,3159,3160,3161,3162,3163,3164,3165,3166,3167,3168,3169,3170,3171,3172,3173,3174,3175,3176,3177,3178,3179,3180,3181,3182,3183,3184,3185,3186,3187,3188,3189,3190,3191,3192,3193,3194,3195,3196,3197,3198,3199,3200,3201,3202,3203,3204,3205,3206,3207,3208,3209,3210,3211,3212,3213,3214,3215,3216,3217,3218,3219,3220,3221,3222,3223,3224,3225,3226,3227,3228,3229,3230,3231,3232,3233,3234,3235,3236,3237,3238,3239,3240,3241,3242,3243,3244,3245,3246,3247,3248,3249,3250,3251,3252,3253,3254,3255,3256,3257,3258,3259,3260,3261,3262,3263,3264,3265,3266,3267,3268,3269,3270,3271,3272,3273,3274,3275,3276,3277,3278,3279,3280,3281,3282,3283,3284,3285,3286,3287,3288,3289,3290,3291,3292,3293,3294,3295,3296,3297,3298,3299,3300,3301,3302,3303,3304,3305,3306,3307,3308,3309,3310,3311,3312,3313,3314,3315,3316,3317,3318,3319,3320,3321,3322,3323,3324,3325,3326,3327,3328,3329,3330,3331,3332,3333,3334,3335,3336,3337,3338,3339,3340,3341,3342,3343,3344,3345,3346,3347,3348,3349,3350,3351,3352,3353,3354,3355,3356,3357,3358,3359,3360,3361,3362,3363,3364,3365,3366,3367,3368,3369,3370,3371,3372,3373,3374,3375,3376,3377,3378,3379,3380,3381,3382,3383,3384,3385,3386,3387,3388,3389,3390,3391,3392,3393,3394,3395,3396,3397,3398,3399,3400,3401,3402,3403,3404,3405,3406,3407,3408,3409,3410,3411,3412,3413,3414,3415,3416,3417,3418,3419,3420,3421,3422,3423,3424,3425,3426,3427,3428,3429,3430,3431,3432,3433,3434,3435,3436,3437,3438,3439,3440,3441,3442,3443,3444,3445,3446,3447,3448,3449,3450,3451,3452,3453,3454,3455,3456,3457,3458,3459,3460,3461,3462,3463,3464,3465,3466,3467,3468,3469,3470,3471,3472,3473,3474,3475,3476,3477,3478,3479,3480,3481,3482,3483,3484,3485,3486,3487,3488,3489,3490,3491,3492,3493,3494,3495,3496,3497,3498,3499,3500,3501,3502,3503,3504,3505,3506,3507,3508,3509,3510,3511,3512,3513,3514,3515,3516,3517,3518,3519,3520,3521,3522,3523,3524,3525,3526,3527,3528,3529,3530,3531,3532,3533,3534,3535,3536,3537,3538,3539,3540,3541,3542,3543,3544,3545,3546,3547,3548,3549,3550,3551,3552,3553,3554,3555,3556,3557,3558,3559,3560,3561,3562,3563,3564,3565,3566,3567,3568,3569,3570,3571,3572,3573,3574,3575,3576,3577,3578,3579,3580,3581,3582,3583,3584,3585,3586,3587,3588,3589,3590,3591,3592,3593,3594,3595,3596,3597,3598,3599,3600,3601,3602,3603,3604,3605,3606,3607,3608,3609,3610,3611,3612,3613,3614,3615,3616,3617,3618,3619,3620,3621,3622,3623,3624,3625,3626,3627,3628,3629,3630,3631,3632,3633,3634,3635,3636,3637,3638,3639,3640,3641,3642,3643,3644,3645,3646,3647,3648,3649,3650,3651,3652,3653,3654,3655,3656,3657,3658,3659,3660,3661,3662,3663,3664,3665,3666,3667,3668,3669,3670,3671,3672,3673,3674,3675,3676,3677,3678,3679,3680,3681,3682,3683,3684,3685,3686,3687,3688,3689,3690,3691,3692,3693,3694,3695,3696,3697,3698,3699,3700,3701,3702,3703,3704,3705,3706,3707,3708,3709,3710,3711,3712,3713,3714,3715,3716,3717,3718,3719,3720,3721,3722,3723,3724,3725,3726,3727,3728,3729,3730,3731,3732,3733,3734,3735,3736,3737,3738,3739,3740,3741,3742,3743,3744,3745,3746,3747,3748,3749,3750,3751,3752,3753,3754,3755,3756,3757,3758,3759,3760,3761,3762,3763,3764,3765,3766,3767,3768,3769,3770,3771,3772,3773,3774,3775,3776,3777,3778,3779,3780,3781,3782,3783,3784,3785,3786,3787,3788,3789,3790,3791,3792,3793,3794,3795,3796,3797,3798,3799,3800,3801,3802,3803,3804,3805,3806,3807,3808,3809,3810,3811,3812,3813,3814,3815,3816,3817,3818,3819,3820,3821,3822,3823,3824,3825,3826,3827,3828,3829,3830,3831,3832,3833,3834,3835,3836,3837,3838,3839,3840,3841,3842,3843,3844,3845,3846,3847,3848,3849,3850,3851,3852,3853,3854,3855,3856,3857,3858,3859,3860,3861,3862,3863,3864,3865,3866,3867,3868,3869,3870,3871,3872,3873,3874,3875,3876,3877,3878,3879,3880,3881,3882,3883,3884,3885,3886,3887,3888,3889,3890,3891,3892,3893,3894,3895,3896,3897,3898,3899,3900,3901,3902,3903,3904,3905,3906,3907,3908,3909,3910,3911,3912,3913,3914,3915,3916,3917,3918,3919,3920,3921,3922,3923,3924,3925,3926,3927,3928,3929,3930,3931,3932,3933,3934,3935,3936,3937,3938,3939,3940,3941,3942,3943,3944,3945,3946,3947,3948,3949,3950,3951,3952,3953,3954,3955,3956,3957,3958,3959,3960,3961,3962,3963,3964,3965,3966,3967,3968,3969,3970,3971,3972,3973,3974,3975,3976,3977,3978,3979,3980,3981,3982,3983,3984,3985,3986,3987,3988,3989,3990,3991,3992,3993,3994,3995,3996,3997,3998,3999,4000,4001,4002,4003,4004,4005,4006,4007,4008,4009,4010,4011,4012,4013,4014,4015,4016,4017,4018,4019,4020,4021,4022,4023,4024,4025,4026,4027,4028,4029,4030,4031,4032,4033,4034,4035,4036,4037,4038,4039,4040,4041,4042,4043,4044,4045,4046,4047,4048,4049,4050,4051,4052,4053,4054,4055,4056,4057,4058,4059,4060,4061,4062,4063,4064,4065,4066,4067,4068,4069,4070,4071,4072,4073,4074,4075,4076,4077,4078,4079,4080,4081,4082,4083,4084,4085,4086,4087,4088,4089,4090,4091,4092,4093,4094,4095,4096,4097,4098,4099,4100,4101,4102,4103,4104,4105,4106,4107,4108,4109,4110,4111,4112,4113,4114,4115,4116,4117,4118,4119,4120,4121,4122,4123,4124,4125,4126,4127,4128,4129,4130,4131,4132,4133,4134,4135,4136,4137,4138,4139,4140,4141,4142,4143,4144,4145,4146,4147,4148,4149,4150,4151,4152,4153,4154,4155,4156,4157,4158,4159,4160,4161,4162,4163,4164,4165,4166,4167,4168,4169,4170,4171,4172,4173,4174,4175,4176,4177,4178,4179,4180,4181,4182,4183,4184,4185,4186,4187,4188,4189,4190,4191,4192,4193,4194,4195,4196,4197,4198,4199,4200,4201,4202,4203,4204,4205,4206,4207,4208,4209,4210,4211,4212,4213,4214,4215,4216,4217,4218,4219,4220,4221,4222,4223,4224,4225,4226,4227,4228,4229,4230,4231,4232,4233,4234,4235,4236,4237,4238,4239,4240,4241,4242,4243,4244,4245,4246,4247,4248,4249,4250,4251,4252,4253,4254,4255,4256,4257,4258,4259,4260,4261,4262,4263,4264,4265,4266,4267,4268,4269,4270,4271,4272,4273,4274,4275,4276,4277,4278,4279,4280,4281,4282,4283,4284,4285,4286,4287,4288,4289,4290,4291,4292,4293,4294,4295,4296,4297,4298,4299,4300,4301,4302,4303,4304,4305,4306,4307,4308,4309,4310,4311,4312,4313,4314,4315,4316,4317,4318,4319,4320,4321,4322,4323,4324,4325,4326,4327,4328,4329,4330,4331,4332,4333,4334,4335,4336,4337,4338,4339,4340,4341,4342,4343,4344,4345,4346,4347,4348,4349,4350,4351,4352,4353,4354,4355,4356,4357,4358,4359,4360,4361,4362,4363,4364,4365,4366,4367,4368,4369,4370,4371,4372,4373,4374,4375,4376,4377,4378,4379,4380,4381,4382,4383,4384,4385,4386,4387,4388,4389,4390,4391,4392,4393,4394,4395,4396,4397,4398,4399,4400,4401,4402,4403,4404,4405,4406,4407,4408,4409,4410,4411,4412,4413,4414,4415,4416,4417,4418,4419,4420,4421,4422,4423,4424,4425,4426,4427,4428,4429,4430,4431,4432,4433,4434,4435,4436,4437,4438,4439,4440,4441,4442,4443,4444,4445,4446,4447,4448,4449,4450,4451,4452,4453,4454,4455,4456,4457,4458,4459,4460,4461,4462,4463,4464,4465,4466,4467,4468,4469,4470,4471,4472,4473,4474,4475,4476,4477,4478,4479,4480,4481,4482,4483,4484,4485,4486,4487,4488,4489,4490,4491,4492,4493,4494,4495,4496,4497,4498,4499,4500,4501,4502,4503,4504,4505,4506,4507,4508,4509,4510,4511,4512,4513,4514,4515,4516,4517,4518,4519,4520,4521,4522,4523,4524,4525,4526,4527,4528,4529,4530,4531,4532,4533,4534,4535,4536,4537,4538,4539,4540,4541,4542,4543,4544,4545,4546,4547,4548,4549,4550,4551,4552,4553,4554,4555,4556,4557,4558,4559,4560,4561,4562,4563,4564,4565,4566,4567,4568,4569,4570,4571,4572,4573,4574,4575,4576,4577,4578,4579,4580,4581,4582,4583,4584,4585,4586,4587,4588,4589,4590,4591,4592,4593,4594,4595,4596,4597,4598,4599,4600,4601,4602,4603,4604,4605,4606,4607,4608,4609,4610,4611,4612,4613,4614,4615,4616,4617,4618,4619,4620,4621,4622,4623,4624,4625,4626,4627,4628,4629,4630,4631,4632,4633,4634,4635,4636,4637,4638,4639,4640,4641,4642,4643,4644,4645,4646,4647,4648,4649,4650,4651,4652,4653,4654,4655,4656,4657,4658,4659,4660,4661,4662,4663,4664,4665,4666,4667,4668,4669,4670,4671,4672,4673,4674,4675,4676,4677,4678,4679,4680,4681,4682,4683,4684,4685,4686,4687,4688,4689,4690,4691,4692,4693,4694,4695,4696,4697,4698,4699,4700,4701,4702,4703,4704,4705,4706,4707,4708,4709,4710,4711,4712,4713,4714,4715,4716,4717,4718,4719,4720,4721,4722,4723,4724,4725,4726,4727,4728,4729,4730,4731,4732,4733,4734,4735,4736,4737,4738,4739,4740,4741,4742,4743,4744,4745,4746,4747,4748,4749,4750,4751,4752,4753,4754,4755,4756,4757,4758,4759,4760,4761,4762,4763,4764,4765,4766,4767,4768,4769,4770,4771,4772,4773,4774,4775,4776,4777,4778,4779,4780,4781,4782,4783,4784,4785,4786,4787,4788,4789,4790,4791,4792,4793,4794,4795,4796,4797,4798,4799,4800,4801,4802,4803,4804,4805,4806,4807,4808,4809,4810,4811,4812,4813,4814,4815,4816,4817,4818,4819,4820,4821,4822,4823,4824,4825,4826,4827,4828,4829,4830,4831,4832,4833,4834,4835,4836,4837,4838,4839,4840,4841,4842,4843,4844,4845,4846,4847,4848,4849,4850,4851,4852,4853,4854,4855,4856,4857,4858,4859,4860,4861,4862,4863,4864,4865,4866,4867,4868,4869,4870,4871,4872,4873,4874,4875,4876,4877,4878,4879,4880,4881,4882,4883,4884,4885,4886,4887,4888,4889,4890,4891,4892,4893,4894,4895,4896,4897,4898,4899,4900,4901,4902,4903,4904,4905,4906,4907,4908,4909,4910,4911,4912,4913,4914,4915,4916,4917,4918,4919,4920,4921,4922,4923,4924,4925,4926,4927,4928,4929,4930,4931,4932,4933,4934,4935,4936,4937,4938,4939,4940,4941,4942,4943,4944,4945,4946,4947,4948,4949,4950,4951,4952,4953,4954,4955,4956,4957,4958,4959,4960,4961,4962,4963,4964,4965,4966,4967,4968,4969,4970,4971,4972,4973,4974,4975,4976,4977,4978,4979,4980,4981,4982,4983,4984,4985,4986,4987,4988,4989,4990,4991,4992,4993,4994,4995,4996,4997,4998,4999,5000,5001,5002,5003,5004,5005],"label":[1,2,3,4,5,6,7,8,9,10,11,12,16,17,18,19,20,21,23,24,26,27,30,31,32,33,35,36,37,38,39,40,42,43,44,45,46,47,48,50,51,52,53,55,56,57,60,61,62,63,64,65,67,68,69,70,71,72,73,74,75,76,77,78,79,81,82,83,84,85,86,87,88,90,91,92,94,95,96,97,98,99,101,102,103,104,106,107,108,109,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,149,150,151,152,153,154,155,156,159,160,161,162,163,164,165,166,168,169,170,171,172,173,174,175,176,177,178,179,181,184,185,186,187,188,189,190,192,194,196,197,198,200,201,202,203,204,205,206,208,209,210,211,213,214,215,216,219,220,221,222,223,224,226,227,228,229,230,231,233,234,235,236,237,238,239,240,241,242,243,244,245,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,317,318,319,320,321,322,323,324,325,326,327,329,330,331,332,333,334,335,336,337,338,340,341,342,343,344,345,346,347,349,350,351,352,353,356,357,358,359,360,361,362,363,364,365,368,369,370,372,373,374,375,376,377,378,380,381,382,383,384,385,386,387,388,389,390,392,393,394,395,397,398,399,400,401,402,403,404,405,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,424,425,426,427,428,430,431,432,433,434,435,436,437,438,439,440,442,443,444,445,446,448,450,453,454,455,456,457,458,459,460,461,462,463,464,465,467,468,470,471,472,473,474,475,476,478,479,480,481,482,483,484,485,486,488,489,490,491,492,493,494,497,498,499,500,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,518,519,520,521,522,523,524,525,526,529,530,531,532,533,534,535,536,537,538,539,540,541,543,545,546,549,550,551,552,553,555,556,557,558,559,560,561,562,563,564,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,585,586,587,588,590,591,592,593,594,597,598,600,601,602,603,604,605,606,608,609,611,612,613,614,615,616,617,618,619,620,621,622,623,625,626,627,628,630,631,632,633,635,636,637,638,639,640,641,642,644,645,647,648,649,650,651,652,653,654,655,656,657,659,660,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,679,680,682,683,685,687,688,689,691,692,693,694,695,696,697,699,700,701,702,703,704,705,707,709,710,712,713,714,715,716,717,718,719,721,722,723,724,725,726,727,728,729,731,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,752,753,754,755,756,757,758,759,760,761,762,764,765,766,767,768,769,770,771,772,774,775,776,777,779,780,781,783,784,785,787,789,790,791,792,793,794,795,796,797,800,801,802,803,805,806,807,808,809,810,811,812,813,815,817,818,819,820,821,822,823,824,825,826,827,828,830,831,832,833,835,836,837,838,839,841,842,843,844,845,846,847,848,849,850,851,852,854,856,859,860,861,862,864,865,866,867,868,869,870,871,873,874,875,876,877,878,879,880,881,882,883,884,885,886,888,889,890,891,892,893,894,895,896,897,898,901,902,903,904,905,906,907,908,909,910,911,912,914,916,917,918,919,920,921,922,923,924,925,926,927,928,930,931,932,933,935,936,937,938,939,940,941,943,944,945,948,949,950,951,952,953,954,955,957,959,962,963,964,965,966,967,969,970,971,973,974,975,976,977,978,979,980,982,983,984,985,986,987,988,989,990,991,992,993,995,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1012,1013,1016,1017,1018,1019,1020,1021,1022,1023,1024,1026,1027,1028,1029,1030,1031,1033,1034,1035,1037,1038,1039,1040,1041,1042,1043,1045,1046,1047,1048,1049,1050,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1063,1064,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1102,1103,1104,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1120,1121,1122,1123,1124,1125,1126,1127,1129,1130,1132,1134,1135,1136,1137,1138,1140,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1153,1154,1155,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1173,1174,1175,1176,1177,1178,1179,1180,1181,1183,1184,1185,1187,1188,1189,1190,1192,1193,1194,1195,1196,1197,1198,1200,1201,1202,1204,1206,1207,1208,1209,1210,1211,1212,1214,1215,1216,1218,1219,1220,1221,1222,1224,1227,1229,1231,1232,1233,1234,1235,1236,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1252,1253,1254,1255,1256,1257,1258,1260,1262,1263,1264,1265,1267,1270,1271,1272,1273,1274,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1303,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1320,1321,1322,1323,1324,1326,1327,1329,1330,1331,1332,1333,1334,1335,1337,1338,1339,1340,1341,1342,1343,1344,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1373,1375,1376,1377,1378,1379,1381,1382,1384,1386,1387,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1402,1403,1405,1406,1407,1408,1409,1411,1412,1413,1414,1415,1416,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1432,1434,1435,1436,1437,1439,1440,1444,1445,1446,1447,1449,1450,1451,1453,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1483,1484,1485,1488,1489,1490,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1505,1506,1507,1509,1510,1511,1512,1514,1515,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1528,1529,1530,1532,1533,1536,1537,1538,1540,1541,1542,1543,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1557,1559,1560,1561,1562,1563,1564,1565,1566,1567,1569,1570,1571,1572,1573,1574,1577,1578,1579,1580,1582,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1633,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1659,1660,1661,1662,1663,1664,1666,1667,1669,1670,1672,1673,1674,1675,1676,1677,1680,1681,1682,1683,1685,1686,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1701,1703,1705,1706,1707,1708,1709,1710,1711,1714,1715,1716,1717,1718,1719,1720,1722,1723,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1740,1741,1742,1743,1744,1745,1746,1748,1750,1751,1752,1753,1754,1755,1757,1759,1760,1761,1762,1763,1764,1765,1766,1768,1771,1772,1774,1775,1776,1777,1778,1779,1780,1781,1782,1784,1785,1787,1788,1789,1790,1791,1793,1794,1795,1796,1798,1799,1800,1801,1802,1803,1806,1808,1809,1810,1811,1815,1816,1817,1818,1819,1820,1822,1823,1824,1825,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1855,1856,1858,1859,1860,1862,1863,1865,1866,1867,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1894,1895,1896,1898,1899,1901,1902,1903,1904,1907,1908,1909,1910,1911,1915,1916,1917,1918,1919,1921,1922,1923,1924,1925,1927,1928,1929,1930,1931,1932,1933,1934,1936,1937,1938,1939,1941,1942,1943,1944,1945,1946,1949,1950,1951,1952,1953,1954,1955,1957,1959,1960,1961,1962,1964,1965,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2005,2006,2007,2009,2010,2011,2012,2013,2014,2016,2017,2018,2019,2020,2021,2022,2023,2024,2026,2027,2028,2029,2030,2031,2033,2034,2035,2036,2037,2038,2039,2041,2042,2043,2044,2045,2046,2047,2048,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2062,2063,2065,2066,2067,2068,2069,2070,2071,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2110,2111,2112,2113,2114,2115,2116,2117,2119,2120,2121,2123,2124,2125,2127,2128,2129,2131,2133,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2147,2148,2149,2150,2151,2152,2153,2154,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2168,2169,2170,2171,2172,2175,2179,2180,2181,2182,2183,2184,2185,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2212,2213,2214,2215,2216,2217,2219,2220,2221,2222,2223,2224,2225,2228,2229,2230,2231,2233,2234,2235,2237,2238,2239,2240,2241,2242,2243,2244,2246,2248,2249,2250,2251,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2265,2266,2267,2268,2269,2270,2274,2276,2277,2278,2280,2281,2282,2283,2284,2285,2286,2288,2289,2290,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2306,2308,2309,2310,2311,2312,2313,2314,2315,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2328,2329,2330,2331,2332,2334,2335,2336,2337,2340,2343,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2356,2357,2359,2360,2363,2365,2366,2367,2368,2369,2371,2372,2373,2374,2376,2377,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2406,2409,2410,2412,2413,2415,2416,2417,2418,2419,2420,2421,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2441,2442,2443,2444,2445,2446,2447,2448,2450,2452,2454,2455,2456,2459,2460,2461,2462,2463,2464,2465,2466,2467,2470,2471,2472,2473,2474,2475,2476,2477,2478,2480,2481,2482,2484,2485,2486,2488,2489,2490,2491,2492,2494,2495,2496,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2513,2514,2517,2518,2520,2522,2523,2524,2525,2526,2527,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2544,2547,2548,2549,2550,2551,2553,2554,2555,2556,2557,2558,2559,2561,2563,2564,2566,2567,2568,2569,2570,2571,2573,2574,2575,2576,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2591,2592,2593,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2607,2608,2609,2610,2611,2615,2616,2617,2618,2619,2620,2621,2622,2624,2626,2627,2628,2629,2631,2632,2634,2635,2636,2637,2638,2639,2640,2642,2643,2644,2645,2647,2648,2649,2650,2651,2652,2653,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2670,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2689,2691,2692,2694,2695,2696,2697,2698,2699,2700,2701,2703,2704,2706,2707,2708,2709,2710,2711,2712,2713,2715,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2733,2734,2735,2736,2737,2738,2739,2740,2741,2743,2744,2745,2746,2747,2749,2750,2751,2752,2753,2754,2755,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2774,2775,2776,2779,2780,2782,2783,2784,2785,2786,2788,2790,2791,2792,2793,2794,2795,2797,2798,2800,2802,2803,2804,2806,2807,2808,2809,2810,2811,2813,2815,2816,2817,2819,2820,2821,2822,2823,2824,2825,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2841,2842,2843,2844,2846,2847,2848,2850,2851,2852,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2872,2874,2876,2877,2878,2879,2880,2883,2884,2885,2886,2887,2888,2889,2890,2892,2893,2894,2895,2897,2898,2899,2900,2901,2902,2903,2905,2906,2907,2908,2909,2911,2912,2913,2914,2915,2916,2917,2918,2919,2921,2922,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2936,2937,2938,2940,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2955,2957,2959,2960,2962,2963,2964,2965,2966,2967,2968,2969,2970,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2984,2985,2986,2988,2989,2990,2991,2992,2993,2995,2997,2998,2999,3000,3002,3003,3004,3006,3007,3010,3011,3012,3013,3015,3016,3017,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3029,3030,3031,3032,3033,3037,3038,3039,3040,3041,3042,3043,3044,3045,3046,3048,3049,3050,3053,3056,3059,3060,3061,3062,3063,3064,3065,3069,3070,3071,3072,3073,3074,3076,3077,3078,3079,3080,3081,3082,3083,3085,3086,3087,3089,3090,3092,3093,3094,3095,3096,3097,3098,3099,3100,3101,3103,3104,3105,3106,3107,3108,3109,3110,3111,3112,3114,3115,3116,3117,3118,3120,3121,3123,3124,3125,3126,3127,3129,3130,3131,3132,3133,3134,3135,3136,3138,3139,3140,3141,3142,3143,3144,3145,3146,3147,3148,3150,3151,3152,3153,3154,3155,3156,3157,3158,3159,3160,3162,3163,3164,3166,3167,3168,3169,3170,3171,3172,3174,3175,3177,3178,3179,3180,3181,3182,3183,3184,3185,3187,3189,3190,3191,3192,3193,3194,3195,3196,3197,3198,3200,3201,3202,3203,3204,3205,3206,3207,3208,3209,3210,3211,3212,3213,3214,3215,3216,3219,3220,3221,3222,3223,3224,3225,3227,3229,3230,3231,3232,3233,3235,3236,3237,3239,3241,3242,3243,3244,3246,3247,3248,3249,3251,3252,3254,3255,3256,3257,3258,3259,3260,3261,3262,3263,3264,3265,3266,3267,3268,3269,3270,3271,3272,3273,3275,3276,3279,3280,3281,3282,3283,3284,3285,3286,3287,3288,3291,3292,3293,3294,3295,3296,3297,3298,3299,3300,3301,3303,3304,3305,3306,3307,3308,3310,3311,3312,3313,3314,3315,3316,3317,3318,3319,3320,3321,3322,3323,3324,3325,3326,3327,3328,3329,3330,3331,3332,3333,3334,3336,3337,3338,3339,3340,3341,3342,3343,3344,3345,3346,3347,3348,3349,3350,3351,3352,3353,3354,3355,3356,3357,3358,3359,3362,3364,3366,3368,3370,3371,3372,3374,3375,3376,3377,3378,3379,3380,3381,3383,3384,3385,3386,3387,3388,3390,3391,3392,3393,3394,3395,3396,3397,3399,3400,3401,3402,3404,3405,3407,3408,3409,3410,3411,3412,3413,3414,3415,3416,3417,3419,3420,3422,3423,3425,3428,3429,3430,3431,3432,3433,3434,3435,3436,3439,3440,3441,3442,3443,3444,3445,3447,3448,3449,3450,3451,3452,3453,3454,3455,3456,3459,3463,3464,3465,3466,3467,3468,3469,3471,3472,3473,3474,3475,3476,3477,3478,3479,3480,3481,3482,3484,3485,3486,3487,3488,3489,3492,3493,3494,3495,3496,3500,3501,3503,3504,3506,3507,3510,3511,3512,3513,3515,3516,3518,3519,3520,3521,3522,3524,3525,3526,3527,3528,3529,3530,3531,3532,3533,3534,3535,3537,3538,3539,3540,3542,3544,3545,3546,3548,3549,3550,3551,3552,3553,3554,3555,3556,3558,3559,3560,3562,3564,3565,3567,3568,3569,3571,3572,3573,3574,3575,3576,3577,3578,3579,3580,3581,3582,3583,3584,3585,3586,3587,3588,3589,3590,3591,3592,3593,3594,3597,3598,3599,3600,3601,3602,3603,3604,3605,3606,3607,3609,3610,3611,3612,3613,3614,3615,3616,3617,3618,3619,3620,3621,3622,3624,3625,3626,3628,3630,3631,3632,3633,3634,3635,3636,3639,3640,3641,3642,3643,3644,3645,3646,3647,3648,3650,3651,3652,3654,3655,3656,3657,3658,3659,3660,3661,3663,3664,3665,3667,3668,3669,3671,3673,3675,3677,3678,3680,3681,3682,3684,3685,3686,3687,3688,3689,3690,3691,3692,3693,3694,3695,3696,3697,3698,3699,3700,3701,3702,3703,3704,3706,3707,3708,3709,3710,3711,3713,3715,3717,3718,3720,3721,3722,3724,3726,3727,3728,3730,3731,3732,3734,3735,3736,3737,3739,3740,3741,3742,3743,3744,3745,3747,3748,3749,3750,3751,3753,3754,3757,3758,3760,3761,3763,3764,3765,3766,3767,3768,3769,3770,3771,3772,3773,3774,3776,3777,3779,3780,3782,3783,3784,3786,3787,3788,3789,3790,3792,3793,3795,3796,3797,3798,3800,3801,3804,3805,3807,3808,3810,3811,3814,3815,3816,3817,3818,3819,3820,3821,3823,3824,3827,3828,3829,3831,3832,3833,3834,3835,3836,3837,3839,3840,3841,3843,3844,3845,3846,3847,3848,3849,3850,3851,3852,3854,3855,3856,3857,3858,3859,3860,3861,3862,3863,3864,3865,3866,3867,3868,3869,3870,3871,3875,3876,3877,3878,3880,3881,3882,3883,3884,3885,3886,3887,3888,3890,3892,3893,3894,3895,3896,3897,3899,3902,3903,3904,3905,3906,3908,3911,3912,3913,3914,3915,3916,3917,3918,3919,3920,3921,3923,3924,3925,3926,3927,3928,3931,3932,3933,3934,3935,3936,3937,3938,3939,3940,3941,3943,3944,3945,3946,3947,3948,3949,3950,3952,3953,3954,3955,3956,3957,3959,3960,3961,3962,3963,3964,3965,3967,3968,3969,3970,3972,3973,3974,3975,3976,3977,3978,3979,3981,3982,3983,3985,3986,3987,3989,3990,3991,3992,3993,3994,3996,3997,3999,4000,4001,4002,4004,4005,4008,4009,4010,4011,4012,4013,4014,4015,4016,4017,4018,4020,4021,4023,4024,4025,4026,4027,4028,4033,4034,4035,4036,4037,4038,4039,4040,4041,4043,4045,4046,4048,4049,4050,4051,4052,4053,4055,4056,4058,4059,4060,4061,4062,4065,4067,4068,4069,4070,4071,4072,4073,4074,4075,4076,4077,4078,4079,4080,4081,4083,4088,4089,4090,4091,4092,4094,4096,4097,4098,4099,4100,4101,4102,4103,4104,4107,4108,4109,4110,4111,4112,4113,4114,4116,4117,4118,4119,4123,4125,4126,4128,4129,4130,4131,4132,4133,4134,4136,4138,4139,4140,4142,4143,4144,4146,4147,4149,4150,4151,4152,4153,4154,4157,4159,4160,4161,4162,4164,4165,4166,4167,4169,4170,4171,4172,4173,4174,4175,4176,4177,4178,4179,4180,4181,4182,4184,4185,4186,4187,4188,4189,4190,4191,4192,4194,4195,4196,4197,4198,4200,4201,4202,4203,4204,4205,4206,4208,4209,4210,4211,4212,4213,4215,4217,4218,4219,4220,4221,4222,4223,4224,4225,4228,4229,4230,4231,4232,4233,4234,4235,4236,4237,4238,4240,4241,4243,4244,4245,4246,4248,4249,4250,4252,4253,4254,4255,4256,4257,4258,4259,4260,4261,4262,4263,4264,4266,4267,4268,4269,4270,4271,4272,4273,4275,4276,4277,4278,4279,4280,4281,4282,4283,4284,4285,4287,4290,4291,4292,4294,4295,4296,4297,4299,4300,4302,4303,4304,4305,4306,4307,4308,4309,4310,4311,4313,4315,4316,4317,4318,4319,4320,4323,4325,4327,4328,4329,4330,4331,4332,4333,4335,4336,4337,4338,4339,4340,4341,4342,4343,4344,4345,4346,4347,4348,4349,4350,4351,4352,4354,4355,4356,4358,4359,4360,4362,4363,4364,4365,4366,4369,4370,4371,4372,4373,4374,4375,4378,4379,4381,4382,4383,4384,4385,4386,4387,4388,4389,4390,4391,4392,4395,4396,4397,4400,4401,4402,4403,4404,4405,4406,4407,4409,4410,4411,4412,4414,4415,4416,4418,4421,4422,4425,4426,4427,4428,4429,4431,4432,4434,4435,4436,4438,4439,4440,4441,4443,4444,4445,4447,4448,4449,4452,4453,4454,4455,4456,4457,4458,4459,4461,4462,4463,4464,4465,4466,4467,4469,4470,4472,4473,4474,4476,4477,4478,4479,4480,4481,4482,4483,4485,4486,4487,4488,4489,4490,4491,4492,4493,4494,4495,4496,4497,4498,4499,4501,4502,4503,4504,4505,4506,4507,4508,4510,4511,4512,4513,4514,4515,4516,4517,4518,4520,4521,4522,4523,4524,4525,4526,4527,4528,4529,4530,4531,4532,4533,4534,4537,4538,4539,4540,4541,4542,4543,4544,4546,4547,4548,4552,4553,4554,4555,4556,4557,4558,4560,4561,4562,4563,4564,4565,4566,4567,4568,4569,4571,4572,4573,4574,4575,4576,4577,4579,4580,4581,4582,4583,4585,4586,4587,4588,4589,4590,4591,4592,4593,4595,4596,4597,4598,4600,4601,4602,4604,4605,4606,4607,4608,4609,4610,4611,4614,4615,4616,4617,4618,4620,4621,4622,4623,4624,4625,4626,4627,4628,4629,4630,4631,4632,4633,4634,4635,4636,4638,4639,4640,4641,4642,4643,4644,4645,4646,4647,4648,4649,4651,4653,4654,4655,4656,4657,4659,4660,4661,4662,4663,4664,4665,4667,4668,4669,4670,4671,4672,4673,4674,4676,4678,4680,4681,4682,4683,4684,4685,4686,4687,4688,4689,4690,4691,4692,4693,4694,4695,4696,4697,4698,4699,4700,4701,4702,4703,4704,4705,4707,4708,4709,4710,4712,4713,4714,4715,4717,4718,4720,4721,4722,4723,4724,4725,4726,4727,4728,4729,4730,4731,4732,4733,4734,4735,4736,4738,4739,4740,4741,4742,4743,4744,4745,4746,4747,4748,4749,4750,4751,4753,4754,4755,4756,4757,4758,4759,4760,4761,4762,4763,4764,4765,4766,4767,4768,4769,4770,4771,4772,4773,4776,4777,4778,4779,4780,4782,4784,4785,4786,4787,4788,4789,4790,4791,4793,4794,4795,4797,4798,4799,4800,4801,4804,4805,4806,4807,4808,4809,4810,4811,4812,4813,4814,4816,4817,4818,4819,4821,4822,4823,4824,4825,4826,4827,4828,4829,4830,4831,4832,4834,4835,4837,4838,4839,4841,4842,4843,4844,4846,4847,4848,4849,4850,4851,4852,4854,4855,4856,4858,4859,4861,4863,4864,4865,4866,4867,4868,4869,4870,4871,4873,4874,4875,4876,4877,4878,4879,4880,4881,4882,4883,4884,4886,4887,4888,4889,4890,4891,4892,4893,4894,4895,4896,4897,4899,4900,4902,4903,4904,4908,4909,4910,4911,4914,4916,4917,4919,4920,4921,4922,4923,4924,4925,4926,4927,4928,4930,4931,4933,4934,4935,4936,4937,4938,4939,4940,4941,4942,4945,4946,4947,4948,4949,4950,4951,4953,4954,4955,4956,4959,4960,4961,4963,4964,4965,4966,4968,4969,4970,4971,4972,4973,4974,4975,4976,4977,4978,4979,4980,4981,4982,4983,4984,4985,4986,4987,4988,4989,4990,4991,4992,4993,4994,4995,4996,4997,4998,5000,5001,5002,5003,5004,5006,5007,5008,5009,5010,5011,5012,5013,5014,5015,5016,5017,5018,5020,5021,5022,5023,5024,5025,5026,5027,5028,5029,5030,5031,5032,5033,5034,5035,5036,5038,5040,5041,5042,5043,5046,5047,5048,5049,5050,5051,5053,5054,5056,5057,5058,5059,5062,5063,5064,5066,5067,5068,5070,5071,5072,5074,5075,5076,5077,5078,5079,5080,5081,5082,5083,5084,5085,5087,5088,5089,5090,5091,5092,5093,5095,5096,5097,5098,5099,5100,5101,5103,5104,5105,5106,5107,5108,5110,5111,5112,5113,5114,5115,5116,5117,5118,5119,5120,5121,5122,5123,5124,5125,5126,5127,5128,5130,5133,5134,5135,5136,5137,5138,5139,5140,5141,5142,5143,5144,5145,5147,5148,5149,5150,5151,5152,5153,5154,5156,5157,5158,5159,5160,5161,5163,5164,5165,5166,5168,5169,5170,5171,5172,5174,5175,5177,5178,5181,5182,5183,5184,5185,5186,5187,5188,5189,5190,5192,5193,5194,5195,5196,5198,5200,5201,5202,5203,5204,5205,5206,5207,5208,5209,5210,5211,5212,5213,5214,5215,5216,5217,5218,5219,5220,5221,5222,5223,5224,5225,5226,5227,5228,5230,5231,5232,5233,5234,5236,5237,5238,5240,5241,5242,5243,5245,5246,5247,5248,5249,5250,5251,5252,5253,5255,5256,5257,5258,5259,5260,5261,5262,5263,5265,5266,5267,5268,5269,5270,5271,5272,5273,5274,5275,5278,5279,5280,5282,5283,5285,5286,5288,5290,5291,5292,5293,5294,5295,5296,5298,5299,5301,5302,5304,5305,5308,5309,5310,5311,5313,5314,5315,5316,5317,5318,5319,5320,5321,5323,5324,5325,5326,5327,5328,5329,5330,5332,5333,5336,5337,5338,5339,5340,5341,5342,5343,5344,5346,5347,5348,5349,5350,5351,5352,5353,5354,5355,5356,5358,5359,5360,5362,5364,5366,5367,5368,5369,5370,5371,5372,5374,5375,5376,5377,5378,5379,5380,5381,5382,5385,5388,5389,5391,5392,5393,5395,5397,5398,5399,5400,5401,5402,5404,5407,5408,5409,5410,5411,5412,5413,5414,5416,5417,5418,5419,5420,5421,5424,5425,5427,5428,5429,5430,5431,5433,5434,5435,5436,5438,5439,5440,5441,5442,5443,5444,5445,5446,5447,5448,5449,5450,5451,5452,5454,5455,5456,5457,5458,5459,5460,5461,5463,5464,5465,5466,5467,5469,5470,5471,5472,5473,5474,5475,5476,5477,5478,5479,5480,5481,5482,5483,5484,5485,5486,5487,5488,5490,5493,5494,5496,5497,5498,5499,5500,5501,5502,5503,5504,5506,5507,5509,5510,5511,5512,5513,5514,5515,5516,5517,5518,5520,5521,5522,5523,5524,5525,5526,5527,5528,5529,5532,5533,5534,5535,5536,5538,5539,5540,5541,5542,5543,5544,5545,5546,5547,5548,5550,5551,5553,5555,5556,5557,5558,5559,5560,5561,5562,5563,5564,5566,5567,5568,5569,5570,5571,5572,5573,5574,5575,5576,5577,5578,5579,5580,5582,5583,5584,5586,5587,5588,5589,5591,5592,5593,5594,5595,5596,5597,5599,5601,5602,5603,5604,5605,5606,5607,5609,5610,5611,5613,5614,5615,5616,5618,5619,5620,5621,5622,5623,5624,5625,5626,5627,5629,5630,5632,5633,5634,5635,5636,5637,5638,5639,5640,5643,5645,5646,5647,5648,5649,5651,5652,5654,5655,5656,5657,5659,5660,5661,5662,5665,5666,5667,5668,5669,5670,5671,5672,5673,5674,5675,5676,5678,5679,5680,5681,5682,5683,5684,5685,5686,5688,5689,5690,5691,5692,5694,5695,5696,5697,5698,5700,5702,5703,5704,5706,5708,5710,5711,5712,5713,5714,5715,5716,5717,5718,5719,5720,5721,5722,5724,5726,5727,5728,5729,5730,5731,5732,5733,5734,5735,5739,5740,5744,5745,5746,5747,5749,5750,5752,5753,5754,5755,5756,5758,5759,5761,5762,5763,5764,5765,5766,5767,5768,5769,5770,5771,5772,5774,5775,5776,5779,5780,5782,5783,5785,5786,5787,5788,5789,5790,5791,5792,5793,5794,5795,5796,5797,5798,5799,5800,5801,5802,5803,5804,5805,5807,5808,5809,5810,5811,5812,5813,5814,5815,5816,5817,5818,5819,5821,5822,5823,5824,5826,5827,5828,5829,5830,5831,5833,5834,5835,5836,5837,5838,5839,5840,5841,5842,5843,5844,5845,5847,5848,5849,5851,5852,5854,5855,5856,5857,5858,5859,5860,5862,5863,5864,5865,5866,5867,5868,5869,5870,5871,5872,5873,5874,5875,5876,5877,5878,5880,5881,5883,5884,5885,5886,5887,5888,5889,5890,5891,5894,5895,5897,5898,5899,5900,5901,5902,5903,5904,5905,5906,5907,5908,5909,5910,5911,5912,5913,5914,5915,5916,5918,5919,5920,5921,5922,5923,5924,5925,5926,5927,5928,5930,5931,5932,5933,5934,5935,5936,5937,5938,5939,5940,5941,5944,5945,5946,5948,5949,5950,5951,5952,5953,5954,5956,5957,5958,5959,5960,5961,5962,5963,5965,5966,5967,5968,5969,5970,5971,5972,5973,5974,5975,5976,5977,5979,5980,5982,5983,5984,5985,5987,5988,5989,5990,5991,5992,5993,5995,5996,5997,5999,6000,6001,6002,6003,6004,6005,6006,6007,6008,6009,6011,6012,6013,6014,6015,6016],"text":["Preliminary Design of a Network Protocol Learning Tool Based on the Comprehension of High School Students: Design by an Empirical Study Using a Simple Mind MapThe purpose of this study is to develop a learning tool for high school students studying the scientific aspects of information and communication net- works. More specifically, we focus on the basic principles of network proto- cols as the aim to develop our learning tool. Our tool gives students hands-on experience to help understand the basic principles of network protocols.","Identifying Psychological Theme Words from Emotion Annotated InterviewsRecent achievements in Natural Language Processing (NLP) and Psychology invoke the challenges to identify the insight of emotions. In the present study, we have identified different psychology related theme words while analyzing emotions on the interview data of ISEAR (International Survey of Emotion Antecedents and Reactions) research group. Primarily, we have developed a Graphical User Interface (GUI) to generate visual graphs for analyzing the impact of emotions with respect to different background, behavioral and physiological variables available in the ISEAR dataset. We have discussed some of the interesting results as observed from the generated visual graphs. On the other hand, different text clusters are identified from the interview statements by selecting individual as well as different combinations of the variables. Such textual clusters are used not only for retrieving the psychological theme words but also to classify the theme words into their respective emotion classes. In order to retrieve the psychological theme words from the text clusters, we have developed a rule based baseline system considering unigram based keyword spotting technique. The system has been evaluated based on a Top-n ranking strategy (where n=10, 20 or 30 most frequent theme words). Overall, the system achieves the average F-Scores of .42, .32, .36, .42, .35, .40 and .40 in identifying theme words with respect to Joy, Anger, Disgust, Fear, Guilt, Sadness and Shame emotion classes, respectively.","A Platform for Disaster Response Planning with Interdependency Simulation Functionality ","A pedestrian navigation method for user's safe and easy wayfindingIn recent years, most of mobile phones have a function of pedestrian navigation guidance. It was reported that users sometimes feel anxiety because of low accuracy of the position estimation especially in urban area and delay of information updating. In order to reduce the anxiety, a route planning algorithm is proposed in this study, which weighs user's difficulty (or easiness) of locating own current position as well as total physical distance of courses. The difficulty is estimated by valuation functions based on the \"recognizability\" and \"visibility\" of landmarks. An experimental study conducted in real situation using a prototype system to examine and refine the model for the optimal route planning. As the result, a modified model is proposed as a promising method of route planning for user's easy wayfinding.","Automatic Detection of Annotation Errors in Polish-Language Corpora ","Breast Cancer Identification Based on Thermal Analysis and a Clustering and Selection Classification EnsembleBreast cancer is the most common form of cancer in women. Early diagnosis is necessary for effective treatment and therefore of crucial importance. Medical thermography has been demonstrated an effective and inexpensive method for detecting breast cancer, in particular in early stages and in dense tissue. In this paper, we propose a medical decision support system based on analysing bilateral asymmetries in breast thermograms. The underlying data is imbalanced, as the number of benign cases significantly exceeds that of malignant ones, which will lead to problems for conventional pattern recognition algorithms. To address this, we propose an ensemble classifier system which is based on the idea of Clustering and Selection. The feature space, which is derived from a series of image symmetry features, is partitioned in order to decompose the problem into a set of simpler decision areas. We then delegate a locally competent classifier to each of the generated clusters. The set of predictors is composed of both standard models as well as models dedicated to imbalanced classification, so that we are able to employ a specialised classifier to clusters that show high class imbalance, while maintaining a high specificity for other clusters. We demonstrate that our method provides excellent classification performance and that it statistically outperforms several state-of-the-art ensembles dedicated to imbalanced problems.","Quality Assessment on User Generated Image for Mobile Search ApplicationQuality specified image retrieval is helpful to improve the user experiences in mobile searching and social media sharing. However, the model for evaluating the quality of the user generated images, which are popular in social media sharing, remains unexploited. In this paper, we propose a scheme for quality assessment on user generated image. The scheme is formed by four attribute dimensions, including intrinsic quality, favorability, relevancy and accessibility of images. Each of the dimensions is defined and modeled to pool a final quality score of a user generated image. The proposed scheme can reveal the quality of user generated image in comprehensive manner. Experimental results show that the scores obtained by our scheme have high correlation coefficients with the benchmark data. Therefore, our scheme is suitable for quality specified image retrieval on mobile applications.","Spectral Sparsification in Dynamic Graph Streams ","Two notes from experimental study on image steganalysisIn recent years, several advanced methods for image steganalysis were proposed. During research process, some concerns are more and more addressed by steganalyzer. In this paper, we focus on several of these concerns. The first one is how to utilize SVM classifier in practical steganalysis, we use clustering analysis to divide training samples and train several SVM for detecting stego image. In this part we also discussed building an image database that can be used for evaluating steganography/steganalysis fairly. The second is how to designed proper classifier for steganalysis, especially how to take information of cover/stego image pair into account. We will discuss several notions regard to these two concerns.","Hypergraph Transversal Computation with Binary Decision DiagramsWe study a hypergraph transversal computation: given a hypergraph, the problem is to generate all minimal transversals. This problem is related to many applications in computer science and vari- ous algorithms have been proposed. We present a new efficient algorithm using the compressed data structures BDDs and ZDDs, and we analyze the time complexity for it. By conducting computational experiments, we show that our algorithm is highly competitive with existing algorithms.","The role of the community in a technical support community: a case studyResource tagging has become an integral and important feature in enabling community users to easily access relevant content in a timely manner. Various methods have been proposed and implemented to optimize the identification of and access to tags used to characterize resources across different types of social web-based communities. While these user-focused tagging methods have shown promise in their limited application, they do not transfer well to internal business applications where the cost, time, tagged content, and user resources needed to implement them is prohibitive. This paper provides a case study of the process, tools, and methods used to engage users in the development and management of a tag taxonomy (folksontology) used to characterize content in an internal technical support community in the Cisco Global Technology Center.","Semantic Adaptation of Knowledge Representation Systems ","A Proposal for the Improvement Predictability of Cost Using Earned Value Management and Quality Data ","Structure and Practice of \"Four in One\" Hybrid-Practice Teaching ModeYunnan Radio and TV University tried to \"explore the Open Univer- sity building model\" that was approved by the State Council in October 2010. Having tried for more than two years, the university explores building the \"Four in One\" hybrid-practice teaching model which is an integration of network virtual training, entities training inside school, outside expand training, and learning package individual training. It aims to break through the bottleneck of open and distance education. The model has been applied gradually in practice teaching, and it shows positive initial results.","Development of a Training System for Lathe Operation Using a Simulator ","Soft Systems Methodology for Hard Systems Engineering - The Case of Information Systems Development at LIT/INPE/BRAZILThe Soft Systems Methodology (SSM) was developed to deal with soft systems, systems in which the human components predominate. Any kind of soft- ware is a hard system, since technical factors predominate in it. But when the software is a component of an Information System its success depends heavily on soft aspects. This paper analyzes the potential contribution of SSM to Software Engineering in order to propose a method to support requirements elicitation for the development of Information System that helps to understand and consider the human, social and political factors that will influence the system success. A real situation of the Integration and Testing Laboratory (LIT) of INPE (Brazilian Insti- tute for Space Research) was used to perform the study and to exemplify the use of the proposed method.","Complex Networks Topology: The Statistical Self-similarity Characteristics of the Average Overlapping Index ","A Scientometrics Study of Rough Sets in Three DecadesRough set theory has been attracting researchers and practitioners over three decades. The theory and its applications experienced unprecedented prosperity especially in the recent ten years. It is essential to explore and review the progress made in the field of rough sets. Mainly based on Web of Science database, we analyze the prolific authors, impact authors, impact groups, and the most impact papers in the past three decades. In addition, we also examine rough set development in the recent five years. One of the goals of this article is to use scientometrics approaches to study three decade research in rough sets. We review the historic growth of rough sets and elaborate on recent development status in this field.","Automatic pipeline construction for real-time annotationMany annotation tasks in computational linguistics are tackled with manually constructed pipelines of algorithms. In real-time tasks where information needs are stated and addressed ad-hoc, however, manual construction is infeasible. This paper presents an artificial intelligence approach to automatically construct annotation pipelines for given information needs and quality prioritizations. Based on an abstract ontological model, we use partial order planning to select a pipeline's algorithms and informed search to obtain an efficient pipeline schedule. We realized the approach as an expert system on top of Apache UIMA, which offers evidence that pipelines can be constructed ad-hoc in near-zero time.","Agricultural Knowledge Management Systems in Practice: The Ability to Support Wereda Knowledge Centers in EthiopiaAgriculture is the dominant sector in the Ethiopian economy but it is characterized by low productivity. Ethiopia is interested in creating access to agricultural knowledge through an agricultural knowledge management system (AKMS). Such a system has been developed using a web-based portal named Ethiopian Agriculture Portal (EAP). It is facilitated through Woreda Knowledge Centers (WKCs) which are in 10 Pilot Learning Woredas (PLW). Providing knowledge in the appropriate format, identification of affordable technological infrastructure, and integrating indigenous agricultural knowledge into the knowledge system is vital to empowering development agents (extension workers) in Ethiopia. This study addresses two research questions: 1)To what extent does the centralized AKMS support WKCs access and utilization of agricultural knowledge? 2) How can the existing AKMS support capturing and sharing of indigenous agricultural knowledge and best practices?","Dot, line, network: helping individuals make sense of New dataUbiquitous computing has led to an ever-increasing cascade of information about us, our friends, our societies, and the planet. Lima and others view this \"new data\" as an opportunity for individuals to develop network thinking; once people understand the whole, they can better control their contribution to global social issues like climate change. However, at present, such data is difficult to interpret by anyone, let alone by non-specialist users.#R##N##R##N#I believe that a variety of issues stand in the way of individuals understanding complex data sets. I will begin by discussing cognitive style (deductive and inductive logic). Then, after considering existing graphic principles for dealing with \"visual complexity,\" I suggest interfaces need to provide indications of place, date, validity, probability, and privacy. Finally, I briefly discuss some of the boundaries that exist between my networks of data and yours due to the hidden algorithms of search engines and the challenge of creating common ground when visualizations are increasingly personalized.","Assuring Dependability of Software Reuse: An Industrial Standard ","Polarity trend analysis of public sentiment on YouTubeFor the past several years YouTube has been by far the largest user-driven online video provider. While many of these videos contain a significant number of user comments, little work has been done to date in extracting trends from these comments because of their low information consistency and quality. In this paper we perform sentiment analysis of the YouTube comments related to popular topics using machine learning techniques. We demonstrate that an analysis of the sentiments to identify their trends, seasonality and forecasts can provide a clear picture of the influence of real-world events on user sentiments.","Mining Correlated Patterns with Multiple Minimum All-Confidence ThresholdsCorrelated patterns are an important class of regularities that exist in a database. The all-confidence measure has been widely used to discover the patterns in real-world applications. This paper theoretically analyzes the all-confidence measure, and shows that, although the measure satisfies the null-invariant property, mining correlated patterns involving both frequent and rare items with a single minimum all-confidence (minAllConf) threshold value causes the \"rare item problem\" if the items' frequencies in a database vary widely. The problem involves either finding very short length correlated patterns involving rare items at a high minAllConf threshold, or generating a huge number of patterns at a low minAllConf threshold. The cause for the problem is that the single minAllConf threshold was not sufficient to capture the items' frequencies in a database effectively. The paper also introduces an alternative model of correlated patterns using the concept of multiple minAllConf thresholds. The proposed model facilitates the user to specify a different minAllConf threshold for each pattern to reflect the varied frequencies of items within it. Experiment results show that the proposed model is very effective.","A Robust Hand Pose Estimation Algorithm for Hand RehabilitationDuring a rehabilitation session, patient activity should be continuously monitored in order to correct wrong movements and to follow patient improvements. Therefore, the application of human motion tracking techniques to rehabilitation is finding more and more consensus. The aim of this paper is to propose a novel, low-cost method for hand pose estimation by using a monocular motion sensing device and a robust marker-based pose estimation approach based on the Unscented Kalman Filter. The hand kinematics is used to enclose geometrical constraints in the estimation process. The approach is applied for evaluating some significant kinematic parameters necessary for understanding human hand motor improvements during rehabilitation. In particular, the parameters evaluated for the hand fingers are joint positions, angles, Range Of Motion and trajectory. Moreover, the position, orientation and velocity of the wrist are estimated.","Robust fin control for ship roll stabilization by using functional-link neural networksTo reduce the roll of a surface ship, a robust fin controller based on functional-link neural networks is proposed. The plant consists of the ship roll dynamics and that of the fin actuators. Modeling errors and the environmental disturbance induced by waves are considered in the cascaded roll system, which are identified by the neural networks. Lyapunov function is employed in the controller design, which guarantees the stability of the fin stabilizer. Numerical simulation demonstrates the good performance of the roll reduction based on the controller proposed.","Research of Intelligent Evacuation SystemDesign a system that combines the professional intelligent evacuation system and GIS (Geographic Information Systems), which can dynamically guide people to leave the fire site in the shortest time through a safe route according to instantaneity situation.","Computing the Split Points for Learning Decision Tree in MapReduce ","Development of Brand Selection Model Considering Customer Service ","Ripple Effects: Small-Scale Investigations into the Sustainability of Ocean Science Education Networks ","A Methodology and Framework for Automatic Layout Independent GUI Testing of Applications Developed in Magic xpa ","Wasp Colony with a Multiobjective Local Optimizer for Dynamic Task Planning in a Production Plant ","Actor Network Theory in Interpretative Research Approach ","Detection of vortical structures in 4D velocity encoded phase contrast MRI data using vector template matchingWe present the Adaptive Vector Pattern Matching (AVPM) method, a novel method for the detection of vortical structures specifically designed for velocity encoded 4D PCMRI datasets. AVPM is based on vector pattern matching combined with robust orientation estimation. This combination provides for a simple yet robust algorithm, which is a priori axial flow invariant. We demonstrate these properties by comparing the performance of AVPM with Heiberg's Vector Pattern Matching algorithm.","Exploration on Similar Spatial Textual Objects Retrieval ","A modified real AdaBoost algorithm to discover intensive care unit subgroups with a poor outcome.The Intensive Care Unit (ICU) population is heterogeneous. At individual ICUs, the quality of care may vary within subgroups. We investigate whether poor outcomes of an ICU can be traced back to excess deaths in specific patient subgroups, by discovering candidate subgroups, with a modified adaptive decision tree boosting algorithm applied to 80 Dutch ICUs. Genuine subgroups were selected from candidate subgroups when the case-mix adjusted outcomes were poorer than those of the five top performing ICUs. For 59 ICUs we discovered 122 genuine subgroups and most were defined by one to four variables, with a median of three [2\u20134]. Variables Glasgow Coma Scale and age were used most. There were 29 ICUs with overall poor outcomes, and for 22 our algorithm found all excess deaths. A new method based on adaptive decision tree boosting discovered many subgroups of ICU patients for which there is potentially room for outcomes improvement.","Formal Verification Integration Approach for DSMLThe application of formal methods especially, model checking and static analysis techniques for the verification of safety critical embedded systems has produced very good results and raised the interest of system designers up to the application of these technologies in real size projects. However, these methods usually rely on specific verification oriented formal languages that most designers do not master. It is thus mandatory to embed the associated tools in automated verification toolchains that allow designers to rely on their usual domain-specific modeling languages DSMLs while enjoying the benefits of these powerful methods. More precisely, we propose a language to formally express system requirements and interpret verification results so that system designers DSML end-users avoid the burden of learning some formal verification technologies. Formal verification is achieved through translational semantics. This work is based on a metamodeling pattern for executable DSML that favors the definition of generative tools and thus eases the integration of tools for new DSMLs.","A Semantics-Aware I/O Interface for High Performance Computing ","Responses to Social Predicament on Online Social Networks ","NLP EAC Recognition by Component Separation in the Eye Region ","An Application of the \u03c8-Theory to the Analysis of Business Process ModelsThis paper presents a method to analyse the consistency and completeness of process models according to the principles of the \u03c8-theory and the underlying concept of business transaction. Transactions specify the collaborative behaviour between actors while services are being requested and provided. The method assesses the consistency of a process in terms of the business transactions that can be inferred from it. To do so, it takes as input a process model that is converted to a transactional model. The transactional model is then analysed and revised so that all transactions become consistent and complete according to the transactional pattern. This enables to identify the problems on the original process model and to prompt areas of improvement.","The Plan4business Approach to Transfer Open Data into Real Estate Businesses ","Full Length Article: SAR image multiclass segmentation using a multiscale and multidirection triplet Markov fields model in nonsubsampled contourlet transform domainTriplet Markov fields (TMFs) model recently proposed is to deal with nonstationary image segmentation and has achieved promising results. In this paper, we propose a multiscale and multidirection TMF model for nonstationary synthetic aperture radar (SAR) image multiclass segmentation in nonsubsampled contourlet transform (NSCT) domain, named as NSCT-TMF model. NSCT-TMF model is capable of capturing the contextual information of image content in the spatial and scale spaces effectively by the construction of multiscale energy functions. And the derived multiscale and multidirection likelihoods of NSCT-TMF model can capture the dependencies of NSCT coefficients across scale and directions. In this way, the proposed model is able to achieve multiscale information fusion in terms of image configuration and features in underlying labeling process. Experimental results demonstrate that due to the effective propagation of the contextual information, NSCT-TMF model turns out to be more robust against speckle noise and improves the performance of nonstationary SAR image segmentation.","Fuzzy property-oriented concept lattices in morphological image and signal processingFuzzy property-oriented concept lattices are a formal tool for modeling and processing incomplete information in information systems. This paper relates this theory to fuzzy mathematical morphology, which scope, for instance, is to process and analyze images and signals. Consequently, the theory developed in the concept lattice framework can be used in these particular settings.","The generate-and-solve framework revisited: generating by simulated annealingThe Generate-and-Solve is a hybrid framework to cope with hard combinatorial optimization problems by artificially reducing the search space of solutions. In this framework, a metaheuristic engine works as a generator of reduced instances of the problem. These instances, in turn, can be more easily handled by an exact solver to provide a feasible (optimal) solution to the original problem. This approach has commonly employed genetic algorithms and it has been particularly effective in dealing with cutting and packing problems. In this paper, we present an instantiation of the framework for tackling the constrained two-dimensional non-guillotine cutting problem and the container loading problem using a simulated annealing generator. We conducted computational experiments on a set of difficult benchmark instances. Results show that the simulated annealing implementation overachieves previous versions of the Generate-and-Solve framework. In addition, the framework is shown to be competitive with current state-of-the-art approaches to solve the problems studied here.","A Highly Efficient RFID Distance Bounding Protocol without Real-Time PRF Evaluation ","Self-virtualized CAN controller for multi-core processors in real-time applicationsThe long-rising number of electronic control units (ECUs) in cars is a major problem for OEMs, because of high costs and installation space requirements. The complexity could be reduced by the use of multi-core processors, where several ECUs can be repartitioned into virtual machines (VMs) running on one multi-core processor. Such a consolidation of ECUs is challenging, because I/O devices for real-time capable interconnects have to be shared by multiple VMs. In this paper we present a concept for offloading the functionality for CAN controller virtualization into a self-virtualized controller. By means of a thorough real-time analysis, it is shown that proposed solution is capable of real-time message transmission with additional latencies, that are multiple orders smaller than the common deadlines.","Loose particle classification using a new wavelet fisher discriminant methodLoose particles left inside aerospace components or equipment can cause catastrophic failure in aerospace industry. It is vital to identify the material type of these loose particles and eliminate them. This is a classification problem, and autoregressive (AR) model and Learning Vector Quantization (LVQ) networks have been used to classify loose particles inside components. More recently, the test objects have been changed from components to aerospace equipments. To improve classification accuracy, more data samples often have to be dealt with. The difficulty is that these data samples contain redundant information, and the aforementioned two conventional methods are unable to process redundant information, thus the classification accuracy is deteriorated. In this paper, the wavelet Fisher discriminant is investigated for loose particle classifications. First, the fisher model is formulated as a least squares problem with linear-in-the-parameters structure. Then, the previously proposed two-stage subset selection method is used to build a sparse wavelet Fisher model in order to reduce redundant information. Experimental results show the wavelet Fisher classification method can perform better than AR model and LVQ networks.","Towards a Characterization and Systematic Evaluation Framework for Theories and Models of Human, Social, Behavioral, and Cultural Processes within Agent-Based Models ","Long-Term Study of a Software Keyboard That Places Keys at Positions of Fingers and Their SurroundingsIn this paper, we present a software keyboard called Ley- board that enables users to type faster. Leyboard makes typing easier by placing keys at the positions of fingers and their surroundings. To this end, Leyboard automatically adjusts its key positions and sizes to users' hands. This design allows users to type faster and more accurately than using ordinary software keyboards, the keys of which are unperceptive. We have implemented a prototype and have performed a long-term user study. The study has proved the usefulness of Leyboard and its pros and cons.","Visualising Temporal Item Sets: Guided Drill-Down with Hierarchical Attributes ","New propagation algorithm in dynamic directed evidential networks with conditional belief functionsProposed as a subclass of directed evidential network with conditional belief functions (DEVN), dynamic directed evidential network with conditional belief functions (DDEVN) was introduced as a new approach for modeling systems evolving in time. Considered as an alternative to dynamic Bayesian network and dynamic possibilistic network, this framework enables to reason under uncertainty expressed in the belief function formalism. In this paper, we propose a new propagation algorithm in DDEVNs based on a new computational structure, namely the mixed binary join tree, which is appropriate for making the exact inference in these networks.","Minimal Preference ChangeWe propose a novel approach to preference change. We treat a set of preferences as a special kind of theory, and define minimal change contraction and revision operations in the spirit of minimal change as advocated by the Alchourron, Gardenfors, and Makinson AGM theory of belief revision. We characterise minimal contraction of preference sets by a set of postulates and prove a representation theorem. We also give a linear time algorithm which implements minimal contraction by a single preference. We also define minimal contraction by a set of preferences, and for a significant special case state postulates, prove a representation theorem, and provide an efficient algorithm implementing minimal contraction by a set of preferences.","Generation of fundamental frequency contours for Thai speech synthesis using tone nucleus model.\u5831\u544a\u756a\u53f7: ; \u5b66\u4f4d\u6388\u4e0e\u65e5: 2013-03-25 ; \u5b66\u4f4d\u306e\u7a2e\u5225: \u4fee\u58eb ; \u5b66\u4f4d\u306e\u7a2e\u985e: \u4fee\u58eb\uff08\u60c5\u5831\u7406\u5de5\u5b66\uff09 ; \u5b66\u4f4d\u8a18\u756a\u53f7: ; \u7814\u7a76\u79d1\u30fb\u5c02\u653b: \u60c5\u5831\u7406\u5de5\u5b66\u7cfb\u7814\u7a76\u79d1\u30fb\u96fb\u5b50\u60c5\u5831\u5b66\u5c02\u653b","On the Security of an Efficient Attribute-Based SignatureIn CT-RSA 2011, Maji et.al proposed an attribute-based sig- nature (ABS) scheme, which is the most efficient ABS scheme that sup- ports general predicates until now. They claimed that their ABS scheme is unforgeable under generic group model. Unfortunately, we found a forgery attack on this ABS scheme. In this paper, we firstly give a forgery exam- ple, then analyze the reason cause this attack and gives the conditions this attack worked. We found this attack is fatal to Maji et.al's ABS scheme.","Minimum Memory Vectorisation of Wavelet LiftingWith the start of the widespread use of discrete wavelet transform the need for its effective implementation is becoming increasingly more important. This work presents a novel approach to discrete wavelet transform through a new computational scheme of wavelet lifting. The presented approach is compared with two other. The results are obtained on a general purpose processor with 4-fold SIMD instruction set (such as Intel x86-64 processors). Using the frequently exploited CDF 9/7 wavelet, the achieved speedup is about 3\u00d7 compared to naive implementation.","The KBGen ChallengeGiven a preselected set of relations extracted from the AURA knowledge base on biology, the KBGEN Task consisted in generating a sentence verbalising these relations. Three team submitted the results of their systems. The systems were compared using both automatic metrics (BLEU, NIST) and subjective ratings by 12 human users for three dimensions namely, fluency, grammaticality and meaning similarity. In this report, we summarise the KBGen Task, the evaluation methods and the results obtained.","Revisiting Frank-Wolfe: Projection-Free Sparse Convex OptimizationWe provide stronger and more general primal-dual convergence results for Frank-Wolfe-type algorithms (a.k.a. conditional gradient) for constrained convex optimization, enabled by a simple framework of duality gap certificates. Our analysis also holds if the linear subproblems are only solved approximately (as well as if the gradients are inexact), and is proven to be worst-case optimal in the sparsity of the obtained solutions.#R##N##R##N#On the application side, this allows us to unify a large variety of existing sparse greedy methods, in particular for optimization over convex hulls of an atomic set, even if those sets can only be approximated, including sparse (or structured sparse) vectors or matrices, low-rank matrices, permutation matrices, or max-norm bounded matrices.#R##N##R##N#We present a new general framework for convex optimization over matrix factorizations, where every Frank-Wolfe iteration will consist of a low-rank update, and discuss the broad application areas of this approach.","Speeding-up reinforcement learning through abstraction and transfer learningWe are interested in the following general question: is it possible to abstract knowledge that is generated while learning the solution of a problem, so that this abstraction can accelerate the learning process? Moreover, is it possible to transfer and reuse the acquired abstract knowledge to accelerate the learning process for future similar tasks? We propose a framework for conducting simultaneously two levels of reinforcement learning, where an abstract policy is learned while learning of a concrete policy for the problem, such that both policies are refined through exploration and interaction of the agent with the environment. We explore abstraction both to accelerate the learning process for an optimal concrete policy for the current problem, and to allow the application of the generated abstract policy in learning solutions for new problems. We report experiments in a robot navigation environment that show our framework to be effective in speeding up policy construction for practical problems and in generating abstractions that can be used to accelerate learning in new similar problems.","Region of Interest Discovery in Location-Based Social Networking Services with Protected Locations ","Analyzing barriers for people with hearing loss on the web: a semiotic studyThe correct interpretation of Web content by users is a major condition for an effective and accessible Web. However, many people with hearing loss have difficulties interpreting long and complex texts. In this work, we investigated barriers in the usage of Web systems by users with hearing loss. A participatory study with 21 users with hearing loss was conducted in the city of Macapa in Brazil. All the participants use internet frequently, but have different profiles, and reading and writing skill levels. Artifacts and methods from Organizational Semiotics were employed in the elicitation and analysis of problems, barriers, as well as solutions with the participants. The results provide alternatives that range from simple design directives to solutions that demand further research.","Human Identification with Electroencephalogram (EEG) for the Future Network SecurityHuman identification becomes huge demand in particular for the security related areas, in particular for the network security. EEG signals are confidential and hard to imitate, since EEG signals are a reflection of individual-dependent inner mental tasks. Generally speaking, it has several advantages, such as (i) it is confidential as it corresponds to a mental task, (ii) it is very difficult to mimic and (iii) it is almost impossible to steal as the brain activity is sensitive to the stress and the mood of the person, an aggressor cannot force the person to reproduce his/her mental pass-phrase. In this paper we first proposed a novel algorithm to create a spatial pattern of EEG signals obtained from the open public database. In our EEG signal processing, we have analyzed 64-electrode EEG samples for two databases, one is for 45 people and calculate the equivalent root mean square (rms) values for each electrode signal over 1 second period, by which created a 64-value input for each subject. With this neural network (NN) model, our analysis clearly showed that our designed classifier is able to identify all the 45 people correctly (successful rate of 100%) with a mean square error of 2.0334\u00d710 -7 and the same algorithm applying to the","Security and the networked societyThis book examines technological and social events during 2011 and 2012, a period that saw the rise of the hacktivist, the move to mobile platforms, and the ubiquity of social networks. It covers key technological issues such as hacking, cyber-crime, cyber-security and cyber-warfare, the internet, smart phones, electronic security, and information privacy. This book traces the rise into prominence of these issues while also exploring the resulting cultural reaction. The authors' analysis forms the basis of a discussion on future technological directions and their potential impact on society. The book includes forewords by Professor Margaret Gardner AO, Vice-Chancellor and President of RMIT University, and by Professor Robyn Owens, Deputy Vice-Chancellor (Research) at the University of Western Australia. Security and the Networked Society provides a reference for professionals and industry analysts studying digital technologies. Advanced-level students in computer science and electrical engineering will also find this book useful as a thought-provoking resource.","On Semi-Static Interference Coordination under Proportional Fair Scheduling in LTE SystemsIn this paper we consider the design of semi-static inter-cell interference coordination schemes for LTE networks. In this approach, base stations coordinate the power settings per resource block o ...","An o *(1.84 k) parameterized algorithm for the multiterminal cut problemWe study the multiterminal cut problem, which, given an n-vertex graph whose edges are integer-weighted and a set of terminals, asks for a partition of the vertex set such that each terminal is in a distinct part, and the total weight of crossing edges is at most k. Our weapons shall be two classical results known for decades. One is max volume min (s,t)-cuts by [Ford and Fulkerson, Flows in Networks. Princeton University Press, 1962], and the other is isolating cuts by [Dahlhaus et al., The complexity of multiterminal cuts. SIAM J. Comp. 23(4), 1994]. We sharpen these old weapons with the help of submodular functions, and apply them to this problem, which enable us to design a more elaborated branching scheme on deciding whether a non-terminal vertex is with a terminal or not. This bounded search tree algorithm can be shown to run in $1.84^k\\cdot n^{{\\cal O}(1)}$, thereby breaking the $2^k\\cdot n^{{\\cal O}(1)}$ barrier. As a by-product, it gives a $1.36^k\\cdot n^{{\\cal O}(1)}$ algorithm for 3-terminal cut. The preprocessing applied on non-terminal vertices might be of use for study of this problem from other aspects.","On Communication Complexity of Some Hard Problems in ECPe SystemsIn this paper, we present non-confluent solutions to some NP-complete problems using recognizer Evolution-Communication P systems with Energy (ECPe systems). We then evaluate the communication resources used in these systems using dynamical communication measures proposed for computations in ECPe systems. Specifically, we evaluate based on number of communication steps, communication rules and energy required for all communication.","Understanding the Role of Organizational Culture for Design and Success of Enterprise Architecture ManagementEnterprise architecture management is considered a valuable means to guide the consistent design and evolution of increasingly complex information systems. Despite existing research on EAM methods and models, organizations often face serious difficulties making EAM effective. The paper proposes to take organizational culture as a highly aggregated construct describing the context of EAM initiatives for building situational-or for that matter culture sensitive EAM methods-into account. We find that organizational culture significantly moderates the impact of EAM's design on EAM's success. In group culture, hierarchical culture and developmental culture it is essential to develop EAM from a passive into an actively designing approach to make it effective. Particularly in group culture it is rewarding to strive for an EAM approach that impacts stakeholders outside the IT department.","Market Separations Perspective of Agricultural Markets and Successful AMIS: Beyond Technical Rationality ","Big Data Analytics in Future Internet of ThingsCurrent research on Internet of Things (IoT) mainly focuses on how to enable general objects to see, hear, and smell the physical world for themselves, and make them connected to share the observations. In this paper, we argue that only connected is not enough, beyond that, general objects should have the capability to learn, think, and understand both the physical world by themselves. On the other hand, the future IoT will be highly populated by large numbers of heterogeneous networked embedded devices, which are generating massive or big data in an explosive fashion. Although there is a consensus among almost everyone on the great importance of big data analytics in IoT, to date, limited results, especially the mathematical foundations, are obtained. These practical needs impels us to propose a systematic tutorial on the development of effective algorithms for big data analytics in future IoT, which are grouped into four classes: 1) heterogeneous data processing, 2) nonlinear data processing, 3) high-dimensional data processing, and 4) distributed and parallel data processing. We envision that the presented research is offered as a mere baby step in a potentially fruitful research direction. We hope that this article, with interdisciplinary perspectives, will stimulate more interests in research and development of practical and effective algorithms for specific IoT applications, to enable smart resource allocation, automatic network operation, and intelligent service provisioning.","Psychological Empowerment of Patients with Chronic Diseases: The Role of Digital IntegrationInformation technology (IT) is enabling better healthcare delivery and care. However, the role of IT in managing chronic diseases is still unclear. Chronic diseases are a challenge today, accounting for a huge cost burden in the United States. This article is focused on addressing the research question that how digital integration can play a role in enhancing patients\u2019 psychological empowerment to manage a chronic disease. Based on existing literature, we develop a conceptual research model that provides antecedents and consequences of psychological empowerment for chronic disease treatment, and suggest a mediating role of digital integration through three tenets of digitization, mobilization and personalization. We develop a set of propositions based on the research model, and suggest a set of measurable constructs to test the propositions. A research methodology is introduced with a plan for the empirical analysis. Contributions and implications of this study are discussed.","Bodily expression media by dual domain design of shadowIn an improvised bodily expression, it is important to create the image inside the self. We developed a body expression generator called \"shadow media\" that generates an image by causing a gap between the body and its shadow. In this study, we focused on the dual residual shadow, a type of the shadow media, which generates a dual gap. Using this aspect of the shadow media, we develop new body expression media by introducing fluctuation and cellar automation to the boundary of the dual residual shadow. Experimental results indicate that these shadow media outputs can effectively support the generation of bodily expressions.","Computer Entertainment in Cars and TransportationThis workshop deals with the potential that entertainment systems and games hold for the transportation context. Travelling by car, bus, plane or by foot can be frustrating and full of negative experiences, but also holds great potential for innovative entertainment application. New off the shelf technology offers great potential beyond old-fashioned rear seat entertainment systems with the sole purpose of keeping kids quiet. The richness of contextual factors and social situations have so far not sufficiently been exploited, which is why this workshop aims at discussing potentials for gaming in transportation.","A Mobile Learning Community of Practice: Facilitating Conceptual Shifts in PedagogyUniversity lecturers are usually experts within a specific context domain of knowledge, however they are seldom expert teachers or educational technology wizards. Facilitating professional development for lecturers to engage with innovation in teaching and learning utilizing new technologies is no simple process. However, we have found that structuring lecturer professional development around a sustained community of practice can result in a journey of conceptual and pedagogical transformation [1]. The increasing ubiquity of mobile devices and social media provides a platform for enabling pedagogical change. Thus we established a MOBile Community Of Practice MOBCOP of lecturers interested in researching the potential of mobile social media in education interested in exploring the concept of the pedagogy-andragogy-heutagogy continuum [2], and how mobile learning can be utilized as a catalyst [3] to move towards student-directed heutagogy. We argue that the MOPCOP framework is potentially applicable to a variety of higher education contexts.","What Happened to the Crossdisciplinarity of Technology-Enhanced Learning in 2004?In a recent study the crossdisciplinarity of the field of Technology-Enhanced Learning was analysed with science-overlay-maps and diversity measures. Results reveal that the crossdisciplinarity of the field has constantly increased over the last 10 years. Only in 2004, a significant decrease of interdisciplinary research could be identified. In this paper we take a closer look at the publications of this year and test our hypotheses for the decrease of crossdisciplinarity.","Developing SBVR Vocabularies and Business Rules from OWL2 Ontologies ","The Minimal Group Paradigm in Virtual TeamsAs established by Social Identity Theory (SIT), belonging to specific groups is part of our identity and constitutes the feeling of \"who I am\" and \"who I am not\". Social groups are thus an essential part of life - not only for social interactions but also for defining part of our self-conception. Early experiments found that even minimal, entirely random in-group/out-group cate- gorizations are sufficient to cause a status gain of the in-group, while simulta- neously discriminating the out-group. In this paper we transfer this so-called Minimal Group Paradigm (MGP) to online collaboration. Two empirical studies with a total of N=190 participants were conducted to replicate the Minimal Group Paradigm in different virtual settings (informal vs. work) and with dif- ferent degrees of information available about the supposed group members. Overall, results show that indeed in-group favoritism could be elicited in totally anonymous virtual settings without any real interaction. Yet, the Minimal Group effect varied according to the complexity of the clues: in-group favorit- ism was stronger in settings with less information available. Implications for research and practice are discussed.","Forecasting Net Migration by Functional Demographic ModelNet migration is the net total of migrants during the period, that is, the total number of immigrants less the annual number of em- igrants, including both citizens and noncitizens. To derive estimates of net migration, the United Nations Population Division takes into account the past migration history of a country or area, the migration policy of a country, and the influx of refugees in recent periods. The data to cal- culate these official estimates come from a variety of sources, including border statistics, administrative records, surveys, and censuses. When no official estimates can be made because of insufficient data, net mi- gration is derived through the balance equation, which is the difference between overall population growth and the natural increase during the intercensal period. In this contribution, we apply the functional data model to Italian data, for forecasting net migration numbers.","Bone Age Assessment Using Support Vector Machine RegressionBone age assessment on hand radiographs is a costly and time consuming task in radiology. Recently, an automatic approach com- bining content-based image retrieval and support vector machines (SVM) has been developed. In this paper, we we apply support vector regression (SVR) as a novel method, yielding a gain in performance. Our methods are designed to cope with the age range 0-18 years as compared to the age range 2-17 of the commercial product BoneXpert. On a standard data set from University of South Carolina, our approaches reach a root- mean-square error of 0.95 and 0.80 years for SVM and SVR, respectively. This is slightly below the performance of the commercial product using an active shape approach.","DART: an efficient method for direction-aware bichromatic reverse k nearest neighbor queriesThis paper presents a novel type of queries in spatial databases, called the direction-aware bichromatic reverse k nearest neighbor (DBRkNN) queries,which extend the bichromatic reverse nearest neighbor queries.Given two disjoint sets, P and S, of spatial objects, and a query object q in S, the DBRkNN query returns a subset P\u2032 of P such that k nearest neighbors of each object in P\u2032 include q and each object in P\u2032 has a direction toward q within a pre-defined distance.We formally define the DBRkNN query, and then propose an efficient algorithm, called DART, for processing the DBRkNN query. Our method utilizes a grid-based index to cluster the spatial objects, and the B+-tree to index the direction angle.We adopt a filter-refinement framework that is widely used in many algorithms for reverse nearest neighbor queries. In the filtering step,DART eliminates all the objects that are away from the query object more than the pre-defined distance, or have an invalid direction angle. In the refinement step, remaining objects are verified whether the query object is actually one of the k nearest neighbors of them. From extensive experiments, we show that DART outperforms an R-tree-based naive algorithm in both indexing time and query processing time.","Use of Diffusion Tensor Images in Glioma Growth Modeling for Radiotherapy Target DelineationIn radiotherapy of gliomas, a precise definition of the treatment volume is problematic, because current imaging modalities reveal only the central part of the tumor with a high cellular density, but fail to detect all regions of microscopic tumor cell spread in the adjacent brain parenchyma. Mathematical models can be used to integrate known growth characteristics of gliomas into the target delineation process. In this paper, we demonstrate the use of diffusion tensor imaging (DTI) for simulating anisotropic cell migration in a glioma growth model that is based on the Fisher-Kolmogorov equation. For a clinical application of the model, it is crucial to develop a detailed understanding of its behavior, capabilities, and limitations. For that purpose, we perform a retrospective analysis of glioblastoma patients treated at our institution. We analyze the impact of diffusion anisotropy on model-derived target volumes, and interpret the results in the context of the underlying images. It was found that, depending on the location of the tumor relative to major fiber tracts, DTI can have significant influence on the shape of the radiotherapy target volume.","Progress Toward Mobility in Microfabricated MillirobotsResearch on mobile millirobots has been ongoing for the last 20 years, but the few robots that have walked have done so at slow speeds on smooth silicon wafers. However, ants can move at speeds approaching 40 body lengths/second on surfaces from picnic tables to front lawns. What challenges do we still need to tackle for millirobots to achieve this incredible mobility? This chapter presents some of the mechanisms that have been designed and fabricated to enable robot mobility at the insect size scale. These mechanisms utilize new microfabrication processes to incorporate materials with widely varying moduli and functionality for more complexity in smaller packages. Results include a 4 mm jumping mechanism that can be launched over 30 cm straight up, an actuated jumping mechanism used as a catapult, and preliminary leg designs for a walking/running millirobot.","Adaptive splitting and selection method for noninvasive recognition of liver fibrosis stageTherapy of patients suffer form liver diseases strongly depends on the liver fibrosis progression. Unfortunately, to asses it the liver biopsy has been usually used which is an invasive and raging medical procedure which could lead to serious health complications. Additionally even when experienced medical experts perform liver biopsy and read the findings, up to a 20% error rate in liver fibrosis staging has been reported. Nowadays a few noninvasive commercial tests based on the blood examinations are available for the mentioned above problem. Unfortunately they are quite expensive and usually they are not refundable by the health insurance in Poland. Thus, the cross-disciplinary team, which includes researches form the Polish medical and technical universities has started work on new noninvasive method of liver fibrosis stage classification. This paper presents a starting point of the project where several traditional classification methods are compared with the originally developed classifier ensembles based on local specialization of the classifiers in given feature space partitions. The experiment was carried out on the basis of originally acquired database about patients with the different stages of liver fibrosis. The preliminary results are very promising, because they confirmed the possibility of outperforming the noninvasive commercial tests.","Modelling and Experimental Validation of an Optical Fiber for Solar Devices ","Parameterized Verification of Broadcast Networks of Register AutomataWe study parameterized verification problems for networks of interacting register automata. We consider safety properties expressed in terms of reachability, from arbitrarily large initial configurations, of a configuration exposing some given control states and patterns. We introduce a formal model of data-sensitive distributed protocols, called Broad- cast Networks of Register Automata (BNRA), aimed at modelling both the local knowledge of distributed nodes as well as their interaction via broadcast communi- cation. A network is modelled via a finite graph where each node runs an instance of a common protocol. A protocol is specified via a register automaton, an automa- ton equipped with a finite set of registers (20). Each register assumes values taken from the set of natural numbers. Node interaction is specified via broadcast com- munication, well-suited to model scenarios in which individual nodes have par- tial information about the network topology. Messages are allowed to carry data, that can be assigned to or tested against the local registers of receivers. Dynamic updates of the current configuration are modelled via non-deterministic recon- figurations of the underlying connectivity graph. A node may disconnect from its neighbours and connect to other ones at any time of the execution. This behaviour models in a natural way unexpected power-off and dynamic movement of devices. The resulting model can be used to reason about core parts of client-server pro- tocols as well as of routing protocols, e.g. route maintainance as in Link Reversal Routing. In the paper we focus our attention on the decidability and complexity of parameterized verificatiom, i.e., the problem of finding a sufficient number of nodes and an initial topology that may lead to a configuration exposing a bad pattern (e.g. a loop in the information contained in the routing tables). The con- sidered class of verification problems is parametric in four dimensions, namely, the number of nodes, the topology of the initial configuration to be discovered, and the amount of data contained in local registers and exchanged messages. Related Works. Our formal model of topology-sensitive broadcast communica- tion with data naturally extends those obtained in (11,12,10). Formal models of broadcast networks date back to CBS (22), extended in several ways (time,","Non-rigid 2D-3D Medical Image Registration Using Markov Random Fields ","Architecture for Medical Image Processing ","A Pairing Based Authentication and Key Establishment Scheme for Remote Patient Monitoring Systems ","Estimating Time Complexity of Rumor Spreading in Ad-Hoc Networks ","Securing legacy firefox extensions with SENTINELA poorly designed web browser extension with a security vulnerability may expose the whole system to an attacker. Therefore, attacks directed at \"benign-but-buggy\" extensions, as well as extensions that have been written with malicious intents pose significant security threats to a system running such components. Recent studies have indeed shown that many Firefox extensions are over-privileged, making them attractive attack targets. Unfortunately, users currently do not have many options when it comes to protecting themselves from extensions that may potentially be malicious. Once installed and executed, the extension needs to be trusted. This paper introduces Sentinel, a policy enforcer for the Firefox browser that gives fine-grained control to the user over the actions of existing JavaScript Firefox extensions. The user is able to define policies (or use predefined ones) and block common attacks such as data exfiltration, remote code execution, saved password theft, and preference modification. Our evaluation of Sentinel shows that our prototype implementation can effectively prevent concrete, real-world Firefox extension attacks without a detrimental impact on users' browsing experience.","An Adequate Representation of Medical Data Based on Partial Set Approximation ","Extraction of Statements in News for a Media Response AnalysisThe extraction of statements is an essential step in a Me- dia Response Analysis (MRA), because statements in news represent the most important information for a customer of a MRA and can be used as the underlying data for Opinion Mining in newspaper articles. We propose a machine learning approach to tackle this problem. For each sentence, our method extracts different features which indicate the importance of a sentence for a MRA. Classified sentences are filtered through a density-based clustering, before selected sentences are com- bined to statements. In our evaluation, this technique achieved better results than comparison methods from Text Summarization and Opin- ion Mining on two real world datasets.","On the Meaning Representation of Fuzzy WordsThe basic characteristic of fuzzy language is the meaning uncertainty and fuzziness of the language units, such as words and sentences, and how to represent such fuzzy meaning formally is a problem that is worth studying. This paper attempts to analyze and explore the formal meaning representation of Chinese fuzzy words. The fuzzy language reflects the ambiguity of human thinking and understanding, which is objective and inevitable. Marx once said: A thing is itself and changing continuously, which has a contradiction of invariability and variability (1). Therefore, all materials in the world are in the unceasing and absolute movement, while stillness is a certain period of development and is relatively temporary. So, people mostly take the continuous movement as a background when they distinguish the properties of things and use a limited discrete model to characterize a continuous process of infinite development (2). This will inevitably lead to ambiguity in people's understanding of the properties of things, which has reflection in fuzzy language, such as fuzzy words and sentences. This paper mainly discusses the fuzzy words in Chinese. Currently, semantic problem is the bottleneck of language information processing. The fundamental precondition of solving this problem is a symbolic and formal representation of the meaning of various elements in language systems. So that the computer can more accurately understand and process natural languages. The fundamental property of the fuzzy language is the semantic ambiguity. This paper attempts to explore a formal meaning representation of fuzzy words.","Fast and Scalable, Lock-Free k-FIFO QueuesWe introduce fast and scalable algorithms that implement bounded- and unbounded-size lock-free k-FIFO queues on parallel, shared memory hardware. Logically, a k-FIFO queue can be understood as queue where elements may be dequeued out-of-order up to k-1, or as pool where the oldest element is dequeued within at most k dequeue operations. The presented algorithms enable up to k enqueue and k dequeue operations to be performed in parallel. Unlike previous designs, however, the algorithms also implement linearizable emptiness and full checks without impairing scalability. We show experimentally that there exist optimal and robust k that result in best access performance and scalability. We then demonstrate that our algorithms outperform and outscale all state-of-the-art concurrent pool and queue algorithms that we considered in all micro- and most macrobenchmarks. Moreover, we demonstrate a prototypical controller which identifies optimal k automatically at runtime achieving better performance than with any statically configuredi\u00be?k.","Improved Arabic-French Machine Translation through Preprocessing Schemes and Language Analysis ","Technical Section: A Lagrangian framework for simulating granular material with high detailWe present an efficient Lagrangian framework for simulating granular material with high visual detail. Our model solves the computationally and numerically critical forces on a coarsely sampled particle simulation. Pressure and friction forces are expressed as constraint forces which are iteratively computed. We realize stable and realistic interactions with rigid bodies by employing pressure and friction-based boundary forces. Stable formations of sand piles are realized by employing the concept of rigid-body sleeping. Furthermore, material transitions from dry to wet can be modeled. Visual realism is achieved by coupling a set of highly resolved particles with the base simulation at low computational costs. Thereby, detail is added which is not resolved by the base simulation. The practicability of the approach is demonstrated by showing various high-resolution simulations with up to 20 million particles.","Automated Tongue Segmentation Based on 2D Gabor Filters and Fast MarchingIn this paper, we propose a novel automated tongue segmentation scheme which can well address the edge enhancement and the initialization problem of the tongue body contour. First, according to the grey level distribution of the contour, we propose a 2D Gabor magnitude - based detector for the enhancement of the contour of tongue body. Second, to cope with the discontinuity of edge detection results, we select two stable segments of the tongue body contours and use the fast marching method to obtain the closed tongue body contour. Moreover, gradient vector flow (GVF) snake is used to obtain the final segmentation result and an augmented Lagrangian method is adopted for fast computation of GVF field. Qualitative and quantitative comparisons further verify the superiority of the proposed method for the segmentation of tongue body.","Identifying Factors of an Information Security Management System of Local Self-government BodiesThis article presents synthetically expressed results of studies on in- formation security management system in Polish local self-government bodies. Standardized surveys, internal network scans and penetration tests of web por- tals were carried out in five institutions. These were municipal offices and local budgetary companies. Research surveys were conducted among all employees of the aforementioned organizations. The research allowed identifying key factors and proposing methods to solve the most common problems faced by local self-government bodies. Moreover, the paper presents a model of a system supporting information security man- agement developed based on the identified factors.","Guarded Variable Automata over Infinite AlphabetsWe define guarded variable automata (GVAs), a simple extension of finite automata over infinite alphabets. In this model the transitions are labelled by letters or variables ranging over an infinite alphabet and guarded by conjunction of equalities and disequalities. GVAs are well-suited for modeling component-based applications such as web services. They are closed under intersection, union, concatenation and Kleene operator, and their nonemptiness problem is PSPACE-complete. We show that the simulation preorder of GVAs is decidable. Our proof relies on the characterization of the simulation by means of games and strategies. This result can be applied to service composition synthesis.","Compiler Optimizations Do Impact the Reliability of Control-Flow Radiation Hardened Embedded Software ","Thomas Jansen: Analyzing Evolutionary Algorithms: The Computer Science Perspective: Springer, 2013, 255 pp, ISBN: 978-3-642-17338-7 ","LOG FILE ANALYSIS WITH CONTEXT-FREE GRAMMARSClassical intrusion analysis of network log files uses statistical machine learning or regular expressions. Where statistically machine learning methods are not analytically exact, methods based on regular expres- sions do not reach up very far in Chomsky's hierarchy of languages. This paper focuses on parsing traces of network traffic using context- free grammars. \"Green grammars\" are used to describe acceptable log files while \"red grammars\" are used to represent known intrusion pat- terns. This technique can complement or augment existing approaches by providing additional precision. Analytically, the technique is also more powerful than existing techniques that use regular expressions.","Automatic Annotation of Medical Records in Spanish with Disease, Drug and Substance NamesThis paper presents an annotation tool that detects entities in the biomedical domain. By enriching the lexica of the Freeling analyzer with bio-medical terms extracted from dictionaries and ontologies as SNOMED CT, the system is able to automatically detect medical terms in texts. An evaluation has been performed against a manually tagged corpus focusing on entities referring to pharmaceutical drug-names, sub- stances and diseases. The obtained results show that a good annotation tool would help to leverage subsequent processes as data mining or pat- tern recognition tasks in the biomedical domain.","Training efficient tree-based models for document rankingGradient-boosted regression trees (GBRTs) have proven to be an effective solution to the learning-to-rank problem. This work proposes and evaluates techniques for training GBRTs that have efficient runtime characteristics. Our approach is based on the simple idea that compact, shallow, and balanced trees yield faster predictions: thus, it makes sense to incorporate some notion of execution cost during training to \"encourage\" trees with these topological characteristics. We propose two strategies for accomplishing this: the first, by directly modifying the node splitting criterion during tree induction, and the second, by stagewise tree pruning. Experiments on a standard learning-to-rank dataset show that the pruning approach is superior; one balanced setting yields an approximately 40% decrease in prediction latency with minimal reduction in output quality as measured by NDCG.","Towards Improving Reliability of Computational RFID Based Smart Healthcare Monitoring Systems ","Youtube User and Usage Profiling: Stories of Political Horror and Security Success ","Improving Model Checking Stateful Timed CSP with non-Zenoness through Clock-Symmetry Reduction ","Influence of monetary and non-monetary incentives on students' behavior in blended learning settings in higher educationPrevious research shows that blended learning has the ability to increase the learners' motivation and learning success. However, motivational aspects in blended learning have not been sufficiently researched yet. We therefore investigated the influence of non-monetary and monetary incentives on learners' behavior. We selected \"likes\" as a non-monetary incentive and enabled students to rate other students' posts (similar to Facebook). In a second turn, a monetary incentive (a tablet PC or the cash equivalent, respectively) was raffled among the students of a top 10 \"like\"-ranking. Based on log-file data and survey results, we observe that both variations ((1) only \"likes\" and (2) \"likes\" &amp; tablet PC prize) do not differ with respect of their influence on the overall activity of learners during the lecture. Thus, the additional monetary incentive did not increase activity. We conclude that monetary incentives do not seem to be efficient.","An overview of state of the art and research in the fields of sensible, latent and thermo-chemical thermal energy storageDue to the increase in volatile renewable power and heat generation (wind or solar), thermal energy storage (TES) has obtained growing importance and interest. The technology can be distinguished into three main types: sensible, latent and thermochemical storage. Apart from low and medium temperature heat applications, high temperature TES also is an attractive means to store power in the form of heat (before the thermodynamic transformation process). Thermochemical storage allows for long duration seasonal storage of energy.","Automatic Detection of the Prosodic Structures of Speech UtterancesThis paper presents an automatic approach for the detection of the prosodic structures of speech utterances. The algorithm relies on a hierarchical representation of the prosodic organization of the speech utterances. The approach is applied on a corpus of radio French broadcast news and also on radio and TV shows which are more spontaneous speech data. The algorithm detects prosodic boundaries whether they are followed or not by pause. The detection of the prosodic boundaries and of the prosodic structures is based on an approach that integrates little linguistic knowledge and mainly uses the amplitude of the F0 slopes and the inversion of the slopes as described in [1], as well as phone durations. The automatic prosodic segmentation results are then compared to a manual prosodic segmentation made by an expert phonetician. Finally, the results obtained by this automatic approach provide an insight into the most frequently used prosodic structures in the broadcasting speech style as well as in a more spontaneous speech style.","A Novel Approach for Adaptive EEG Artefact Rejection and EOG Gaze Estimation ","Data refinement in Isabelle/HOLThe paper shows how the code generator of Isabelle/HOL supports data refinement, i.e., providing efficient code for operations on abstract types, e.g., sets or numbers. This allows all tools that employ code generation, e.g., Quickcheck or proof by evaluation, to compute with these abstract types. At the core is an extension of the code generator to deal with data type invariants. In order to automate the process of setting up specific data refinements, two packages for transferring definitions and theorems between types are exploited.","Business process mining success ","Prefix Table Construction and ConversionThe prefix table of a string x\u2009=\u2009x[1..n] is an array \u03c0\u2009=\u2009\u03c0[1..n] such that \u03c0[i] is the length of the longest substring beginning at i that equals a prefix of x. In this paper we describe and evaluate algorithms for prefix table construction, some previously proposed, others designed by us. We also describe and evaluate new linear-time algorithms for transformations between \u03c0 and the border array.","Reinforcement Learning Based Model Selection and Parameter Estimation for Pharmacokinetic Analysis in Drug Selection ","Making Sense of Paraconsistent Logic: The Nature of Logic, Classical Logic and Paraconsistent Logic ","Impact of Varying Vocabularies on Controlling Motion of a Virtual Actor ","Model-Based implementation of parallel real-time systemsOne of the main challenges in the design of real-time systems is how to derive correct and efficient implementations from platform-independent specifications.#R##N##R##N#We present a general implementation method in which the application is represented by an abstract model consisting of a set of interacting components. The abstract model executes sequentially components interactions atomically and instantaneously. We transform abstract models into physical models representing their execution on a platform. Physical models take into account execution times of interactions and allow their parallel execution. They are obtained by breaking atomicity of interactions using a notion of partial state. We provide safety conditions guaranteeing that the semantics of abstract models is preserved by physical models. These provide bases for implementing a parallel execution engine coordinating the execution of the components. The implementation has been validated on a real robotic application. Benchmarks show net improvement of its performance compared to a sequential implementation.","First-Order Theorem Proving and VampireIn this paper we give a short introduction in first-order theorem proving and the use of the theorem prover Vampire. We discuss the superposition calculus and explain the key concepts of saturation and redundancy elimination, present saturation algorithms and preprocessing, and demonstrate how these concepts are implemented in Vampire. Further, we also cover more recent topics and features of Vampire designed for advanced applications, including satisfiability checking, theory reasoning, interpolation, consequence elimination, and program analysis.","Exploring the need for, and feasibility of, a web-based self-management resource for teenage and young adult cancer survivors in the UKThe growth in social networking sites and online forums make the internet a potential platform to be considered for the provision of self-management and e-learning support to young people following cancer treatment. However, the feasibility and potential barriers to this as a post treatment option should be considered. A mixed methods approach was adopted that included an online survey, focus groups and interviews with cancer survivors, their parents, and information technology, clinical and social work professionals to consider the potential of a web-based self-management resource. Barriers were identified to the delivery of care using this method. Developing such a self-management system requires close working between IT and clinical staff, alongside patient representation and usability expertise. As computer access and use amongst this group is commonplace, there is an expectation that self-management needs will be met at least partially in this way in the future.","A MapReduce-Based Method for Learning Bayesian Network from Massive DataBayesian network (BN) is the popular and important probabilistic graphical model for representing and inferring uncertain knowledge. Learning BN from massive data is the basis for uncertain-knowledge-centered inferences, prediction and decision. The inherence of massive data makes BN learning be adjusted to the large data volume and executed in parallel. In this paper, we proposed a MapReduce-based approach for learning BN from massive data by extending the traditional scoring &amp; search algorithm. First, in the scoring process, we developed map and reduce algorithms for obtaining the required parameters in parallel. Second, in the search process, for each node we devel- oped map and reduce algorithms for scoring all the candidate local structures in parallel and selecting the local optimal structure with the highest score. Thus, the local optimal structures of each node are merged to the global optimal one. Experimental result indicates our proposed method is effective and efficient.","How to prevent reinventing the wheel?: design principles for project knowledge management systemsToday, many companies still struggle in documenting and reusing the knowledge gained by project teams. However, knowledge only creates value if it is applied. There exists a vast amount of research in the field of knowledge management focusing on documentation, storage and exchange of knowledge, but knowledge reuse is often omitted by researchers. The presented work aims to close this gap by developing a project knowledge management system enabling project teams to apply company-internal knowledge. We followed an action design research approach to explore meta-requirements in a case company, translate these requirements into design principles and test the design principles by evaluating an artifact of a project knowledge management system. By our work, the knowledge management research field can benefit since our design theory extends the existing body of knowledge. Furthermore, our research results are instantiated in a concrete artifact which can be directly transferred into practice.","Proficiency of Fuzzy Logic Controller for Stabilization of Rotary Inverted Pendulum based on LQR Mapping ","Hash chains to secure proactive protocolsSeveral secure extensions have been proposed to deal with the OLSR proactive routing protocol security, but they often involve a very high resource consumption that degrades network performances. The protocol ADVSIG is one of these extensions. It presents an efficient security approach, but generates very high computational costs due to the cryptographic operations it performs on the control messages. In this paper, we present a secure mechanism for OLSR, based on ADVSIG protocol, that we call ADVHCA. Its purpose is to improve ADVSIG performances using hash chains to reduce the cost of securing HELLO control messages. A watching mechanism is also proposed to counter the wormhole attack. The whole solution is simulated and analyzed using NS2.","Dynamic information flow analysis for javascript in a web browserJavaScript has become a central technology of the web, but it is also the source of many security problems, including cross-site scripting attacks and malicious advertising code. Central to these problems is the fact that code from untrusted sources runs with the same privileges as trusted code in the same frame. #R##N#While much work has been done to secure JavaScript in a somewhat piecemeal approach, information flow analysis presents a compelling option for providing a more systemic solution to the problem. By tracking the flow of sensitive information in the browser, we can prevent it from leaking out to untrusted sources. Formally, information flow analysis can provide non-interference, the guarantee that public outputs do not depend on private inputs. #R##N#Previous information flow techniques have primarily relied on static type systems. While effective, they are an awkward fit for dynamically typed JavaScript code. This dissertation explores three different runtime enforcement mechanisms that can guarantee non-interference dynamically. #R##N#The no-sensitive-upgrade check forbids updating public reference cells in a private context through the use of a runtime monitor. This approach can be done with minimal performance overhead by using a sparse-labeling strategy, which leaves security labels on data implicit whenever possible. Experimental results demonstrate the efficiency of this approach. #R##N#While the no-sensitive-upgrade check is effective, it sometimes rejects valid program executions that do not violate the security property. The permissive upgrade strategy is a refinement of this approach that still guarantees non-interference, but which accepts strictly more executions. When a public reference cell is updated in a private context, the permissive upgrade strategy marks the data as partially leaked rather than terminating execution. Partially leaked data is carefully tracked to avoid leaking private information. #R##N#The final approach introduces special faceted values, which capture multiple views for a single object. Faceted values simulate multiple executions for different security levels, giving the following benefits: (1) Faceted values do not rely on the stuck executions of the no-sensitive-upgrade and permissive upgrade approaches, and therefore accept strictly more programs than either of the monitor-based approaches. (2) Faceted values avoid redundant computations, improving efficiency over related approaches. #R##N#Finally we implement faceted values in Firefox and show how they may be used to prevent a variety of attacks.","Psychological assessment instruments: a coverage analysis using SNOMED CT, LOINC and QS terminology.Psychometric instruments, inventories, surveys, and questionnaires are widely accepted tools in the field of behavioral health. They are used extensively in primary and clinical research, patient care, quality measurement, and payor oversight. To accurately capture and communicate instrument-related activities and results in electronic systems, existing healthcare standards must be capable of representing the full range of psychometric instruments used in research and clinical care. Several terminologies and controlled vocabularies contain representations of psychological instruments. While a handful of studies have assessed the representational adequacy of terminologies in this domain, no study to date has assessed content coverage. The current study was designed to fill this gap. Using a sample of 63 commonly used instruments, we found no concept in any of the three terminologies evaluated for more than half of all instruments. Of the three terminologies studied, SNOMED CT (Standard Nomenclature of Medicine \u2013 Clinical Terms) had the greatest breadth, but least granular coverage of all systems. While SNOMED CT contained concepts for over one third (36%) of the instrument classes in this sample, only 11% of the actual instruments were represented in SNOMED CT. LOINC (Logical Observation Identifiers, Names, and Codes), on the other hand, was able to represent instruments with the greatest level of granularity of the three terminologies. However, LOINC had the poorest coverage, covering fewer than 8% of the instruments in our sample. Given that instruments selected for this study were selected on the basis of their status as gold standard measures for conditions most likely to present in clinical settings, we believe these results overestimate the actual coverage provided by these terminologies. The results of this study demonstrate significant gaps in existing healthcare terminologies vis-a-vis psychological instruments and instrument-related procedures. Based on these findings, we recommend that systematic efforts be made to enhance standard healthcare terminologies to provide better coverage of this domain.","Summarizing and Detecting Structural Drifts from Multiple Data Streams ","Multi-Agent Systems Meet GPU: Deploying Agent-Based Architectures on Graphics ProcessorsEven given today\u2019s rich hardware platforms, computation-intensive algorithms and applications, such as large-scale simulations, are still challenging to run with acceptable response times. One way to increase the performance of these algorithms and applications is by using the computing power of Graphics Processing Units (GPU). However, effectively mapping distributed software models to GPU is a non-trivial endeavor. In this paper, we investigate ways of improving execution performance of multi-agent systems (MAS) models by means of relevant task allocation mechanisms, which are suitable for GPU execution. Several task allocation architecture variants for MAS using GPU are identified and their properties analyzed. In particular, we study three cases: Agents and their runtime environment can be (i) completely on the host (CPU); (ii) partly on host and device (GPU); (iii) completely on the device. For each of these architecture variants, we propose task allocation models that take GPU restrictions into account.","Exploiting click logs for adaptive intranet navigationWeb sites and intranets can be difficult to navigate as they tend to be rather static and a new user might have no idea what documents are most relevant to his or her need. Our aim is to capture the navigational behaviour of existing users (as recorded in the click logs) so that we can assist future users by proposing the most relevant pages as they navigate the site without changing the actual Web site and do this adaptively so that a continuous learning cycle is being employed. In this paper we explore three different algorithms that can be employed to learn such suggestions from navigation logs. We find that users managed to conduct the tasks significantly quicker than the (purely frequency-based) baseline by employing ant colony optimisation or random walk approaches to the log data for building a suggestion model.","Link analysis for representing and retrieving legal informationLegal texts consist of a great variety of texts, for example laws, rules, statutes, etc. This kind of documents has as an important feature, that they are strongly linked among them, since they include references from one part to another. This makes it difficult to consult them, because in order to satisfy an information request, it is necessary to gather several references and rulings from a single text, and even with other texts. The goal of this work is to help in the process of consulting legal rulings through their retrieval from a request expressed as a question in natural language. For this, a formal model is proposed; this model is based on a weighted, non-directed graph; nodes represent the articles that integrate each document, and its edges represent references between articles and their degree of similarity. Given a question, this is added to the graph, and by combining a shortest-path algorithm with edge weight analysis, a ranked list of articles is obtained. To evaluate the performance of the proposed model we gathered 8,987 rulings and evaluated the answer to 40 test-questions as correct, incorrect or partial. A lawyer validated the answer to these questions. We compared results with other systems such as Lucene and JIRS (Java Information Retrieval System)","A Design Science Approach to Interactive Greenhouse Climate Control Using Lego Mindstorms for Sensor-Intensive PrototypingIn this paper we present a case study of early prototyping work performed within a Danish advanced technology project. We specifically investigate the problems and issues related to throw-away prototypes in sensor-intensive systems. An important criterion is to record and perhaps later reproduce the identified contributions of the throw-away prototypes, and to this end we use the educational version of Lego Mindstorms NXT. To achieve methodological rigor we have used the Design Science Framework by Hevner et. al. It allows us to focus on the prototyping effort (called the design cycle) without letting go of either the relevance or rigor related to the project. We relate the case study to a Human Work Interaction Design (HWID) framework for the use of interactive, sensor-intensive prototypes to develop interactive greenhouse climate management systems. By applying guidelines suggested in design science to the case studied, we identify a number of interactive prototypes that successively address core issues in this particular setting. Finally, the problems and issues pertaining to this setting is presented and identified. The main contribution of this paper is that it, by pointing out problems and issues related throw-away prototyping with sensor-intensive systems, extends the design cycle of the original design science framework. This is determined to be a necessary step in order to address the inherent multi-disciplinarily of sensor-intensive HWID systems.","Specific Behaviour of GPA-ES Evolutionary System Observed in Deterministic Chaos Regression ","ShareDay: A Novel Lifelog Management System for Group SharingLifelogging is the automatic capture of daily activities using environmental and wearable sensors such as MobilePhone/SenseCam. The potential to capture such a large data collection presents many chal- lenges, including data analysis, visualisation and motivating users of dif- ferent ages and technology experience to lifelog. In this paper, we present a new generation of lifelog system to support reminiscence through in- corporating event segmentation and group sharing.","A Biomedical Information System for Retrieval and Manipulation of NHANES DataThe retrieval and manipulation of data from large public databases like the U.S. National Health and Nutrition Examination Survey (NHANES) may require sophisticated statistical software and significant expertise that may be unavailable in the university setting. In response, we have developed the Data Retrieval And Manipulation System (DReAMS), an automated information system to handle all processes of data extraction and cleaning and then joining different subsets to produce analysis-ready output. The system is a browser-based data warehouse application in which the input data from flat files or operational systems are aggregated in a structured way so that the desired data can be read, re-coded, queried and extracted efficiently. The current pilot implementation of the system provides access to a limited amount of NHANES database. We plan to increase the amount of data available through the system in the near future and to extend the techniques to other large databases from CDU archive with a current holding of about 53 databases.","Refining Rules Learning Using Evolutionary PDUsing glyphs to associate digital media with physical materials has great potential to enhance learning. A key challenge, however, lies in enabling children to author their own glyphs that integrate well with their drawings. One possible solution lies in the d-touch system which uses a topological approach to structuring glyphs. Through a series of Participatory Design studies, we have explored how children can be supported in creating their own d-touch glyphs. Main highlights from our findings indicate that it is difficult for children to create glyphs following only written rules. A structured diagrammatic approach is then introduced in which colour-coded hierarchy diagrams support a mapping between their drawings and the underlying rules. We found this has significant- ly improved their drawing attempts. The paper then concludes with a potential to integrate the approach into more sophisticated learning experience.","Fast ASA Modeling and Texturing Using Subgraph Isomorphism Detection Algorithm of Relational ModelIn this paper, a new method based on Subgraph Isomorphism Detection (SID) algorithm was proposed to automatically construct Anhui-Styled Architecture(ASA) models. Firstly, by analyses intrinsic features of ASA, we setup architecture module database. Then use SID algorithm to get a topology graph and traverse each node of the topology graph. Finally, render these graph nodes to get 3D model of ASA.","Towards Interoperable BioNLP Semantic Web Services Using the SADI Framework ","Logical Aspects of the Lexicographic Order on 1-Counter Languages ","On the Use of Parallel Programming Techniques for Real-Time Scheduling Water Pumping Problems ","A Service Delivery Framework to Support Opportunistic Collaborations ","Positive results for mechanism design without moneyConsider the problem of allocating multiple divisible goods to two agents in a strategy-proof fashion without the use of payments or priors. Previous work has aimed at implementing allocations that are competitive with respect to an appropriately defined measure of social welfare. These results have mostly been negative, proving that no dictatorial mechanism can achieve an approximation factor better than 0.5, and leaving open the question of whether there exists a non-dictatorial mechanism that outperforms this bound. We provide a positive answer to this question by presenting an interesting non-dictatorial mechanism that achieves an approximation factor of 2/3 for this measure of social welfare. In proving this bound we also touch on the issue of fairness: we show that the proportionally fair solution, a well known fairness concept for money-free settings, is highly competitive with respect to social welfare. We then show how to use the proportionally fair solution to design our non-dictatorial strategy-proof mechanism.","Energy Efficiency in W-Grid Data-Centric Sensor Networks via Workload Balancing ","Analysis of Optimization Techniques to Improve User Response Time of Web Applications and Their Implementation for MOODLEAnalysis of seven optimization techniques grouped under three categories (hardware, back-end, and front-end) is done to study the reduction in average user response time for Modular Object Oriented Dynamic Learning Environment (Moodle), a Learning Management System which is scripted in PHP5, runs on Apache web server and utilizes MySQL database software. Before the implementation of these techniques, performance analysis of Moodle is performed for varying number of concurrent users. The results obtained for each optimization technique are then reported in a tabular format. The maximum reduction in end user response time was achieved for hardware optimization which requires Moodle server and database to be installed on solid state disk.","The String-Meaning Relations Definable by Lambek Grammars and Context-Free GrammarsWe show that the class of string-meaning relations definable by the following two types of grammars coincides: (i) Lambek grammars where each lexical item is assigned a (suitably typed) lambda term as a representation of its meaning, and the meaning of a sentence is computed according to the lambda- term corresponding to its derivation; and (ii) cycle-free context-free grammars that do not generate the empty string where each rule is associated with a (suitably typed) lambda term that specifies how the meaning of a phrase is determined by the meanings of its immediate constituents.","Projection Onto The k-Cosparse Set is NP-HardWe investigate the computational complexity of a problem arising in the context of sparse optimization, namely, the projection onto the set of k-cosparse vectors w.r.t. some given matrix \u03a9. We show that this projection problem is (strongly) NP-hard, even in the special cases where the matrix \u03a9 contains only ternary or bipolar coefficients. Interestingly, this is in stark contrast to the projection onto the set of k-sparse vectors, which is trivially solved by keeping only the k largest coefficients.","Communication Setup in Anonymous MessagingIn anonymous group messaging any group member may wish to send a message anonymously to the other members, and all members follow a defined protocol. Not all members can be trusted, meaning that some may disclose relevant information to an adversary, and our adver- sary could have complete access to network communications. We will discuss here the protocol setup and start-up phase in anony- mous messaging: this phase is highly critical and can actually compro- mise the anonymity of subsequent communication the very goal we wanted to achieve. The start-up phase actually represents a secondary communication channel, where relevant information is released, that can be caught by an adversary. Two cases will be discussed: onion routing (section 1) and token pass- ing (section 2). The first case dates back to Mix-nets (1), and has being addressed in substantial later research (13-15). Here we will specifically refer to the newest real-world Internet implementation of Tor, as described in (2). In Tor, we have a free topology, where the actual path of messages within the onion router (OR) network is chosen at the source. This path-setup phase can be seen as part of communications on a secondary channel, that can provide useful information to an adversary. The second case is based on new protocol, based on token passing over a fixed ring topology. The method can be related to some characteristics of DC-nets (6, 16, 17), and in particular to the Dissent (3) system. In the token passing system a start-up phase requires choosing the node that will first transmit relevant information, as well as guaranteeing that any node will be able to communicate (anti-starvation policy). The start- up phase, again, may contain secondary channels that will need special attention. The discussion is limited to 3 nodes, and the general n-node case is left for future work.","Parameter Optimization of Local-Concentration Model for Spam Detection by Using Fireworks Algorithm ","Parallel Partitioning and Mining Gene Expression Data with Butterfly NetworkIn the area of massive gene expression analysis, Order-Preserving Sub-Matrices have been employed to find biological associations between genes and experimental conditions from a large number of gene expression datasets. While many techniques have been developed, few of them are parallel, and they lack the capability to incorporate the large-scale datasets or are very time-consuming. To help fill this critical void, we propose a Butterfly Network based parallel partitioning and mining method BNPP, which formalizes the communication and data transfer among nodes. In the paper, we firstly give the details of OPSM and the implementations of OPSM on MapReduce and Hama BSP and their shortcomings. Then, we extend the Hama BSP framework using Butterfly Network to reduce the communication time, workload of bandwidth and duplicate results percent, and call the new framework as BNHB. Finally, we implement a state-of-the-art OPSM mining method OPSM and our BNPP method on top of the framework of naive Hama BSP and our BNHB, and the experimental results show that the computational speed of our methods are nearly one order faster than that of the implementation on a single machine and the proposed framework has better effectiveness and scalability.","Compila\u00e7\u00e3o Just-In-Time: Hist\u00f3rico, Arquitetura, Princ\u00edpios e SistemasDiversas implementacoes de linguagens de alto nivel focam no desenvolvimento de sistemas baseados em mecanismos de compilacao just-in-time. Esse mecanismo possui o atrativo de melhorar o desempenho de tais linguagens, mantendo a portabilidade. Contudo, ao preco da inclusao do tempo de compilacao ao tempo total de execucao. Diante disso, as pesquisas na area tem voltado balancear o custo de compilacao com eficiencia de execucao. Os primeiros sistemas de compilacao just-in-time empregavam estrategias estaticas para selecionar e otimizar as regioes de codigo propicias para gerar bom desempenho. Sistemas mais sofisticados aprimoraram tais estrategias com o objetivo de aplicar otimizacoes de forma mais criteriosa. Nesse sentido, este tutorial apresenta os principios que fundamentam a compilacao just-in-time e sua evolucao ao longo dos anos, bem como a abordagem utilizada por diversos sistemas para garantir o balanceamento de custo e eficiencia. Embora seja dificil definir a melhor abordagem, trabalhos recentes mostram que estrategias rigidas para deteccao e otimizacao de codigo, juntamente com recursos de paralelismo oferecidos pelas arquiteturas multi-core formarao a base dos futuros sistemas de compilacao just-in-time.","Incorporating Hierarchical Dirichlet Process into Tag Topic ModelThe Latent Dirichlet Allocation (LDA) is a parametric approach and the number of topics must be predefined. So it is natural to try to capture uncer- tainty regarding the number of topics. This paper proposes a Tag Hierarchical Dirichlet Process (THDP) that automatically infers the number of topics while also leveraging the tag information associated with each document. In this model, we assume that an author is clear in his mind that the content will con- tains which aspects and for each aspect he will choose a tag to describe it, and then we consider problems involving groups of tag, where each tag within a group is a draw from a mixture model and it is desirable to share topic between groups. In this setting it is natural to consider Hierarchical Dirichlet Process, Where the well-known clustering property of the Dirichlet process provides a nonparametric prior for the number of topic within each tag. Experimental re- sults on corpora demonstrate superior performance over the THDP model.","Preliminary implementation of context-aware attention system for humanoid robotsA context-aware attention system is fundamental for regulating the robot behaviour in a social interaction since it enables social robots to actively select the right environmental stimuli at the right time during a multiparty social interaction. This contribution presents a modular context-aware attention system which drives the robot gaze. It is composed by two modules: the scene analyzer module manages incoming data flow and provides a human-like understanding of the information coming from the surrounding environment; the attention module allows the robot to select the most important target in the perceived scene on the base of a computational model. After describing the motivation, we report the proposed system and the preliminary test.","Performance Management of IT in Public Administrations: A Literature Review on Driving Forces, Barriers and Influencing FactorsThe increased importance of IT in the public sector results in a greater need to establish IT performance management mechanisms. Public administrations need to control IT related investments by using performance management in order to assess and reduce IT costs. However, public sector organizations are only slowly adopting performance management of IT. So far, the driving forces, barriers and influencing factors regarding performance management of IT in the public sector have not been analyzed. The aim of this paper is to identify, analyze and discuss these driving forces, barriers and influencing factors by conducting a literature review and to show how performance management of IT can be designed in the public sector in order to improve its acceptance.","Automating theorem proving with SMTThe power and automation offered by modern satisfiability-modulo-theories (SMT) solvers is changing the landscape for mechanized formal theorem proving. For instance, the SMT-based program verifier Dafny supports a number of proof features traditionally found only in interactive proof assistants, like inductive, co-inductive, and declarative proofs. To show that proof tools rooted in SMT are growing up, this paper presents, using Dafny, a series of examples that illustrate how theorems are expressed and proved. Since the SMT solver takes care of many formal trivialities automatically, users can focus more of their time on the creative ingredients of proofs.","A Framework for Modeling, Computing and Presenting Time-Aware RecommendationsLately, recommendation systems have received significant at- tention. Most existing approaches though, recommend items of potential interest to users by completely ignoring the temporal aspects of rat- ings. In this paper, we argue that time-aware recommendations need to be pushed in the foreground. We introduce an extensive model for time-aware recommendations from two perspectives. From a fresh-based perspective, we propose using different aging schemes for decreasing the effect of historical ratings and increasing the influence of fresh and novel ratings. From a context-based perspective, we focus on providing dif- ferent suggestions under different temporal specifications. To facilitate user browsing, we propose an effective presentation layer for time-aware recommendations based on user preferences and summaries for the sug- gested items. Our experiments with real movies ratings show that time plays an important role in the recommendation process.","A Multi-dimensional Personalization Approach to Developing Adaptive Learning SystemsIn this study, a multi-dimensional personalization approach is pro- posed for developing adaptive learning systems by taking various personalized features into account, including learning styles and cognitive styles of student. In this innovative approach, learning materials were categorized into several types and associated as a learning content based on students' learning styles to provide personalized learning materials and presentation layouts. Furthermore, personalized user interfaces and navigation strategies were developed based on students' cognitive styles. To evaluate the performance of the proposed ap- proach, an experiment was conducted on the learning activity on the learning activity of the \"Computer Networks\" course of a college in Taiwan. The expe- rimental results showed that the students who learned with the system devel- oped with the proposed approach revealed significantly better learning achievements than the students who learn with conventional adaptive learning system, showing that the proposed is effective and promising.","Predicting Depression via Social MediaMajor depression constitutes a serious challenge in personal and public health. Tens of millions of people each year suffer from depression and only a fraction receives adequate treatment. We explore the potential to use social media to detect and diagnose major depressive disorder in individuals. We first employ crowdsourcing to compile a set of Twitter users who report being diagnosed with clinical depression, based on a standard psychometric instrument. Through their social media postings over a year preceding the onset of depression, we measure behavioral attributes relating to social engagement, emotion, language and linguistic styles, ego network, and mentions of antidepressant medications. We leverage these behavioral cues, to build a statistical classifier that provides estimates of the risk of depression, before the reported onset. We find that social media contains useful signals for characterizing the onset of depression in individuals, as measured through decrease in social activity, raised negative affect, highly clustered egonetworks, heightened relational and medicinal concerns, and greater expression of religious involvement. We believe our findings and methods may be useful in developing tools for identifying the onset of major depression, for use by healthcare agencies; or on behalf of individuals, enabling those suffering from depression to be more proactive about their mental health.","A Mobile Robotic Personal Nightstand with Integrated Perceptual ProcessesWe present an intelligent interactive nightstand mounted on a mobile robot, to aid the elderly in their homes using physical, tactile and visual percepts. We show the integration of three different sensing modalities for controlling the navigation of a robot mounted nightstand within the constrained environment of a general purpose living room housing a single aging individual in need of assistance and monitoring. A camera mounted on the ceiling of the room, gives a top-down view of the obstacles, the person and the nightstand. Pressure sensors mounted beneath the bed-stand of the individual provide physical perception of the person's state. A proximity IR sensor on the nightstand acts as a tactile interface along with a Wii Nunchuck (Nintendo) to control mundane operations on the nightstand. Intelligence from these three modalities are combined to enable path planning for the nightstand to approach the individual. With growing emphasis on assistive technology for the aging individuals who are increasingly electing to stay in their homes, we show how ubiquitous intelligence can be brought inside homes to help monitor and provide care to an individual. Our approach goes one step towards achieving pervasive intelligence by seamlessly integrating different sensors embedded in the fabric of the environment.","A Norm-Based Probabilistic Decision-Making Model for Autonomic Traffic NetworksWe propose a norm-based agent-oriented model of decision-making of semi-autonomous vehicles in urban traffic scenarios. Computational norms are used to represent the driving rules and conventions that influence the distributed decision-making process of the vehicles. As norms restrict the admissible be- haviour of the agents, we propose to represent them as constraints, and we ex- press the agents' individual and group decision-making in terms of distributed constraint optimization problems. The uncertain nature of the driving environ- ment is reflected in our model through probabilistic constraints - collective norm compliance is considered as a stochastic distributed constraint optimization prob- lem. In this paper, we introduce the basic conceptual and algorithmic ingredients of our model, including the norms provisioning and enforcement mechanisms (where electronic institutions are used), the norm semantics, as well as methods of the agents' cooperative decision-making. For motivation and illustration of our approach, we study a cooperative multi-lane highway driving scenario; we pro- pose a formal model, and illustrate our approach by a small example.","Range-free mobile node localization using static anchorIn this paper we have proposed a deterministic, range-free, distributed localization algorithm for mobile sensor nodes with static anchors. Mobile node calculates its approximate line of movement and corresponding position based on received beacons from two different anchors. The positional error can be further reduced by updating the approximate line of movement on receiving beacons from more anchors. We also have incorporated irregular radio propagation in our model. We have compared performance of our algorithm with existing localization algorithms. Simulation results show 80% improvement in performance of our proposed algorithm over the existing algorithms in terms of positional accuracy.","Optimal Design of a Haptic Device for a Particular Task in a Virtual Environment ","Shared Structure Learning for Multiple Tasks with Multiple ViewsReal-world problems usually exhibit dual-heterogeneity, i.e., every task in the problem has features from multiple views, and multiple tasks are related with each other through one or more shared views. To solve these multi-task problems with multiple views, we propose a shared structure learning framework, which can learn shared predictive structures on common views from multiple related tasks, and use the consistency among different views to improve the performance. An alternating optimization algorithm is derived to solve the proposed framework. Moreover, the computation load can be dealt with locally in each task during the optimization, through only sharing some statistics, which significantly reduces the time complexity and space complexity. Experimental studies on four real-world data sets demonstrate that our framework significantly outperforms the state-of-the-art baselines.","Undo/redo by trajectoryWe have developed a trajectory based undo/redo interface. Using the interface, a user traces actions' trajectories shown on a display. As a result, undo/redo manipulations are performed rapidly with selection of a target from a history. In this paper, we describe interaction techniques, implementation, and advanced usages of the interface.","Optimal Distance Bounds for the Mahalanobis DistanceThe Mahalanobis distance, or quadratic form distance, is a distance measure commonly used for feature-based similarity search in scenarios where features are correlated. For efficient query processing on such data effective distance-based spatial pruning techniques are required. In this work we investigate such pruning techniques by means of distance bounds of the Mahalanobis distance in the presence of rectangular spatial approximations. Specifically we discuss how to transform the problem of computing minimum and maximum distance approximations between two minimum bounding rectangles MBRs into a quadratic optimization problem. Furthermore, we show how the recently developed concept of spatial domination can be solved under the Mahalanobis distance by a quadratic programming approach.","Theorem Proving Graph Grammars: Strategies for Discharging Proof Obligations ","Proactive home furnishings: inspiring from interactive art for designing functional aesthetics in a spaceThis paper presents our vision of the futuristic product. Proactive Home Furnishings allows user to realize (useful) information embedded of physical objects and/or on the top of architectural surfaces. Proactive Home Furnishings also display as interactive art form through the used of interactive techniques and computer graphics in an augmented physical object. The goal of Proactive Home Furnishings is to create the combination between both the digital aesthetics and the functional information, as well as seamless with living environment in a soothing way. This paper describes five interactive artworks used biomimetic perspective to develop the interaction feature - MSOrgm, Lbskeletons, Portrait of Dandelion, Artificial Phototropism, River Space. We treat them as pioneers to investigate the ongoing relation between the user and the home furnishings in a future living.","Game Design for All: The Example of Hammer and PlanksLast years have seen a growing interest on the Serious Games topic - and in particular on Games for Health - from both scientific and industrial communities. However not only the effectiveness of this kind of games is not yet demonstrated but the distribution and adoption of these games from the normal public is still very low. In this paper we present a design strategy we adopted in on the occasion of the development of a game for hemiplegic rehabilitation named \"Hammer and Planks\". This game strategy allowed us to create a \"game for all\", as will be demonstrated by the example of the usage of the game on the occasion of a game event in the south of France.","Configurations and Path Planning of Convex Planar Polygonal Loops ","Blood Flow Modeling in a Synthetic Cylindrical Vessel for Validating Methods of Vessel Segmentation in MRA Images ","Semi-Automatic Semantic Video Annotation ToolVideo management systems require semantic annotation of video for indexing and retrieval tasks. Currently, it is not possible to extract all high-level semantic information automatically. Also, automatic content based retrieval sys- tems use high-level semantic annotations as ground truth data. We present a semi- automatic semantic video annotation tool that assists user to generate annota- tions to describe video in fine detail. Annotation process is partly automated to reduce annotation time. Generated annotations are in MPEG-7 metadata format for interoperability.","Rough Pragmatic Description LogicIn this chapter, a rough description logic is built on the basis of a pragmatic standpoint of representation of knowledge. The pragmatic standpoint has influenced the acceptance of a broader definition of the semantic network than that appearing in the literature. The definition of the semantic network is a motiva- tion of the introduced semantics of the language of the descriptive logic. First, the theoretical framework of representation of knowledge that was proposed in the pa- pers (24, 25) is adjusted to the description of data processing. The pragmatic sys- tem of knowledge representation is determined, as well as situations of semantic adequacy and semantic inadequacy for represented knowledge are defined. Then, it is shown that general information systems (generalized information systems in Pawlak's sense) presented in the paper (5) can be interpreted in pragmatic systems of knowledge representation. Rough sets in the set-theoretical framework proposed in papers (7,8) are defined for the general information systems. The pragmatic stand- point about objects is also a motivation to determine a model of semantic network. This model is considered as a general information system. It determines a formal language of the descriptive logic. The set-theoretical framework of rough sets, which was introduced for general information systems, makes it possible to describe the interpretation of this language in the theory of rough sets. Therefore this interpreta- tion includes situations of semantic inadequacy. At the same time, for the class of all interpretations of this type, there exists a certain descriptive logic, which \u2014 in this chapter \u2014 is called rough pragmatic description logic.","A New Concept of Sets to Handle Similarity in Databases: The SimSetsTraditional DBMS are heavily dependent on the concept that a set never includes the same element twice. On the other hand, modern applications require dealing with complex data, such as images, videos and genetic sequences, in which exact match of two elements seldom occurs and, generally, is meaningless. Thus, it makes sense that sets of complex data should not include two elements that are \"too similar\". How to create a concept equivalent to \"sets\" for complex data? And how to design novel algorithms that allow it to be naturally embedded in existing DBMS? These are the issues that we tackle in this paper, through the concept of \"similarity sets\", or SimSets for short. Several scenarios may benefit from our SimSets. A typical example appears in sensor networks, in which SimSets can identify sensors recurrently reporting similar measurements, aimed at turning some of them off for energy saving. Specifically, our main contributions are: i highlighting the central properties of SimSets; ii proposing the basic algorithms required to create them from metric datasets, which were carefully designed to be naturally embedded into existing DBMS, and; iii evaluating their use on real world applications to show that our SimSets can improve the data storage and retrieval, besides the analysis processes. We report experiments on real data from networks of sensors existing within meteorological stations, providing a better conceptual underpinning for similarity search operations.","Fairtrace: Applying Semantic Web Tools and Techniques to the Textile Traceability ","3D Structure Estimation from a Single View Using Generic Fitted Primitives (GFP) ","Using the Smart Card Web Server in Secure Branchless Banking ","SA-MAS: self-adaptation to enhance software qualities in multi-agent systemsEngineering multi-agent systems (MAS) is known to be a complex task. One of the reasons lays in the complexity to combine multiple concerns that a MAS has to address, such as system functionality, coordination, robustness, etc. A well-recognized approach to manage system complexity is the use of self-adaptation (SA). Self-adaptation extends a system with support to monitor and adapt itself to realize a concern of interest (optimization, fault-tolerance, etc.). The key idea behind self-adaptation is complexity management through separation of concerns. In this paper, we present SA-MAS, an architectural approach that integrates MAS with SA. We present a reference model for SA-MAS and illustrate it with an excerpt of our ongoing research.","Domestic load scheduling using genetic algorithmsAn approach using a genetic algorithm to optimize the scheduling of domestic electric loads, according to technical and user-defined constraints and input signals, is presented and illustrative results are shown. The aim is minimizing the end-user's electricity bill according to his/her preferences, while accounting for the quality of the energy services provided. The constraints include the contracted power level, end-users' preferences concerning the admissible and/or preferable time periods for operation of each load, and the amount of available usable power in each period of time to account for variations in the (non-manageable) base load. The load scheduling is done for the next 36 hours assuming that a dynamic pricing structure is known in advance. The results obtained present a noticeable decrease of the electricity bill when compared to a reference case in which there is no automated scheduling.","Integrating programming by example and natural language programmingWe motivate the integration of programming by example and natural language programming by developing a system for specifying programs for simple text editing operations based on regular expressions. The programs are described with unconstrained natural language instructions, and providing one or more examples of input/output. We show that natural language allows the system to deduce the correct program much more often and much faster than is possible with the input/output example(s) alone, showing that natural language programming and programming by example can be combined in a way that overcomes the ambiguities that both methods suffer from individually and, at the same time, provides a more natural interface to the user.","Image Secret Sharing in Stego-Images with AuthenticationRecently, a polynomial-based (t,n) image sharing and hiding schemes with authentication was proposed to hid n shares of a secret image into n ordinary cover images and form n stego-images that can be transmitted securely. But each stego-image of all existing method should be expanded to 4 times of the secret image. In this paper we propose an enhanced scheme, where the size of the stego-image is reduced to \u0b38\u123a\u0b36\u0be1\u0b3f\u0be7\u123b \u0be1 \u0c2e times of the secret image. In addition our proposed scheme provides better authentication using hash function.","A Spatio-temporal Probabilistic Model of Hazard and Crowd Dynamics in Disasters for Evacuation PlanningPublished version of a chapter in the book: Recent Trends in Applied Artificial Intelligence. Also available from the publisher at: http://dx.doi.org/10.1007/978-3-642-38577-3_7","Creating and Updating Personalized and Verbalized Business Process DescriptionsThe increasing adoption of process-aware information systems (PAISs) has resulted in large process model collections. To support users having different perspectives on complex processes and related data, a PAIS should enable personalized process views, i.e., user-specific abstractions of process models. Despite the abstraction achieved through views of the graphical process models, many end users still struggle with understanding these graphical models and their details. For selected user#R##N#groups, therefore, a PAIS should provide verbalized process descriptions describing their role in the process. Existing PAISs neither provide mechanisms for managing process views nor verbalized process descriptions. While process views have been used as visual abstractions for large process models, so far no work exists on how to provide both personalized and verbalized process descriptions based on respective views. This paper presents an approach for creating such personalized and verbalized process descriptions based on process views. Furthermore, textual changes of a personalized and verbalized process description are correctly mapped to corresponding updates of the underlying process model. In this context, all other views and process descriptions related to this process model are migrated to the new version of the process model as well. Overall, our approach enables end users to understand and evolve large process models based on personalized and verbalized process descriptions.","A Layered Dirichlet Process for Hierarchical Segmentation of Sequential Grouped DataWe address the problem of hierarchical segmentation of sequential grouped data, such as a collection of textual documents, and propose a Bayesian nonparametric approach for this problem. Existing Bayesian nonparametric models such as the sticky HDP-HMM are suitable only for single-layer segmentation. We propose the Layered Dirichlet Process LaDP, where each layer has a countable set of Dirichlet Processes, draws from which define a distribution over the countable set of Dirichlet Processes at the next layer. Each data item gets assigned to a distribution index from each layer of the hierarchy, leading to hierarchical segmentation of the sequence. The complexity of inference depends upon the exchangeability assumptions for the measures at different layers. We propose a new notion of exchangeability called Block Exchangeability, which lies between Markov Exchangeability used in HDP-HMM and Complete Group Exchangeability used in HDP, and allows for faster inference than Markov Exchangeability. Using experiments on a news transcript dataset and a product review dataset, we show that LaDP generalizes better than existing non-parametric models for sequential data, and by simultaneously segmenting at multiple levels, outperforms existing models in terms of single-layer segmentation. We also show empirically that using Block Exchangeability greatly speeds up inference and allows trading off accuracy for execution time.","Claims and evidence for architecture-based self-adaptation: a systematic literature reviewEngineering the upcoming generation of software systems and guaranteeing the required qualities is complex due to the inherent uncertainties at design time, such as new user needs and changing availability of resources. Architecture-based self-adaptation is a promising approach to tackle these challenges. In this approach, a system maintains a model of itself and adapts itself to realize particular quality objectives using a feedback loop. Despite a vast body of work, no systematic study has been performed on the claims associated with architecture-based self-adaptation and the evidence that exists for these claims. As such insight is important for researchers and engineers, we performed a systematic literature review covering 20 leading software engineering conferences and journals in the field, resulting in 121 studies used for data collection. The review shows that self-adaptation is primarily used to improve performance, reliability, and flexibility. The tradeoffs implied by self-adaptation have not received much attention, and evidence is mainly obtained from simple examples. From the study, we derive a number of recommendations for future research in architecture-based self-adaptive systems.","NFC in the K-Project Secure Contactless Sphere\u2014smart RFID technologies for a connected worldRepresentatives from the entire RFID supply chain have come together to form a consortium to work on the K-Project Secure Contactless Sphere (SeCoS). The aims of the project are to develop a Web of Things platform with built-in NFC support which places the highest demands on security and protection of privacy. Research will be carried out in three important thematic fields to enable secure mobile NFC applications. The first research activity focuses on defining the service architecture and implementing the core components of the Web of Things application platform, which is built on a message driven paradigm. The second research activity develops and assesses security and privacy policy enhancing technologies for NFC devices. The third research activity aims at achieving higher data rates with NFC systems through innovative design solutions. Finally, the project shows the research results in concrete demonstrators.","Empirical Evaluation of Complex System Interfaces for Power Plant Control Room Using Human Work Interaction Design FrameworkThis paper first discusses two cognitive science paradigms and then present third approach related to interaction with the world as known as embo- died cognition. The focus is to analyze work settings with the help of cognitive work analysis and human work interaction design approaches. The case of power plant control room is discussed and analyzed in the context of human system interactions, work and task analysis. This approach helps in reducing cognitive workload on operator which can result in reduction in errors in managing the control room of the power plant.","Modelling of Environmental Risk Management under Information Asymmetry ","Secure semi-supervised vector quantization for dissimilarity dataThe amount and complexity of data increase rapidly, however, due to time and cost constrains, only few of them are fully labeled. In this context non-vectorial relational data given by pairwise (dis-)similarities without explicit vectorial representation, like score- values in sequences alignments, are particularly challenging. Existing semi-supervised learning (SSL) algorithms focus on vectorial data given in Euclidean space. In this paper we extend a prototype-based classifier for dissimilarity data to non i.i.d. semi-supervised tasks. Using conformal prediction the 'secure region' of unlabeled data can be used to improve the trained model based on labeled data while adapting the model complexity to cover the 'insecure region' of labeled data. The proposed method is evaluated on some benchmarks from the SSL domain.","Discriminant Splitting of Regions in Traffic Sign Recognition ","Agent-based simulation for UAV swarm mission planning and executionSwarms of Unmanned Aerial Vehicles (UAV) have been foreseen by multiple organizations to serve an important role in future air-based warfare and civilian operations. UAVs are less expensive than their piloted counterparts, provide greater flexibilities and remove the need for on-board pilot support. Efficient control of swarms opens a set of new challenges, such as automatic UAV coordination, efficient swarm monitoring and dynamic mission planning. In this paper, we investigate the problem of dynamic mission planning for a UAV swarm. An agent-based control framework is proposed, which employs a control agent for task assignment and multiple UAV agents for local task scheduling. A prototype simulation framework is implemented as a proof-of-concept. Experimentation with the framework suggests the effectiveness of swarm control using several mission planning mechanisms.","Design of CAPTCHA Script for Indian Regional WebsitesTo improve accessibility of Indian regional websites especially government websites content is offered in regional languages besides English language. However, these websites use CAPTCHA tests in English languages in regional language pages. This reduces usability and accessibility because non-native speakers of English language are required to pass CAPTCHA tests in English language. The accessibility of such websites can be improved substantially if secure CAPTCHA tests in regional languages are used. However, such an implementation is challenging as Indian regional languages are unique in many ways, are written differently and have different alphabets, glyphs, pronunciations, accents, etc. This paper reviews existing CAPTCHA scripts and Indian regional websites in terms of their usability, accessibility and multilingual support. It reports the design of CAPTCHA script in Hindi, Punjabi, Urdu and English languages which can be used to generate CAPTCHA tests in websites offering content in these languages. The designed CAPTCHA script offers features such as audio, localized onscreen keyboard, random patterns and fonts to improve usability and security.","A Spatial Multicriteria Assessment Decision Support System (SMCA-DSS) for East Naples: Towards a Water Opportunity Map ","Performance Evaluation of Process Partitioning Using Probabilistic Model CheckingConsider the problem of partitioning a number of concurrent interacting processes into a smaller number of physical processors. The performance and efficiency of such a system critically depends on the tasks that the processes perform and the partitioning scheme. Although empirical measurements have been extensively used a posteriori to assess the success of partitioning, the results only focus on a subset of possible executions and cannot be generalized. In this paper, we propose a prob- abilistic state exploration method to evaluate a priori the efficiency of a set of partitions in terms of the speedup they achieve for a given model. Our experiments show that our method is quite effective in identifying partitions that result in better levels of parallelism.","End of life management of industrial robotsEnd of life management (EOL) is currently a hot topic in the electronics industry. Currently, mostly IT equipment and goods of consumer electronics are considered. In the nearest future automation equipment has also to be taken into account. There are three possibilities depending on the age and kind of the device: resell\u2013reuse\u2013recycle, called the \u201c3Rs\u201d. For recycling fully or semi-automated disassembly will gain in importance in the nearest future also for robots. Producers of robots have to take into account EoL because of regulations and laws as well as according to ethical codes contributing to protection of the environment. Based on previous works a real example will be presented and discussed.","Identification of radio disturbances of wireless sensor networksWe propose a novel method to identify the sources for transmission disturbances related to radio propagation in wireless sensor networks. Especially in industrial environments there are challenges for reliability and performance. For example, dead spots indicate destructive interference caused by the signal multipath propagation. The recognition of this phenomenon during the network installation and operation, and systematic methods for network optimization, will significantly improve the data transmission quality and reliability even in difficult conditions. By computing the amplitude histograms of the received signal strength and characteristics of the histograms, we can deduce what kind of interference causes the signal degradation in radio link, i.e. interfering radio traffic or signal multipath propagation. We use software defined radio (SDR) as the receiver to capture the transmitted signal and analyze the statistical properties of the captured signal with Matlab/Simulink tools. The results show that the shape of the histograms reveals the nature of the radio channel interferences and in that way can help to choose the right actions in order to overcome the communication problems.","Sparse Reductions for Fixed-Size Least Squares Support Vector Machines on Large Scale Data ","Product Form Solution for a Simple Control of the Power Consumption in a Service Center ","Exploiting Partial-Packet Information for Reactive Jamming Detection: Studies in UWSN EnvironmentReactive jamming in an underwater sensor network (UWSN) environment is a realistic and very harmful threat. It, typically, affects only a small part of a packet (not the entire one), in order to maintain a low detection probability. Prior works on reactive jamming detection were focused on terrestrial wireless sensor networks (TWSNs), and are limited in their ability to (a) detect it correctly, (b) distinguish the small corrupted part from the uncorrupted part of a packet, and (c) be adap- tive with dynamic environment. Further, there is currently a need for a generalized framework for jamming detection that outlines the basic op- erations governing it. In this paper, we address these research lacunae by broadly designing such a framework for jamming detection, and specif- ically a detection scheme for reactive jamming. A key characteristic of this work is introducing the concept of partial-packet (PP) in jamming detection. The introduction of such an approach is unique - the existing works rely on holistic packet analysis, which degrades their performance - a fundamental issue that would substantially affect achieving real-time performance. We estimate the probability of high deviation in received signal strength (RSS) using a weak estimation learning scheme, which helps in absorbing the impact of dynamic environment. Finally, we per- form CUSUM-test for reactive jamming detection. We evaluate the per- formance of our proposed scheme through simulation studies in UWSN environment. Results show that, as envisioned, the proposed scheme is capable of accurately detecting reactive jamming in UWSNs, with an accuracy of 100% true detection, while the average detection delay is substantially less.","Estimation of the Regularisation Parameter in Huber-MRF for Image Resolution EnhancementThe Huber Markov Random Field H-MRF has been proposed for image resolution enhancement as a preferable alternative to Gaussian Random Markov Fields G-MRF for its ability to preserve discontinuities in the image. However, its performance relies on a good choice of a regularisation parameter. While automating this choice has been successfully tackled for G-MRF, the more sophisticated form of H-MRF makes this problem less straightforward. In this paper we develop an approximate solution to this problem, by upper-bounding the partition function of the H-MRF. We demonstrate the working and flexibility of our approach in image super-resolution experiments.","Group chats on TwitterWe report on a new kind of group conversation on Twitter that we call a group chat. These chats are periodic, synchronized group conversations focused on specific topics and they exist at a massive scale. The groups and the members of these groups are not explicitly known. Rather, members agree on a hashtag and a meeting time (e.g, 3pm Pacific Time every Wednesday) to discuss a subject of interest. Topics of these chats are numerous and varied. Some are support groups, for example, post-partum depression and mood disorder groups. Others are about a passionate interest: topics include skiing, photography, movies, wine and foodie communities. We develop a definition of a group that is inspired by how sociologists define groups and present an algorithm for discovering groups. We prove that our algorithms find all groups under certain assumptions. While these groups are of course known to the people who participate in the discussions, what we do not believe is known is the scale and variety of groups. We provide some insight into the nature of these groups based on over two years of tweets. Finally, we show that group chats are a growing phenomenon on Twitter and hope that reporting their existence propels their growth even further.","Automated Promotion of Technology Acceptance by Clinicians Using Relational AgentsProfessionals are often resistant to the introduction of technology and can feel threatened if they perceive the technology as replacing some aspect of their jobs. We anticipated some of these problems in the process of introducing a bedside patient education system to a hospital, especially given that the system presents itself as a \"virtual discharge nurse\" in which an animated nurse agent interacts with patients using simulated face-to-face conversation. To increase acceptance by nursing staff we created a version of the character designed to build trust and rapport through a personalized conversation with them. In a randomized trial, we compared responses after 15 minute in-service briefings on the technology versus responses to the same briefings plus a personalized conversation with the agent. We found that the nurses who participated in briefings that included the personalized conversation had significantly greater acceptance of and lower feelings of being threatened by the agent.","Application of l1 Estimation of Gaussian Mixture Model Parameters for Language IdentificationIn this paper we explore the using of  l  1 optimization for a parameter estimation of Gaussian mixture models GMM applied to the language identification. To train the Universal background model UBM at each step of Expectation maximization EM algorithm the problem of the GMM means estimation is stated as  l  1 optimization. The approach is Iteratively reweighted least squares IRLS. Also here is represented the corresponding solution of the Maximum a posteriori probability MAP adaptation. The results of the above UBM-MAP system combined with Support vector machine SVM are reported on the LDC and GlobalPhone datasets.","Adaptive Stochastic Airline Seat Inventory Control under Parametric UncertaintyAirline seat inventory control is a very profitable tool in the airline industry. The problem of adaptive stochastic airline seat inventory control lies at the heart of airline revenue management. This problem concerns the allocation of the finite seat inventory to the stochastic customer demand that occurs over time before the flight is scheduled to depart. The objective is to find the right combination of customers of various fare classes on the flight such that revenue is maximized. In this paper, the static and dynamic policies of stochastic airline seat inventory control (airline booking) are developed under parametric uncertainty of underlying models, which are not necessarily alternative. For the sake of simplicity, but without loss of generality, we consider (for illustration) the case of nonstop flights with two fare classes. The system developed is able to recognize a situation characterized by the number of reservations made by customers of the above fare classes at certain moment of time before departure. The proposed policies of the airline seat inventory control are based on the use of order statistics of cumulative customer demand, which have such properties as bivariate dependence and conditional predictability. Dynamic adaptation of the system to airline customer demand is carried out via the bivariate dependence of order statistics of cumulative customer demand. Dynamic optimization of the airline seat allocation is carried out via the conditional predictability of order statistics. The system makes on- line decisions as to whether to accept or reject any customer request using established decision rules based on order statistics of the current cumulative customer demand. The computer simulation results are promising.","Extracting Product Features from Online Consumer ReviewsThe exponential growth of user-generated content in online environment calls for techniques that can help to make sense of the content. Despite of a host of research on online consumer reviews, there is still a great demand for research to improve the techniques for feature extraction. To this end, we proposed extraction methods based on detailed categorization of review features. By taking into account of the characteristics and patterns of different types of features, the proposed methods not only identify new features but also filter irrelevant features. The results of an experiment demonstrate that our proposed methods outperform the state-of-the-art techniques.","Exploring the Potential for Mapping Schema.org Microdata and the Web of Linked Data ","Applying the clinical adoption framework to evaluate the impact of an ambulatory electronic medical record. ","Discernibility Matrix Based Attribute Reduction in Intuitionistic Fuzzy Decision SystemsBased on the theory of rough sets and intuitionistic fuzzy sets, this paper researches attribute reduction in intuitionistic fuzzy decision systems IFDS. Firstly, we establish an intuitionistic fuzzy rough set model based on the similarity relation. Secondly, the discernibility matrix based on the maximal consistent block is constructed and an algorithm of attribute reduction is designed, which can eliminate the redundant information from the given IFDS. Finally, an illustrative example is employed to show the validity of the algorithm in this paper.","O uso integrado de interface multimodal e dispositives m\u00f3veis em gest\u00e3o de emerg\u00eanciasCrisis Management requires communication and collaboration among of people. Approaches to support information sharing through mobile devices may not have built an appropriate interaction on this domain. This paper discusses an approach to provide a multimodal interface on mobile devices to work with emergency response teams.","Numerical solution for a kind of nonlinear telegraph equations using radial basis functions ","SanTrain: A Serious Game Architecture as Platform for Multiple First Aid and Emergency Medical Trainings ","Estimating Clusters Centres Using Support Vector Machine: An Improved Soft Subspace Clustering AlgorithmIn this paper, a new approach of soft subspace clustering is proposed. It is based on the estimation of the clusters centres using a multi-class support vector machine SVM. This method is an extension of the ESSC algorithm which is performed by optimizing an objective function containing three terms: a weighting within cluster compactness, entropy of weights and a weighting between clusters separations. First, the SVM is used to compute initial centres and partition matrices. This new developed formulation of the centres is integrated in each iteration to yield new centres and membership degrees. A comparative study has been conducted on UCI datasets and different image types. The obtained results show the effectiveness of the suggested method.","Monitoring and Controlling in an Industrial Service Ecosystem ","Toward a procedure for data mining proofsIn this paper, we report results of an experiment to use the mutual information criterion to automatically select formulas to guide the search for proofs using McCune's Prover9 system. The formulas were selected from the TPTP library of problems for theorem-provers.","A Notion of a Computational Step for Partial Combinatory Algebras ","Visual stimulus background effects on SSVEP-based brain-computer interfaceThe flickering source is an indispensable component in steady-state visual evoked potentials based brain-computer interface, and its background severely influences the potentials evoked by the repetitive stimuli. In this paper, we designed the experiment paradigm under three different backgrounds in the context of the SSVEP controlled small car, including black screen, static scene of the environment, and dynamic scene of the environment. From the spectrogram analysis of the EEG signals at occipital cortex, we found apparent decrease in SSVEP amplitude in dynamic scene condition comparing to the reference condition black screen. And the SSVEP amplitude changes under these three conditions further resulted in identification accuracy decreasing in dynamic scene condition as compared to black screen reference condition, which was evaluated from 10 10 cross validation. Besides, in real-time control of the small car, our results indicated that training in static scene condition exhibited better performance than that in black screen.","Conservative Graph Coloring: A Robust Method for Automatic PCI Assignment in LTE ","Knowledge Creation in Requirements Engineering - A Systematic Literature ReviewRequirements engineering (RE) is crucial for software development, yet software requirements are often not properly identified or implemented. As the RE process thereby highly depends on human knowledge (explicit and tac- it), this problem can in many cases be attributed to the lack of mutual under- standing between customers and developers which is caused by diverging do- main knowledge. To solve this problem, we conduct a systematic literature re- view to identify methods associated with Nonaka's organizational knowledge creation theory. We map eight such methods on six common RE problems as we analyze to which extent the methods overcome the associated problems. Although it is not always obvious which problems apply to specific software projects, the identified methods provide an adequate first approach to reduce the risk of potential RE problems, thus making project failure less likely.","On Matters of Invariance in Latent Variable Models: Reflections on the Concept, and its Relations in Classical and Item Response Theory ","VCG AUCTION MECHANISM COST EXPECTATIONS AND VARIANCESWe consider Vickrey-Clarke-Groves (VCG) auctions for a very general combinatorial structure, in an average-case set- ting where item costs are independent, identically distributed uni- form random variables. We prove that the expected VCG cost is at least double the expected nominal cost, and exactly double when the desired structure is a basis of a bridgeless matroid. In the ma- troid case we further show that, conditioned upon the VCG cost, the expectation of the nominal cost is exactly half the VCG cost, and we show several results on variances and covariances among the nominal cost, the VCG cost, and related quantities. As an application, we find the asymptotic variance of the VCG cost of the minimum spanning tree in a complete graph with random edge costs.","Ultrametric Component Analysis with Application to Analysis of Text and of EmotionWe review the theory and practice of determining what parts of a data set are ultrametric. It is assumed that the data set, to begin with, is endowed with a metric, and we include discussion of how this can be brought about if a dissimilarity, only, holds. The basis for part of the metric-endowed data set being ultrametric is to consider triplets of the observables (vectors). We develop a novel consensus of hierarchical clusterings. We do this in order to have a framework (including visualization and supporting interpretation) for the parts of the data that are determined to be ultrametric. Furthermore a major objective is to determine locally ultrametric relationships as opposed to non-local ultrametric relationships. As part of this work, we also study a particular property of our ultrametricity coefficient, namely, it being a function of the difference of angles of the base angles of the isosceles triangle. This work is completed by a review of related work, on consensus hierarchies, and of a major new application, namely quantifying and interpreting the emotional content of narrative.","iARIS \u2013 Supporting Enterprise Transformation Using An Iterative ISD Method ","On Model Based Clustering in a Spatial Data Mining Context ","An investigation of single-pass ASR system combination for spoken language understandingThis paper studies the benefits provided by a single-pass Automatic Speech Recognition (ASR) exchange-based combination approach for spoken dialog system. Three famous open-source ASR systems are used to experiment this approach in the framework of Spoken Language Understanding (SLU). On the ASR side, single-pass ASR systems are used with an online acoustic model adaptation using the previous utterances said by a speaker. On the SLU side, a competitive CRF-based SLU system is applied on outputs of ASR system to obtain the semantic concepts. The evaluation is done on the French PORT-MEDIA test data in terms of both Word Error Rate (WER) and Concept Error Rate (CER). While the best single pass system used alone shows a CER of 29.8% for a WER of 22.8%, single-pass ASR exchange-based combination reaches a CER of 27.3% for a WER of 26%. This CER is only slightly higher than the one reached by a 5-passes ASR system which obtained a CER of 26.8% for a WER of 22.8% in better conditions, i.e. better acoustic model adaptation made on all the speech utterances said by a speaker, advanced feature extraction techniques and search graph rescoring using language model with higher order.","Collaborative Design Support System Based on Interactive Genetic Algorithm (IGA) ","Semi-supervised Concept Detection by Learning the Structure of Similarity GraphsWe present an approach for detecting concepts in images by a graph-based semi-supervised learning scheme. The proposed approach builds a similarity graph between both the labeled and unlabeled im- ages of the collection and uses the Laplacian Eigemaps of the graph as features for training concept detectors. Therefore, it offers multiple options for fusing different image features. In addition, we present an incremental learning scheme that, given a set of new unlabeled images, efficiently performs the computation of the Laplacian Eigenmaps. We evaluate the performance of our approach both on synthetic datasets and on MIR Flickr, comparing it with high-performance state-of-the-art learning schemes with competitive and in some cases superior results.","FI-FCM Algorithm for Business IntelligenceBusiness Intelligence combines the large data with analytical tools to present knowledge to the decision makers. It is used to understand the trends,future directions ,capabilities and technologies in the business. It has set of methods, process and technologies that transform raw data into meaningful information. Data Mining is one of Business Intelligence techniques that are used to obtain knowledge from data. The applications of business intelligence includes E-commerce recommender system, approval of bank loan, credit/debit card fraud detection etc., In this paper we have proposed FI-FCM algorithm for Business intelligence based on frequent itemsets and Fuzzy C Means clustering to extract the intelligence from the dataset in order to make the decision making process more efficient and to improve the business intelligence. E-commerce recommender system applications is selected to experiment this algorithm to help customers to find ,recommend products they wish to purchase by producing the list of recommended products.","Trend Based Vertex Similarity for Academic Collaboration RecommendationIn this paper, we propose a new method used for collaboration recommendation in the academic domain. The proposed method is based on combination of probability theory and graph theory for modeling and analysing co-author network. In the co-author network, similar vertices are explored as potential candidates for collaboration recommendation. Taking the trend information into considering similarity of vertices in the network is the main contribution of this research. We did experiments with co-author networks extracted from the DBLP. Co-authorship that will occur in future used to evaluate accuracy of collaboration recommendation methods. We used metadata of publications from 2001 to 2005 for building the training network. The testing networks were built with publications from 2006-2008 (the testing network 1 for the near future prediction) and 2009-2011 (the testing network 2 for the far future prediction). The experimental results show that the proposed method, called TBRSS (Trend Based Relation Strength Similarity), outperforms other existing methods.","Game-Theoretic Approach to Feedback-Driven Multi-stage Moving Target DefenseThe static nature of computer networks allows malicious attackers to easily gather useful information about the network using network scanning and packet sniffing. The employment of secure perimeter firewalls and intrusion detection systems cannot fully protect the network from sophisticated attacks. As an alternative to the expensive and imperfect detection of attacks, it is possible to improve network security by manipulating the attack surface of the network in order to create a moving target defense. In this paper, we introduce a proactive defense scheme that dynamically alters the attack surface of the network to make it difficult for attackers to gather system information by increasing complexity and reducing its signatures. We use concepts from systems and control literature to design an optimal and efficient multi-stage defense mechanism based on a feedback information structure. The change of attack surface involves a reconfiguration cost and a utility gain resulting from risk reduction. We use information- and control-theoretic tools to provide closed-form optimal randomization strategies. The results are corroborated by a case study and several numerical examples.","A Stable Energy-Efficient Location Based Clustering Scheme for Ad Hoc NetworksClustering is an approach applied in mobile ad hoc networks to organize the hosts in groups called Clusters. The paper focuses on implementing a Clustering technique that conserves Energy, provides Stability and keeps the Communication Traffic and Overheads low using Location based approaches by setting Thresholds for different parameters in dynamic ad hoc environment of uncontrolled movement of nodes, low bandwidth of wireless channel and energy limited nodes. The mechanism uses pools of Primary and Secondary cluster heads (CHs) to provide uninterrupted communication due to node mobility. The protocol saves network resources by reducing the information exchange amongst the nodes and limiting it to clusters and CHs. The paper includes a case that models different scenarios based on the proposed protocol. Also, characteristic analysis of our clustering scheme with some of the existing algorithms is done which shows the strength of this scheme over others.","Stochastic Analysis for Forecasting the MW Load of Plug-In Electric VehiclesThis paper proposes a Monte Carlo analysis for forecasting the MW load of plug-in electric vehicles. The method considers the number of vehicles in a city, Wh/km, km per vehicle, vehicles on chargers, and power factor of chargers. Using the Monte Carlo method, the range of the MW load is forecasted, considering the associated ranges of the various parameters and variables.","Bio-inspired Optimization Methods on Graphic Processing Unit for Minimization of Complex Mathematical Functions ","Fit between Knowledge Transfer Complexity and Media Capability: A Meta-Analysis. ","A Trust-Based Approach for Detecting Compromised Nodes in SCADA SystemsNowadays, many critical infrastructures are monitored by SCADA systems processing data obtained by underlying sensor net- works. Modern SCADA systems are usually networked, also using wire- less connections. Thus, security concerns are crucial when developing SCADA applications, as they are increasingly vulnerable to cyber at- tacks. In this context, the detection of misbehaving nodes is a key issue, which is in general not easy to address due to the logical and physical high distribution of nodes as well as their complex functions in the net- work. To deal with the above problem, approaches based on information sharing among collaborative components seem suitable. However, all the past proposals based on information sharing only focus on detecting mis- behaving sensor nodes without considering all the other SCADA nodes at any level of complexity. In this paper, we present a trust-based ap- proach to detecting high-level compromised nodes in a SCADA system that is based on a competition among agents associated to nodes. Some preliminary experiments we have performed show promising results of the proposed approach in terms of ef fectiveness and ef fi ciency.","Groupwise Segmentation with Multi-atlas Joint Label FusionGroupwise segmentation that simultaneously segments a set of images and ensures that the segmentations for the same structure of interest from different images are consistent usually can achieve better performance than segmenting each image independently. Our main contribution is that we adopt the groupwise segmentation framework to improve the performance of multi-atlas label fusion. We develop a novel statistical model to allow this extension. Comparing to previous atlas propagation and groupwise segmentation work, one key novelty of our method is that the error produced during label propagation is explicitly addressed in the joint label fusion framework. Experiments on hippocampus segmentation in magnetic resonance images show the effectiveness of the new groupwise segmentation technique.","Using a Pipeline Approach to Build Data Cube for Large XML Data StreamsXML has become a widely used standard for data representation, distribution and sharing. The concept of the Sensor Web has led to web generated sensor data in many diverse applications where delivery of the sensed data takes place using the Web. In order to obtain useful knowledge from XML sensor data, data warehouse and OLAP applications aimed at providing support for decision making for operational data must be developed. In this paper, we present a pipeline design based OLAP data cube construction framework designated for real time web generated sensor data, transforming sensor data into XML streams conforming to an underlying data warehouse logical model, which constructs corresponding data cubes. As part of this work, we discuss how our cube construction and acceleration strategy improves the efficiency in managing large volumes of XML data.","Automated Specification Discovery via User-Defined Predicates ","Novel initialisation and updating mechanisms in PSO for feature selection in classificationIn classification, feature selection is an important, but difficult problem. Particle swarm optimisation (PSO) is an efficient evolutionary computation technique. However, the traditional personal best and global best updating mechanism in PSO limits its performance for feature selection and the potential of PSO for feature selection has not been fully investigated. This paper proposes a new initialisation strategy and a new personal best and global best updating mechanism in PSO to develop a novel feature selection algorithm with the goals of minimising the number of features, maximising the classification performance and simultaneously reducing the computational time. The proposed algorithm is compared with two traditional feature selection methods, a PSO based method with the goal of only maximising the classification performance, and a PSO based two-stage algorithm considering both the number of features and the classification performance. Experiments on eight benchmark datasets show that the proposed algorithm can automatically evolve a feature subset with a smaller number of features and higher classification performance than using all features. The proposed algorithm achieves significantly better classification performance than the two traditional methods. The proposed algorithm also outperforms the two PSO based feature selection algorithms in terms of the classification performance, the number of features and the computational cost.","Work Safety and Health Games-Based Learning ","A Multi-objective Genetic Algorithm for Generating Test Suites from Extended Finite State MachinesWe propose a test suite generation technique from extended finite state machines based on a genetic algorithm that fulfills multiple conflicting objectives. We aim at maximizing coverage and feasibility of a set of test cases while minimizing similarity between these cases and minimizing overall cost.","Time Series of Fuzzy Sets in Classification of Electrocardiographic Signals ","The Influence of Analyst Communication in IS Projects ","Vision-Based User Interface for Mouse and Multi-mouse SystemThis paper proposes a vision-based methodology that recognizes the users' fingertips so that the users can perform various mouse operations by gestures as well as implements multi-mouse operations. By using the Ramer-Douglas-Peucker algorithm, the system retrieves the coordinates of the finger from the palm of the hand. The system also recognizes the users' intended operation on the mouse through the movements of recognized fingers. When the system recognizes several palms of hands, it changes its mode to the multi-mouse mode so that several users can coordinate their works on the same screen. The number of mice is the number of recognized palms. In order to implement our proposal, we have employed the Kinect motion capture camera and have used the tracking function of the Kinect to recognize the fingers of users. Operations on the mouse pointers are reflected in the coordinates of the detected fingers. In order to demonstrate the effectiveness of our proposal, we have conducted several user experiments. We have observed that the Kinect is suitable equipment to implement the multi-mouse operations. The users who participated in the experiments quickly learned the multi-mouse environment and performed naturally in front of the Kinect motion capture camera.","Generating a Conceptual Representation of a Legacy Web Application ","Qualitative Propagation and Scenario-based Explanation of Probabilistic ReasoningComprehensible explanations of probabilistic reasoning are a prerequisite for wider acceptance of Bayesian methods in expert systems and decision support systems. A study of human reasoning under uncertainty suggests two different strategies for explaining probabilistic reasoning: The first, qualitative belief propagation, traces the qualitative effect of evidence through a belief network from one variable to the next. This propagation algorithm is an alternative to the graph reduction algorithms of Wellman (1988) for inference in qualitative probabilistic networks. It is based on a qualitative analysis of intercausal reasoning, which is a generalization of Pearl's \"explaining away\", and an alternative to Wellman's definition of qualitative synergy. The other, Scenario-based reasoning, involves the generation of alternative causal \"stories\" accounting for the evidence. Comparing a few of the most probable scenarios provides an approximate way to explain the results of probabilistic reasoning. Both schemes employ causal as well as probabilistic knowledge. Probabilities may be presented as phrases and/or numbers. Users can control the style, abstraction and completeness of explanations.","A Topological Approach for Detecting Twitter Communities with Common Interests ","Measuring usability of the mobile mathematics curriculum-based measurement application with childrenIn this paper, we present the application software on mobile tablet device called mathematics curriculum-based measurement (iCBM). The iCBM was developed by various mobile technologies. Thirty-four fifth-grade elementary students participated in the study. The findings demonstrated that students had positive attitudes toward the iCBM system as well as taking math tests through mobile tablet devices. The observations of usability test on iCBM system indicated that children can use iCBM successfully. Suggestions are made about the interface design for children while using iCBM to solve math problems.","GDSL: A Universal Toolkit for Giving Semantics to Machine LanguageThe static analysis of executable programs has gained importance due to the need to audit larger and larger programs for security vulnerabilities or safety violations. The basis for analyzing executables is the decoding of byte sequences into assembler instructions and giving a semantics to them. We illustrate how our domain specific language GDSL facilitates this task by specifying Intel x86 semantics. In particular, we show how simple optimizations of the generated code can drastically reduce its size. Since these optimizations are also written in GDSL they can be re-used with other processor front-ends. Hence, analyses based on our toolkit can be adapted to several architectures with little change.","Web Accessibility in Africa: A Study of Three African Domains ","An Approach to Efficient Processing of Multi-word Units ","Comparative Evaluation among Diverse Interaction Techniques in Three Dimensional EnvironmentsThis paper reports on the results of a user-based evaluation that was conducted on a 3D virtual environment that supports diverse interaction techniques. More specifically, the interaction techniques that were evaluated were touch, gestures hands and legs and the use of a smart object. The goal of the experiment was to assess the effectiveness of each interaction modes as a means for the user to complete common tasks within the application. A comparison is attempted in order to provide an insight to the suitability of each technique and direct future research in the area.","Learning KPCA for Face Recognition ","Synthesizing Round Based Fault-Tolerant Programs Using Genetic ProgrammingIn this paper, we present an approach to synthesize round based distributed fault-tolerant programs using stack based genetic programming. Our approach evolves a fault-tolerant program based on a round based structure and the program specification. To permit such evolution, we use a multi-objective fitness function that characterizes the correctness of the program in the absence of faults, in the presence of a single fault and in the presence of multiple faults. This multi-objective fitness function attempts to synthesize a program that works equally well in all these scenarios. We demonstrate the effectiveness of our approach using two case studies: a byzantine agreement problem and a token ring problem.","Planned Behavior versus Goal-directed Automaticity \u2013 The Impact of Attitude and General Habit on Adoption and Non-adoption ","Enabling dynamic delegation interactions with multiple unmanned vehicles; flexibility from top to bottomA \"delegation approach\" to human interaction with automation should strive to achieve all of the flexibility that a human supervisor has in instructing, managing, redirecting and overriding well-trained human subordinates. But in the absence of human-like, natural-language understanding \"androids\", what would such interaction look like? This multi-year design and evaluation project explores such interaction concepts for pilot control of multiple remotely piloted systems. This paper details the underlying philosophy of delegation and presents many design innovations developed to date.","Is Matching Pursuit Solving Convex ProblemsSparse recovery ({\\tt SR}) has emerged as a very powerful tool for signal processing, data mining and pattern recognition. To solve {\\tt SR}, many efficient matching pursuit (\\texttt{MP}) algorithms have been proposed. However, it is still not clear whether {\\tt SR} can be formulated as a convex problem that is solvable using \\texttt{MP} algorithms. To answer this, in this paper, a novel convex relaxation model is presented, which is solved by a general matching pursuit (\\texttt{GMP}) algorithm under the convex programming framework. {\\tt GMP} has several advantages over existing methods. At first, it solves a convex problem and guarantees to converge to a optimum. In addition, with $\\ell_1$-regularization, it can recover any $k$-sparse signals if the restricted isometry constant $\\sigma_k\\leq 0.307-\\nu$, where $\\nu$ can be arbitrarily close to 0. Finally, when dealing with a batch of signals, the computation burden can be much reduced using a batch-mode \\texttt{GMP}. Comprehensive numerical experiments show that \\texttt{GMP} achieves better performance than other methods in terms of sparse recovery ability and efficiency. We also apply \\texttt{GMP} to face recognition tasks on two well-known face databases, namely, \\emph{{Extended using}} and \\emph{AR}. Experimental results demonstrate that {\\tt GMP} can achieve better recognition performance than the considered state-of-the-art methods within acceptable time. {Particularly, the batch-mode {\\tt GMP} can be up to 500 times faster than the considered $\\ell_1$ methods.}","The Cooperative Ballistic Missile Defence GameThe increasing proliferation of ballistic missiles and weapons of mass destruction poses new risks worldwide. For a threatened nation and given the characteristics of this threat a layered ballistic missile defence system strategy appears to be the preferred solution. However, such a strategy involves negotiations with other nations concerning the use of their defence systems as part of the layered defence system. This paper introduces the Cooperative Ballistic Missile Defense Game,    $\\mathcal{CBMDG}$   , to support the strategic negotiations between a threatened nation and the possible coalition nations. The model determines the assignment of ballistic missile interceptors to the coalition nations that minimizes the expected number of interceptors required to achieve the desired defence level in case of an attack. Simultaneously, it identifies the bargaining strength of each coalition of nations, in order to determine the compensation for participating in the layered defence system to protect the threatened nation.","Adopting open protocols to increase the impact on digital repositories ","Current Attitude Prediction Model Based on Game Theory ","SmacC: A Retargetable Symbolic Execution EngineSmacC is a symbolic execution engine for C programs. It can be used #R##N#for program verification, bounded model checking and generating SMT benchmarks. #R##N#More recently we also successfully applied SmacC for high-level timing #R##N#analysis of programs to infer exact loop bounds and safe over-approximations. #R##N#SmacC uses the logic for bit-vectors with arrays to construct a bit-precise memory-model of a program for path-wise exploration.","High Speed Reconfigurable FPGA Based Digital FilterDigital Finite Impulse Response filters are essential building blocks in most Digital Signal Processing (DSP) systems. A large application area is telecommunication, where filters are needed in receivers and transmitters, and an increasing portion of the signal processing is done digitally. However, power dissipation of the digital parts can be a limiting factor, especially in portable, battery operated devices. Scaling of the feature sizes and supply voltages naturally helps to reduce power. For a certain technology, there are still many kinds of architectural and implementation approaches available to the designer. In this paper, a reconfigurable FPGA based pipelined FIR filter is implemented and analyzed. This realized FIR filter is compared for area, power dissipation and data processing rate (throughput). Simulation and compilation of the VHDL code written for the implementation of FIR filters is done using Mentor Graphics ModelSim. For the synthesis targeting to FPGA Xilinx Virtex II Pro XP2VP30 device Xilinx ISE Design Suite 10.1 tool is used. Power estimation is done using Xilinx Xpower tool. FPGA implementation of FIR filter model with respect to power, silicon area, and data processing rate (throughput) is analysed.before and after the abstract. This document is in the required format.","Mixed Factorial Analysis of In-Vehicle Information Systems: Age, Driving Behavior, and Task Performance ","Towards a Polish LTAG GrammarThis paper reports on a Lexicalised Tree Adjoining Gram- mar for Polish, extracted automatically from the Polish constituency treebank. The grammar consists of 23 570 elementary trees anchored by 11 515 lexemes. Running the grammar on the sentences from the tree- bank using a modified version of TuLiPA parser showed that it achieves a high accordance (almost 99%) with the treebank annotation - in terms of syntactic categories assigned to phrases - on the trees which were suc- cessfully parsed. For many trees, however, obtaining a TAG parse was impossible due to time or memory shortcomings of the used tool.","Investigating clinical care pathways correlated with outcomesClinical care pathway analysis is the process of discovering how clinical activities impact patients in their care journeys, and uses the discovered knowledge for various applications including the redesign and optimization of clinical pathways. We present an approach for mining clinical care pathways correlated with patient outcomes that involves a combination of clustering, process mining and frequent pattern mining. Our approach is implemented as a set of interactive tools in the business process insight (BPI) platform, a a collaborative software as a service platform, that provides an event-driven process-aware analytics toolset. After interactively utilizing the individual clustering, process mining, and frequent pattern mining capabilities in BPI, users can overlay frequent patterns, ranked according to their correlation with a particular patient outcome, on a mined model of the patient population with that outcome. We have tested our approach for mining care pathways correlated with outcomes on electronic medical record data obtained from a US based healthcare provider on congestive heart failure (CHF) patients. Experimental results show that the tools we have developed and implemented can provide new insights to facilitate the improvement of existing clinical care pathways.","Mergers and collusion in all-pay auctions and crowdsourcing contestsWe study the effects of bidder collaboration in all-pay auctions. We analyse both mergers, where the remaining players are aware of the agreement between the cooperating participants, and collusion, where the remaining players are unaware of this agreement. We examine two scenarios: the sum-profit model where the auctioneer obtains the sum of all submitted bids, and the max-profit model of crowdsourcing contests where the auctioneer can only use the best submissions and thus obtains only the winning bid. We show that while mergers do not change the expected utility of the participants, or the principal's utility in the sum-profit model, collusion transfers the utility from the non-colluders to the colluders. Surprisingly, we find that in some cases such collaboration can increase the social welfare. Moreover, mergers and, curiously, also collusion can even be beneficial to the auctioneer under certain conditions.","Challenges in mobile apps: a multi-disciplinary perspectiveThe popularity of mobile devices, i.e., smart-phones and tablets, has been rapidly growing. These mobile devices run mobile apps. Mobile apps are small software applications that are intended to achieve specific functionalities. For example, some mobile apps are used for gaming; others are used for everyday banking.","Three years of DLMF: web, math and searchDLMF was released to the public in May 2010 and is now completing its 3rd year online. As a somewhat early adopter of largescale MathML content online, and exposing a math-aware search engine to the public, the project encountered situations distinct from those with our previous web sites. In the hopes that our experiences may inform developers of current and future Digital Library projects, we describe some of our observations delivering MathML content and trends in both web usage and browser evolution. We will also look at the the ways our readers have used math search, attempting to assess whether they found what they sought, and ways the engine might be improved.","Skeleton extraction of vertex sets lying on arbitrary triangulated 3d meshesComplex models can be simply described by notions such as skeletons. These robust shape descriptors faithfully characterize the geometry and the topology of an object. Several methods have been developed yet to obtain the skeleton from regular object representations (e.g. 2D images or 3D volumes) but only a few attempt to extract the skeleton from unstructured 3D mesh patches. In this article, we extract a skeleton by topological thinning from vertex sets lying on arbitrary triangulated surface meshes in 3D. The key idea comes down to eroding a 2D set located on a discrete 2-manifold. The main difficulty is to transpose the notion of neighborhood from the classical thinning algorithms where the adjacency is constant (e.g. 26-adjacency in digital volumes, 8-adjacency in 2D images) to the mesh domain where the neighborhood is variable due to the adjacency of each vertex. Thus we propose a thinning operator dedicated to irregular meshes in order to extract the skeleton of a vertex set. To estimate the robustness of our technique, several tests and an application to the feature line detection are presented as a case-study.","A workflow for the prediction of the effects of residue substitution on protein stabilityThe effects of residue substitution in protein can be dramatic and predicting its impact may benefit scientists greatly. Like in many scientific domains there are various methods and tools available to address the potential impact of a mutation on the structure of a protein. The identification of these methods, their availability, the time needed to gain enough familiarity with them and their interface, and the difficulty of integrating their results in a global view where all view points can be visualized often limit their use. In this paper, we present the Structural Prediction for pRotein fOlding UTility System (SPROUTS) workflow and describe our method for designing, documenting, and maintaining the workflow. The focus of the workflow is the thermodynamic contribution to stability, which can be considered as acceptable for small proteins. It compiles the predictions from various sources calculating the \u0394\u0394G upon point mutation, together with a consensus from eight distinct algorithms, with a prediction of the mean number of interacting residues during the process of folding, and a sub domain structural analysis into fragments that may potentially be considered as autonomous folding units, i.e., with similar conformations alone and in the protein body. The workflow is implemented and available online. We illustrate its use with the analysis of the engrailed homeodomain (PDB code 1enh).","Challenges for inclusive affective detection in educational scenariosThere exist diverse challenges for inclusive emotions detection in educational scenarios. In order to gain some insight about the difficulties and limitations of them, we have analyzed requirements, accommodations and tasks that need to be adapted for an experiment where people with different functional profiles have taken part. Adaptations took into consideration logistics, tasks involved and user interaction techniques. The main aim was to verify to what extent the same approach, measurements and technological infrastructure already used in previous experiments were adequate for inducing emotions elicited from the execution of the experiment tasks. In the paper, we discuss the experiment arrangements needed to cope with people with different functional profiles, which include adaptations on the analysis and results. Such analysis was validated in a pilot experiment with 3 visually impaired participants.","k -means clustering on pre-calculated distance-based nearest neighbor search for image searchContent-based image retrieval (CBIR) would be an important future trend in search engines. This paper proposed a nearest neighbor search (NNS) method that uses k-means clustering and pre-calculated distances on a known set of image samples to be used for performing image queries within the set. The proposed algorithm adds a clustering step prior to the rest on an existing algorithm and uses the nearest clusters only for the NNS. The distance between the query images to the cluster is determined by using twice the standard deviation for the clusters to estimate the boundary of each cluster. The feature used is grey-level co-occurrence matrices (GLCM). This reduces both the samples explored by 25.21% and execution time by 26.62% for 16 chosen clusters within 23 clusters and a search radius of 0.2. The experimental results had shown an improvement in time complexity but on the same time sacrifices the hit rate that had dropped from 100% in the previous method that explores all potential samples but the proposed method only manage to achieve 70.77%.","Iterative Super-Resolution for Facial Image by Local and Global RegressionIn this paper, we propose an iterative framework to super-resolve the facial image from a single low-resolution (LR) input. To retrieve local and global information, we first model two linear regressions for the local patch and global face, respectively. In both regression models, we restrict the responses of the regressors under the considerations of facial property and discriminability. Since the responses estimated from the LR training samples can be directly applied to the (high-resolution) HR training ones, the restricted linear regressions essentially describe the desired output. More specifically, the local regression reveals the facial details, and the global regression characterizes the features of overall face. The final results are obtained by alternately using two regressions. Experimental results show the superiority of the proposed method over some state-of-the-art methods.","A Statistical Method for Non-Linear Quantization in Lossy JPEG2000 CompressionThe paper presents a non-linear quantization method for detail components in the JPEG2000 standard. The quantization step sizes are determined by actual statistics of the wavelet coefficients. Mean and standard deviation are the two statistical parameters used to obtain the step sizes. Moreover, weighted mean of the coefficients lying within the step size is chosen as quantized value - contrary to the uniform quantizer. The empirical results are compared using mean squared error of uniformly quantized and non-linearly quantized wavelet coefficients w.r.t. original wavelet coefficients. Through empirical results, it has been concluded that for low bit rate compression, the quantization error introduced by uniform quantizer is higher than that of non-linear quantizer, and thus suggesting the use of non-linear quantizer for low bit rate lossy compression.","Robust Solutions for a Robotic Manipulator Optimization ProblemIn robotics, pose errors are known as positional and rota- tional errors of a given mechanical system. Those errors are commonly produced by the so-called joint clearances, which are the play between pairing elements. Predicting pose errors can be done via the formulation of two optimization models holding continuous domains, which belong to the NP-Hard class of problems. In this paper, we focus on the use of constraint programming in order to provide rigorous and reliable solution to this problem.","Holder and Topic Based Analysis of Emotions on Blog Texts: A Case Study for Bengali ","Developing, Deploying and Evaluating Protocols with ManetLabEvaluating the performance of MANET-specific communication protocols is essential to build robust mobile adi\u00be\u017ahoc applications. Unfortunately, most existing evaluation results are either based on simulations --- which makes it difficult to draw conclusions beyond confined lab settings --- or they are based on custom testbed results --- which makes it difficult to reproduce them. In order to overcome this challenge, we introduce ManetLab, a modular and configurable software framework for creating and running testbeds to evaluate MANET-specific protocols. Withi\u00be\u017aManetLab, one can easily configure and automate reproducible protocol executions on standard computer hardware, and thus provides both the accuracy of testbed-based evaluations and the reproducibility of simulation-based evaluations. After presenting ManetLab's extensible architecture, based on the notion of modular protocol stack, we show how it helps evaluate the performance of different broadcast protocols in real MANETs and how its results compare with simulation-based results.","Image Search Reranking with Semi-supervised LPP and Ranking SVMLearning to rank is one of the most popular ranking methods used in image retrieval and search reranking. However, the high-dimension of the visual features usually causes the problem of \"curse of dimensionality\". Dimensionality reduction is one of the key steps to overcome these problems. However, existing dimensionality reduction methods are typically designed for classification, but not for ranking tasks. Since they do not utilize ranking information such as relevance degree labels, direct utilization of conventional dimensionality reduction methods in ranking applications generally cannot achieve the best performance. In this paper, we study the task of image search reranking, and propose a novel system scheme based on Locality Preserving Projections (LPP) and RankingSVM. And further, in the proposed scheme, we improve LPP by incorporating the relevance degree information into it. Since this kind of method can use the information of labeled and unlabeled data, we name it as semi-supervised LPP (Semi-LPP). Experiments on the popular MSRA-MM dataset demonstrate the superiority of the proposed scheme and Semi-LPP method in image search reranking application.","Analysis of Asymmetric Two-Sided Matching: Agent-Based Simulation with Theorem-Proof ApproachThis paper discusses an extended version of the matching problem which includes the mate search problem; this version is a generalization of a traditional optimization problem. The matching problem is extended to a form of the asymmetric two-sided matching problem. An agent-based simulation model is built and simulation results are presented. Todd and Miller (1999) simulated the two-sided matching problem in a symmetric setting. In his model, there are the same number of agents in both parties (groups), each of whom has his/her own mate value. Each agent in a party tries to find his/her mate in the other party, based on his/her candidate's mate value and his/her own aspiration level for his/her partner's mate value. Each agent learns his/her own mate value and adjusts his/her aspiration level through the trial period (adolescence). Todd and Miller (1999) tried several search rules and learning mechanisms that are symmetric for both parties. In the present paper, Todd and Miller's (1999) model is extended to an asymmetric setting where the two parties have different numbers of agents, and the search rule and the learning mechanism for the two parties differ. Through the simulation, the search rules and the learning mechanisms which were identified to be appropriate in a symmetric setting are revealed to be inappropriate in the asymmetric setting and the reason why this is so is discussed. Furthermore, some general facts are derived using a mathematical theorem-proof approach. Some of these facts are used to direct a revision of the model, and a revised simulation model is presented. An implication is obtained for practical situations in asymmetric matching setting. For example, in the job hunting case, if job applicants want to finish their job hunting successfully, they should be modest at the beginning of the hunt.","New Penalty Scheme for Optimal Subsequence BijectionOptimal Subsequence Bijection OSB is a method that allows comparing two sequences of endnodes of two skeleton graphs which represent articulated shapes of 2D images. The OSB dissimilarity function uses a constant penalty cost for all endnodes not matching between two skeleton graphs; this can be a problem, especially in those cases where there is a big amount of not matching endnodes. In this paper, a new penalty scheme for OSB, assigning variable penalties on endnodes not matching between two skeleton graphs, is proposed. The experimental results show that the new penalty scheme improves the results on supervised classification, compared with the original OSB.","Debate Games in Logic ProgrammingA debate game provides an abstract model of debates between two players based on the formal argumentation framework. This paper presents a method of realizing debate games in logic programming. Two players have their knowledge bases represented by extended logic pro- grams, and build claims using arguments associated with those programs. A player updates its knowledge base with arguments posed by the oppo- nent player, and tries to refute claims by the opponent. During a debate game, a player may claim false or incorrect arguments as a tactic to win the game. The result of this paper provides a new formulation of debate games in a non-abstract argumentation framework associated with logic programming. Moreover, it provides a novel application of logic program- ming to modelling social debates which involve argumentative reasoning, belief update and dishonest reasoning.","Human Body Segmentation with Multi-limb Error-Correcting Output Codes Detection and Graph Cuts Optimization ","Normal Forms for Multiple Context-Free Languages and Displacement Lambek GrammarsWe introduce a new grammar formalism, the displacement context-free grammars, which is equivalent to well-nested multiple context-free grammars. We generalize the notions of Chomsky and Greibach normal forms for these grammars and show that every lan- guage without the empty word generated by a displacement context-free grammar can be also generated by displacement Lambek grammars.","A Short History of VoIP ServicesWhile starting as an experimental research topic in the early seventies VoIP went through different stages before becoming a commodity service competing with the circuit switched telephony and in some cases even replacing it. In this chapter we give a brief overview of the major developments in the area of voice over IP (VoIP) and look at the major milestones and competing standards. We further give a short look into the latest developments and recent applications and deployment scenarios.","Neural Network Development and Training for the Simulation of Dynamic Robot Movement Behavior ","An Application of Software Fault Injection for Assessment of Quality of Test Sets for Business Processes Orchestrating Web-Services ","The Modelling of Glaucoma Progression through the Use of Cellular AutomataWe propose a model of glaucoma progression based on the application of Cellular Automata CA to visual field VF data, obtained through automated perimetry. VF sensitivities are converted into ganglion cell loss and CA are utilised to model the gradual deterioration of vision, mimicking degeneration of the actual ganglia. First we discuss the construction of a grid that approximates the VF map and the corresponding layer of ganglia in terms of cell counts in individual fields. The grid is populated with dead cells in accordance with patients' tests, and then we run a CA, utilising a majority and a probabilistic rule. Preliminary results are presented, showing that during its evolution, the CA often converges to configurations where the death of cells resembles VF data of the same patients, at later time. That is, the percentage loss of cells in VF fields observed in the CA resembles the real VF data.","Single Camera Railways Track Profile Inspection Using an Slice Sampling-Based Particle Filter ","Human Action Recognition Using Temporal Segmentation and Accordion Representation ","On the Duality of E-Participation --- Towards a Foundation for Citizen-Led ParticipationWhat remains unclear after a decade of e-Participation research and practice is the extent to which the social web and informal channels have empowered citizens in government-citizen interactions where government determines what, where and how to discuss. Lately, attention has shifted to how these informal channels could be better harnessed as part of a holistic e-Participation solution. However, this implicit notion of duality of e-Participation is yet to be explored or conceptualized. This paper provides a first step towards understanding the duality of Government-led and Citizen-led e-Participation based on structuration and dynamic capabilities theories. We employ structuration theory to understand how dynamics of power between government and citizen in deciding what is important for the society and the solutions to adopt could tilt towards the side of citizens through citizen-led deliberations. Through the dynamic capabilities theory, we determine additional capabilities required by governments to meaningfully exploit and sustain citizen-led e-participation as a part or a holistic e-participation framework. We show through a case study how our resulting analytical tool could be employed in identifying salient technical, organisational and political issues in an on-going Irish e-Participation initiative planning to adopt citizen-led deliberation.","Realistic Roofs over a Rectilinear Polygon RevisitedA common task in automatically reconstructing a three di- mensional city model from its two dimensional map is to compute all the possible roofs over the ground plans. A roof over a simple polygon in the xy-plane is a terrain over the polygon such that each face f of the terrain is supported by a plane passing through at least one polygon edge and making a dihedral angle \u03c0 with the xy-plane (3). This defini- tion, however, allows roofs with faces isolated from the boundary of the polygon and local minimum edges inducing pools of rainwater. Recently, Ahn et al. (1,2) introduced \"realistic roofs\" over a simple rectilinear poly- gon P with n vertices by imposing two additional constraints under which no isolated faces and no local minimum vertices are allowed. Their defi- nition is, however, too restrictive that it excludes a large number of roofs with no local minimum edges. In this paper, we propose a new definition of realistic roofs corresponding to the class of roofs without isolated faces and local minimum edges. We investigate the geometric and combina- torial properties of realistic roofs and show that the maximum possible number of distinct realistic roofs over P is at most 1.3211 m m \ufffd m 2 \ufffd ,w here m = n\u2212 4 2 . We also present an algorithm that generates all combinatorial representations of realistic roofs.","Efficient Mixed-Norm Regularization: Algorithms and Safe Screening MethodsSparse learning has recently received increasing attention in many areas including machine learning, statistics, and applied mathematics. The mixed-norm regularization based on the l1q norm with q&gt;1 is attractive in many applications of regression and classification in that it facilitates group sparsity in the model. The resulting optimization problem is, however, challenging to solve due to the inherent structure of the mixed-norm regularization. Existing work deals with special cases with q=1, 2, infinity, and they cannot be easily extended to the general case. In this paper, we propose an efficient algorithm based on the accelerated gradient method for solving the general l1q-regularized problem. One key building block of the proposed algorithm is the l1q-regularized Euclidean projection (EP_1q). Our theoretical analysis reveals the key properties of EP_1q and illustrates why EP_1q for the general q is significantly more challenging to solve than the special cases. Based on our theoretical analysis, we develop an efficient algorithm for EP_1q by solving two zero finding problems. To further improve the efficiency of solving large dimensional mixed-norm regularized problems, we propose a screening method which is able to quickly identify the inactive groups, i.e., groups that have 0 components in the solution. This may lead to substantial reduction in the number of groups to be entered to the optimization. An appealing feature of our screening method is that the data set needs to be scanned only once to run the screening. Compared to that of solving the mixed-norm regularized problems, the computational cost of our screening test is negligible. The key of the proposed screening method is an accurate sensitivity analysis of the dual optimal solution when the regularization parameter varies. Experimental results demonstrate the efficiency of the proposed algorithm.","A Dependency-Inspired Semantic Evaluation of Machine Translation SystemsThe goal of translation is to preserve the original text meaning. However, lexical-based machine translation MT evaluation metrics count the similar terms in MT output with the human translated reference rather than measuring the similarity in meaning. In this paper, we developed an MT evaluation metric to assess the output of MT systems, semantically. Inspiring by the dependency grammar, we consider to what extent the headword and its dependents contribute in preserving the meaning of the original input text. Our experimental results show that this metric is significantly better correlated with human judgment.","Continuous Release Planning in a Large-Scale Scrum Development Organization at EricssonScrum development at large-scale requires a release planning process that supports the agile way of working and planning. Most of the existing release planning processes are plan-driven and ill suited for a large Scrum organization. This case study describes how release plan- ning was conducted in a 350-person Scrum development organization with over 20 teams at Ericsson in 2011, and the related challenges and benefits. Data was collected with 39 interviews which were transcribed, coded and analysed. The release planning process was continuous and characterized by regular scoping and prioritization decisions, and by in- cremental elaboration of features. The challenges were the overcommit- ment caused by external pressure, managing non-feature specific work, and balancing between development efficiency and building generalist teams. The benefits were the increased flexibility and decreased develop- ment lead time, waste eliminated in the planning process, and increased developer motivation.","Detecting Emergent Behavior in a Social Network of Agents ","Random Key and Key Dependent S-box Generation for AES Cipher to Overcome Known Attacks ","The Antecedents And Outcomes Of Brand Experience On The Social Networking Site ","Facial Expressions and Gestures to Convey Emotions with a Humanoid RobotThis paper presents the results of a perceptual study with ZECA (Zeno Engaging Children with Autism), a robot able to display facial expressions. ZECA is a robotic tool used to study human-robot interactions with children with Autism Spectrum Disorder. This study describes the first steps towards this goal. Facial expressions and gestures conveying emotions such as sadness, happiness, or surprise are displayed by the robot. The design of the facial expressions based on action units is presented. The participants answered a questionnaire intended to verify if these expressions with or without gestures were recognized as such in the corresponding video. Results show that participants were successfully able to recognize the emotion featured in the corresponding video, and the gestures were a valuable addition to the recognition.","Sparse Coding Neural Gas Applied to Image Recognition ","Ranking factors of team successAs an increasing number of human activities are moving to the Web, more and more teams are predominantly virtual. Therefore, formation and success of virtual teams is an important issue in a wide range of fields. In this paper we model social behavior patterns of team work using data from virtual communities. In particular, we use data about the Web community of the multiplayer online game Dota 2 to study cooperation within teams. By applying statistical analysis we investigate how and to which extent different factors of the team in the game, such as role distribution, experience, number of friends and national diversity, have an influence on the team's success. In order to complete the picture we also rank the factors according to their influence. The results of our study imply that cooperation within the team is better than competition.","User acceptance of a community-based healthcare information system preserving user privacyCommunity-based healthcare information systems (HIS) are developed to cope with the demand for home healthcare. However, the issue of privacy protection in HIS adoption has not been given sufficient attention. This study is to propose a privacy-enhanced framework and to investigate the role of privacy protection in HIS adoption. Our research model extends the unified theory of acceptance and use of technology by considering perceived security and information security literacy. Our experimental HIS is implemented according to our proposed privacy-enhanced framework which integrates healthcare applications and privacy protection mechanisms. The former includes health management, physiological monitoring, healthcare education, and healthcare consulting modules. The latter contains secure transmission, privacy protection and access control modules. Analyses indicate that user adoption of HIS is directly affected by social influence, performance expectancy, facilitating conditions, and perceived security. Perceived security has a mediating effect between information security literacy and user adoption.","Motor expressions as creativity support: exploring the potential for physical interactionThis research explores the effects of physical interactions designed on the basis of motor expressions to support creative ideation in creativity support technologies. The presented research looks into the effects on creative ideation of incompatibility between motor expressions and problem situations, and appraisals of (un)pleasantness. We report the results of a preliminary study which suggests that affective incompatibility between a problem situation and a motor expression benefits creative ideation, and that pleasantness motor expressions enhance task enjoyment, which in turn leads to a beneficial effect on the originality of ideas generated. Based on these results, we conclude with two new directions for the design of physical interactions with novel creativity support technologies.","Toward Robust and Fast Two-Dimensional Linear Discriminant AnalysisThis paper presents an approach toward robust and fast Two-Dimensional Linear Discriminant Analysis (2DLDA). 2DLDA is an extension of Linear Discriminant Analysis (LDA) for 2-dimensional objects such as images. Linear transformation matrices are iteratively calculated based on the eigenvectors of asymmetric matrices in 2DLDA. However, repeated calculation of eigenvectors of asymmetric matrices may lead to unstable performance. We propose to use simultaneous diagonalization of scatter matrices so that eigenvectors can be stably calculated. Furthermore, for fast calculation, we propose to use approximate decomposition of a scatter matrix based on its several leading eigenvectors. Preliminary experiments are conducted to investigate the effectiveness of our approach. Results are encouraging, and indicate that our approach can achieve comparative performance with the original 2DLDA with reduced computation time.","Endogenous boolean gamesIn boolean games players exercise control over propositional variables and strive to achieve a goal formula whose realization might require the opponents' cooperation. Recently, a theory of incentive engineering for such games has been devised, where an external authority steers the outcome of the game towards certain desirable properties consistent with players' goals, by imposing a taxation mechanism on the players that makes the outcomes that do not comply with those properties less appealing to them. The present contribution stems from a complementary perspective and studies, instead, how boolean games can be transformed from inside, rather than from outside, by endowing players with the possibility of sacrificing a part of their payoff received at a certain outcome in order to convince other players to play a certain strategy. What we call here endogenous boolean games (EBGs) boils down to enriching the framework of boolean games with the machinery of side payments coming from game theory. We analyze equilibria in EBGs, showing the preconditions needed for desirable outcomes to be achieved without external intervention. Finally, making use of taxation mechanism, we show how to transform an EBG in such a way that desirable outcomes can be realized independently of side payments.","GPU-Accelerated Collocation Pattern DiscoveryCollocation Pattern Discovery is a very interesting field of data mining in spatial databases. It consists in searching for types of spatial objects that are frequently located together in a spatial neighborhood. Application domains of such patterns include, but are not limited to, biology, geography, marketing and meteorology. To cope with processing of these huge volumes of data programmable high-performance graphic cards GPU can be used. GPUs have been proven recently to be extremely efficient in accelerating many existing algorithms. In this paper we present GPU-CM, a GPU-accelerated version of iCPI-tree based algorithm for the collocation discovery problem. To achieve the best performance we introduce specially designed structures and processing methods for the best utilization of the SIMD execution model. In experimental evaluation we compare our GPU implementation with a parallel implementation of iCPI-tree method for CPU. Collected results show order of magnitude speedups over the CPU version of the algorithm.","Design Considerations for Leveraging Over-familiar Items for Elderly Health MonitorsJapan is facing the phenomenon of an aging population. Elderly individuals in Japan are becoming increasingly isolated, with no one to look after him or her as the elderly individual's health deteriorates. To prevent this decline in elderly individuals, the Japanese government has been introducing various devices to monitor the health of elderly individuals. However, existing products in Japan do not fully address customer needs because they focus solely on functionality. As a result, elderly individuals that do not depend on monitoring may find the system too inconvenient. However, it is still important for elderly individuals in good health to be monitored to identify risks and prevent a decline in health. Therefore, health monitor designers must reduce the inconvenience to the user caused by systems that monitor elderly individuals.","Back to User-Centered Usability TestingUsability testing is a widely used evaluation method for product de- sign during and after the development. Conventional usability testing applies short and discrete test tasks and task scenarios that are based on the tasks the product is designed to support. Thus, conventional test task design relies heavi- ly on the representations of the specified context of use and the specified user requirements of the proposed design solution. However, a premature commit- ment to the specified context, requirements and proposed solutions may limit the scope of usability testing in a manner that hinders its capability to elicit and validate new user requirements, which is one of the objectives of the evaluation phase in the iterative user-centered design process. In this paper, we introduce a user-centered task design approach, which allows test participants to follow their natural work flow and freely express their needs during a test session. The main idea of this open-ended task approach is to break the tight link between the produced design solutions and the tasks used in the usability test and in this way increase the probability that novel user needs can emerge during a test ses- sion. Empirical results from a case study are used to depict the approach and its prerequisites, strengths, and limitations are discussed.","Throwing Skill Optimization through Synchronization and Desynchronization of Degree of FreedomHumanoid robots have a large number of degrees of freedom (DoFs), therefore motor learning by such robots which explore the optimal parameters of behaviors is one of the most serious issues in humanoid robotics. In contrast, it has been suggested that humans can solve such a problem by synchronizing many body parts in the early stage of learning, and then desynchronizing their movements to optimize a behavior for a task. This is called as \"Freeze and Re- lease.\" We hypothesize that heuristic exploration through synchronization and desynchronization of DoFs accelerates motor learning of humanoid robots. In this paper, we applied this heuristic to a throwing skill learning in soccer. First, all motors related to the skill are actuated in a synchronized manner, thus the robot explores optimal timing of releasing a ball in one-dimensional search space. The DoFs are released gradually, which allows to search for the best timing to actuate the motors of all joints. The real robot experiments showed that the exploration method was fast and practical because the solution in low-dimensional subspace was approximately optimum.","Think Individually, Act Collectively: Studying the Dynamics of a Technologically Enabled Civic MovementFCT via Bolsa de Doutoramento SFRH/BD/60838/2009 and also support of Fundos Feder-COMPETE and FCT via FCOMP-01-0124-FEDER022674","Algorithms for In-Place Matrix TranspositionThis paper presents an implementation of an in-place swap- based algorithm for transposing rectangular matrices, and a proof of correctness is also sketched. The implementation is based on an algorithm described by Tretyakov and Tyrtyshnikov (4), but we have introduced a number of variations. In particular, we show how the original algorithm can be modified to require constant additional memory. We also identify opportunities for exploiting parallelism.","Towards a Wearable Coach: Classifying Sports Activities with Reservoir Computing ","Using the Bhattacharyya Mean for the Filtering and Clustering of Positive-Definite Matrices ","Solving Google's Continuous Audio CAPTCHA with HMM-Based Automatic Speech RecognitionCAPTCHAs play critical roles in maintaining the security of various Web services by distinguishing humans from automated programs and prevent- ing Web services from being abused. CAPTCHAs are designed to block auto- mated programs by presenting questions that are easy for humans but difficult for computers, e.g., recognition of visual digits or audio utterances. Recent audio CAPTCHAs, such as Google's audio reCAPTCHA, have presented overlapping and distorted target voices with stationary background noise. We investigate the security of overlapping audio CAPTCHAs by developing an audio reCAPTCHA solver. Our solver is constructed based on speech recognition techniques using hidden Markov models (HMMs). It is implemented by using an off-the-shelf li- brary HMM Toolkit. Our experiments revealed vulnerabilities in the current ver- sion of audio reCAPTCHA with the solver cracking 52% of the questions. We further explain that background stationary noise did not contribute to enhance security against our solver.","How e-inclusion and innovation policy affect digital access and use for senior citizens in europeResearch on e-inclusion and innovation policy on a national and supra-national (European Union) level not always shows to what extent successful e-inclusion and innovation policy have been pursued. Therewithal the aims of national e-inclusion and innovation strategies do not always coincide with the aims of the European Commission. Policies with regard to active aging and senior citizens' participation in the information society on the one hand and local, regional or national initiatives and policy on the other hand might hence be different from the European level. We discuss how e-inclusion and digital access of and use by senior citizens became an important topic in Europe and European policy. We propose not only to focus on a top-down (policy) approach but also a bottom-up approach, where local, regional or national initiatives alongside policy are included in the assessment. We will discuss this on the basis of a literature research together with case studies of The Netherlands and Estonia.","Enhancing Rough Clustering with Outlier Detection Based on Evidential ClusteringSoft clustering plays an important role in many real world applications. Fuzzy clustering, rough clustering, evidential clustering and many other approaches are used effectively to overcome the rigidness of crisp clustering. Each approach has its own unique features that set it apart from others. In this paper, we propose an enhanced rough clustering approach by combining the strengths of rough clustering and evidential clustering. The rough K-means algorithm is augmented with an ability to determine outliers in datasets using the concepts from the Evidential c-means algorithm. Different experiments are carried on various datasets and it is found that the modified rough K-means can effectively detect outliers with relatively smaller computational complexity.","ManyClaw: Slicing and dicing Riemann solvers for next generation highly parallel architecturesNext generation computer architectures will include order of magnitude more intra-node parallelism; however, many application programmers have a difficult time keeping their codes current with the state-of-the-art machines. In this context, we analyze Hyperbolic PDE solvers, which are used in the solution of many important applications in science and engineering. We present ManyClaw, a project intended to explore the exploitation of intra-node parallelism in hyperbolic PDE solvers via the Clawpack software package for solving hyperbolic PDEs. Our goal is to separate the low level parallelism and the physical equations thus providing users the capability to leverage intra-node parallelism without explicitly writing code to take advantage of newer architectures.","Self-Organized Functional Hierarchy Through Multiple Timescales: Neuro-dynamical Accounts for Behavioral Compositionality ","Leveraging online courses to increase student success in a Computer Science degreeThis paper looks at how courses by experts that are available on the internet can be used to enhance student understanding of Computer Science prior to them entering or during their first year of study at a university. A secondary school exit skill-set is proposed which is based on existing secondary school curricula and studies that have recently been conducted.#R##N##R##N#A selection of online courses from the internet is proposed in order to help students succeed in Computer Science at university. These courses are selected by taking the secondary school skill-set into account as well as the pedagogical setting of the course.","An ET-Based Low-Level Solution for Query-Answering ProblemsQuery-answering QA problems have attracted wider attention in recent years. Methods for solving QA problems based on the equivalent transformation ET principle have been recently developed. Meanwhile efficient satisfiability solvers SAT solvers have been invented and successfully applied to many kinds of problems. In this paper, we propose an ET-based low-level solution for QA problems. By slightly modifying it, we also propose a low-level solution using an all-solution SAT solver. We show that the obtained SAT-solver-based solution can also be seen as another ET-based low-level solution. Our findings clarify that the ET principle supports not only high-level computation but also low-level computation, and it provides a formal basis for correctness verification of computation in both levels.","Abnormality detection in multiagent systems inspired by the adaptive immune systemFault tolerance is one of the most prominent challenges in the field of multirobot systems. The efficient and long term operation of a robot collective requires an accurate detection and accommodation of abnormally behaving robots. Most of the existing fault tolerant systems prescribe a characterization of normal behavior, and train a model to recognize them. Behaviors not recognized by the model are labelled abnormal. However, these models require a priori knowledge of the normal behavior. Furthermore, multirobot systems employing these models do not transition well to scenarios involving temporal changes to normal behavior. We propose to address this challenging problem by taking inspiration from the regulation of tolerance and (auto)immunity in the adaptive immune system. We adopt the Crossregulation model, used to explain the robust immunological maintenance of tolerance, and deploy it within a multiagent system. Results of extensive simulation-based experiments demonstrate that a distributed multiagent system can detect abnormalities under varying conditions of normal behaviors. The collective dynamics gives rise to a meaningful normal-abnormal classification of the behavior by individual agents, even if these categories were not prescribed a priori in the agents.","Modeling 4D Changes in Pathological Anatomy Using Domain Adaptation: Analysis of TBI Imaging Using a Tumor DatabaseAnalysis of 4D medical images presenting pathology (i.e., lesions) is significantly challenging due to the presence of complex changes over time. Image analysis methods for 4D images with lesions need to account for changes in brain structures due to deformation, as well as the formation and deletion of new structures (e.g., edema, bleeding) due to the physiological processes associated with damage, intervention, and recovery. We propose a novel framework that models 4D changes in pathological anatomy across time, and provides explicit mapping from a healthy template to subjects with pathology. Moreover, our framework uses transfer learning to leverage rich information from a known source domain, where we have a collection of completely segmented images, to yield effective appearance models for the input target domain. The automatic 4D segmentation method uses a novel domain adaptation technique for generative kernel density models to transfer information between different domains, resulting in a fully automatic method that requires no user interaction. We demonstrate the effectiveness of our novel approach with the analysis of 4D images of traumatic brain injury (TBI), using a synthetic tumor database as the source domain.","Improving Recommender Systems with Simplification Logic to Manage Implications with Grades ","An Agent-Based Approach for Efficient Energy Management in the Context of Smart HousesTraditional power systems are centralized systems that sup- ply electricity to end users through unidirectional transmission and dis- tribution networks. The heterogeneity of renewable energy sources has introduced complexity in the transmission and distribution of electricity. Thus, intelligent distributed coordination and real-time information is needed to ensure that the electricity infrastructure will run efficiently in the future. This information enables the grid to meet the challenge of balancing supply and demand by actively sensing and responding to fluc- tuations in power demand, supply, and costs. In the near future, smart homes will be able to exchange energy, to sell to or buy from different actors available in the market. These new changes will introduce a soft competition in the market where each user will try to get lower contract prices according to his needs. In order to respond to the user's needs while integrating new sources of energy, we propose an agent-based approach for optimizing energy consumption. We present the agents' interactions that aim to procure energy for household activities at a suitable price to satisfy the user's needs. The results showed that these strategies can lead to a more environmental friendly, responsible, and efficient way to consume and distribute energy.","Motif Identification Based on Local Structure Clustering ","Introducing Probabilities in Contract-Based Approaches for Mobile Application SecuritySecurity for mobile devices is a problem of capital importance, especially due to new threats coming from malicious applications. This has been proved by the increasing interest of the research community on the topic of security on mobile devices. Several security solutions have been recently proposed, to address the uprising threats coming from malicious applications. However, several mechanisms may result not flexible enough, hard to apply, or too coarse grained, e.g. several critics have been raised against the Android permission system.#R##N##R##N#We argue that, it is possible to obtain more flexible security tools and finer grained security requirements by introducing probability measurements.#R##N##R##N#In this paper we discuss how to introduce probabilistic clauses into the Security-by-Contract and the Security-by-Contract-with-Trust frameworks, revising the main building blocks and providing tools to write probabilistic contracts and policies. A proof-of-concept implementation on Android system has also been presented.","Binary coded output support vector machineTo solve multi-class classification problems for large-scale datasets, the authors propose a coded output support vector machine (COSVM) by introducing the idea of information coding. The COSVM is built based on the support vector regression (SVR) machine that is implemented by the sequential minimal optimization (SMO) algorithm. The paper first introduces the soft e-tube SVR's basic principles, next gives the idea and procedure of the SMO algorithm, and then illustrates the COSVM's topology. For studying the parameters impact on the binary COSVM's performance, we perform two experiments with the Character Trajectories dataset, in which output labels are coded with the binary number system. And some useful results are obtained in these experiments. The final section gives a conclusion and further research ideas.","Proposal of Cost-Effective Tenant-Based Resource Allocation Model for a SaaS SystemSoftware-as-a-Service (SaaS) is a software distribution paradigm in cloud computing and represents the highest, software layer in the cloud stack. Since most cloud services providers charge for the resource use it is important to create resource efficient applications. One of the ways to achieve that is multi-tenant architecture of SaaS applications. It allows the application for effi- cient self-managing of the resources. In this paper the influence of tenant-based resource allocation model on cost-effectiveness of SaaS systems is investigated. The tenant-based resource allocation model is one of the methods to tackle under-optimal resource utilization. When compared to traditional resource scaling it can reduce the costs of running SaaS systems in cloud environments. The more tenant-oriented the SaaS systems are the more benefits that model can provide.","Model-Guided Directional Minimal Path for Fully Automatic Extraction of Coronary Centerlines from Cardiac CTAExtracting centerlines of coronary arteries is a challenging but important task in clinical applications of cardiac CTA. In this pa- per, we propose a model-guided approach, the directional minimal path, for the centerline extraction. The proposed method is based on the min- imal path algorithm and a prior coronary model is used. The model is first registered to the unseen image. Then, the start point and end point for the minimal path algorithm are provided by the model to automate the centerline extraction process. Also, the direction information of the coronary model is used to guide the path tracking of the minimal path procedure. This directional tracking improves the robustness and accu- racy of the centerline extraction. Finally, the proposed method can auto- matically recognize the branches of the extracted coronary artery using the prior information in the model. We validated the proposed method by extracting the three main coronary branches. The mean accuracy of the 56 cases was 1.32\u00b10.81 mm and the detection ratio was 88.7%.","Information Technology and Firm Profitability in Network Environments. ","A Morphologic Analysis of Cirrhotic Liver in CT ImagesCirrhosis will cause significant morphological changes on both liver and spleen. In this paper, we constructed not only the liver statistical shape models (SSM), but also the spleen SSM and a joint SSM of the liver and the spleen for a morphologic analysis of the cirrhotic liver in CT images. We also proposed a mode selection method based on both its accumulation contribution rate and its correlation with doctor's opinions (labels). The classification performance for normal and abnormal livers is significantly improved by our proposed method. The classification accuracies for normal and cirrhotic livers are 88% and 90%, respectively.","Creating Integrated Evidence Graphs for Network Forensics ","Toward the Revision of CTL Models through Kripke Modal Transition SystemsIn this paper we consider the problem of automatic repair of models in the context of system partial specification. This problem is a challenge involving theoretical and practical issues and the theory of belief revision is an alternative to give theoretical support to its so- lution. A Kripke structure is widely used to model systems, but it does not express partial information explicitly and a set of these structures might be required to represent several possibilities of behavior. A more general structure is the Kripke Modal Transition System (KMTS) which can specify systems with partial information and can be interpreted as a set of Kripke models. In this paper, we propose a framework for the repair of KMTS based on belief revision combined with model check- ing as an approach to revise sets of Kripke structures. We demonstrate the advantages of our approach, even with the existing restrictions in representing general sets of CTL models over the KMTS formalism.","Tree-Based Mining for Discovering Patterns of Reposting Behavior in Microblog ","An Automated Visual Inspection System for the Classification of the Phases of Ti-6Al-4V Titanium AlloyAbstract. Metallography is the science of studying the physical properties of metal microstructures, by means of microscopes. While traditional approaches involve the direct observation of the acquired images by human experts, Com-puter Vision techniques may help experts in the analysis of the inspected mate-rials. In this paper we present an automated system to classify the phases of a Titanium alloy, Ti-6Al-4V. Our system has been tested to analyze the final products of a Friction Stir Welding process, to study the states of the micro-structures of the welded material. Keywords: Titanium, Ti-6Al-4V, Metallography, Computer Vision, Automated Visual Inspection, SVM, Texture. 1 Introduction and Previous Works In an a industrial workflow, visual inspection and quality control of the manufacturing process, until to the end product, are traditionally performed by human experts. Even if usually the human expertise works better than a machine application, it is much slower and more expensive. Moreover, in certain applications human inspection is tedious (repetitive actions) or dangerous (e.g. underwater inspection, nuclear or chem-ical industry, etc.). Computer vision is an effective solution in such cases [1]. In this work we focused on a specific field of the industrial engineering: metallo-graphy, that is the study of the physical properties of metals, by optical and electron microscopy. One of the aims of metallography is to study the microstructures of an inspected metal, under certain working conditions. According to metallography, struc-tures which are coarse enough to be discernible by the naked eye or under low magni-fications are termed","GLUEPS-AR: A System for the Orchestration of Learning Situations across Spaces Using Augmented RealityUbiquitous and mobile learning scenarios define activities happening within and beyond the walls of a classroom. However, the orchestration of authentic learning situations involving both physical and virtual spaces is still a significant challenge for teachers. Several proposals recently reported in the literature try to reduce teachers' orchestration burden by means of authoring tools, and usage of Augmented Reality technologies for connecting physical and virtual spaces. However, these proposals are restricted to specific technologies, pedagogies, or to a very limited range of activities. We present GLUEPSAR, a system to aid teachers in the orchestration of across-spaces learning situations. With GLUEPS-AR, learning designs defined with multiple authoring tools can be deployed and managed at run-time throughout ubiquitous learning environments composed by different VLEs, Web 2.0 tools and AR applications. Thus, GLUEPS-AR allows multiple design and enactment technologies, and a wide range of learning activities, not restricted to a single pedagogy.","Linear Kalman Filter for Dead Time Affected Measurement Signals Implemented in a Small Scale Automated Guided Vehicle ","Semi-automated Prototyping of a TPM v2 Software and Hardware Simulation Platform ","A Modular Approach for Reusing Formalisms in Verification Tools of Concurrent SystemsOver the past two decades, numerous verification tools have been successfully used for verifying complex concurrent systems, modelled using various formalisms. However, it is still hard to coordinate these tools since they rely on such a large number of formalisms. Having a proper syntactical mechanism to interrelate them through variability would increase the capability of effective integrated formal methods. In this paper, we propose a modular approach for defining new formalisms by reusing existing ones and adding new features and/or constraints. Our approach relies on standard XML technologies; their use provides the capability of rapidly and automatically obtaining tools for representing and validating models. It thus enables fast iterations in developing and testing complex formalisms. As a case study, we applied our modular definition approach on families of Petri nets and timed automata.","Multiresolution Hierarchical Shape Models in 3D Subcortical Brain StructuresPoint Distribution Models (PDM) are one of the most exten- ded methods to characterize the underlying population of set of samples, whose usefulness has been demonstrated in a wide variety of applications, including medical imaging. However, one important issue remains unsol- ved: the large number of training samples required. This problem becomes critical as the complexity of the problem increases, and the modeling of 3D multiobjects/organs represents one of the most challenging cases. Based on the 3D wavelet transform, this paper introduces a multiresolution hier- archical variant of PDM (MRH-PDM) able to efficiently characterize the different inter-object relationships, as well as the particular locality of each element separately. The significant advantage of this new method over two previous approaches in terms of accuracy has been successfully verified for the particular case of 3D subcortical brain structures.","Understanding Vertical Scalability of I/O Virtualization for MapReduce Workloads: Challenges and Opportunities ","Optimizing Nop-shadows Typestate Analysis by Filtering Interferential ConfigurationsNop-shadows Analysis (NSA) is an efficient static typestate analysis, which can be used to eliminate unnecessary monitoring instru- mentations for runtime monitors. In this paper, we propose two opti- mizations to improve the precision of NSA. Both of the optimizations filter interferential configurations when determining whether a monitor- ing instrumentation is necessary. We have implemented our optimization methods in Clara and conducted extensive experiments on the DaCapo benchmark. The experimental results indicate that the optimized NSA can further remove unnecessary instrumentations after the original NSA in more than half of the cases, without a significant overhead. In addi- tion, for two cases, all the instrumentations are removed, which implies the program is proved to satisfy the typestate property.","Infrastructure for Efficient Exploration of Large Scale Linked Data via Contextual Tag CloudsIn this paper we present the infrastructure of the contextual tag cloud system which can execute large volumes of queries about the number of instances that use particular ontological terms. The contextual tag cloud system is a novel application that helps users explore a large scale RDF dataset: the tags are ontological terms (classes and properties), the context is a set of tags that defines a subset of instances, and the font sizes reflect the number of instances that use each tag. It visualizes the patterns of instances specified by the context a user constructs. Given a request with a specific context, the system needs to quickly find what other tags the instances in the context use, and how many instances in the context use each tag. The key question we answer in this paper is how to scale to Linked Data; in particular we use a dataset with 1.4 billion triples and over 380,000 tags. This is complicated by the fact that the calculation should, when directed by the user, consider the entailment of taxonomic and/or domain/range axioms in the ontology. We combine a scalable preprocessing approach with a specially-constructed inverted index and use three approaches to prune unnecessary counts for faster intersection computations. We compare our system with a state-of-the-art triple store, examine how pruning rules interact with inference and analyze our design choices.","Joins: a case study in modular specification of a concurrent reentrant higher-order libraryWe present a case study of formal specification for the C$^\\sharp$ joins library, an advanced concurrent library implemented using both shared mutable state and higher-order methods. The library is specified and verified in HOCAP, a higher-order separation logic extended with a higher-order variant of concurrent abstract predicates.","Automated Addition of Fault-Tolerance under Synchronous SemanticsWe focus on the problem of automated model repair for synchronous systems. Model repair focuses on revising a model, so that it satisfies a new property while preserving its existing properties. While the problem of model repair has been studied previously in the context of interleaving semantics, we argue that the corresponding solutions are not applicable for several problems encountered in embedded systems. Specifically, in interleaving semantics, only one of the components executes in a given step. On the contrary, in many commonly considered distributed embedded systems, several components can execute synchronously.#R##N##R##N#We present a polynomial-time sound and complete algorithm for repairing models in synchronous semantics (also called maximum parallelism semantics). We show that our approach allows us to design fault-tolerant systems, where after the occurrence of faults, the system recovers to its normal behavior within a given number of steps. We illustrate our approach by synthesizing a fault-tolerant group membership protocol and a protocol for cache coherence.","An adaptive bat algorithmAfter analyzing the deficiencies of bat algorithm (BA), we proposed an improved bat algorithm called an adaptive bat algorithm(ABA). In the ABA, each bat can dynamic and adaptively adjust its flight speed and its flight direction while it is searching for food, and makes use of the hunting approach of combining random search with shrinking search. The experimental results show that the ABA not only has marked advantage of global convergence property but also can effectively avoid the premature convergence problem.","Participatory interaction design for the healthcare service fieldInnovative service operations in the healthcare field should be cooperative and proactive. However, this is often difficult because separate providers have different ideas and backgrounds and little information of others' practices. For example, we found that workers in a care facility share one notebook for communication and have no incentive to improve the workflow. We also observed that most point-of-care system PDAs in a hospital were not being used to record and share information by the nurses, mainly because the system interface impeded their workflow. In addition, members of a dance sports circle, who want to improve their health, are inactive because of a lack of support. Such healthcare communities should be encouraged to be proactive and collaborate in solving problems. Participatory interaction design is important for this purpose, and so an activity methodology combined with technical systems should be developed. This paper proposes three steps towards participatory interaction design and describes a prototype of the methodology.","Who are seeking friends? the portrait of stranger-seeker in social network sitesWe aim to understand the stranger seeking behaviors on Social Network Sites (SNSs) and learn about the characteristics of these people who frequently seek strangers (stranger-seeker). By conducting two surveys, we obtain an overall acknowledgement of stranger seeking behavior and give a portrait of stranger-seekers in social network sites. We find: stranger-seekers are extroversive, narcissism, in poor family relationship, motivated to seek belongingness, but without a larger proportion of strange friends. This finding may contribute to personal attractiveness oriented online product design.","Knowledge Acquisition Activity in Software Development ","Towards a theory of interface-based design of hierarchical reactive systemsThis paper presents a formal methodology for hierarchical interface-based design of component-based reactive automation systems with behavioral contracts. Based on seminal work of de Alfaro and Henzinger, a hierarchical component approach with behavioral interface contracts and verification methods for checking that components fulfill specified contracts is presented. In contrast to other approaches, components form a strict hierarchical structure of upper and sub-ordinate components. We discuss different questions which arise in such settings and present formal methods to answer those. Moreover, as an extension of the interface-based design methodology, a method is introduced which allows deriving the externally observable behavior of a component as a structure-preserving abstraction.","Application of Social Network Metrics to a Trust-Aware Collaborative Model for Generating Personalized User Recommendations ","Processing Ubiquitous Personal Event Streams to Provide User-Controlled SupportThe increase in use of smart devices nowadays provides us with a lot of personal data and context information. In this paper we describe an approach which allows users to define and register rules based on their personal data ac- tivities in an event processor, which continuously listens to perceived context data and triggers any satisfied rules. We describe the Rule Management Ontology (DRMO) as a means to define rules using a standard format, whilst providing a scalable solution in the form of a Rule Network Event Processor which detects and analyses events, triggering rules which are satisfied. Following an evalua- tion of the network v.s. a simplistic sequential approach, we justify a trade-off between initialisation time and processing time.","Multi-regularization for Fuzzy Co-clusteringCo-clustering is a powerful technique with varied applications in text clustering and recommender systems. For large scale high dimensional and sparse real world data, there is a strong need to provide an overlapped co-clustering algorithm that mitigates the effect of noise and non-discriminative information, generalizes well to the unseen data, and performs well with respect to several quality measures. In this paper, we introduce a novel fuzzy co-clustering algorithm that incorporates multiple regularizers to address these important issues. Specifically, we propose MRegFC that considers terms corresponding to Entropy, Gini Index, and Joint Entropy simultaneously. We demonstrate that MRegFC generates significantly higher quality results compared to many existing approaches on several real world benchmark datasets.","Learner Experiences and Perceptions of Using Social Media Tools in Formal Workplace Learning ","A Network-Controlled Approach for the Timely and Reliable Acquisition of Bursty Data in WMSNsTo build a Safety MOnitoring and Control System SMOCS that monitors the safety of the workers and warns them of hazardous situation, many sensor communication devices with different data rates are deployed in the target field. SMOCS collects small scalar data such as temperature, the oxygen content of the air, the occurrence of smoke, gas and/or flame from sensor devices periodically and judges the safety of the working environment primarily. If it perceives a dangerous sign, it acquires still image or video streaming on demand to confirm the situation. Otherwise, the evacuation order by any misjudgment can cause a big loss or annoyance. Since these bursty data have to be delivered to SMOCS reliably and with time constraints, it is challengeable to process those data using a wireless sensor network. A new TDMA-based protocol is designed and is experimented with 30 sensor devices. The results indicate that the new protocol satisfies application requirements well.","Issues and Understandings for Rural HCI Systems Development: Agile Approaches \u201cIn the Wild\u201d ","Beyond 2-Safety: Asymmetric Product Programs for Relational Program VerificationRelational Hoare Logic is a generalization of Hoare logic that allows reasoning about executions of two programs, or two executions of the same pro- gram. It can be used to verify that a program is robust or (information flow) secure, and that two programs are observationally equivalent. Product programs provide a means to reduce verification of relational judgments to the verification of a (standard) Hoare judgment, and open the possibility of applying standard verification tools to relational properties. However, previous notions of product programs are defined for deterministic and structured programs. Moreover, these notions are symmetric, and cannot be applied to properties such as refinement, which are asymmetric and involve universal quantification on the traces of the first program and existential quantification on the traces of the second program. Asymmetric products generalize previous notions of products in three direc- tions: they are based on a control-flow graph representation of programs, they are applicable to non-deterministic languages, and they are by construction asym- metric. Thanks to these characteristics, asymmetric products allow to validate ab- straction/refinement relations between two programs, and to prove the correctness of advanced loop optimizations that could not be handled by our previous work. We validate their effectiveness by applying a prototype implementation to verify representative examples from translation validation and predicate abstraction.","Developing creative business models: the octoproz toolBusiness models are of great importance for business innovation. They can be understood as conceptual models that describe how organizations create and deliver value. Their creation is increasingly supported by information technology artifacts, as information technology facilitates information sharing, allows for continuous modification, and supports complex calculations. In this paper, we introduce a new prototype to create process-oriented business models: the OctoProz tool. We build up on creativity support system literature, present the design of the artifact, and discuss its significance for both research and practice. We close with an outlook on the evaluation of OctoProz.","Discovering multilingual concepts from unaligned web documents by exploring associated imagesThe Internet is experiencing an explosion of information presented in different languages. Though written in different languages, some articles implicitly share common concepts. In this paper, we propose a novel framework to mine cross-language common concepts from unaligned web documents. Specifically, visual words of images are used to bridge articles in different languages and then common concepts of multiple languages are learned by using an existing topic modeling algorithm. We conduct cross-lingual text classification in a real-world data set using the mined multilingual concepts from our method. The experiment results show that our approach is effective to mine cross-lingual common concepts.","Towards affect sensitive and socially perceptive companionsThis chapter investigates affect sensitivity as an important requirement for socially perceptive companions. Challenges and issues arising in the design of an affect recognition framework for artificial companions are identified. A multi-level approach to the analysis of non-verbal affective expressions in human-companion interaction is also presented. The chapter ends with a discussion on the importance of affect recognition for the generation of empathic reactions and the establishment of long-term human-companion relationships.","Trading Friendship for Value: An Investigation of Collective Privacy Concerns in Social Application Usage ","Preliminary Work towards Publishing Vocabularies for Germplasm and Soil Data as Linked DataThe agINFRA project focuses on the production of interoperable data in agriculture, starting from the vocabularies and KOS used to classify and an-notate them. In this paper we report on our first steps in the direction of con-tributing to a LOD of agricultural data. In particular we look at germplasm data and soil data, which are still widely missing from the LOD landscape, seeming-ly because information managers in this field are still not very familiar with LOD practices.","Didactic Galactic: Types of Knowledge Learned in a Serious Game ","The Undefined Domain: Precise Relational Information for Entities That Do Not ExistVerification by static analysis often hinges on the inference of relational numeric information. In real-world programs, the set of active variables is often not fixed for a given program point due to, for instance, heap-allocated cells or recursive function calls. For these program points, an invariant has to summarize values for traces E where a variable x exists and values for traces N where x does not exist. Non-relational domains solve this problem by copying all information on x in traces E to those in N. Relational domains face the challenge that the relations in traces E between x and other variables cannot simply be replicated for the traces N. This work illustrates this problem and proposes a general solution in form of a co-fibered abstract domain that forwards each domain operation to operations on a child domain. By tracking which variables are undefined, it transparently stores suitable values in the child domain thus minimizing the loss of relational information. We present applications in heap abstractions and function summaries.","How do we feel when babyloid starts crying suddenlyWe investigated whether Babyloid, which is a robot designed to act like a human baby, induces feeling that people want to care or help it by focusing on the distance between individuals and the robot. We evaluated how people when Babyloid suddenly started crying by using three distances of personal spaces (intimate (30 cm), personal (100 cm), and social (200 cm)). As a result, participants at an intimate distance had a feeling to help Babyloid, those at a personal distance either wanted to help it or avoided it, and those at a social distance showed no such feeling.","Design of an Intelligent System to Improve Traditional Chinese Medicine Dispensing Practice ","Towards a Taxonomy of Service Design Methods and Tools ","The Relevance of Computing Research History \u2013 The Monads-PC: A Case Study ","A 2-D Visual Model for Sasang Constitution Classification Based on a Fuzzy Neural Network ","A Software Framework for Cognition, Embodiment, Dynamics, and Autonomy in Robotics: CedarWe present Cedar, a software framework for the implementation and simulation of embodied cognitive models based on Dynamic Field Theory (DFT). DFT is a neurally inspired theoretical framework that integrates perception, action, and cognition. Cedar captures the power of DFT in software by facilitating the process of software development for embodied cognitive systems, both artificial and as models of human cognition. In Cedar, models can be designed through a graphical interface and interactively tuned. We demonstrate this by implementing an exemplary robotic architecture.","Using On-Line Technologies to Identify and Track Early Warning Signs of PsychosisThis research in progress examines ways to design on-line applications that help young people suffering from psychosis to identify and act on the early warning signs that indicate a potential relapse in their condition. It examines how proven treatments from face-to-face therapy can be incorporated in information systems design to create effective on-line or mobile therapy tools. It uses a multi-disciplinary approach to propose a design and testing program based on both psychological and usability principles.","Auto-scoring Discovery and Confirmation Bias in Interpreting Data during Science Inquiry in a MicroworldMany students have difficulty with inquiry and difficulty with inter- preting data, in particular. Of interest here is confirmation bias, i.e., when students won't discard a hypothesis based on disconfirming results, which is in direct contrast to when students make a discovery, having originally made a scientifically inaccurate hypothesis. The goal of the present study is to better understand these two data interpretation patterns and autoscore them. 145 eighth grade students engaged in inquiry with a state change microworld. Production rules were written to produce model-tracing in order to identify when students either made a discovery or engaged in confirmation bias. Interesting to note was an emerging pattern wherein many of the same students made discoveries across the four inquiry tasks. These data are important for performance assess- ment of inquiry and suggest that students may need adaptive scaffolding support while engaging in data interpretation.","Dynamic Threshold Selection Method for Multi-label Newspaper Topic IdentificationNowadays, the multi-label classification is increasingly required in modern categorization systems. It is especially essential in the task of newspaper article topics identification. This paper presents a method based on general topic model normalisation for finding a threshold defining the boundary between the \"correct\" and the \"incorrect\" topics of a newspaper article. The proposed method is used to improve the topic identification algorithm which is a part of a complex system for acquisition and storing large volumes of text data. The topic identifi- cation module uses the Naive Bayes classifier for the multiclass and multi-label classification problem and assigns to each article the topics from a defined quite extensive topic hierarchy - it contains about 450 topics and topic categories. The results of the experiments with the improved topic identification algorithm are presented in this paper.","Formal Analysis of GPU Programs with Atomics via Conflict-Directed Delay-Bounding ","Hypersequent and Labelled Calculi for Intermediate LogicsHypersequent and labelled calculi are often viewed as an- tagonist formalisms to define cut-free calculi for non-classical logics. We focus on the class of intermediate logics to investigate the methods of turning Hilbert axioms into hypersequent rules and frame conditions into labelled rules. We show that these methods are closely related and we extend them to capture larger classes of intermediate logics.","A Notification-Centric Mobile Interaction Survey and FrameworkIn this paper we describe the results of a survey amongst smartphone owners into the use and perception of mobile notifications against 160 parameters. We conclude that not all notifications should be created or treated equally by mobile operating systems. The current generation of notifications proves not diverse enough and doesn't fit the needs and preferences of most smartphone users. Based on our findings, we offer a framework of design guidelines for more effectively engaging users with interactions initiated by the system.","An Alternative Coarse Space Method for Overlapping Schwarz Preconditioners for Raviart-Thomas Vector Fields ","Incremental Algorithms for Sampling Dynamic GraphsAmong the many reasons that justify the need for efficient and effective graph sampling algorithms is the ability to replace a graph too large to be processed by a tractable yet representative subgraph. For instance, some approximation algorithms start by looking for a solution on a sample subgraph and then extrapolate it. The sample graph should be of manageable size. The sample graph should preserve properties of interest. There exist several efficient and effective algorithms for the sampling of graphs. However, the graphs encountered in modern applications are dynamic: edges and vertices are added or removed. Existing graph sampling algorithms are not incremental. They were designed for static graphs. If the original graph changes, the sample must be entirely recomputed. Is it possible to design an algorithm that reuses whole or part of the already computed sample?#R##N##R##N#We present two incremental graph sampling algorithms preserving selected properties. The rationale of the algorithms is to replace a fraction of vertices in the former sample with newly updated vertices. We analytically and empirically evaluate the performance of the proposed algorithms. We compare the performance of the proposed algorithms with that of baseline algorithms. The experimental results on both synthetic and real graphs show that our proposed algorithms realize a compromise between effectiveness and efficiency, and, therefore provide practical solutions to the problem of incrementally sampling the large dynamic graphs.","Mutual Information for Performance Assessment of Multi Objective Optimisers: Preliminary ResultsSolving multi-objective problems usually results in a set of Perto-optimal solutions, or a Pareto front. Assessing the quality of these solutions, however, and comparing the performance of different multi-objective optimisers is still not very well understood. Current trends either model the outcome of the optimiser as a probability density function in the objective space, or defines an indicator that quantify the overall performance of the optimiser. Here an approach based on the concept of mutual information is proposed. The approach models the probability density function of the optimisers' output and use that to define an indicator, namely the amount of shared information among the compared Pareto fronts. The strength of the new approach is not only in better assessment of performance but also the interpretability of the results it provides.","A Novel Business Intelligence Technique to Improve High Performance within an Organization Applying Insights from Hydrogeological Case ","Enhanced Search in Unstructured Peer-to-Peer Overlay NetworksUnstructured Peer-to-Peer (P2P) overlays are the most wide- ly used topologies in P2P systems because of their simplicity and very limited control overhead. A P2P overlay specifies the logical connections among peers in a network. Such logical links define the order in which peers are queried in search for a specific resource. The most popular query routing algorithms are based on flooding, thus they do not scale well as each query generates a large amount of tra!c. In this paper, we use heuristics to improve overlay search in an unstructured P2P file shar- ing system. The proposed heuristics e\"ectively decide replica locations for popular resources based on the availability of computing and stor- age at a given peer, its neighborhood information, and the used routing strategy. Simulations performed over two di\"erent types of unstructured P2P network topologies (i.e., power law and random graphs) show sig- nificant improvements over plain flooding in terms of reduced network tra!c and search time.","Analysis of Wireless Power TransmissionThe advent of various wireless technologies have revolutionized the communication infrastructure and consequently changed the entire world into a global village. Use of wireless technology has also been made for transmission of electric power wirelessly. It increases the portability of power systems and integrates the communication technologies and electric power to the same platform. This paper presents a comprehensive review and detailed analysis of various techniques used for wireless power transmission. Feasibility, implementations, operations, results and comparison among different methods have also been covered in order to identify the favorable and economical method for low power and small distance applications.","Graph-based malware distributors detectionSearch engines are currently facing a problem of websites that distribute malware. In this paper we present a novel efficient algorithm that learns to detect such kind of spam. We have used a bipartite graph with two types of nodes, each representing a layer in the graph: web-sites and file hostings (FH), connected with edges representing the fact that a file can be downloaded from the hosting via a link on the web-site. The performance of this spam detection method was verified using two set of ground truth labels: manual assessments of antivirus analysts and automatically generated assessments obtained from antivirus companies. We demonstrate that the proposed method is able to detect new types of malware even before the best known antivirus solutions are able to detect them.","Position-Restricted Substring Searching over Small AlphabetsWe consider the problem of indexing a given text  T [0... n  - 1] of  n  characters over an alphabet set \u03a3 of size  \u03c3 , in order to answer the position-restricted substring searching queries. The query input consists of a pattern  P  (of length  p ) and two indices l and  r  and the output is the set of all  occ  l, r  occurrences of  P  in  T [l... r ]. In this paper, we propose an  O ( n log \u03c3 )-word space index with  O ( p  +  occ  l, r  loglog n ) query time. Our solution is interesting when the alphabet size is small. For example, when the alphabet set is of constant size, we achieve exponential time improvement over the previously best-known linear space index by Navarro and Nekrich [SWAT 2012] with  O ( p  +  occ  l, r  log  e   n ) query time, where  e  &gt; 0 is any positive constant. We also study the property matching problem and provide an improved index for handling semi-dynamic (only insertions) properties, where we use position-restricted substring queries as the main technique.","Major Issues in the Successful Implementation of Information Systems in Developing CountriesInformation systems projects in developing countries continue to fail. Our research aims to understand some of the major issues that negatively im- pact the success of public sector information systems projects in developing countries. For this, we conducted a qualitative study of a state agricultural mar- keting board in India. The board initiated an information systems project in 2003. The objective of the project was to connect the various agricultural mar- kets spread across the state by deploying hi-tech information and communica- tion technologies. Unfortunately, the project was abandoned because of the growing conflicts between the government and private vendors implementing the project. The major stakeholders in the project included the government, pri- vate vendors, farmers and traders. The data for this critical case study were col- lected over a period of eight months from 2009 to 2012 using semi structured interviews, field visits and observations. The findings suggest that the lack of trust and resignation (to certain unfair practices being virtually impossible to change) are the core issues that impede success of information systems imple- mentation in developing countries.","Discrimination of the Micro Electrode Recordings for STN Localization during DBS Surgery in Parkinson's PatientsDuring deep brain stimulation DBS treatment of Parkinson disease, the target of the surgery is a small 9 x 7 x 4 mm deep within brain placed structure called Subthalamic Nucleus STN. It is similar morphologically to the surrounding tissue and as such poorly visible in CT or MRI. The goal of the surgery is the permanent precise placement of the stimulating electrode within target nucleus. Precision is extremely important as wrong placement of the stimulating electrode may lead to serious mood disturbances. To obtain exact location of the STN nucleus an intraoperative stereotactic supportive navigation is being used. A set of 3 to 5 parallel micro electrodes is inserted into brain and in measured steps advanced towards expected location of the nucleus. At each step electrodes record activity of the surrounding neural tissue. Because STN has a distinct physiology, the signals recorded within it also display specific features. It is therefore possible to provide analytical methods targeted for detection of those STN specific characteristics. Basing on such methods this paper presents clustering and classification approaches for discrimination of the micro electrode recordings coming from the STN nucleus. Application of those methods during the neurosurgical procedure might lessen the risks of medical complications and might also shorten the --- out of necessity awake --- part of the surgery.","Program extraction from nested definitionsMinlog is a proof assistant which automatically extracts computational content in an extension of Godel's T from formalized proofs. We report on extending Minlog to deal with predicates defined using a particular combination of induction and coinduction, via so-called nested definitions. In order to increase the efficiency of the extracted programs, we have also implemented a feature to translate terms into Haskell programs. To illustrate our theory and implementation, a formalisation of a theory of uniformly continuous functions due to Berger is presented.","Sponsored search ad selection by keyword structure analysisIn sponsored search, the ad selection algorithm is used to pick out the best candidate ads for ranking, the bid keywords of which are best matched to the user queries. Existing ad selection methods mainly focus on the relevance between user query and selected ads, and consequently the monetization ability of the results is not necessarily maximized. To this end, instead of making selection based on keywords as a whole, our work takes advantages of the different impacts, as revealed in our data study, of different components inside the keywords on both relevance and monetization ability. In particular, we select keyword components and then maximize the relevance and revenue on the component level. Finally, we combine the selected components to generate the bid keywords. The experiments reveal that our method can significantly outperform two baseline algorithms on the metrics including recall, precision and the monetization ability.","Periodicity Extraction using Superposition of Distance Matching Function and One-dimensional Haar Wavelet TransformPeriodicity of a texture is one of the important visual characteristics and is often used as a measure for textural discrimination at the structural level. Knowledge about periodicity of a texture is very essential in the field of texture synthesis and texture compression and also in the design of frieze and wall papers. In this paper, we propose a method of periodicity extraction from noisy images based on superposition of distance matching function (DMF) and wavelet decomposition without de-noising the test images. Overall DMFs are subjected to single-level Haar wavelet decomposition to obtain approximate and detailed coefficients. Extracted coefficients help in determination of periodicities in row and column directions. We illustrate the usefulness and the effectiveness of the proposed method in a texture synthesis application.","Personalized Quality Prediction for Dynamic Service Management Based on Invocation PatternsRecent service management needs, e.g., in the cloud, require services to be managed dynamically. Services might need to be selected or replaced at runtime. For services with similar functionality, one approach is to identify the most suitable services for a user based on an evaluation of the quality QoS of these services. In environments like the cloud, further personalisation is also paramount. We propose a personalized QoS prediction method, which considers the impact of the network, server environment and user input. It analyses previous user behaviour and extracts invocation patterns from monitored QoS data through pattern mining to predict QoS based on invocation QoS patterns and user invocation features. Experimental results show that the proposed method can significantly improve the accuracy of the QoS prediction.","Discrimination of Resting-State fMRI for Schizophrenia Patients with Lattice Computing Based Features ","How status and reputation shape human evaluations: consequences for recommender systemsRecommender systems are inherently driven by evaluations and reviews provided by the users of these systems. Understanding ways in which users form judgments and produce evaluations can provide insights for modern recommendation systems. Many online social applications include mechanisms for users to express evaluations of one another, or of the content they create. In a variety of domains, mechanisms for evaluation allow one user to say whether he or she trusts another user, or likes the content they produced, or wants to confer special levels of authority or responsibility on them. We investigate a number of fundamental ways in which user and item characteristics affect the evaluations in online settings. For example, evaluations are not unidimensional but include multiple aspects that all together contribute to user's overall rating. We investigate methods for modeling attitudes and attributes from online reviews that help us better understand user's individual preferences. We also examine how to create a composite description of evaluations that accurately reflects some type of cumulative opinion of a community. Natural applications of these investigations include predicting the evaluation outcomes based on user characteristics and to estimate the chance of a favorable overall evaluation from a group knowing only the attributes of the group's members, but not their expressed opinions.","Variable Selection in Cluster Analysis: An Approach Based on a New Index ","Detection of spam tipping behaviour on foursquareIn Foursquare, one of the currently most popular online location based social networking sites (LBSNs), users may not only check-in at specific venues but also post comments (or  tips ), sharing their opinions and previous experiences at the corresponding physical places. Foursquare tips, which are visible to everyone, provide venue owners with valuable user feedback besides helping other users to make an opinion about the specific venue. However, they have been the target of spamming activity by users who exploit this feature to spread tips with unrelated content.   In this paper, we present what, to our knowledge, is the first effort to identify and analyze different patterns of tip spamming activity in Foursquare, with the goal of developing automatic tools to detect users who post spam tips -  tip spammers . A manual investigation of a real dataset collected from Foursquare led us to identify four categories of spamming behavior, viz. Advertising/Spam, Self-promotion, Abusive and Malicious. We then applied machine learning techniques, jointly with a selected set of user, social and tip's content features associated with each user, to develop automatic detection tools. Our experimental results indicate that we are able to not only correctly distinguish legitimate users from tip spammers with high accuracy (89.76%) but also correctly identify a large fraction (at least 78.88%) of spammers in each identified category.","Rules of Engagement: Brain-Computer Interfaces for Military Training ","A holistic approach for integrating methods in quality management.Quality management has become more and more important in the last couple of years. The user is faced with a multitude of methods such as Six Sig- ma, TQM or Theory of Constraints. Therefore quality managers are more and more engaged in the selection of an appropriate approach for achieving the quality goals as they have been defined. Due to the necessity of coordinating heterogeneous quality methods, employees usually oppose the use of more than one approach within an enterprise. However, guidelines on how to integrate several methods, while considering the strengths of the original approaches, are still missing. This problem is being dealt with in the paper at hand. The paper introduces an integration approach, supporting the user in establishing an inte- grated quality management method. The variety of quality management ap- proaches within an enterprise can thus be influenced by the user.","Coordinating multi-agent reinforcement learning with limited communicationCoordinated multi-agent reinforcement learning (MARL) provides a promising approach to scaling learning in large cooperative multi-agent systems. Distributed constraint optimization (DCOP) techniques have been used to coordinate action selection among agents during both the learning phase and the policy execution phase (if learning is off-line) to ensure good overall system performance. However, running DCOP algorithms for each action selection through the whole system results in significant communication among agents, which is not practical for most applications with limited communication bandwidth. In this paper, we develop a learning approach that generalizes previous coordinated MARL approaches that use DCOP algorithms and enables MARL to be conducted over a spectrum from independent learning (without communication) to fully coordinated learning depending on agents' communication bandwidth. Our approach defines an interaction measure that allows agents to dynamically identify their beneficial coordination set (i.e., whom to coordinate with) in different situations and to trade off its performance and communication cost. By limiting their coordination set, agents dynamically decompose the coordination network in a distributed way, resulting in dramatically reduced communication for DCOP algorithms without significantly affecting overall learning performance. Essentially, our learning approach conducts co-adaptation of agents' policy learning and coordination set identification, which outperforms approaches that sequence them.","Decision Tree Driven Rule Induction for Heart Disease Prediction Model: Korean National Health and Nutrition Examinations Survey V-1 ","Continuation-based Mobile Personalization Agent in Human Behavior Change. ","Agent-Based Population Learning Algorithm for RBF Network TuningRadial Basis Function Neural Networks (RBFNs) are quite popular due to their ability to discover and approximate complex non- linear dependencies within the data under analysis. The performance of the RBF network depends on numerous factors. One of them is a value of the RBF shape parameter. This parameter has a direct impact on perfor- mance of the transfer function of each hidden unit. Values of the transfer function parameters, including the value of its shape, are set during the RBFN tuning phase. Setting values of the transfer function parameters, including its shape can be viewed as the optimization problem in which the performance of the considered RBFN is maximized. In the paper the agent-based population learning algorithm finding the optimal or near optimal value of the RBF shape parameter is proposed and evaluated.","A PHD-Filter-Based Multitarget Tracking Algorithm for Sensor Networks ","OWA-FRPS: A Prototype Selection Method Based on Ordered Weighted Average Fuzzy Rough Set TheoryThe Nearest Neighbor NN algorithm is a well-known and effective classification algorithm. Prototype Selection PS, which provides NN with a good training set to pick its neighbors from, is an important topic as NN is highly susceptible to noisy data. Accurate state-of-the-art PS methods are generally slow, which motivates us to propose a new PS method, called OWA-FRPS. Based on the Ordered Weighted Average OWA fuzzy rough set model, we express the quality of instances, and use a wrapper approach to decide which instances to select. An experimental evaluation shows that OWA-FRPS is significantly more accurate than state-of-the-art PS methods without requiring a high computational cost.","Factoring Multi-power RSA Modulus N = p r q with Partial Known BitsFactoring large integers is a fundamental problem in algebraic number theory and modern cryptography, which many cryptosystems, e.g. RSA, are based on. Up to now, there is no known polynomial-time al- gorithm to solve it with classical computers. However, in practice side- channel attacks usually cause serious damage: Even if a small proportion of bits in the secret primes is leaked, one may efficiently factor. In this paper, we study the problem of factoring with partial known bits for multi-power RSA modulus N = p r q. In 1999, Boneh, Durfee and Howgrave-Graham showed that this problem can be solved efficiently given a 1 r+1 -fraction of the most significant bits (MSB) of p .I n their at- tack, the unknown bits are located in one consecutive block. We propose two lattice-based approaches that extend the number of unknown blocks to arbitrary n (n \u2265 1). The advantage of our approaches is that now knowledge of a ln(1+r) r -fraction of the bits of p is already sufficient (for any n). In fact, our result is a first step towards unifying and extending previous works by Boneh-Durfee-Howgrave (Crypto'99) and Herrmann- May (Asiacrypt'08).","A File Recommendation Method Based on Task Workflow Patterns Using File-Access LogsIn recent years, office workers spend much time and effort searching for the documents required for their jobs. To reduce these costs, we propose a new method for recommending files and operations on them. Existing technologies for recommendation, such as collaborative filtering, suffer from two problems. First, they can only work with doc- uments that have been accessed in the past, so that they cannot recom- mend when only newly generated documents are inputted. Second, they cannot easily handle sequences involving similar or differently ordered elements because of the strict matching used in the access sequences. To solve these problems, such minor variations should be ignored. In our proposed method, we introduce the concepts of abstract files as groups of similar files used for a similar purpose, abstract tasks as groups of sim- ilar tasks, and frequent abstract workflows grouped from similar work- flows, which are sequences of abstract tasks. In experiments using real file-access logs, we confirmed that our proposed method could extract workflow patterns with longer sequences and higher support-count val- ues, which are more suitable as recommendations.","Modeling the intermolecular interactions and characterization of the dynamics of collisional autoionization processesThe autoionization dynamics of triatomic molecules induced by He*(23,1S1,0) and Ne*(3P2,0) collisions has been discussed. The systems are analyzed by using an optical potential model within a semiclassical approach. The real part of the potential is formulated applying a semiempirical method, while the imaginary part has been used in the fitting procedure of the data adjusting its pre-exponential factor. The good agreement between calculations and experiment confirms the attractive nature of the potential energy surface driving the He* and Ne*-H2O dynamics.","Transformation of Acyclic Phase Type Distributions for Correlation Fitting ","A Linear-Time Algorithm for Computing the Prime Decomposition of a Directed Graph with Regard to the Cartesian ProductIn this paper, we design the first linear-time algorithm for computing the prime decomposition of a digraph G with regard to the cartesian product. A remarkable feature of our solution is that it computes the decomposition of G from the decomposition of its underlying undirected graph, for which there exists a linear-time algorithm. First, this allows our algorithm to remain conceptually very simple and in addition, it provides new insight into the connexions between the directed and undirected versions of cartesian product of graphs.","SVID Speaker Recognition System for NIST SRE 2012A description of the SVID speaker recognition system is presented. This system was developed for submission to the NIST SRE 2012.","Performance Improvement via Bagging Competitive Associative Nets for Multiobjective Robust Controller Using Difference SignalsSo far, we have shown that, using difference signals of a plant to be controlled, a single CAN2 (competitive associative net) is capable of leaning piecewise Jacobian matrices of nonlinear dynamics of the plant. Here, the CAN2 is an artificial neural net for learning efficient piecewise linear approximation of nonlinear function. Furthermore, a multiobjective robust controller is obtained by means of combining the GPC (generalized predictive controller) and a switching scheme of multiple CAN2s to cope with plant parameter change and control ob- jective change. This paper focuses on an improvement of control performance by means of replacing single CAN2 by bagging CAN2. We analyze to show the effectiveness of the present method via numerical experiments of a crane system.","Exploration of picture e-book design for app webThe objective of this study is to investigate the interactive relationship between picture e-book design and children with the interface of APP web for mobile devices. In order to achieve the objective, the focus of this study is in applying APP technology to picture e-book. Also, APP web interfaces based on both smartphone and tablet via picture book are designed in the study. Furthermore, this study discusses children interface satisfaction in reading the e-book. It shows that both the interactive process and the result differ in smartphone and in tablet. It seems to be the best way for children to read the picture e-book if they can easily touch the buttons on the screen of a tablet.","Global Constraints for Syntactic Consistency in OMR: An Ongoing ApproachOptical Music Recognition (OMR) systems are an indispens- able tool to transform the paper-based music scores and manuscripts into a machine-readable symbolic format. A system like this potentiates search, retrieval and analysis. One of the problematic stages is the musi- cal symbols detection where operations to localize and to isolate musical objects are developed. The complexity is caused by printing and digital- ization, as well as the paper degradation over time. Distortions inherent in staff lines, broken, connected and overlapping symbols, differences in sizes and shapes, noise, and zones of high density of symbols is even worst when we are dealing with handwritten music scores. In this paper the exploration of an optimization approach to support semantic and syn- tactic consistency after the music symbols extraction phase is proposed. The inclusion of this ongoing technique can lead to better results and encourage further experiences in the field of handwritten music scores recognition.","A Hybrid Algorithm for Image Watermarking against Signal Processing AttacksIn this paper, we have presented a hybrid image watermarking technique and developed an algorithm based on the three most popular trans form techniques which are discrete wavelet transforms DWT, discrete cosine transforms DCT, and singular value decomposition SVD against signal processing attacks. However, the experimental results demonstrate that this algorithm combines the advantages and remove the disadvantages of these three transform. This proposed hybrid algorithm provides better imperceptibility and robustness against various attacks such as Gaussian noise, salt and pepper noise, motion blur, speckle noise, and Poisson noise etc.","Transducer-Based Algorithmic Verification of Retransmission Protocols over Noisy ChannelsUnreliable communication channels are a practical reality. They add to the complexity of protocol design and verification. In this paper, we consider noisy channels which can corrupt messages. We present an approach to model and verify protocols which combine error detection and error control to provide reliable communication over noisy channels. We call these protocols retransmission protocols as they achieve reliable communication through repeated retransmissions of messages. These protocols typically use cyclic redundancy checks and sliding window protocols for error detection and control respectively. We propose models of these protocols as regular transducers operating on bit strings. Streaming string transducers provide a natural way of modeling these protocols and formalizing correctness requirements. The verification problem is posed as functional equivalence between the protocol transducer and the specification transducer. Functional equivalence checking is decidable for this class of transducers and this makes the transducer models amenable to algorithmic verification. We present case studies based on TinyOS serial communication and the HDLC retransmission protocol.","GOAL for games, omega-automata, and logicsThis paper introduces the second generation of GOAL, which is a graphical interactive tool for games, \u03c9-automata, and logics. It is a complete redesign with an extensible architecture, many enhancements to existing functions, and new features. The extensible architecture allows easy integration of third-party plugins. The enhancements provide more automata conversion, complementation, simplification, and testing algorithms, translation of full QPTL formulae, and better automata navigation with more layout algorithms and utility functions. The new features include game solving, manipulation of two-way alternating automata, translation of ACTL formulae and \u03c9-regular expressions, test of language star-freeness, classification of \u03c9-regular languages into the temporal hierarchy of Manna and Pnueli, and a script interpreter.","Modeling of High Frequency Out-of-Plane Single Axis MEMS Capacitive AccelerometerThe present paper deals with the modeling of high resonance frequency electrostatically actuated MEMS accelerometer having out-of-plane sensing axis. The accelerometer is based on folded beam support and comb structure configuration. Capacitance change phenomenon is used to determine the device acceleration. Effect of different structural parameters on the device performance is analyzed and the simulation is carried out on COMSOL Multiphysics, a strong 3D modeling software. The design is based on standard SOI-MUMP'S technology and with in-house fabrication capabilities. SOI- MUMP'S technology is preferred because of its outstanding performance and ease of fabrication.","Characterizing Geographic Variation in Well-Being Using TweetsThe language used in tweets from 1,300 different US counties was found to be predictive of the subjective well-being of people living in those counties as measured by representative surveys. Topics, sets of co-occurring words derived from the tweets using LDA, improved accuracy in predicting life satisfaction over and above standard demographic and socio-economic controls (age, gender, ethnicity, income, and education). The LDA topics provide a greater behavioural and conceptual resolution into life satisfaction than the broad socio-economic and demographic variables. For example, tied in with the psychological literature, words relating to outdoor activities, spiritual meaning, exercise, and good jobs correlate with increased life satisfaction, while words signifying disengagement like \u2019bored\u2019 and \u2019tired\u2019 show a negative association.","BCI-based navigation in virtual and real environmentsA Brain-Computer Interface (BCI) is a system that enables people to control an external device with their brain activity, without the need of any muscular activity. Researchers in the BCI field aim to develop applications to improve the quality of life of severely disabled patients, for whom a BCI can be a useful channel for interaction with their environment. Some of these systems are intended to control a mobile device (e. g. a wheelchair). Virtual Reality is a powerful tool that can provide the subjects with an opportunity to train and to test different applications in a safe environment. This technical review will focus on systems aimed at navigation, both in virtual and real environments.","Method and Development of Magnetic Positioning Device for Magnetic Guided VehicleIn this paper, device development for AGV using magnet navigation and method of magnetic localization method are described. The most commercial AGV is using magnet navigation. This is more stable and lower cost of sensors than different navigation systems of AGV. However, the commercial magnet navigation devices use magnet hall sensor of digital type and those accuracy are decided by the number of magnet hall sensor and interval. The interval is about 10mm generally because interference occurs in the case of close interval, but the AGV using this interval has low accuracy. This AGV doesn't matter in straight driving, but occur breakaway or false operation in curve driving. Therefore, we create an magnet navigation device using magnet hall sensor of analog type and design fitting functions with the experimental results of magnet hall sensor in the work environment. Based on this, this paper proposes the method to detect magnet navigation line. In the result of proposed method, localization method accuracy is improved more about 16.73mm by this method than the commercial magnet navigation device and space to detect magnet navigation line is larger.","Revisiting Aggregation for Data Intensive Applications: A Performance StudyAggregation has been an important operation since the early days of relational databases. Today's Big Data applications bring further challenges when processing aggregation queries, demanding adaptive aggregation algorithms that can process large volumes of data relative to a potentially limited memory budget (especially in multiuser settings). Despite its importance, the design and evaluation of aggregation algorithms has not received the same attention that other basic operators, such as joins, have received in the literature. As a result, when considering which aggregation algorithm(s) to implement in a new parallel Big Data processing platform (AsterixDB), we faced a lack of \"off the shelf\" answers that we could simply read about and then implement based on prior performance studies. #R##N#In this paper we revisit the engineering of efficient local aggregation algorithms for use in Big Data platforms. We discuss the salient implementation details of several candidate algorithms and present an in-depth experimental performance study to guide future Big Data engine developers. We show that the efficient implementation of the aggregation operator for a Big Data platform is non-trivial and that many factors, including memory usage, spilling strategy, and I/O and CPU cost, should be considered. Further, we introduce precise cost models that can help in choosing an appropriate algorithm based on input parameters including memory budget, grouping key cardinality, and data skew.","Hypervisor Event Logs as a Source of Consistent Virtual Machine Evidence for Forensic Cloud InvestigationsCloud Computing is an emerging model of computing where users can leverage the computing infrastructure as a service stack or commodity. The security and privacy concerns of this infrastructure arising from the large co-location of tenants are, however, significant and pose considerable challenges in its widespread deployment. The current work addresses one aspect of the security problem by facilitating forensic investigations to determine if these virtual tenant spaces were maliciously violated by other tenants. It presents the design, application and limitations of a software prototype called the Virtual Machine (VM) Log Auditor that helps in detecting inconsistencies within the activity timelines for a VM history. A discussion on modeling a consistent approach is also provided.","Closing the Gap between the Motivation of Users and the Design Requirements for Social SitesThe goal of this paper is to propose an extended format for describing interaction pattern making it an important artifact to associate aspects regarding the user's motivation with interaction solutions to design Social Systems (SS). 19 patterns, which were created, modeled in Semantic Media Wiki and applied in a case study, led designers to understand what motivates people to social involvement, and not just focuses on meeting the design requirements.","Multiwinner elections under preferences that are single-peaked on a treeWe study the complexity of electing a committee under several variants of the Chamberlin-Courant rule when the voters' preferences are single-peaked on a tree. We first show that this problem is easy for the egalitarian, or \"minimax\" version of this problem, for arbitrary trees and misrepresentation functions. For the standard (utilitarian) version of this problem we provide an algorithm for an arbitrary misrepresentation function whose running time is polynomial in the input size as long as the number of leaves of the underlying tree is bounded by a constant. On the other hand, we prove that our problem remains computationally hard on trees that have bounded degree, diameter, or pathwidth. Finally, we show how to modify Trick's [1989] algorithm to check whether an election is single-peaked on a tree whose number of leaves does not exceed a given parameter \u03bb.","Towards Comprehensive Concept Description Based on Association RulesThe paper presents two approaches to post-processing of association rules that are used for concept description. The first approach is based on the idea of meta-learning; a subsequent association rule mining step is applied to the results of \"standard\" association rule mining. We thus obtain \"rules about rules\" that in a condensed form represent the knowledge found using association rules generated in the first step. The second approach finds a \"core\" part of the association rules that can be used to derive the confidence of every rule created in the first step. Again, the core part is substantially smaller than the set of all association rules. We experimentally evaluate the proposed methods on some benchmark data taken from the UCI repository. The system LISp-Miner has been used to carry out the experiments.","A Parallel Implementation of Computing Composite Rough Set Approximations on GPUsIn information systems, there may exist multiple different types of attributes like categorical attributes, numerical attributes, set-valued attributes, interval-valued attributes, missing attributes, etc. Such information systems are called as composite information systems. To process such attributes with rough set theory, composite rough set model and corresponding matrix methods were introduced in our previous research. Rough set approximations of a concept are the basis for rule acquisition and attribute reduction in rough set based methods. To accelerate the computation process of rough set approximations, this paper first presents the boolean matrix representation of the lower and upper approximations in the composite information system, then designs a parallel method based on matrix, and implements it on GPUs. The experiments on data sets from UCI and user-defined data sets show that the proposed method can accelerate the computation process efficiently.","Bengali Printed Character Recognition - A New ApproachThis paper presents a new method for Bengali character recognition based on view-based approach. Both the top-bottom and the lateral view-based approaches have been considered. A layer-based methodology in modification of the basic view-based processing has been proposed. This facilitates handling of unequal logical partitions. The document image is acquired and segmented to extract out the text lines, words, and letters. The whole image of the individual characters is taken as the input to the system. The character image is put into a bounding box and resized whenever necessary. The view-based approach is applied on the resultant image and the characteristic points are extracted from the views after some preprocessing. These points are then used to form a feature vector that represents the given character as a descriptor. The feature vectors have been classified with the aid of k-NN classifier using Dynamic Time Warping (DTW) as a distance measure. A small dataset of some of the compound characters has also been considered for recognition. The promising results obtained so far encourage the authors for further work on handwritten Bengali scripts.","Path Planning Using Clonal Selection Algorithm ","MaxMax: a graph-based soft clustering algorithm applied to word sense inductionThis paper introduces a linear time graph-based soft clustering algorithm. The algorithm applies a simple idea: given a graph, vertex pairs are assigned to the same cluster if either vertex has maximal affinity to the other. Clusters of varying size, shape, and density are found automatically making the algorithm suited to tasks such Word Sense Induction (WSI), where the number of classes is unknown and where class distributions may be skewed. The algorithm is applied to two WSI tasks, obtaining results comparable with those of systems adopting existing, state-of-the-art methods.","Estimation of the facial impression from individual facial features for constructing the makeup support systemThe aim of this study was to construct a makeup support system. This system will show what kind of impression a user's face gives to other persons. Moreover, the system shows how to apply makeup, on the basis of individual facial features, to achieve the ideal impression. In the first step of the research described in this paper, we conducted an experiment in which subjects evaluated facial pictures of eight impressions. On each face, facial-feature points were extracted and used to calculate the ratio of the length and the width of parts of the face. The results of the experiment suggested that the user's impression will be changed by modifying a part of the face by the use of makeup.","Improving Kerberos Ticket Acquisition during Application Service Access ControlKerberos is one of the most deployed protocols to achieve a controlled access to application services by ensuring a secure authentication and key distribution process. Given its growing popularity, Kerberos is envisaged to become a widespread solution for single sign-on access. For this reason, the evolution of the protocol still continues in order to address new features or challenges which were not considered when initially designed. This paper focuses on the ticket acquisition process and proposes a new mechanism called Kerberos Ticket Pre-distribution that reduces the time required to recover tickets from the Key Distribution Center KDC. We offer a flexible solution which is able to work in three different modes of operation, depending on what entity the user, the network or both controls the pre-distribution process. By employing the extensibility mechanisms available in Kerberos, we maintain interoperability with current implementations without compromising the security and robustness of the protocol. Using an implemented prototype, we evaluate our solution and demonstrate that our proposal significantly improves the standard Kerberos ticket acquisition process.","Fast multi-update operations on compressed XML dataGrammar-based XML compression reduces the volume of big XML data collections, but fast updates of compressed data may become a bottleneck. An open question still was, given an XPath Query and an update operation, how to efficiently compute the update positions within a grammar representing a compressed XML file. In this paper, we propose an automaton-based solution, which computes these positions, combines them in a so-called Update DAG, supports parallel updates, and uses dynamic programming to avoid an implicit decompression of the grammar. As a result, our solution updates compressed XML even faster than MXQuery and Qizx update uncompressed XML.","Boltzmann Machines for Image DenoisingImage denoising based on a probabilistic model of local image patches has been employed by various researchers, and recently a deep denoising autoencoder has been proposed in [2] and [17] as a good model for this. In this paper, we propose that another popular family of models in the field of deep learning, called Boltzmann machines, can perform image denoising as well as, or in certain cases of high level of noise, better than denoising autoencoders. We empirically evaluate these two models on three different sets of images with different types and levels of noise. The experiments confirmed our claim and revealed that the denoising performance can be improved by adding more hidden layers, especially when the level of noise is high.","Using Wikipedia with associative networks for document classificationWe demonstrate a new technique for building associative networks based on Wikipedia, comparing them to WordNet-based associative networks that we used previously, nding the Wikipedia-based networks to perform better at document classification. Additionally, we compare the performance of associative networks to various other text classification techniques using the Reuters-21578 dataset, establishing that associative networks can achieve comparable results.","Modeling Emotions with Social TagsWe present an emotion model based on social tags, which is built upon an automatically generated lexicon that describes emotions by means of synonym and antonym terms. Using this model we develop a number of methods that transform social tag-based item profiles into emotion-oriented item profiles. We show that the model's representation of a number of basic emotions is in accordance with the well known psychological circumplex model of affect, and we report results from a user study that show a high precision of our methods to infer the emotions evoked by items in the movie and music domains.","Paper and Pen: A 3D Sketching SystemThis paper proposes a method that resembles a natural pen and paper interface to create curve based 3D sketches. The system is particularly useful for representing initial 3D design ideas without much effort. Users interact with the systembythehelpofapressuresensitive pentablet.Theinputstrokesoftheusersare projectedontoadrawingplane,whichservesasa paper thattheycanplaceanywhere in the 3D scene. The resulting 3D sketch is visualized emphasizing depth perception. Our evaluation involving several naive users suggest that the system is suitable for a broad range of users to easily express their ideas in 3D. We further analyze the system with the help of an architect to demonstrate the expressive capabilities.","Comparison of classical and sequential design of experiments in note onset detection ","BOSS: building operating system servicesCommercial buildings are attractive targets for introducing innovative cyber-physical control systems, because they are already highly instrumented distributed systems which consume large quantities of energy. However, they are not currently programmable in a meaningful sense because each building is constructed with vertically integrated, closed subsystems and without uniform abstractions to write applications against. We develop a set of operating system services called BOSS, which supports multiple portable, fault-tolerant applications on top of the distributed physical resources present in large commercial buildings. We evaluate our system based on lessons learned from deployments of many novel applications in our test building, a four-year-old, 140,000sf building with modern digital controls, as well as partial deployments at other sites.","Interactive Visual Transformation for Symbolic Representation of Time-Oriented DataData Mining on time-oriented data has many real-world ap- plications, like optimizing shift plans for shops or hospitals, or analyzing traffic or climate. As those data are often very large and multi-variate, several methods for symbolic representation of time-series have been pro- posed. Some of them are statistically robust, have a lower-bound distance measure, and are easy to configure, but do not consider temporal struc- tures and domain knowledge of users. Other approaches, proposed as basis for Apriori pattern finding and similar algorithms, are strongly configurable, but the parametrization is hard to perform, resulting in ad-hoc decisions. Our contribution combines the strengths of both ap- proaches: an interactive visual interface that helps defining event classes by applying statistical computations and domain knowledge at the same time. We are not focused on a particular application domain, but intend to make our approach useful for any kind of time-oriented data.","Interactive Information Service Technology of Tea Industry Based on Demand-DrivenInformation service technology is a bridge between user and information resource, also is the critical factor to weight the quality of information service. Focusing on the information service features of tea industry, the demand-driven and interaction of information service were emphasized in this paper. User and market as the major criterion for testing the quality of information service, the interactive information service mode based on the demand-driven was proposed to realize the maximum of information service value. Demands of users as the driving factor in the mode, introducing the interactive ideas of loop optimization on information demand and combining the push and feedback mechanism of information, the information service mechanism was further optimized to meet the actual demands of users.","Characterization of Tissue Histopathology via Predictive Sparse Decomposition and Spatial Pyramid MatchingImage-based classification of tissue histology, in terms of different components (e.g., subtypes of aberrant phenotypic signatures), provides a set of indices for tumor composition. Subsequently, integration of these indices in whole slide images (WSI), from a large cohort, can provide predictive models of the clinical outcome. However, the performance of the existing histology-based classification techniques is hindered as a result of large technical and biological variations that are always present in a large cohort. In this paper, we propose an algorithm for classification of tissue histology based on predictive sparse decom- position (PSD) and spatial pyramid matching (SPM), which utilize sparse tissue morphometric signatures at various locations and scales. The method has been evaluated on two distinct datasets of different tumor types collected from The Cancer Genome Atlas (TCGA). The novelties of our approach are: (i) extensibil- ity to different tumor types; (ii) robustness in the presence of wide technical and biological variations; and (iii) scalability with varying training sample size.","Arbitrated Quantum Signature Schemes: Attacks and SecurityIn this paper, we first summarize the attacks on the existing arbitrated quantum signature (AQS) schemes and then present a valid forgery attack. Also, we discuss the effectiveness of these attacks and an- alyze the reasons for these schemes suffered attacks. Moreover, we pro- pose an AQS scheme which can resist all existent attacks. The proposed AQS scheme can preserve all merits in the previous AQS schemes such as it can sign the known and unknown quantum messages. To achieve higher security of AQS, we also construct a strong quantum one-time pads encryption which is applied to improve the AQS schemes.","Design of a Sensing Limited Autonomous Robotic SystemThis paper describes the development and implementation of a behavioral-based solution for a sensing-limited robotic system in area coverage problem using the LEGO Mindstorms NXT robotics kit. The main aim is to investigate how area coverage algorithms can be implemented on a robot with limited sensing and processing capabilities to cover a given area efficiently without localization or map building as well as to compare these algorithms with each other. Interestingly, there has been limited research done in this aspect, particularly in the efficiencies of current heuristic based algorithms in commercially available robots. In this project, three behaviors: Random Walk, Spiral, and Weave are proposed. A robot was constructed to mimic a sensing limited robot and it was used to carry out the proposed behaviors to determine the most efficient behavior. During experiment, it was found that aspects such as the parameter being measured and placement of obstacles in the environment affected the perception and performance by the robot. Results showed that the zigzag motion of Weave was the most efficient movement of the three, performing consistently well under varied environments and measurements.","On the Number of Abelian Bordered WordsIn the literature, many bijections between (labeled) Motzkin paths and various other combinatorial objects are studied. We consider abelian (un)bordered words and show the connection with irreducible symmetric Motzkin paths and paths in Z not returning to the origin. This study can be extended to abelian unbordered words over an arbitrary alphabet and we derive expressions to compute the number of these words. In particular, over a 3-letter alphabet, the connection with paths in the triangular lattice is made. Finally, we study the lengths of the abelian unbordered factors occurring in the Thue-Morse word.","Zero-Probability and coherent betting: a logical point of viewThe investigation reported in this paper aims at clarifying an important yet subtle distinction between (i) the logical objects on which measure theoretic probability can be defined, and (ii) the interpretation of the resulting values as rational degrees of belief. Our central result can be stated informally as follows. Whilst all subjective degrees of belief can be expressed in terms of a probability measure, the converse doesn't hold: probability measures can be defined over linguistic objects which do not admit of a meaningful betting interpretation. The logical framework capable of expressing this will allow us to put forward a precise formalisation of de Finetti's notion of event which lies at the heart of the Bayesian approach to uncertain reasoning.","Estimating structural relevance of XML elements through language modelLanguage modeling approaches have been extensively used as an effective way of measuring ad-hoc document content relevance. However, in structured information retrieval (SIR) there is to our knowledge no approach which aims at assessing structural relevance using language models. In this paper we present a language model based on document-query structure likelihood. As the effectiveness of language modeling relies on the associated smoothing technique we experimented two of these techniques. Experiments are conducted on the INEX 2010 Datacentric test set and show the interest of our method compared to official participants to the task.","Morphological Investigations of Skulls for Sex Determination Based on Sparse Principal Component AnalysisSex determination from skeletons is a significant step in the analysis of forensic anthropology. The relationship between morphological characteristics and the gender of skull is of great importance in forensic anthropology research. This paper presents an automatic method relating the local morphological characteristics of the skull to the sex classification based on sparse principle component analysis (SPCA). Our contributions are: (1)A set of important local characteristics on the skull are obtained using sparse principal component analysis, which correspond to local areas on the skull. The importance of the local characteristics in sex classification are obtained; (2)Experiments on Chinese skulls including 127 males and 81 females are given. The results show the effectiveness of SPCA on Sex determination.","Homecare risk management: nursing issues related to technologyTraditional risk management may not address the needs of technology being introduced into homecare situations for nurses. We propose to augment traditional risk management with insights from Prevention through Design and The 8 Rights giving a more technology focus to risk management.","Improvement of Imperfect String Matching Based on Asymmetric n-GramsTypical approaches to string comparing treats them as either different or identical without taking into account the possibility of misspelling of the word. In this article we present an approach we used for improvement of imperfect string matching that allows one to reconstruct potential string distortions. The proposed method increases the quality of imperfect string matching, allowing the lookup of misspelled words without significant impact on computational effectiveness. The paper presents the proposed method, experimental data sets and obtained results of comparison to state of the art methods.","Transform for Simplified Weight Computations in the Fuzzy Analytic Hierarchy Process ","Customer-Driven Software Product Development Software Products for the Social Media World \u2013 A Case StudyNowadays customer experience is driven by software. Software devel- opment processes therefore must be orientated towards customer experience. Product Management must listen to the Voice of the Customer (VoC), extract product requirements, and guide the development team accordingly. The customer is not available for explaining experience until it is too late and the product al- ready developed. Traditional questionnaires, customer surveys and sensing groups do not work for analyzing customer experience. However, with the arrival of so- cial media, new sources of customer experience are available that require new me- thods for analyzing customer's voice. Six Sigma transfer functions provide the methods needed. This paper presents a case study how to use Six Sigma transfer functions based on Net Promoter \u00ae Score for Voice of the Customer for product requirements gathering in a software requirement elicitation processes. Transfer functions are an advancement of Quality Function Deployment (QFD) and Design for Six Sigma (DfSS), based on Eigenvector search techniques.","Information Security Policy Compliance: An Empirical Study on Escalation of CommitmentThis study aims to facilitate a new understanding on employees\u2019 attitude towards compliance with the requirements of their information security policy (ISPs) through the lens of escalation. Escalation presents a situation in which employees must decide whether to persist in or withdraw from a non-performing task. Drawing on the Theory of Planned Behavior (TPB) and Agency Theory, our model delineates three mediating factors in explaining attitude: work impediment, information asymmetry, and safety of resources. We also propose information security awareness as an independent variable having an indirect effect on attitude through mediating factors. The proposed model is tested using the data collected from 376 employees working in the banking industry. The results of the PLS analyses show that while information asymmetry and safety of resources have significant impacts on attitude, work impediment does not. The results also show that ISA has significant impact on all three mediating factors.","Use of Social Media in the Workplace ","A Case Based Approach to Serve Information Needs in Knowledge Intensive ProcessesCase workers who are involved in knowledge intensive business processes have critical information needs.When dealing with a case, they often need to check how similar cases were handled and what best practices, methods and tools proved useful. In this paper, we present our Solution Information Management SIM system developed to assist case workers by retrieving and offering targeted and contextual content recommendations to them. In particular, we present a novel method for intelligently weighing different fields in a case when they are used as context to derive recommendations. Experimental results indicate that our approach can yield recommendations that are approximately 15 more precise than those obtained through a baseline approach where the fields in the context have equal weights. SIM is being actively used by case workers in a large IT services company.","Study on the statistical test for string pseudorandom number generatorsMany fields need random and pseudorandom numbers, especially in cryptographic applications. d-bit segment binary pseudorandom numbers can be more easily used for block encryption. This paper studies on the statistical test for binary d string pseudorandom number generator (PRNG). Three postulates on the randomness for ideal pseudorandom d-bit segment sequences have been proposed. Based on the FIPS140-2 tests, a statistical test suite for d-bit segment sequences generated by PRNG has been proposed. Using the test suite tests the 100 key streams generated by RC4 PRNG and Matlab PRNG, respectively. The test results show that in the two 100 key streams generated via the two PRNGs with different seeds, about 97% 8-bit strings have passed the test suite, respectively. Using the key streams generated via the two PRNGs encrypts an RGB image. The results have shown that the encrypted RGB images have significant stream encryption avalanche effect.","REDACT: a framework for sanitizing RDF dataResource Description Framework (RDF) is the foundational data model of the Semantic Web, and is essentially designed for integration of heterogeneous data from varying sources. However, lack of security features for managing sensitive RDF data while sharing may result in privacy breaches, which in turn, result in loss of user trust. Therefore, it is imperative to provide an infrastructure to secure RDF data. We present a set of graph sanitization operations that are built as an extension to SPARQL. These operations allow one to sanitize sensitive parts of an RDF graph and further enable one to build more sophisticated security and privacy features, thus allowing RDF data to be shared securely.","The Role of Augmented Reality in Training the Planning of Brain Tumor Resection ","Task Topic Knowledge vs. Background Domain Knowledge: Impact of Two Types of Knowledge on User Search Performance ","Teaching-Learning-Based Optimization Algorithm in Dynamic Environments ","A tale of two studiesRunning user evaluation studies is a useful way of getting feedback on partially or fully implemented software systems. Unlike hypothesis-based testing (where specific design decisions can be tested or comparisons made between design choices) the aim is to find as many problems (both usability and functional) as possible prior to implementation or release. It is particularly useful in small-scale development projects that may lack the resources and expertise for other types of usability testing. Developing a user-study that successfully and efficiently performs this task is not always straightforward however. It may not be obvious how to decide what the participants should be asked to do in order to explore as many parts of the system's interface as possible. In addition, ad hoc approaches to such study development may mean the testing is not easily repeatable on subsequent implementations or updates, and also that particular areas of the software may not be evaluated at all. In this paper we describe two (very different) approaches to designing an evaluation study for the same piece of software and discuss both the approaches taken, the differing results found and our comments on both of these.","\"I Can Simply\u2026\" - Theorizing Simplicity As A Design Principle And Usage Factor ","Identifying Usability Problems in a Smart TV Music ServiceThirty-one usability problems for a smart TV music service system have been identified by different user groups through the cooperative evaluation method. Design solutions can be provided based on the priority of the identified usability problems, the classifications between functionality and quality issues, or between display and control issues, and the foci on specific user groups.","Assessing the Accuracy of the SIRAH Force Field to Model DNA at Coarse Grain LevelWe present a comparison between atomistic and coarse grain models for DNA developed in our group, which we introduce here with the name SIRAH. Molecular dynamics of DNA fragments performed using implicit and explicit solvation approaches show good agreement in structural and dynamical features with published state of the art atomistic simulations of double stranded DNA (using Amber and Charmm force fields). The study of the multi-microsecond timescale results in counterion condensation on DNA, in coincidence with high-resolution X-ray crystals. This result indicates that our model for solvation is able to correctly reproduce ionic strength effects, which are very difficult to capture by CG schemes.","An OLAP Server for Sensor Networks Using Augmented Statistics TreesThe datacube is a conceptual data structure to support OnLine Analytical Processing (OLAP). It is essentially a series of tables organized according to attributes (called dimensions). Table rows (or cells) contain aggregated information for collections of records that satisfy value constraints for each dimension. The Statistics Tree (ST) uses a tree structure for storing the datacube in memory in order to optimize cell lookup time and handle a variety of types of cell-based queries. An Augmented ST (AST) is proposed with additional list structures within the ST. The additional lists link together the cells that comprise the tables of the datacube. An algorithm that builds table lists requires only a single traversal of the ST. Thus the AST supports both cell-level and table-level queries. Algorithms to build and update datacubes stored as ASTs are shown. A web-based wireless sensor network OLAP server based on the AST is described.","New features for query dependent sponsored search click predictionClick prediction for sponsored search is an important problem for commercial search engines. Good click prediction algorithm greatly affects on the revenue of the search engine, user experience and brings more clicks to landing pages of advertisers. This paper presents new query-dependent features for the click prediction algorithm based on treating query and advertisement as bags of words. New features can improve prediction accuracy both for ads having many and few views.","Computer science in secondary schools in the UK: ways to empower teachersThe recent move towards more Computer Science in school in the UK has obvious implications for teacher education, both for in-service and pre-service teachers. In England and other parts of the UK we have seen an unprecedented rate of change in the way that curricula are changing from a focus on learning to use software applications to the introduction of Computer Science throughout primary and secondary schools. In this paper we describe some of the challenges that we have faced, the progress made in the integration of CS, and the support provided for teachers in their professional development. Current developments seek to support teachers with varying needs in a holistic way and we propose a transformational model of professional development [1] for CS, both for in-service teachers as well as forming the basis of new teacher training programmes.","Fair Anonymous Authentication for Location Based ServicesWe propose an efficient anonymous authentication scheme that provides untraceability and unlinkability of mobile devices, while accessing Location-Based Services. Following other recent approaches for mobile anonymity, in our scheme the network operator acts as an anonymous credential issuer for its users. However, our scheme supports credential non-transferability, without requiring embedded hardware se- curity features. In addition it supports fairness characteristics. On one hand, it reduces the trust assumptions for the issuer by supporting non- frameability: the issuer, even in collaboration with the LBS provider, cannot simulate a transaction that opens back to an honest user. On the other hand, it supports anonymity revocation for illegally used creden- tials. Our scheme uses standard primitives such as zero-knowledge proofs, MACs and challenge/responses. We provide formal security proofs based on the intractability of the Divisible Diffie-Hellman assumption.","Automation of Upgrade Process for Enterprise Resource Planning Systems ","Network Traffic Analysis Using Android on a Hybrid Computing ArchitectureNowadays more and more smartphone applications use internet connection, resulting, from the analysis point of view, in complex and huge generated traffic. Due to mobility and resource limitations, the classical approaches to traffic analysis are no more suitable. Furthermore, the most widespread mobile operating systems, such as Android, do not provide facilities for this task. Novel approaches have been presented in the literature, in which traffic analysis is executed in hardware using the Decision Tree classification algorithm. Although they have been proven to be effective in accelerating the classification process, they typically lack an integration with the remaining system. In order to address this issue, we propose a hybrid computing architecture which enables the communication between the Android OS and a traffic analysis hardware accelerator coexisting on the same chip. To this aim, we provide an Android OS porting on a Xilinx Zynq architecture, composed of a dual-core ARM-based processor integrated with FPGA cells, and define a technique to realize the connection with programmable logic components.","Improved bounds for Erd\u0151s' Matching ConjectureThe main result is the following. Let F be a family of k-subsets of an n-set, containing no s+1 pairwise disjoint edges. Then for n&gt;=(2s+1)k-s one has |F|=&lt;(nk)-(n-sk). This upper bound is the best possible and confirms a conjecture of Erdos dating back to 1965. The proof is surprisingly compact. It applies a generalization of Katona@'s Intersection Shadow Theorem.","From Discrete to Continuous Motion Planning ","Dimensioning self-sufficient networks of energy harvesting embedded devicesEnergy efficiency and self sustainability are among the primary objectives for networks of embedded devices, such as those of sensor networks and Internet of Things. In this paper we present a reference framework to obtain the optimal configuration parameters of networked devices with energy scavenging capabilities. Specifically, we derive an optimization method that links a simple and yet effective energy consumption model to network topology configurations and to the average energy that is harvested from the environment. This model is efficiently solved using interior point algorithms, making it possible to obtain optimal communication parameters and their feasibility regions, so as to ensure the perpetual operation of embedded communicating devices. Moreover, our framework allows for a dynamic system configuration as a function of the harvested energy income rate, thus making the considered networks flexible and self-adaptable.","Context Aware Business Documents ModelingThe reliable, efficient and seamless exchange of business information is essential for a successful execution of the interwoven business processes. However, development of the contents for electronic data exchange is time consuming and usually can not follow the agile demands of the today's business. If we could contextualize the pieces of the currently valid business information, we could predict its possible context specific variations. Therefore, the business contextual knowledge in which the already existing data contents are valid could be exploited to semi- automatically generate new, more homogeneous contents for electronic data interchange.","A Cognitive Interactive Framework for Multi-Document SummarizerIn this paper, we present a generic interactive framework based on human cognition, where the system can learn continuously from the Internet and from its interactionwiththeusers.Toshowtheutilizationofthisframework,Iintelli,anagent based application for multiple text document summarization is developed and com- pared with the MEAD on the Cran Data Set. Mead is a natural language processing- based summarizer, which provides summary by extracting sentences from a cluster of related documents and Cran is a data set maintained by Information Retrieval Group at University of Glasgow. The human knowledge and experience are repre- sented through fuzzy logic-based word-mesh and sentence-mesh, which can learn. Learning is performed using the competitive models, namely, Maxnet and Mexican Hat Models. As the result shows, the framework performs well as a multi-document summarizer. Though we have tested the framework for multi-document summariza- tion, we believe that it can be extended to develop interactive applications for other domains and tasks.","Building Large Scale Traversability Maps Using Vehicle Experience ","Changes in posture of the upper extremity through the use of various sizes of tablets and charactersThe aim of this study was to analyze the posture of the upper extremities during the use of mobile communication devices. Using various sizes of mobile devices and display characters, we examined subjective muscular loads, viewing distances, and joint angles in the head, neck, shoulder, elbow, and lower back. No postural differences were found between the use of 7-in and 10-in devices, whereas the head and neck were significantly flexed and the elbow angles were decreased during the use of the 13-in device. Character size significantly affected the viewing distance; however, no differences in body angles were found. Participants continually increased their muscular loads during the task by flexing the head and neck, despite their high subjective discomfort levels in the neck and upper arm.","Evaluation of Human-System Interfaces with Different Information Organization Using an Eye Tracker ","Accessibility and Usability of Social Media: Convergence between Blind Users and Design StandardsAbout 300 million people with vision impairments face significant access and usability barriers in interacting with social networking sites (SNS) to communicate, collaborate and enhance professional relationships. These barriers primarily result from the visuo-centric design of Web 2.0 technologies. Literature recognizes that SNS interaction with assistive technologies is problematic, but does not clarify: W here, how and why blind users face SNS interaction challenges? This paper reports the findings of an exploratory field study to answer this question. Thinkaloud observations and verbal protocol analysis was used for a contextually-situated and experiential understanding of blind SNS users\u2019 accessibility and usability problems. Results illustrate the nature of problems, identify problematic design elements, and explain character of these problems. Findings have implications for research on blind empowerment, human-computer interactions, and improving SNS accessibility and usability for all users.","Online Astroturfing: A Theoretical Perspective ","CHARM pad: ontology-based tool for learning systematic knowledge about nursingJapan is no exception among developed countries facing healthcare system problems due to aging and low birthrate as the number of patient increases and health care worker numbers shrink. The introduction of high tech medicine has increased the amount of knowledge to be learned by novice nurses. Although vast amounts of implicit knowledge have accumulated among nursing practitioners, this knowledge needs to be communicated when hospitals train younger generations of nurses. In this paper, the authors have proposed an activity model called CHARM (the Convincing Human Action Rationalized Model) and CHARM Pad, tablet PC with browsing software for CHARM models. CHARM explicates multidimensional purpose-oriented procedure relations often existing as implicit knowledge. For this reason, CHARM supports the training and education of novice nurses. We developed CHARM models according to nursing guidelines of hospitals and applied them to training of the nurses in two hospitals. CHARM and CHARM Pad are being evaluated at these hospitals and positive responses are coming from nurses.","Compact Symbolic ExecutionWe present a generalisation of King\u2019s symbolic execution#N#technique called compact symbolic execution. It proceeds in two#N#steps. First, we analyse cyclic paths in the control flow graph#N#of a given program, independently from the rest of the program.#N#Our goal is to compute a so called template for each such a#N#cyclic path. A template is a declarative parametric description#N#of all possible program states, which may leave the analysed#N#cyclic path after any number of iterations along it. In the#N#second step, we execute the program symbolically with the#N#templates in hand. The result is a compact symbolic execution#N#tree. A compact tree always carry the same information in all#N#its leaves as the corresponding classic symbolic execution#N#tree. Nevertheless, a compact tree is typically substantially#N#smaller than the corresponding classic tree. There are even#N#programs for which compact symbolic execution trees are finite#N#while classic symbolic execution trees are infinite.","Grassmannian Spectral Regression for Action RecognitionAction recognition from multiple views and computational perfor- mance associated with high-dimensional data are common challenges for real-world action classification systems. Subspace learning has received consi- derable attention as a means of finding an efficient low-dimensional representa- tion that leads to better classification and efficient processing. In this paper we propose Grassmannian Spectral Regression (GRASP), a novel subspace learn- ing algorithm which combines the benefits of Grassmann manifolds and spec- tral regression for fast and accurate classification. A Grassmann manifold is a space that promotes smooth surfaces where points represent subspaces and the relationship between points is defined by a mapping of an orthogonal matrix. Spectral regression is a regularized subspace learning approach that overcomes the disadvantages of eigen-based approaches. We demonstrate the effective- ness of GRASP on computationally intensive, multi-view action classification using the INRIA IXMAS dataset and the i3DPost Multi-View dataset.","Contextualized Web Warnings, and How They Cause DistrustCurrent warnings in Web browsers are difficult to understand for lay users. We address this problem through more concrete warning content by contextualizing the warning - for example, taking the user's current intention into account in order to name concrete consequences. To explore the practical value of contextualization and potential obsta- cles, we conduct a behavioral study with 36 participants who we either confront with contextualized or with standard warning content while they solve Web browsing tasks. We also collect exploratory data in a posterior card-sorting exercise and interview. We deduce a higher under- standing of the risks of proceeding from the exploratory data. Moreover, we identify conflicting effects from contextualization, including distrust in the content, and formulate recommendations for effective contextual- ized warning content.","The Effect of Parallelization on a Tetrahedral Mesh Optimization MethodA parallel algorithm for simultaneous untangling and smoothing of tetrahedral meshes is proposed in this paper. This algo- rithm is derived from a sequential mesh optimization method. We provide a detailed analysis of its parallel scalability and efficiency, load balancing, and parallelism bottlenecks using six benchmark meshes. In addition, the influence of three previously-published graph coloring techniques on the performance of our parallel algorithm is evaluated. We demonstrate that the proposed algorithm is highly scalable when run on a shared-memory computer with up to 128 Itanium 2 processors. However, some paral- lel deterioration is observed. Here, we analyze its main causes using a theoretical performance model and experimental results.","Simply-Integrated Method of Judgments of Expert Knowledge Collected in Databases for Objective Computer-Aided Engineering Systems ","Towards a Principled Solution to Simulated Robot Soccer ","Similarity in Web SearchIn this talk we survey how similarity plays an important role in many aspects of Web search, from crawling to indexing and from ranking to query recommendations. This implies similarity of different objects including text of web pages, web links, and web queries. Some similarities are measured directly while other similarities are inferred indirectly. Sometimes the similarity measure can be precomputed while other times needs to be calculated online.","Horizontal and vertical side-channel attacks against secure RSA implementationsSince the introduction of side-channel attacks in the nineties, RSA implementations have been a privileged target. A wide variety of countermeasures have been proposed and most of practical attacks are nowadays efficiently defeated by them. However, in a recent work published at ICICS 2010, Clavier et al.have pointed out that almost all the existing countermeasures were ineffective if the attacks are performed with a modus operandi called Horizontal. Such attacks, originally introduced by Colin Walter at CHES 2001, involve a single observation trace contrary to the classical attacks where several ones are required. To defeat Horizontal attacks, the authors of the ICICS paper have proposed a set of new countermeasures. In this paper, we introduce a general framework enabling to model both Horizontal and classical attacks (called Vertical) in a simple way. This framework enables to enlighten the similarities and the differences of those attack types. From this formalism, we show that even if Clavier et al.'s countermeasures thwart existing attacks, they do not fully solve the leakage issue. Actually, flaws are exhibited in this paper and efficient attacks are devised. We eventually propose a new countermeasure.","Applying DAC Principles to the RDF Graph Data ModelIn this paper we examine how Discretionary Access Control principles, that have been successfully applied to relational and XML data, can be applied to the Resource Description Framework (RDF) graph data model. The objective being to provide a baseline for the spec- ification of a general authorisation framework for the RDF data model. Towards this end we provide a summary of access control requirements for graph data structures, based on the different characteristics of graph models compared to relational and tree data models. We subsequently focus on the RDF data model and identify a list of access rights based on SPARQL query operations; propose a layered approach to authorisation derivation based on the graph structure and RDFSchema; and demon- strate how SQL GRANT and REVOKE commands can be adapted to cater for delegation of privileges in SPARQL.","A Verified Protocol to Implement Multi-way Synchronisation and Interleaving in CSPThe complexity of concurrent systems can turn their development into a very complex and error-prone task. The use of formal methods like CSP considerably simplifies this task. Development, however, usually aims at reaching an executable program:i\u00be?a translation into a programming language is still needed and can be challenging. In previous work, we presented a tool, csp2hc, that translates a subset of CSP into Handel-C source code, which can itself be converted to produce files to program FPGAs. This subset restricts parallel composition:i\u00be?multi-synchronisation and interleaving on shared channels are not allowed. In this paper, we present an extension to csp2hc that removes these restrictions. We provide a performance analysis of our code.","Conceptual Architecture of Knowledge Base for Administrative Procedure Execution ","Collective Learning Paradigm for Rapidly Evolving Curriculum: Facilitating Student and Content Engagement via Social Media. ","On the Complexity of Strong and Epistemic Credal NetworksCredal networks are graph-based statistical models whose parameters take values on a set, instead of being sharply specified as in traditional statistical models (e.g., Bayesian networks). The result of inferences with such models depends on the irrelevance/independence concept adopted. In this paper, we study the computational complexity of inferences under the concepts of epistemic irrelevance and strong independence. We strengthen complexity results by showing that inferences with strong independence are NP-hard even in credal trees with ternary variables, which indicates that tractable algorithms, including the existing one for epistemic trees, cannot be used for strong independence. We prove that the polynomial time of inferences in credal trees under epistemic irrelevance is not likely to extend to more general models, because the problem becomes NP-hard even in simple polytrees. These results draw a definite line between networks with efficient inferences and those where inferences are hard, and close several open questions regarding the computational complexity of such models.","Promises and Failures of Research in Dynamic Service CompositionThis short articles discusses the evolution of research in composition technologies, from workflows to mashups. It emphasizes the failures of composition technologies and makes the case for domain-specific workflows as a possible successful way to leverage composition technologies. 1 Dynamic Workflows This short articles discusses the evolution of research in composition technologies, from workflows to mashups. It takes as a starting point the work reported in the paper Adaptive and dynamic service composition in eFlow(1), published in CAiSE 2000. The objective of that paper was to discuss how we can make a service composition more flexible, deciding at deployment or at runtime which concrete service or sets of services should be invoked. We had already realized, back then, that human intervention in this adaptation would be needed, and so the goal of the paper was to discuss how we could simplify the adaptation process, rather than automating it. At that point, web services and the research area of service composition was in its infancy. Web services themselves were a rather new concept, and indeed in that year we had organized the first workshop on Technologies for e-services in conjunction with the VLDB conference. Back then, research in composition technologies was still mostly in the domain of workflow management. Workflow technology was born in the late 1980s with the promise to automate office procedures and facilitate the coordination and data flow among employees. Composition and workflows - and the related languages and technologies - seemed to make a lot of sense. We have tasks (and often business tasks) which we do need to coordinate and orchestrate to achieve some business value, so why not design a","Active Scene Text Recognition for a Domestic Service Robot ","Using a mark-to-market valuation technique to objectively measure IT portfolio value creationEnterprise executives frequently face the challenge of making decisions under conditions of significant uncertainty when dealing with IT investments, IT project management and realization of intangible organizational benefits enabled by IT. A suitable methodology for accurately estimating the current financial standing of each project in a portfolio of IT projects over the full project lifecycle is useful for IT managers to understand IT value creation and manage the IT projects across the portfolio. In line with this perspective, we propose a Mark-to-Market valuation technique that enables a standardized approach across diverse IT projects that comprise the IT portfolio. Three main contributions may be drawn from this study: 1) the Mark-to-Market approach is a useful valuation technique in the context of IT projects; 2) practitioners may leverage the technique to assess project value and the performance of the IT portfolio over the lifecycle of such projects; and 3) the consistent treatment of each project allows aggregation and applications of standard portfolio management techniques to the practice of IT portfolio management.","Using Hasse Diagrams for Competence-Oriented Learning AnalyticsLearning analytics refers to the process of collecting, analyzing, and visualizing (large scale) data about learners for the purpose of understanding and pro-actively optimizing teaching strategies. A related concept is formative assessment - the idea of drawing information about a learner from a broad range of sources and on a competence-centered basis in order to go beyond mere grading to a constructive and tailored support of individual learners. In this paper we present an approach to competence-centered learning analytics on the basis of so-called Competence-based Knowledge Space Theory and a way to visualize learning paths, competency states, and to identify the most effective next learning steps using Hasse diagrams.","Complete SCARE of AES-Like Block Ciphers by Chosen Plaintext Collision Power AnalysisDespite Kerckhoffs's principle, proprietary or otherwise secret cryptographic algorithms are still used in real life. For security and efficiency reasons a common design practice simply modifies some parameters of widely used and well studied encryption standards. In this paper, we investigate the feasibility of reverse engineering the secret specifications of an AES-like block cipher by SCARE techniques based on collision power analysis. In the considered observational model, we demonstrate that an adversary who does not know the secret key can recover the full set of secret parameters of an AES-like software implementation even if it is protected by common first-order Boolean masking and shuffling of independent operations. We study possible countermeasures and recall some simple guidelines to mitigate the side-channel information with the aim to thwart our attacks.","Integration of the Multi-scale Heterogeneous Data for the Deployment of the Concept of Energy Efficiency in Buildings within an SDI Framework ","Solving Router Nodes Placement Problem with Priority Service Constraint in WMNs Using Simulated Annealing ","Electro-oculogram Based Classification of Eye Movement Direction ","Flexible Nonparametric Kernel Learning with Different Loss FunctionsSide information is highly useful in the learning of a nonparametric kernel matrix. However, this often leads to an expensive semidefinite program SDP. In recent years, a number of dedicated solvers have been proposed. Though much better than off-the-shelf SDP solvers, they still cannot scale to large data sets. In this paper, we propose a novel solver based on the alternating direction method of multipliers ADMM. The key idea is to use a low-rank decomposition of the kernel matrix Z = X i\u00be\u017a Y, with the constraint that X = Y. The resultant optimization problem, though non-convex, has favorable convergence properties and can be efficiently solved without requiring eigen-decomposition in each iteration. Experimental results on a number of real-world data sets demonstrate that the proposed method is as accurate as directly solving the SDP, but can be one to two orders of magnitude faster.","Critical Issues in Model-Based Surrogate Functions in Estimation of Distribution AlgorithmsIn many optimization domains the solution of the problem can be made more efficient by the construction of a surrogate fitness model. Estimation of distribution algorithms (EDAs) are a class of evolutionary algorithms particularly suitable for the conception of model-based surrogate techniques. Since EDAs generate probabilistic models, it is natural to use these models as surrogates. However, there exist many types of models and methods to learn them. The issues involved in the conception of model-based surrogates for EDAs are various and some of them have received scarce attention in the literature. In this position paper, we propose a unified view for model-based surrogates in EDAs and identify a number of critical issues that should be dealt with in order to advance the research in this area.","A Cutting Plane Heuristic Algorithm for the Time Dependent Chinese Postman ProblemIn this paper we describe a cutting plane heuristic algo- rithm for the Time Dependent Chinese Postman Problem. This algo- rithm is based on the facial structure of the time dependent postman polyhedron and on the simplex method. The facial structure investigated here provides cutting planes that can be separated polynomially using a maximum flow algorithm, and the simplex method exhibits the linear programming relaxation solutions, based on which two upper bound heuristics are designed. Computational results show that the cutting planes can improve the lower bound of the formulation substantially, and that the best upper bound obtained by the two stage heuristic is always very close to the lower bound in most cases.","Generation and analysis of 3d virtual neurons using genetic regulatory network modelNeuronal morphology is significant for understanding structure-function relationships and brain information processing in computational neuroscience. So it is very important to simulate neuronal morphology completely and accurately. In this paper, we present a novel approach for efficient generation of 3D virtual neurons using genetic regulatory network model. This approach describes dendritic geometry and topology by locally inter-correlating morphological variables which can be represented by the dynamics of gene expression. The experimental results show that the generating virtual neurons that are anatomically indistinguishable and accurate from experimentally traced real neurons.","Clustering and Prediction of Rankings Within a Kemeny Distance Framework ","A Dependency Graph Isomorphism for News Sentence SearchingGiven that the amount of news being published is only in- creasing, an effective search tool is invaluable to many Web-based com- panies. With word-based approaches ignoring much of the information in texts, we propose Destiny, a linguistic approach that leverages the syn- tactic information in sentences by representing sentences as graphs with disambiguated words as nodes and grammatical relations as edges. Des- tiny performs approximate sub-graph isomorphism on the query graph and the news sentence graphs, exploiting word synonymy as well as hy- pernymy. Employing a custom corpus of user-rated queries and sentences, the algorithm is evaluated using the normalized Discounted Cumulative Gain, Spearman's Rho, and Mean Average Precision and it is shown that Destiny performs significantly better than a TF-IDF baseline on the considered measures and corpus.","An Experimental Study of Pruning Techniques in Handwritten Text Recognition Systems ","An Exact Method for the Assembly Line Re-balancing ProblemIn this paper, we propose a mathematical optimisation model to solve the simple assembly line rebalancing problem. This problem arises when an existing assembly line has to be rebalanced in order to meet new production requirements. In this paper, a Mixed Integer Program is proposed for solving this problem with the objective to minimize the number of changes in the initial line. The computational experiments show the efficacy of the proposed method.","Programming the Goalkeeper of 20 DOF for FIRA CupIn this paper is proposed an algorithm for an autonomus goalkeeper capable of the interaction with the environment of an An- droSot(Android Soccer Tournament) game. The algorithm is based on the behavior of the actuation and the vision systems acting as a trajec- tory sensor. Through a proposed set of trajectories, the goalkeeper es capable to determinate the trajectory of the soccer-player. The experi- mental results shows that the goalkeeper stops any ball shooted by the soccer-player, it was the goalkeeper of the DotMX of the FIRA World Cup 2012.","Indecomposable coverings with unit discsWe disprove the 1980 conjecture of J\\'anos Pach about the cover-decomposability of open convex sets by showing that the unit disc is not cover-decomposable. In fact, our proof easily generalizes to any set with a smooth boundary. We also show that (the suitable variant of) the conjecture holds for unbounded sets.","Centrality of visual aesthetics in the online context: an assessment and empirical evidenceThis research investigates individual differences in the centrality of visual aesthetics (CVA) in the online context. The study examines the influence of CVA on online user responses, namely perception of website visual appeal, trust, and intention to use websites. A series of three experiments provide evidence that CVA influence user responses, especially when users' CVA is assessed by the indirect measure developed in this study. The results indicate that the impact of CVA on user responses is stronger among users with high CVA than those with low CVA, and especially when the users are exposed to website with relatively low visual appeal.","Mechanisms to Locate Non-cooperative Transmitters in Wireless Networks ","The shape of things to run: compiling complex stream graphs to reconfigurable hardware in limeReconfigurable hardware can deliver impressive performance for some applications, when a highly static hardware design closely matches application logic. Obliged to express efficient static hardware structures, hardware designers cannot currently employ abstractions using dynamic features of modern programming languages.#R##N##R##N#We present the design and implementation of new features in the Lime programming language that admit construction of stream graphs of arbitrary shape using the expressive power of an imperative, object-oriented language. The Lime programmer marks computations destined for hardware, and the compiler statically checks these computations for repeatable structure. If the check succeeds, the system guarantees it can extract the static structure needed for hardware synthesis.#R##N##R##N#We describe the language design in detail and present case studies of 10 Lime benchmarks, each successfully synthesized to a Xilinx Virtex 5 FPGA.","The Principle and Algorithm for Generating Incidence Matrix for Any Arbitrary Network ","Cortical Surface Analysis of Multi-contrast MR Data to Improve Detection of Cortical Pathology in Multiple SclerosisCortical multiple sclerosis (MS) lesions are very hard to detect on magnetic resonance images, even though histopathology studies reveal that their extent can be important. Certain pulse sequences are known to help detect the lesions, but this detection is still very incomplete. To aid detection, we propose to use a cortical surface-based analysis of multi-contrast MR data in MS and healthy control subjects. We show that magnetization transfer ratio and T1-weighted scans both show differences at the group level between relapsing-remitting MS patients and healthy controls. This suggests that this approach would be useful to help detect cortical pathology in MS.","Strategy-Based Dynamic Real-Time Route PredictionPeople often experience difficulty traversing novel environments. Predicting where wayfinders will go is desirable for navigational aids to prevent mistakes and influence inefficient traversals. Wayfinders are thought to use criteria, such as minimizing distance, that comprise wayfinding strategies for choosing routes through environments. In this contribution, we computationally generated routes for five different wayfinding strategies and used the routes to predict subsequent decision points that wayfinders in an empirical study traversed. It was found that no single strategy was consistently more accurate than all the others across the two environments in our study. We next performed real-time classification to infer the most probable strategy to be in use by a wayfinder, and used the classified strategy to predict subsequent decision points. The results demonstrate the efficacy of using multiple wayfinding strategies to dynamically predict subsequently traversed decision points, which has implications for navigational aids, among other real-world applications.","Practical Multilinear Maps over the IntegersExtending bilinear elliptic curve pairings to multilinear maps is a long-standing open problem. The first plausible construction of such multilinear maps has recently been described by Garg, Gentry and Halevi, based on ideal lattices. In this paper we describe a different construction that works over the integers instead of ideal lattices, similar to the DGHV fully homomorphic encryption scheme. We also describe a different technique for proving the full randomization of encodings: instead of Gaussian linear sums, we apply the classical leftover hash lemma over a quotient lattice. We show that our construction is relatively practical: for reasonable security parameters a one-round 7-party Diffie-Hellman key exchange requires less than 40 seconds per party. Moreover, in contrast with previous work, multilinear analogues of useful, base group assumptions like DLIN appear to hold in our setting.","Digital Libraries for Experimental Data: Capturing Process through Sheer Curation ","Locality preserving non-negative basis learning with graph embeddingThe high dimensionality of connectivity networks necessitates the development of methods identifying the connectivity building blocks that not only characterize the patterns of brain pathology but also reveal representative population patterns. In this paper, we present a non-negative component analysis framework for learning localized and sparse sub-network patterns of connectivity matrices by decomposing them into two sets of discriminative and reconstructive bases. In order to obtain components that are designed towards extracting population differences, we exploit the geometry of the population by using a graph-theoretical scheme that imposes locality-preserving properties as well as maintaining the underlying distance between distant nodes in the original and the projected space. The effectiveness of the proposed framework is demonstrated by applying it to two clinical studies using connectivity matrices derived from DTI to study a population of subjects with ASD, as well as a developmental study of structural brain connectivity that extracts gender differences.","Expectation Maximization for Average Reward Decentralized POMDPsPlanning for multiple agents under uncertainty is often based on decentralized partially observable Markov decision processes (Dec-POMDPs), but current methods must de-emphasize long-term effects of actions by a discount factor. In tasks like wireless networking, agents are evaluated by average performance over time, both short and long-term effects of actions are crucial, and discounting based solutions can perform poorly. We show that under a common set of conditions expectation maximization (EM) for average reward Dec-POMDPs is stuck in a local optimum. We introduce a new average reward EM method; it outperforms a state of the art discounted-reward Dec-POMDP method in experiments.","3D Surface Reconstruction of Organs Using Patient-Specific Shape Priors in Robot-Assisted Laparoscopic SurgeryWith the advent of robot-assisted laparoscopic surgery RALS, intra-operative stereo endoscopy is becoming a ubiquitous imaging modality in abdominal interventions. This high resolution intra-operative imaging modality enables the reconstruction of 3D soft-tissue surface geometry with the help of computer vision techniques. This reconstructed surface is a prerequisite for many clinical applications such as image-guidance with cross-modality registration, telestration, expansion of the surgical scene by stitching/mosaicing, and collision detection. Reconstructing the surface geometry from camera information alone remains a very challenging problem in RALS mainly due to a small baseline between the optical centres of the cameras, presence of blood and smoke, specular highlights, occlusion, and smooth/textureless regions. In this paper, we propose a method for increasing the overall surface reconstruction accuracy by incorporating patient specific shape priors extracted from pre-operative images. Our method is validated on an ini\u00be?silico phantom and we show that the combination of both pre-operative and intra-operative data significantly improves surface reconstruction as compared to the ground truth. Finally, we verify the clinical potential of the proposed method in the context of abdominal surgery in a phantom study of an exi\u00be?vivo lamb kidney.","Reduction of training noises for text classifiersAutomatic text classification (TC) is essential for the archiving and retrieval of texts, which are main ways of recording information and expertise. Previous studies thus have developed many text classifiers. They often employed training texts to build the classifiers, and showed that the classifiers had good performance in various application domains. However, as the training texts are often inevitably unsound or incomplete in practice, they often contain many terms not related to the categories of interest. Such terms are actually training noises in classifier training, and hence can deteriorate the performance of the classifiers. Reduction of the training noises is thus essential. It is also quite challenging as training texts are unsound or incomplete. In this paper, we develop a technique TNR ( T raining  N oise  R eduction) to remove the possible training noises so that the performance of the classifiers can be further improved. Given a training text d of a category c, TNR identifies a sequence of consecutive terms (in d) as the noises if the terms are not strongly related to c. A case study on the classification of Chinese texts of disease information shows that TNR can improve a Support Vector Machine (SVM) classifier, which is a state-of-the-art classifier in TC. The contribution is of significance to the further enhancement of existing text classifiers.","Hybrid Metaheuristics for the Far From Most String ProblemAmong the sequence selection and comparison problems, the Far From Most String Problem (FFMSP) is one of the computationally hardest with applications in several fields, including molecular biology where one is interested in creating diagnostic probes for bacterial infec- tions or in discovering potential drug targets. In this article, several hybrid metaheuristics are described and tested. Extensive comparative experiments on a large set of randomly generated test instances indicate that these randomized hybrid techniques are both effective and efficient.","The Impact of the MicroprocessorA description and explanation based mainly on the author's personal experiences of the changes in the curriculum for electrical engineering undergraduates and in the required expertise of practising electronics engineers which occurred from the mid-1960s. The changes began with the introduction of digital system design methods, and increased with the subsequent introduction of microprocessors as widely-used programmable components, for which software design expertise was an essential part of their utilisation.","SLA-Aware Load Balancing in a Web-Based Cloud System over OpenStackThis paper focuses on the scalability problem in cloud-based systems when changing the computing requirements, this is, when there is a high degree of requesting service variability in cloud-computing en- vironments. We study a specific scenario for web-based application de- ployed in a cloud system, where the number of requests can change with time. This paper deals with guaranteeing the SLA (Service-Level Agree- ment) in scalable clouds with web-based load variability. We present an architecture able to balance the load (mainly web- browser applications) between different computing virtual machines. This is accomplished by monitoring the system in order to determine when to create or terminate virtual machines. A novel scheduling policy to manage the requested cloud services based on the presented architecture is also proposed. The good results obtained by implementing the proposed architecture in a real cloud framework prove the applicability of our proposal for guaranteeing SLA.","Determination of alarm setpoint for alarm system rationalization using performance evaluationAlarm system is one of the most important element of the plant-operator interfaces in the industrial plants. Alarm lifecycle management is very important to maintain the safety, quality, environmental and economic efficiency of the plant. In our previous study, we proposed the method to select adequate alarm variables and evaluation method in diagnostic and timely manner. In this study, we proposed a method to determine the setpoints for alarm system using three indices and the results of dynamic process simulation on the rationalization stage of the lifecycle of alarm management. And we also presented feasibility of our method by demonstration of a case study.","Adaptive Ensemble Selection for Face Re-identification under Class Imbalance ","Smart NFC-sensors for healthcare applications and further development trendsA promising approach for the application of NFC in healthcare is the combination of the simple handling of NFC with different sensor functionalities. By an advanced design of the NFC-antenna and the surrounding hard- and software, the intelligent NFC-tag can operate as a smart sensor with NFC-interface for the transfer of measurement data. According to this principle, various sensor applications for health care scenarios can be realized. In this article several developments of NFC-sensor applications are introduced like NFC-based fill level measurement, NFC-based analog scale (position detection), NFC-based blood-glucose meter, NFC-based cryo-sensor for vials and NFC-based ultraviolet (UV) assessment for sun burn prevention. The main advantages of these applications are that all NFC-sensors can simply be used by medical, nursing staff or patients and consumers.","On Combining a Context Recognition System and a Configuration Planner for Personalised Ambient Assisted LivingThis abstract describes how a context recognition system and a configuration planner can interact to enable personalised activity monitoring in apartments with different features. The two systems are developed to supporting independent living of senior citizens (primary users) by monitoring their daily interaction with the environment. For this purpose, networked non-intrusive sensors that senses motion, power usage, and pressure are used, in addition relevant physiological parameters such as heart rate and blood pressure are measured on demand.","A Geostatistical Approach for Selecting the Highest Quality MODIS Daily ImagesThe aim of this work was to develop a new methodology for auto- matic selection of the highest quality MODIS daily images, MOD09GA Surface Reflectance product. The methodology developed here complements the quality assessment of MODIS products with a geostatistical analysis of spatial pattern images based on variogram tools. The resulting selection is formed by 26 high- quality images (from an initial dataset of 365) from throughout 2007. Most images with geometric distortion problems, such as the bow-tie effect, were re- jected. The automatic selection was validated by comparing it to manual selec- tion, which showed that it achieved an overall accuracy of 71.4%.","Multi-modal journey planning in the presence of uncertaintyMulti-modal journey planning, which allows multiple types of transport within a single trip, is becoming increasingly popular, due to a strong practical interest and an increasing availability of data. In real life, transport networks feature uncertainty. Yet, most approaches assume a deterministic environment, making plans more prone to failures such as major delays in the arrival. We model the scenario as a non-deterministic planning problem with continuous time and time-dependent probabilities of non-deterministic effects. We present new hardness results. We introduce a heuristic search planner, based on Weighted AO* (WAO*). The planner includes search enhancements such as sound pruning, based on state dominance, and an admissible heuristic. Focusing on plans that are robust to uncertainty, we demonstrate our ideas on data compiled from real historical data from Dublin, Ireland. Repeated calls to WAO*, with decreasing weights, have a good any-time performance. Our search enhancements play an important role in the planner's performance.","Indicator Based Search in Variable Orderings: Theory and Algorithms ","Correlation Mining in Graph Databases with a New MeasureCorrelation mining is recognized as one of the most impor- tant data mining tasks for its capability to identify underlying dependen- cies between objects. Nowadays, data mining techniques are increasingly applied to such non-traditional domains, where existing approaches to obtain knowledge from large volume of data cannot be used, as they are not capable to model the requirement of the domains. In particu- lar, the graph modeling based data mining techniques are advantageous in modeling various real life complex scenarios. However, existing graph based data mining techniques cannot efficiently capture actual corre- lations and behave like a searching algorithm based on user provided query. Eventually, for extracting some very useful knowledge from large amount of spurious patterns, correlation measures are used. Hence, we have focused on correlation mining in graph databases and this paper proposed a new graph correlation measure, gConfidence, to efficiently extract useful graph patterns along with a method CGM (Correlated Graph M ining), to find the underlying correlations among graphs in graph databases using the proposed measure. Finally, extensive perfor- mance analysis of our scheme proved two times improvement on speed and efficiency in mining correlation compared to existing algorithms.","Improving Automatic Edge Selection for Relational Classification ","WANTED: focused queries for focused retrievalFocused retrieval tasks such as XML or passage retrieval strive to provide direct access to the relevant content of a document. In these scenarios users can pose focused queries, i.e., queries that restrict the type of output the user wants to see. We first analyze several characteristics of this type of requests and show that they differ substantially from the unfocused ones. We also show that typical XML retrieval systems tend to perform poorly on focused queries and that systems ranking differs considerably when processing each of the types. Finally, we argue that the unbalanced number of focused queries in the INEX benchmark topic set might lead to misleading interpretations of the evaluation results. To get a better insight of the systems ability to perform focused search, more focused queries are needed.","P2AMF: Predictive, Probabilistic Architecture Modeling FrameworkIn the design phase of business and software system development, it is desirable to predict the properties of the system-to-be. Existing prediction systems do, however, not allow the modeler to express uncertainty with respect to the design of the considered system. In this paper, we propose a formalism, the Predictive, Probabilistic Architecture Modeling Framework (P 2AMF), capable of advanced and probabilistically sound reasoning about architecture models given in the form of UML class and object diagrams. The proposed formalism is based on the Object Constraint Language (OCL). To OCL, P2AMF adds a probabilistic inference mechanism. The paper introduces P2AMF, describes its use for system property prediction and assessment, and proposes an algorithm for probabilistic inference.","Consultant-as-a-service: an interactive and context-driven approach to mobile decision support servicesThis paper presents a new generation of decision support services where techniques from software agents, semantic analysis, and data mining are orchestrated through a new cloud-based concept namely \"Consultant-as-a-Service\". The proposed concept will be offered as a set of new cloud application program interfaces that coach the user, who is not familiar with an organization, to effectively select the desired organization's business services and seamlessly connect them with the proper third-party applications (e.g., map, search engine, calendar, email, voice, video) in the user's mobile device (smart phone or tablet). Such consultant services can be provided for a variety of strategic business domains such as: banking, insurance, government, healthcare, and on-line shopping. A prototype mobile service has been developed using iOS for iPhone.","Barriers and opportunities to the widespread adoption of telemedicine: a bi-country evaluation.Recognizing that current practices for healthcare delivery are no longer sustainable, OECD governments are focusing more and more on how to leverage ICT to facilitate superior healthcare delivery. One such possibility is the use of Telemedicine. A major goal of telemedicine today is to develop next-generation telemedicine tools and technologies. However, key andquot;classicandquot; barriers continue to challenge widespread telemedicine adoption by health care organizations. These barriers include technology, financial, legal/standards, business strategy, and human resources issues. This comparative study explores the current status of barriers and opportunities to the widespread adoption of telemedicine in two different countries: Sweden, and USA.","Moral values from simple game playWe investigate whether a small digital trace, gathered from simple repeated matrix game play data, can reveal fundamental aspects of a person's sacred values or moral identity. We find correlations that are often counterintuitive on the surface, but are coherent upon deeper analysis. This ability to reveal information about a person's moral identity could be useful in a wide variety of settings.","Formal Analysis of the ACE Specification for Cache Coherent Systems-on-ChipSystem-on-Chip (SoC) architectures integrate now many different components, such as processors, accelerators, memory, and I/O blocks, some but not all of which may have caches. Because the validation effort with simulation-based validation techniques, as currently used in industry, grows exponentially with the complexity of the SoC, we investigate in this paper the use of formal verification techniques. More precisely, we use the CADP toolbox to develop and validate a generic formal model of an SoC compliant with the recent ACE specification proposed by ARM to implement system-level coherency.","A Note on Probabilistic Models over Strings: Inference and Representation with Indexed MatricesProbabilistic models over strings have played a key role in developing methods allowing indels to be treated as phylogenetically informative events. In this work, we show how to derive a closed-form expression for computing the probability of a collection of observed sequences given a tree. This expression is in terms of elementary operations on indexed collections of matrices, and can be derived for a wide range of indel models.","Liquid Communication: An Analysis of the Impact of Mobile Micro-blogging on Communication and Decision-Making ","Current state of the digital deception studies in IS ","An RDF/OWL knowledge base for query answering and decision support in clinical pharmacogenetics.Genetic testing for personalizing pharmacotherapy is bound to become an important part of clinical routine. To address associated issues with data management and quality, we are creating a semantic knowledge base for clinical pharmacogenetics. The knowledge base is made up of three components: an expressive ontology formalized in the Web Ontology Language (OWL 2 DL), a Resource Description Framework (RDF) model for capturing detailed results of manual annotation of pharmacogenomic information in drug product labels, and an RDF conversion of relevant biomedical datasets. Our work goes beyond the state of the art in that it makes both automated reasoning as well as query answering as simple as possible, and the reasoning capabilities go beyond the capabilities of previously described ontologies.","Enhancing Modeling and Change Support for Process Families through Change PatternsThe increasing adoption of process-aware information systems (PAISs), together with the variability of business processes (BPs), has resulted in large collections of related process model variants (i.e., process families). To effectively deal with process families, several proposals (e.g., C-EPC, Provop) exist that extend BP modeling languages with variability-specific constructs. While fostering reuse and reducing modeling efforts, respective constructs imply additional complexity and demand proper support for process designers when creating and modifying process families. Recently, generic and language-independent#R##N#adaptation patterns were successfully introduced for creating and evolving single BP models. However, they are not sufficient to cope with the specific needs for modeling and evolving process families. This paper suggests a complementary set of generic and language-independent change patterns specifically tailored to the needs of process families. When used in combination with existing adaptation patterns, change patterns for process families will enable the modeling and evolution of process families at a high-level of abstraction. Further, they will serve as reference for implementing tools or comparing proposals managing process families.","On the periodic behavior of real-time schedulers on identical multiprocessor platformsThis paper is proposing a general periodicity result concerning any deterministic and memoryless scheduling algorithm (including non-work-conserving algorithms), for any context, on identical multiprocessor platforms. By context we mean the hardware architecture (uniprocessor, multicore), as well as task constraints like critical sections, precedence constraints, self-suspension, etc. Since the result is based only on the releases and deadlines, it is independent from any other parameter. Note that we do not claim that the given interval is minimal, but it is an upper bound for any cycle of any feasible schedule provided by any deterministic and memoryless scheduler.","All-or-Nothing generalized assignment with application to scheduling advertising campaignsWe study a variant of the generalized assignment problem (gap) which we label all-or-nothing GAP (AGAP). We are given a set of items, partitioned into n groups, and a set of m bins. Each item l has size sl&gt;0, and utility alj\u22650 if packed in bin j. Each bin can accommodate at most one item from each group, and the total size of the items in a bin cannot exceed its capacity. A group of items is satisfied if all of its items are packed. The goal is to find a feasible packing of a subset of the items in the bins such that the total utility from satisfied groups is maximized. We motivate the study of agap by pointing out a central application in scheduling advertising campaigns.#R##N##R##N#Our main result is an O(1)-approximation algorithm for agap instances arising in practice, where each group consists of at most m/2 items. Our algorithm uses a novel reduction of agap to maximizing submodular function subject to a matroid constraint. For agap instances with fixed number of bins, we develop a randomized polynomial time approximation scheme (PTAS), relying on a non-trivial LP relaxation of the problem.#R##N##R##N#We present a (3+e)-approximation as well as PTASs for other special cases of agap, where the utility of any item does not depend on the bin in which it is packed. Finally, we derive hardness results for the different variants of agap studied in the paper.","Towards a Standards-Based Cloud Service Manager ","EEG Based Coherence Analysis for Identifying Inter Individual Differences in Language and Logic StudyAccording to Multiple Intelligences MI theory by Howard Gardner, human's intelligence can be divided into linguistic, logical/mathematical, musical, spatial, bodily/kinesthetic, interpersonal, intrapersonal and naturalistic areas. In this paper, two groups of students with high and low MI scores in each area for linguistic and logical/mathematical intelligences were categorized and tested based on a questionnaire in an experiment. Electroencephalogram EEG was recorded from 16 electrodes using Emotiv EPOC for 29 kindergarten children and 9 high school students during the assessment. To investigate the neurophysiological substrates of intelligence, EEG signal based coherence analysis in alpha, beta, gamma and theta frequency bands was performed. Our findings indicate that the group with low MI score for both language and logic showed wider and distributed cognitive activations suggesting an increased effort in processing a particular task. The group with high MI score for language showed effective connectivity within left-hemisphere and low activation in the right parietal lobe. The group with high MI score for logic/mathematics showed increased frontal activation. Performance in language and logic test was further correlated with effective connectivity in the task specific areas of brain. Based on our results we conclude that a smarter brain for language and logic is associated with the limited but affective connectivity.","Inverted File-Based General Metric Space Indexing for Quality-Aware Similarity Search in Information RetrievalThe notion of quality in its broadest sense is central to informa- tion retrieval (IR) where a user's information need is to be fulfilled as good as possible. A user searching for cars on sale in Bamberg might be interested in car dealers geographically close to Bamberg with high user ratings. The buyer might already know or trust a person who trusts the particular dealer. Furthermore, the cars which are sold by the dealer should offer a high quality on different levels\u2014the type of car in general as well as the car to be bought. If the buyer can only travel to Bamberg on weekends, availability of the car dealer becomes another important factor. As this example shows, the inte- gration of various quality aspects in IR is challenging but essential. Thus, there is a need for scalable and efficient indexing and retrieval tech- niques which can cope with such search situations. Here, metric space access methods (MAMs) present a flexible indexing paradigm. We will briefly review these techniques and show how they can be applied in the context of quality- aware IR. Furthermore, we will present IF4MI which is purely based on the inverted file concept and thus inherently provides a multi-feature MAM. It can make use of extensive knowledge in the field of inverted file-based index- ing and represents a versatile indexing technique for quality-aware IR.","Application of data mining techniques on EMG registers of hemiplegic patientsGait analysis provides a very large data volume coming from kinematic, kinetic, electromyographic (EMG) registers and physical examinations. The analysis and treatment of these data is difficult and time consuming. This work applies and explores exhaustively different analysis methods from data mining on these gait data. This study aims to provide a classification system based in gait patterns obtained from EMG records in children with spastic hemiplegia. The methods studied from data mining specifically for the classification task include SVM, neural networks, decision trees, regression logistic models and others. Different techniques of feature extraction and selection have been also employed and combined with classifications methods. The LMT algorithm provides the best result with 97% of instances classified correctly taking into account the indicators for 2 legs. A qualitative and quantitative validation were performed on the data.","Perspectives on Productivity and Delays in Large-Scale Agile ProjectsMany large and distributed companies run agile projects in development environments that are inconsistent with the original agile ideas. Problems that result from these inconsistencies can affect the productivity of development projects and the timeliness of releases. To be effective in such contexts, the agile ideas need to be adapted. We take an inductive approach for reaching this aim by basing the design of the development process on observations of how context, practices, challenges, and impacts interact. This paper reports the results of an interview study of five agile development projects in an environment that was unfavorable for agile principles. Grounded theory was used to identify the challenges of these projects and how these challenges affected productivity and delays according to the involved project roles. Productivity and delay-influencing factors were discovered that related to requirements creation and use, collaboration, knowledge management, and the application domain. The practitioners\u2019 explanations about the factors' impacts are, on one hand, a rich empirical source for avoiding and mitigating productivity and delay problems and, on the other hand, a good starting point for further research on flexible large-scale development.","Mapping texture phase diagram of artificial haptic stimuli generated by vibrotactile actuatorsWe propose a classification method of tactile sensations elicited by artificial haptic stimuli by using Japanese onomatopoeias/adjectives. This method classifies adjectives based on user subjective perception and plot basic components of artificial haptic stimuli. The comparison of perceived tactile sensations from artificial haptic stimuli and genuine physical materials is also discussed in this paper.","On embeddings of CAT(0) cube complexes into products of trees via colouring their hyperplanesWe prove that the contact graph of a 2-dimensional CAT(0) cube complex X of maximum degree @D can be coloured with at most @e(@D)=M@D^2^6 colours, for a fixed constant M. This implies that X (and the associated median graph) isometrically embeds in the Cartesian product of at most @e(@D) trees, and that the event structure whose domain is X admits a nice labelling with @e(@D) labels. On the other hand, we present an example of a 5-dimensional CAT(0) cube complex with uniformly bounded degrees of 0-cubes which cannot be embedded into a Cartesian product of a finite number of trees. This answers in the negative a question raised independently by F. Haglund, G. Niblo, M. Sageev, and the first author of this paper.","Making the right decision: supporting architects with design decision dataSoftware architects are often forced to make design decisions based on limited information. In this paper, we present an approach that allows software architects to study information about design decisions made by hundreds or more software architects by automatically analyzing the version management data of large open-source repositories. The contribution is, first, that it develops a conceptual model to reason about the automatic derivation of specifically medium level architectural design decisions. Second, we show that it is indeed possible to derive these design decisions automatically from open source projects. This provides a basis for statistical and quantitative reasoning about software architecture design decisions that allows software architects to make better-informed decisions.","Multi-organ Segmentation Based on Spatially-Divided Probabilistic Atlas from 3D Abdominal CT ImagesThis paper presents an automated multi-organ segmenta- tion method for 3D abdominal CT images based on a spatially-divided probabilistic atlases. Most previous abdominal organ segmentation meth- ods are ineffective to deal with the large differences among patients in organ shape and position in local areas. In this paper, we propose an automated multi-organ segmentation method based on a spatially- divided probabilistic atlas, and solve this problem by introducing a scale hierarchical probabilistic atlas. The algorithm consists of image-space di- vision and a multi-scale weighting scheme. The generated spatial-divided probabilistic atlas efficiently reduces the inter-subject variance in organ shape and position either in global or local regions. Our proposed method was evaluated using 100 abdominal CT volumes with manually traced ground truth data. Experimental results showed that it can segment the liver, spleen, pancreas, and kidneys with Dice similarity indices of 95.1%, 91.4%, 69.1%, and 90.1%, respectively.","Clustering and Planning for Rescue Agent Simulation ","Diversity beats strength?: a hands-on experience with 9x9 goTeam formation is a critical step in deploying a multi-agent team. In some scenarios, agents coordinate by voting continuously. When forming such teams, should we focus on the diversity of the team or on the strength of each member? Can a team of diverse (and weak) agents outperform a uniform team of strong agents? In this demo, the user will be able to explore these questions by playing one of the most challenging board games: Go.","Partial Test Oracle in Model Transformation Testing ","High Performance Adaptive Finite Element Methods : With Applications in AerodynamicsThe massive computational cost for resolving all scales in a turbulent flow makes a direct numerical simulation of the underlying Navier-Stokes equations impossible in most engineering applications ...","A visual dataflow model for the process flow of remote sensing productsIn order to conveniently and rapidly develop algorithms for remote sensing products, the basic idea is using some existing algorithms to develop a new algorithm. Due to the algorithm dependency, the algorithms are called one by one, which forms a process flow of remote sensing products. In this paper, a visual dataflow model is presented for the production of remote sensing products, which can represent the process flow of remote sensing products. The proposed model can reflect not only the relationship between algorithms, but also the number of algorithm to be called and the information of the data to be processed. Using this model, the changes of the process flow can be described conveniently and the concurrent execution of the algorithm can be performed.","A multiobjective proposal based on the firefly algorithm for inferring phylogeniesRecently, swarm intelligence algorithms have been applied successfully to a wide variety of optimization problems in Computational Biology. Phylogenetic inference represents one of the key research topics in this area. Throughout the years, controversy among biologists has arisen when dealing with this well-known problem, as different optimality criteria can give as a result discordant genealogical relationships. Current research efforts aim to apply multiobjective optimization techniques in order to infer phylogenies that represent a consensus between different principles. In this work, we apply a multiobjective swarm intelligence approach inspired by the behaviour of fireflies to tackle the phylogenetic inference problem according to two criteria: maximum parsimony and maximum likelihood. Experiments on four real nucleotide data sets show that this novel proposal can achieve promising results in comparison with other approaches from the state-of-the-art in Phylogenetics.","Enabling outsourcing XDS for imaging on the public cloud. ","Enhancing Model Driven Security through Pattern Refinement TechniquesSecurity requirements are typically defined at a business abstract level by non-technical security officers. However, in order to fulfill the security require- ments, technical security controls or mechanisms have to be considered and de- ployed on the target system. Based on these security controls security patterns have to be selected. The MDS (Model Driven Security) approach uses secu- rity requirement models at a high level of abstraction to automatically gener- ate security artefacts that configure security services. The main drawback of the current MDS solutions is that they consider just one security pattern for each se- curity requirement. Current SOA and cloud services are scattered across multiple heterogeneous security domains. Partners and clients with different security in- frastructures are changing continuously, which requires the support of multiple patterns for the same security service. The challenge is to provide configurable security services that can support different patterns. In order to overcome this shortcoming we propose a framework that integrates pattern refinement to the MDS approach. In this approach a security pattern refinement layer is added to the traditional MDS layers. The pattern refinement layer supports the configura- tion of one security service with different patterns, which are stored in a pattern catalog. For example, our approach enables the generation of security artefacts that configure a non-repudiation service to support both fair non-repudiation and naive non-repudiation patterns.","Process Alignment for Sustainable Product Development: The Essential Role of Supplier and Customer Involvement ProcessesSustainable product development (SPD) has received increasing attention by scholars and practitioners recently. This paper explores two essential organizational processes to support SPD: supplier and customer involvement. The empirical study in six discrete manufacturing firms shows that various types of sustainability innovations (e.g., recycling or energy efficiency) imply discontinues change in the supply chain and/or customer context, and that these themes only can be implemented when the supplier and customer integration process is sufficiently supported. The results suggest that SPD requires alignment between the type of SPD innovation and the type of SPD organizational processes.","Inter-species Cuckoo Search via Different Levy FlightsIn this paper we improve the meta heuristic algorithm known as Cuckoo Search (CS) to solve optimization problems. The proposed Inter- species Cuckoo Search (ISCS) algorithm is based on the brood parasitic behavior of different inter-related cuckoo species in different areas in combination with Levy flight behavior(which changes with the terrain) of birds. The proposed algorithm is then tested against various test functions and its performance is compared with genetic algorithms, particle swarm optimization and previous versions of Cuckoo Search algorithm.","Coloured video code for in-flight data transmissionWe present a new approach for optical data transmission between the in-flight entertainment (IFE) system of aeroplanes and mobile devices. As wireless in-flight applications are subject to strict frequency and electromagnetic compatibility regulations, we propose to transfer the data optically. We display video streams of 2-dimensional blackand- white or coloured visual codes on the IFE screen. To allow robust reconstruction of the transmitted data, we present a new visual code which is captured and processed by mobile devices of passengers. In order to efficiently compensate for frame losses, the visual codes are coupled with a temporal forward error correction (FEC) scheme. The system is evaluated in an Airbus A330 cabin mock-up under realistic conditions employing representative mobile devices like low-cost and high-end smartphones. Performance evaluations show that the developed transmission system achieves data rates of up to 120 kbit/s per individual passenger seat.","Improved Relay Selection for MIMO-SDM Cooperative Communications ","MRF Based Image Segmentation Augmented with Domain Specific Information ","Seeking for High Level Lexical Association in Texts ","An Interoperability Points Based Interoperability Approach for SaaS ApplicationsSaaS applications have been widely adopted especially by small and medium enterprises. At the same time, the features \"multi-tenancy\" and \"loosely coupled\" bring new challenges to enterprises interoperability. On the basis of the layered interoperability model, the paper presents an approach based on interoperability points to implement interoperation between SaaS applications in the service layer. After carrying out the interoperability point matching algorithm, the intermediary Enterprise Service Bus (ESB) performs dynamic selection of interoperability points dictated by Quality of Service (QoS) attributes. In the premise of a comprehensive consideration of the functional and non-functional preferences and constraints, dynamic interoperation between SaaS applications is realized. Finally, this paper shows a case study of applying the interoperability approach.","Harnessing the Potential of Accessibility Standards and Responsive Web Design Practices to Achieve Learning Interoperability on the Level of the User InterfaceThe emergence of information and communication technologies ICT and web 2.0 has fostered the domain of learning platforms with a variety of learning tools. As a result, many open-source and commercial learning management systems LMS were developed. The variety of platforms and approaches provided by these LMSs makes it difficult to deliver learning content to end users in a consistent manner. Learning tools interoperability, content reusability, learner's information accessibility and share ability are main matters of quality for any LMS. However, learning interoperability standards lack to some extent common semantics on the level of the user interface. This paper discusses this problem in more details and proposes an enhanced approach based on semantics, accessibility standards, and responsive web design practices.","The NIC is the hypervisor: bare-metal guests in IaaS cloudsCloud computing does not inherently require the use of virtual machines, and some cloud customers prefer or even require \"bare metal\" systems, where no hypervisor separates the guest operating system from the CPU. Even for bare-metal nodes, the cloud provider must find a means to isolate the guest system from other cloud resources, and to manage the instantiation and removal of guests. We argue that an enhanced NIC, together with standard features of modern servers, can provide all of the functions for which a hypervisor would normally be required.","Control Strategies and Particle Filter for RGB-D Based Human Subject Tracking and Behavior Recognition by a Bio-monitoring Mobile Robot ","Metro-Line Crossing Minimization: Hardness, Approximations, and Tractable CasesCrossing minimization is one of the central problems in graph drawing. Recently, there has been an increased interest in the problem of minimizing crossings between paths in drawings of graphs. This is the metro-line crossing minimization problem MLCM: Given an embedded graph and a set L of simple paths, called lines, order the lines on each edge so that the total number of crossings is minimized. So far, the complexity of MLCM has been an open problem. In contrast, the problem variant in which line ends must be placed in outermost position on their edges MLCM-P is known to be NP-hard.#R##N##R##N#Our main results answer two open questions: i We show that MLCM is NP-hard. ii We give an    $O\\sqrt{\\log |L|}$   -approximation algorithm for MLCM-P.","Single- and Multi-label Prediction of Burden on Families of Schizophrenia Patients ","Can a Wiki Be Used as a Knowledge Service Platform ","A Study of Electricity Price Features on Distributed Internet Data CentersMany modern cloud services are provided using Internet Data Centers (IDCs), e.g. the Google search engine. A network of IDCs is implemented using a set of data centers that are geographically distributed over many locations. The energy requirements of these systems are considerable, and there is growing interest in minimizing the total cost of energy required to operate them either by making the hardware more energy efficient or by ensuring that opportunities to access low-cost energy are exploited. In this paper we present a methodology for studying the energy cost implications of minimizing IDC energy costs under different operational and energy cost prediction regimes. We systematically study the impact of the level of price variability, time lag between locations due to the geographical distribution, reconfiguration delay, and accuracy of price predictions, on the overall electricity cost associated with managing an IDC.","A Structural SVM Based Approach for Optimizing Partial AUCThe area under the ROC curve (AUC) is a widely used performance measure in machine learning. Increasingly, however, in several applications, ranging from ranking and biometric screening to medical diagnosis, performance is measured not in terms of the full area under the ROC curve, but instead, in terms of the partial area under the ROC curve between two specified false positive rates. In this paper, we develop a structural SVM framework for directly optimizing the partial AUC between any two false positive rates. Our approach makes use of a cutting plane solver along the lines of the structural SVM based approach for optimizing the full AUC developed by Joachims (2005). Unlike the full AUC, where the combinatorial optimization problem needed to find the most violated constraint in the cutting plane solver can be decomposed easily to yield an efficient algorithm, the corresponding optimization problem in the case of partial AUC is harder to decompose. One of our key technical contributions is an efficient algorithm for solving this combinatorial optimization problem that has the same computational complexity as Joachims' algorithm for optimizing the usual AUC. This allows us to efficiently optimize the partial AUC in any desired false positive range. We demonstrate the approach on a variety of real-world tasks.","Energy-Efficient Operation of a Mobile User in a Multi-tier Cellular Network ","Open Creative Framework for a Smart Cultural City: Bologna Porticoes and the Involvement of Citizens for a UNESCO Candidacy ","Balancing Fidelity of Simulation Game Environments to Increase Situational Awareness Skills ","Deformation-based augmented reality for hepatic surgery.In this paper we introduce a method for augmenting the laparoscopic view during hepatic tumor resection. Using augmented reality techniques, vessels, tumors and cutting planes computed from pre-operative data can be overlaid onto the laparoscopic video. Compared to current techniques, which are limited to a rigid registration of the pre-operative liver anatomy with the intra-operative image, we propose a real-time, physics-based, non-rigid registration. The main strength of our approach is that the deformable model can also be used to regularize the data extracted from the computer vision algorithms. We show preliminary results on a video sequence which clearly highlights the interest of using physics-based model for elastic registration.","X-Band Radar Sensor for the Landslide Risk MitigationAbstract. A low cost Stepped Frequency Continuous Wave sensor is proposed in this work as radar module for the long range monitoring of environmental scenarios subject to landslide risk. A radar configuration based on the adoption of a variable scanning antenna array is proposed for the accurate detection of land movements. Furthermore, a X-band radar module prototype is realized and tested to demonstrate the high resolution capabilities of the proposed configuration. Keywords: Radar, sensor, early warning, environmental risk. 1 Introduction The adoption of low-cost and compact radar systems with high resolution capabilities can be strongly helpful in the framework of risk issues management, with a special focus on the monitoring, early warning and mitigation of landslide risk, where the accurate detection of the displacements of large areas is required. When considering standard real aperture radars, limited resolution capabilities, typically of the order of tens meters at high microwave frequencies, can be achieved. To further improve the resolution, synthetic aperture radar techniques and/or interferometric methods are usually adopted, but at the expense of increased signal processing complexity. Most of commercial radar modules work in the millimeter range of frequency for automotive applications. They don\u2019t need a high transmitted power, as operating at short distances. As a consequence of this, they are characterized by a limited frequency bandwidth which precludes a higher resolution in distance and does not allow velocity measurements. A simple and low cost solution is presented in this work, by proposing the use of an own customized Stepped Frequency Continuous Wave (SFCW) radar module, able to achieve range resolution of the order of centimeters. Furthermore, a radar configuration based on the use of a variable scanning antenna array [1], [2], [3], [4] is specifically proposed to face the problem of landslides monitoring, with the ability to dynamically change and address the antenna focus beam on a specified sub-area revealing some kind of anomalous displacement. To demonstrate the claimed features of the proposed approach, a X-band radar module prototype is realized and some preliminary indoor and outdoor tests are discussed.","A three-level approach to the study of multi-cultural social networkingThis paper firstly introduces three levels of research on online social networking and the corresponding three levels of research on multi-cultural social networking in our project: individual level, interaction level and consequence level. Our studies on multi-cultural online social networking through these three levels are then presented in more detail, ranging from the discussion of previous cross-cultural research at each level, to the research designs and main findings of our studies. Lastly the combined results from the three studies are discussed to achieve an overall picture of this phenomenon.","Cascaded Shape Regression for Automatic Prostate Segmentation from Extracorporeal Ultrasound Images ","Verified stochastic methodsMarkov chains provide quite attractive features for simulating a system's behavior under consideration of uncertainties. However, their use is somewhat limited because of their deterministic transition matrices. Vague probabilistic information and imprecision appear in the modeling of real-life systems, thus causing difficulties in the pure probabilistic model set-up. Moreover, their accuracy suffers due to implementations on computers with floating point arithmetics. Our goal is to address these problems by extending the Dempster-Shafer with Intervals toolbox for MATLAB with novel verified algorithms for modeling that work with Markov chains with imprecise transition matrices, known as Markov set-chains. Additionally, in order to provide a statistical estimation tool that can handle imprecision to set up Markov chain models, we develop a new verified algorithm for computing relations between the mean and the standard deviation of fuzzy sets.","Towards Privacy-by-Design Peer-to-Peer Cloud ComputingCurrent Cloud services raise serious security and privacy concerns due to the potential misuse of user data by the omniscient Cloud service provider. Solutions proposing the \"Cloud-of-clouds\" paradigm just mitigate service availability threats, and additional encryption operations do not prevent users from being identified and traced. Moreover, these solutions still fail to address a main orthogonal problem, i.e. the intrinsic contrast between the provider's business model and the user's privacy. In this paper, we propose a new architecture for Cloud computing which addresses the protection of the user's privacy from the outset. Cloud services are provided by a number of cooperating independent parties consisting in the user nodes themselves. Unlike current Cloud services, the proposed solution provides user anonymity and untraceability. Such architecture can still take part in the \"Cloud-of-clouds\", allowing users to select service providers on the basis of the expected privacy protection.","Information Complexity in Bandit Subset SelectionWe consider the problem of eciently exploring the arms of a stochastic bandit to identify the best subset of a specied size. Under the PAC and the xed-budget formulations, we derive improved bounds by using KL-divergence-based condence intervals. Whereas the application of a similar idea in the regret setting has yielded bounds in terms of the KL-divergence between the arms, our bounds in the pure-exploration setting involve the \\Cherno information\" between the arms. In addition to introducing this novel quantity to the bandits literature, we contribute a comparison between strategies based on uniform and adaptive sampling for pure-exploration problems, nding evidence in favor of the latter.","BabySTEPS: A Sugar Tracking Electronic Portal System for Gestational DiabetesGestational diabetes is a condition occurring in up to 18% [1] of pregnant women that results in an increase in blood glucose levels due to the body's inability to produce sufficient insulin given the additional needs of the baby, and/or hormonal changes that lower the body's sensitivity to insulin. If left untreated, the growing baby may become too large, increasing the risk of injury to the mother and baby during delivery. Controlling blood glucose can be a challenging task, especially for women with no previous experience and who may have unhealthy diets. An opportunity exists to further encourage compliance by providing patients electronic access to data generated during their pregnancy. Previous studies have shown the potential of portals for managing general diabetes [2], but no work has targeted glucose control in pregnant women. We present BabySTEPS (Sugar Tracking Electronic Portal System), a patient portal focused on engaging women with gestational diabetes that provides personalized feedback with the goal of reducing complications at birth and subsequent medical problems resulting from poor glucose control. \u00a9 2013 IMIA and IOS Press.","Complete Conceptual Schema AlgebrasA schema algebra comprises operations on database schemata for a given data model. Such algebras are useful in database design as well as in schema integration. In this article we address the necessary theoretical underpinnings by introducing a novel notion of conceptual schema morphism that captures at the same time the conceptual schema and its semantics by means of the set of valid instances. This leads to a category of schemata that is finitely complete and co-complete. This is the basis for a notion of completeness of schema algebras, if it captures all universal constructions in the category of schemata. We exemplify this notion of completeness for a recently introduced particular schema algebra.","Ambient assistive technology considered harmfulAmbient assistive technology (AAT) is envisioned as a powerful tool for facing the growing demands the demographic change toward an aging society puts on care. While AAT is often expected to increase the quality of life of older people, this paper holds that relevant interventions often embody values that can contradict such visions, and in some cases even be harmful to care receivers. We argue that the strong focus AAT puts on illness and risk management reflects a medical model of care, which often disregards the psychosocial challenges that impairments and disabilities associated with old age can rise. We suggest that design of AAT could benefit from using the social model of care as design inspiration and value foundation. Such an approach puts focus on the person rather than the illness. The paper ends by providing a short description of work in which the social model of care is adopted as a basis for design of AAT.","A method for discussing musical expression between music ensemble players using a web-based systemMusic ensemble players discuss musical expression of the piece of music they perform, and determine how to play each note in a score such as the length and the dynamics of tone or phrases in every detail of the music. This paper introduces our system that supports the discussion about musical expressions on the web. Our system enables the users to write comments, draw symbols, and link videos on the score where they are discussing about. We also conducted an informal usability study to evaluate the usefulness of the system.","Low SNR FMCW Signal Processing with Prior Information ","Autonomous representation learning in a developing agent ","Differential Power Analysis of MAC-Keccak at Any Key-LengthKeccak is a new hash function selected by NIST as the next SHA-3 standard. Keccak supports the generation of Message Authenti- cation Codes (MACs) by hashing the direct concatenation of a variable- length key and the input message. As a result, changing the key-length directly changes the set of internal operations that need to be targeted with Differential Power Analysis. The proper selection of these target op- erations becomes a new challenge for MAC-Keccak, in particular when some key bytes are hidden under a hierarchical dependency structure. In this paper, we propose a complete Differential Power Analysis of MAC-Keccak under any key-length using a systematic approach to iden- tify the required target operations. The attack is validated by success- fully breaking several, practically difficult, case studies of MAC-Keccak, implemented with the reference software code on a 32-bit Microblaze processor.","Active Contours Tool for the Common Carotid Artery Layers Segmentation in Ultrasound Images ","Predictive modelling for HCI problems in novice program editorsWe extend previous cognitive modelling work to four new programming systems, with results contributing to the development of a new novice programming editor. Results of a previous paper, which quantified differences in certain visual languages, and feedback we had regarding interest in the work, suggested that there may be more systems to which the technique could be applied. This short paper reports on a second series of models, discusses their strengths and weaknesses, and draws comparisons to the first. This matters because we believe \"bottlenecks\" in interaction design to be an issue in some beginner languages -- painfully slow interactions may not always be noticeable at first, but start to become intrusive as the programs grow larger. Conversely, text-based languages are generally less viscous, but often use difficult symbols and terminology, and can be highly error-prone. Based on the models presented here, we propose some simple design choices that appear to make a useful and substantive difference to the editing problems discussed.","Color Edge Preserving SmoothingThe creation of a successively smoother image that retains the edge information of the original is a problem that has attracted researchers and resulted in many different algorithms. Most methods share the same fundamental steps where a measure of the strength of the edge is defined and as a second step diffusion is allowed along the edge but not across it. Moreover, these algorithms are either designed for monochromatic images or developed to consider the color values in their spatial space and thus treat the color image as a single function rather than n different channels. In this paper, we introduce an edge preserving smoothing method which defines an edge by diffusing two color vectors and considering the effect of that operation on the local gradients. We argue that diffusing in the direction of strong gradients results in an increase of small neighboring gradients. This simple observation is shown to result in accurate edge detection and preservation. Our operation is performed in a local color space where we decompose all color values into a component that is along the pixel value under consideration and another that is orthogonal to it thus allowing us to control the level of allowable color change.","Episodic Memory Design for Predicting the User\u2019s Intention ","Should Business Informatics Care about Linked Open Data ","Full length article: Fractal interpolation functions with variable parameters and their analytical propertiesBased on a widely used class of iterated function systems (IFSs), a class of IFSs with variable parameters is introduced, which generates the fractal interpolation functions (FIFs) with more flexibility. Some analytical properties of these FIFs are investigated in the present paper. Their smoothness is first considered and the related results are presented in three different cases. The stability is then studied in the case of the interpolation points having small perturbations. Finally, the sensitivity analysis is carried out by providing an upper estimate of the errors caused by the slight perturbations of the IFSs generating these FIFs.","Algebraic (trapdoor) one-way functions and their applicationsIn this paper we introduce the notion of Algebraic (Trapdoor) One Way Functions, which, roughly speaking, captures and formalizes many of the properties of number-theoretic one-way functions. Informally, a (trapdoor) one way function F: X#8594;Y is said to be algebraic if X and Y are (finite) abelian cyclic groups, the function is homomorphic i.e. F(x)\u00b7F(y)=F(x \u00b7y), and is ring-homomorphic, meaning that it is possible to compute linear operations 'in the exponent' over some ring (which may be different from \u2124p where p is the order of the underlying group X) without knowing the bases. Moreover, algebraic OWFs must be flexibly one-way in the sense that given y=F(x), it must be infeasible to compute (x\u2032, d) such that F(x\u2032)=yd (for d\u22600). Interestingly, algebraic one way functions can be constructed from a variety of standard number theoretic assumptions, such as RSA, Factoring and CDH over bilinear groups.#R##N##R##N#As a second contribution of this paper, we show several applications where algebraic (trapdoor) OWFs turn out to be useful. These include publicly verifiable secure outsourcing of polynomials, linearly homomorphic signatures and batch execution of Sigma protocols.","Lifting Verification Results for Preemption StatementsThe normal operation of synchronous modules may be temporarily suspended or finally aborted due to requests of their environment. Hence, if a temporal logic specification has already been verified for a synchronous module, then the available verification result can typically only be used if neither suspension nor abortion will take place. Also, the simulation of synchronous modules has to be finally aborted so that temporal logic specifications referring to infinite behaviors cannot be completely answered. In this paper, we therefore define transformations on temporal logic specifications to lift available verification results for synchronous modules without suspension or abortion to refined temporal logic specifications that take care of these preemption statements. This way, one can establish simulation and modular verification of synchronous modules in contexts where preemptions are used.","Improving KeyNote Trust Management Model Based on User Behavior for Social Learning ","Heuristics for hub location problems with alternative capacity levels and allocation constraintsWe consider the hub location problem in which the capacity of a hub restricts the amount of traffic transiting through the hub, the capacity of a hub is a decision variable, and each non-hub can only be allocated to a certain number of hubs. The objective is to determine the number of hubs, to locate the hubs, to determine the capacity level of each hub, to allocate the non-hubs to the hubs, and to determine the path for each origin-destination pair such that the total cost is minimized. Two heuristics based on the threshold accepting method are proposed to resolve this type of hub location problems. Computational characteristics of the proposed heuristics are evaluated through computational experiments using the modified CAB and AP data sets.","Ontology-Based Dynamic Forms for Manufacturing Capability Information CollectionBuilding flexible manufacturing supply chains requires availability of interoperable and accurate manufacturing service capability (MSC) informa- tion. These requirements can be met by encoding the MSC information using shared domain ontologies. However, difficulty in understanding the syntax and semantics of the shared ontologies hinders the adoption of such ontology-based approach In this paper, we propose an Ontology-based eXtensible Dynamic Form (OXDF) user interface architecture to assist non-expert users to collect MSC information and represent that information as instances of the shared do- main ontology. To achieve this result, we introduce three key innovations: 1) intelligent ontology navigation that dynamically generates forms and form components from the relevant parts of the ontology; 2) intelligent search engine that helps finding relevant ontology entities; and 3) an update mechanism that allows users to define new terminologies to the shared domain ontology.","An effective method for signal extraction from residual image, with application to denoising algorithmsTo minimize image blurring and detail loss caused by denoising, we propose a novel method to exploit residual image. Firstly, we apply Non-local Means (NLM) filter to original image to get the denoised image and store the weights used for averaging. Secondly, we filter the residual image with the stored weights. Then a Gaussian filter is applied to the denoised residual image before we add the results to image denoised by NLM to recover the lost image details. Different from previous methods, our method uses the structure information in the original image and can be used to extract lost image details from residual images with very low SNR. An analysis on the mechanism of the signal extraction method is given. Quantitative evaluation showed that the proposed algorithm effectively improved accuracy of NLM filter. In addition, the residual of the final results contained fewer observable structures, demonstrating the effectiveness of the proposed method to recover lost details.","AAAI-13 PrefaceWelcome to the Twenty-Seventh AAAI Conference on Artificial Intelligence, AAAI-13! As can be seen in these proceedings, AI\u2019s scope and influence continue to grow. This year, we received 827 submissions across a variety of tracks, allowing us to put together a diverse and exciting technical program featuring the field\u2019s top research.","An Ontology-Based Technique for Online Profile ResolutionInstance matching targets the extraction, integration and matching of instances referring to the same real-world entity. In this paper we present a weighted ontology-based user profile resolution technique which targets the discovery of multiple online profiles that refer to the same person identity. The elaborate technique takes into account profile similarities at both the syntactic and semantic levels, employing text analytics on top of open data knowledge to improve its performance. A two-staged evaluation of the technique performs various experiments to determine the best out of alternative approaches. These results are then considered in an improved algorithm, which is evaluated by real users, based on their real social network data. Here, a profile matching precision rate of 0.816 is obtained. The presented Social Semantic Web technique has a number of useful applications, such as detection of untrusted known persons behind anonymous profiles, and information sharing management across multiple social networks.","Supporting Location Information Privacy in Mobile DevicesSocial networking has evolved as a basic amenity in today's intercon- nected world. Users of social media tools do not always keep up with privacy poli- cies and its adverse effects. It is very common that even experienced users are often caught unaware of actions that happen behind the interface screens of their inter- connection devices. Many-a-time mobile application developers take advantage of such user complacency and leak location information from the device (and hence information about the user) to other applications. Though there has been considera- ble alerts raised on the issue of location information leakage, there are situations wherein applications sneak through these 'walls' and connect with devices / appli- cations to extract / query desired information from the firmware. In this work, we provide a in-depth review of literature on this emerging area of social interest, and propose a four-layer context-based authentication framework (4-CBAF) to address location privacy concerns. The 4-CBAF framework provides a facility for users to share pertinent information only if the user specifically authorizes such information sharing. The 4-CBAF is intelligent enough to reduce the number of human inter- ventions that a user should attend to. The effectiveness of the proposed 4-CBAF is also demonstrated for check-in application for Facebook using smart devices.","An Agents and Artifacts Approach to Distributed Data MiningThis paper proposes a novel Distributed Data Mining (DDM) approach based on the Agents and Artifacts paradigm, as implemented in CArtAgO [9], where artifacts encapsulate data mining tools, inherited from Weka, that agents can use while engaged in collaborative, distributed learning processes. Target hypothesis are currently constrained to decision trees built with J48, but the approach is flexible enough to allow different kinds of learning models. The twofold contribution of this work includes: i) JaCA-DDM: an extensible tool implemented in the agent oriented programming language Jason [2] and CArtAgO [10,9] to experiment DDM agent-based approaches on different, well known training sets. And ii) A collaborative protocol where an agent builds an initial decision tree, and then enhances this initial hypothesis using instances from other agents that are not covered yet (counter examples); reducing in this way the number of instances communicated, while preserving accuracy when compared to full centralized approaches.","Virtual network embedding algorithm based connective degree and comprehensive capacityNetwork virtualization allows multiple virtual networks to coexist on a shared physical substrate infrastructure. As far as possible to support more virtual networks on a shared substrate network, efficient physical resource utilization is crucial. This paper presents a novel approach to increase utility of the substrate network. As an optimization problem, such virtual network embedding problem is formulated as an integer linear programming model. By introducing a sliding window with priority for VN requests, the algorithm embeds virtual nodes based on both connective degree and comprehensive capacity. Experimental results show that comparing with the existing VNE algorithm the proposed algorithm achieve higher VNs accept ratio and gain higher revenue-cost ratio for substrate network.","A Tight Lower Bound for High Frequency Moment Estimation with Small Error ","agriOpenLink: Towards Adaptive Agricultural Processes Enabled by Open Interfaces, Linked Data and ServicesToday, users involved in agricultural production processes increasingly rely on advanced agricultural machines and specialized applications utilizing the latest advances in information and communication technology (ICT). Robots and machines host numerous specialized sensors and measurement devices and generate large amounts of data that combined with data coming from external sources, could provide a basis for better process understanding and process optimization. One serious roadblock to this vision is a lack of interoperability between the equipment of different vendors; another pitfall of current solutions is that the process knowledge is not modelled in a standardized machine readable form. On the other hand, such process model can be flexibly used to support process-specific integration of machines, and enable context-sensitive automatic process optimization. This paper presents an approach and preliminary results regarding architecture for adaptive optimization of agricultural processes via open interfaces, linked data and semantic services that is being developed within the project agriOpenLink; its goal is to provide a novel methodology and tools for semantic proces orchestraion and dynamic context-based adaptation, significantly reducing the effort needed to create new ICT-controlled agricultural applications involving machines and users.","Monomial Strategies for Concurrent Reachability Games and Other Stochastic GamesWe consider two-player zero-sum finite (but infinite-horizon) stochastic games with limiting average payoffs. We define a family of sta- tionary strategies for Player I parameterized by e&gt; 0t o bemonomial, if for each state k and each action j of Player I in state k except pos- sibly one action, we have that the probability of playing j in k is given by an expression of the form ce d for some non-negative real number c and some non-negative integer d. We show that for all games, there is a monomial family of stationary strategies that are e-optimal among sta- tionary strategies. A corollary is that all concurrent reachability games have a monomial family of e-optimal strategies. This generalizes a classi- cal result of de Alfaro, Henzinger and Kupferman who showed that this is the case for concurrent reachability games where all states have value 0o r 1.","Book recommender prototype based on author's writing styleIn this work we present a prototype that calculates similarity between authors and books. The application allows the user to choose the author and the system retrieves books from other authors that are similar to the chosen author's work.","Migrating Researcher from Local to Global: Using ORCID to Develop the TLIS VIVO with CLISA and ScopusThis paper presents a prototype of TLIS VIVO, a researcher networking system of the Library and Information Science field based in Taiwan, by using ORCID, VIVO, and Linked Open Data technologies. It extends VIVO with the author identifier system ORCID, and integrates data thus harvested from Chinese Library &amp; Information Science Abstracts (CLISA), and Scopus. The study demonstrates a practical approach to increase the visibility, collaboration of local and global researchers.","The Data Exploration System for Image Processing Based on Server-Side OperationsIn this paper the possibilities for construction of an ad hoc search system to examine large-sized raster image data sets, e.g. rock images or medical images, for analysis of its characteristic parameters are presented. A new solution for image exploration based on any attributes extracted with computer image analysis by using extensions for server- side operations is proposed.","Knowledge Creation In Information Systems Development Teams: The Role Of Pair Programming And Peer Code Review ","Exploiting Query Logs and Field-Based Models to Address Term Mismatch in an HIV/AIDS FAQ Retrieval SystemOne of the main challenges in the retrieval of Frequently#R##N#Asked Questions (FAQ) is that the terms used by information seekers#R##N#to express their information need are often different from those used#R##N#in the relevant FAQ documents. This lexical disagreement (aka term#R##N#mismatch) can result in a less effective ranking of the relevant FAQ#R##N#documents by retrieval systems that rely on keyword matching in their#R##N#weighting models. In this paper, we tackle such a lexical gap in an SMS-#R##N#Based HIV/AIDS FAQ retrieval system by enriching the traditional FAQ#R##N#document representation using terms from a query log, which are added#R##N#as a separate field in a field-based model.We evaluate our approach using#R##N#a collection of FAQ documents produced by a national health service#R##N#and a corresponding query log collected over a period of 3 months. Our#R##N#results suggest that by enriching the FAQ documents with additional#R##N#terms from the SMS queries for which the true relevant FAQ documents#R##N#are known and combining term frequencies from the different fields, the#R##N#lexical mismatch problem in our system is markedly alleviated, leading#R##N#to an overall improvement in the retrieval performance in terms of Mean#R##N#Reciprocal Rank (MRR) and recall.","A Co-occurrence Prior for Continuous Multi-label OptimizationTo obtain high-quality segmentation results the integration of semantic information is indispensable. In contrast to existing segmentation methods which use a spatial regularizer, i.e. a local interaction between image points, the co-occurrence prior [15] imposes penalties on the co-existence of different labels in a segmentation. We propose a continuous domain formulation of this prior, using a convex relaxation multi-labeling approach. While the discrete approach [15] is employs minimization by sequential alpha expansions, our continuous convex formulation is solved by efficient primal-dual algorithms, which are highly parallelizable on the GPU. Also, our framework allows isotropic regularizers which do not exhibit grid bias. Experimental results on the MSRC benchmark confirm that the use of co-occurrence priors leads to drastic improvements in segmentation compared to the classical Potts model formulation when applied.","SVM Methods for Optimal Management of a Virtual Power Plant ","Solution Methods for General Quadratic Programming Problem with Continuous and Binary Variables: Overview ","Tracing technology diffusion of social media with culturally localized user experience approachThis paper examines two recent technology diffusion cases of social media in a global context, Facebook Japan and Sina Weibo. By tracing the local development of two social media technologies and probing into the deeper issues behind their peculiar use patterns, it presents a new framework--Culturally Localized User Experience (CLUE) for culturally sensitive design and argues the integration of action and meaning in design is key to the success of global social media.","Modeling Data Stream Intensity in Distributed Stream Processing SystemIn recent years energy market has changed. Consumers in many countries are free to buy energy from any of the available providers. This requires continuous reading from a huge number of energy meters to evaluate the amount of energy being bought from a particular provider. In this paper we present a fault-tolerant distributed stream processing system for continuous meter readings. The main goal of the system is to store the readings in a stream data warehouse for further analysis. We focus on modeling of the data stream intensity in order to estimate the size of buffers in a network of components composing the system. We present both the mathematical model of the intensity and the simulation results to prove the correctness of the theoretical analysis.","Virtual butlers and real people: styles and practices in long-term use of a companionIn this chapter, we argue that it is already possible, with existing technologies, to go beyond fictional scenarios of virtual butlers or assistive robot companions, and that realistic, long-term studies of their use contribute much needed knowledge about user styles and hence design requirements. Such a study, undertaken by the EU project SERA (Social Engagement with Robots and Agents) is reported, and the data collected are presented, compared, and discussed. The striking difference between idealized personae (such as \"Tina\") and real users motivated a detailed case study about the frequently observed issue of initiative and floor management. The case study shows the considerable degree to which users shape human-robot interaction with their individual styles. In conclusion, a few such user styles, together with design consequences, are outlined on the basis of the data analysis, with the aim of enriching future scenario descriptions with more realistic personae.","Easing Communication Means Selection Using Context Information and Semantic Technologies ","Formation control for cooperative localization of MAV swarms (demonstration)Large UAVs depend on GPS technology to accurately describe their position, and navigate to their objectives successfully. However, Micro Air Vehicles (MAVS) cannot rely on GPS technology when navigating indoors. Much research has been conducted to develop robust control systems for MAV formations. Most of this research requires off-board sensing to provide formation control. In this work we demonstrate a formation control technique for MAVs, using on-board sensing and off-board processing. We demonstrate the usage of on-board vision and inertial sensors to localize two MAVs relative to each other. Our hardware platform is the Parrot AR Drone, which has a vast sensor suite including two on-board cameras, an inertial measurement unit, compass, and ultrasonic range-finder for altitude measurement. The drones are controlled using National Instrument's LabView 2011, and commands are issued wirelessly via a 802.11 WIFI network.","TiTiMaKe: A Distributed Service Architecture for Security ApplicationsIn this article, we discuss integration of distributed informa- tion services, to support the implementation of applications for fields of safety and security. Although there are standard interfacing technologies, such as SOAP and REST, there is very little architectural support for the development of personalized and case specific applications, where the same data sources and computational services are integrated in different ways. As the main contribution, we present here a distributed service ar- chitecture, called TiTiMaKe, that supports the development of scenario based applications. We also illustrate TiTiMaKe by describing its use in applications in fields of surveillance and emergency rescue.","CoreIIScheduler: Scheduling Tasks in a Multi-core-Based Grid Using NSGA-II Technique *Load balancing has been known as one of the most challenging problems in computer sciences especially in the field of distributed systems and grid environments; hence, many different algorithms have been developed to solve this problem. Considering the revolution occurred in the modern processing units, using mutli-core processors can be an appropriate solution. one of the most important challenges in multi-core-based grids is scheduling. Specific computational intelligence methods are capable of dealing with complex problems for which there is no efficient classic method-based solution. One of these approaches is multi- objective genetic algorithm which can solve the problems in which multiple objectives are to be optimized at the same time. CoreIIScheduler, the proposed approach uses NSGA-II method which is successful in solving most of the multi- objective problems. Experimental results over lots of different grid environments show that the average utilization ratio is over 90% whilst for FCFS algorithm, it is only about 70%. Furthermore, CoreIIScheduler has an improvement ratio of 60% and 80% in wait time and makespan, respectively which is relative to FCFS.","Sensor-based Knowledge Discovery from a Large Quantity of Situational Variables. ","Migrants Selection and Replacement in Distributed Evolutionary Algorithms for Dynamic Optimization ","Identifying Authoritative and Reliable Contents in Community Question Answering with Domain KnowledgeCommunity Question Answering (CQA) has emerged as a popular forum for users to ask and answer questions. Over the last few years, CQA portals such as Yahoo answersand Baidu Zhidao have exploded in popularity, and now provide a viable alternative to general purpose Web search. A number of answers submitted to address questions on CQA sites compose a valuable knowledge repository, which could be a gold mine for information retrieval as well as text mining. Two important questions in CQA research are focused on the quality of contents and the reputation of the answerers. Previous approaches for retrieving relevant and high quality content have been proposed, but not much work has been done on providing an integrated framework to solve these two problems. Besides, no research work has used both text and link information in their methods via leveraging existing ratings of answers and questions. In this paper, we present a novel approach to analyze questions and answers based on the topic modeling framework with Dirichlet forest priors (LDA-DF)[8]. We utilize information obtained from LDA-DF to construct a joint topical and link model to identify authorities and reliable answers on a CQA site.We evaluate our methods in a dataset obtained from Yahoo! Answers. With the new representation of topical structures on CQA datasets, using a limited amount of web resource, we show significant improvements over the state-of-art methods LDA-DF, LDA, and HLDA on performance of authority identification and answer ranking.","Psychological maps 2.0: a web engagement enterprise starting in LondonPlanners and social psychologists have suggested that the recognizability of the urban environment is linked to people's socio-economic well-being. We build a web game that puts the recognizability of London's streets to the test. It follows as closely as possible one experiment done by Stanley Milgram in 1972. The game picks up random locations from Google Street View and tests users to see if they can judge the location in terms of closest subway station, borough, or region. Each participant dedicates only few minutes to the task (as opposed to 90 minutes in Milgram's). We collect data from 2,255 participants (one order of magnitude a larger sample) and build a recognizability map of London based on their responses. We find that some boroughs have little cognitive representation; that recognizability of an area is explained partly by its exposure to Flickr and Foursquare users and mostly by its exposure to subway passengers; and that areas with low recognizability do not fare any worse on the economic indicators of income, education, and employment, but they do significantly suffer from social problems of housing deprivation, poor living conditions, and crime. These results could not have been produced without analyzing life off- and online: that is, without considering the interactions between urban places in the physical world and their virtual presence on platforms such as Flickr and Foursquare. This line of work is at the crossroad of two emerging themes in computing research - a crossroad where \"web science\" meets the \"smart city\" agenda.","Opening Up The Fuzzy Front-End Of Service Process Innovation: Searching Capability, Co-Development Capacity, And IT Competence. ","Innovization: Discovery of Innovative Solution Principles Using Multi-Objective Optimization ","Sampling of Web Images with Dictionary Coherence for Cross-Domain Concept DetectionDue to the existence of cross-domain incoherence resulting from the mismatch of data distributions, how to select sufficient positive training samples from scattered and diffused web resources is a challeng- ing problem in the training of effective concept detectors. In this paper, we propose a novel sampling approach to select coherent positive sam- ples from web images for further concept learning based on the degree of image coherence with a given concept. We propose to measure the co- herence in terms of how dictionary atoms are shared since shared atoms represent common features with regard to a given concept and are robust to occlusion and corruption. Thus, two kinds of dictionaries are learned through online dictionary learning methods: one is the concept dictionary learned from key-point features of all the positive training samples while the other is the image dictionary learned from those of web images. In- tuitively, the coherence degree is then calculated by the Frobenius norm of the product matrix of the two dictionaries. Experimental results show that the proposed approach can achieve constant overall improvement despite cross-domain incoherence.","H.264 Sensor Aided Video Encoder for UAV BLOS MissionsThis paper presents a new low-complexity H.264 encoder, based on x264 implementation, for Unmanned Aerial Vehicles (UAV) applications. The encoder employs a new motion estimation scheme which make use of the global motion information provided by the onboard navigation system. The results are relevant in low frame rate video coding, which is a typical scenario in UAV behind line-of-sight (BLOS) missions","Information System Strategy for Opportunity Discovery and Exploitation: Insights from Business Model Transformation ","An Estimation of Distribution Algorithm for the 3D Bin Packing Problem with Various Bin SizesThe 3D bin packing problem 3DBPP is a practical problem modeled from modern industry application such as container ship loading and plane cargo management. Unlike traditional bin packing problem where all bins are of the same size, this paper investigates a more general type of 3DBPP with bins of various sizes. We proposed a modified univariate marginal distribution algorithm UMDA for solving the problem. A packing strategy derived from a deepest bottom left packing method was employed. The modified UMDA was experimentally compared with CPLEX and a genetic algorithm GA approach. The experimental study showed that the proposed algorithm performed better than GA and CPLEX for large-scale instances.","A new bio-inspired unsupervised learning methodUnsupervised learning has been widely used in many areas such as pattern recognition. However, it is usually difficult to acquire accurate representation of pattern within a limited period of time. Unsupervised learning, in general, is likely to be more common in brain than supervised learning. In this paper, we propose a new neural network based unsupervised learning method and evaluate its applications on 1-D and 2-D pattern learning. Our approach is inspired by recent researches on the physiological process of neural connection and brain activity. A bipolar weight scheme based on biological neural connection mechanism is presented. Moreover, we have also noticed the synaptic plasticity of brain plays an important role in learning. A new brain-inspired short-term and long-term scheme is applied in our method to adjust weights during the learning process. Experimental results of learning over 1-D and 2-D patterns demonstrate the proposed method is effective and high-efficiency.","Signal Processing for Stereoscopic and Multi-View 3D Displays ","A Note on the Classification of the Most Simple Asynchronous Cellular AutomataWe tackle the problem of the classification of elementary cellular automata when the cells are updated in with a fully asynchronous scheme (one cell is selected at random at each time step). We establish a proof of convergence in logarithmic time as a function of the size of the automaton. Techniques involve a direct Markov chain analysis or the construction of potential function whose convergence rate is bounded by a particular martingale.","Layered Self-Organizing Map for Image Classification in Unrestricted Domains ","Higher Automated Learning through Principal Component Analysis and Markov ModelsThis paper reports a hybrid method for data-driven instructional de- sign, a method that combines Principle Components Analysis (PCA), Hidden Markov Models (HMM), and Item Response Theory (IRT). PCA is used to identify instructional objectives as well as potential student states, HMMs are used to identify dynamics between states, and IRT is used to construct measurements of state. We report on the architecture of the system along with preliminary results.","Detection of Probabilistic Dangling References in Multi-core Programs Using Proof-Supported Tools ","An unstructured termination detection algorithm using gossip in cloud computing environmentsDetermining termination in dynamic environments is hard due to node joining and leaving. In previous studies on termination detection, some structures, such as spanning tree or computational tree, are used. In this work, we present an unstructured termination detection algorithm, which uses a gossip based scheme to cope with scalability and fault-tolerance issues. This approach allows the algorithm not to maintain specific structures even when nodes join and leave during runtime. These dynamic behaviors are prevalent in cloud computing environments and little attention has been paid by existing approaches. To measure the complexity of our proposed algorithm, a new metric, self-centered message complexity is used. Our evaluation over scalable settings shows that an unstructured approach has a significant merit to solve scalability and fault-tolerance problems with lower message complexity over existing algorithms.","MiningZinc: a modeling language for constraint-based miningWe introduce MiningZinc, a general framework for constraint-based pattern mining, one of the most popular tasks in data mining. MiningZinc consists of two key components: a language component and a toolchain component.#R##N##R##N#The language allows for high-level and natural modeling of mining problems, such that MiningZinc models closely resemble definitions found in the data mining literature. It is inspired by the Zinc family of languages and systems and supports user-defined constraints and optimization criteria.#R##N##R##N#The toolchain allows for finding solutions to the models. It ensures the solver independence of the language and supports both standard constraint solvers and specialized data mining systems. Automatic model transformations enable the efficient use of different solvers and systems.#R##N##R##N#The combination of both components allows one to rapidly model constraint-based mining problems and execute these with a wide variety of methods. We demonstrate this experimentally for a number of well-known solvers and data mining tasks.","Towards the Development of a Master-Slave Surgical System for Breast Biopsy under Continuous MRI ","Solving the location areas scheme in realistic networks by using a multi-objective algorithmThe optimization of the management tasks in current mobile networks is an interesting research field due to the exponential increase in the number of mobile subscribers. In this paper, we study two of the most important management tasks of the Public Land Mobile Networks: the location update and the paging, since these two procedures are used by the mobile network to locate and track the Mobile Stations. There are several strategies to manage the location update and the paging, but we focus on the Location Areas scheme with a two-cycle sequential paging, a strategy widely applied in current mobile networks. This scheme can be formulated as a multi-objective optimization problem with two objective functions: minimize the number of location updates and minimize the number of paging messages. In previous works, this multi-objective problem was solved with single-objective optimization algorithms by means of the linear aggregation of the objective functions. In order to avoid the drawbacks related to the linear aggregation, we propose an adaptation of the Non-dominated Sorting Genetic Algorithm II to solve the Location Areas Planning Problem. Furthermore, with the aim of studying a realistic mobile network, we apply our algorithm to a scenario located in the San Francisco Bay (USA). Results show that our algorithm outperforms the algorithms proposed by other authors, as well as the advantages of a multi-objective approach.","Influential Users in Social Networks ","Ubiquitous Network Robot Platform for Realizing Integrated Robotic Applications ","Threshold estimation method for spectrum sensing using bootstrap techniqueIn this paper, the bootstrap technique is applied to spectrum sensing for cognitive radio networks. A novel test threshold estimation method based on bootstrap is proposed. From the simulation results, it is seen that the proposed bootstrap procedure can provide satisfied detection performance while only requires the smallest samples compared with the existing methods. Therefore, the proposed method is very accurate and efficient for spectrum sensing.","Applying an O-MaSE Compliant Process to Develop a Holonic Multiagent System for the Evaluation of Intelligent Power Distribution SystemsThis paper describes the application of an Organization-based Multiagent System Engineering O-MaSE compliant process to the development of a holonic multiagent system MAS for testing control algorithms for an intelligent power distribution system. The paper describes the Adaptive O-MaSE AO-MaSE process, which provides architects and developers a structured approach for testing and iteratively adding functionality in complex, adaptive systems. The paper describes the holonic MAS architecture for the intelligent power distribution system, the challenges encountered while developing the holonic architecture, the lessons learned during the project, and demonstrates how the application of the process enhanced project development.","Computing Game StrategiesWe revisit the problem of constructing strategies for simple position games. We derive a general, executable formalism for describing game rules and desired strategy properties. We present the outcomes for several variants of the familiar game of tic-tac-toe.","Multiple Instance Learning for Automatic Image AnnotationMost traditional approaches for automatic image annotation cannot provide reliable annotations at the object level because it could be very expensive to obtain large amounts of labeled object-level images associated to individual regions. To reduce the cost for manually anno- tating at the object level, multiple instance learning, which can leverage loosely-labeled training images for object classifier training, has become a popular research topic in the multimedia research community. One bot- tleneck for supporting multiple instance learning is the computational cost on searching and identifying positive instances in the positive bags. In this paper, a novel two-stage multiple instance learning algorithm is developed for automatic image annotation. The affinity propagation(AP) clustering technique is performed on the instances both in the positive bags and the negative bags to identify the candidates of the positive instances and initialize the maximum searching of Diverse Density like- lihood in the first stage. In the second stage, the most positive instances are then selected out in each bag to simply the computing procedure of Diverse Density likelihood. Our experiments on two well-known image sets have provided very positive results.","Improved Real-Time Discretize Network Intrusion Detection System ","CAFCLA: An AmI-Based Framework to Design and Develop Context-Aware Collaborative Learning Activities ","ASAWA: An Automatic Partition Key Selection StrategyWith the rapid increase of data volume, more and more applications have to be implemented in a distributed environment. In order to obtain high performance, we need to carefully divide the whole dataset into multiple parti- tions and put them into distributed data nodes. During this process, the selection of partition key would greatly affect the overall performance. Nevertheless, there are few works addressing this topic. Most previous projects on data parti- tioning either utilize a simple strategy, or rely on a commercial database sys- tem, to choose partition keys. In this work, we present an automatic partition key selection strategy called ASAWA. It chooses partition keys according to the analysis on both dataset and workload schemas. In this way, intimate tuples, i.e. co-appearing in queries frequently, would be probably put into the same partition. Hence the cross-node joins could be greatly reduced and the system performance could be improved. We conduct a series of experiments over the TPC-H datasets to illustrate the effectiveness of the ASAWA strategy.","Static Validation of Dynamically Generated HTML Documents Based on Abstract Parsing and Semantic ProcessingAbstract parsing is a static-analysis technique for a program that, given a reference LR(k) context-free grammar, statically checks whether or not every dynamically generated string output by the pro- gram conforms to the grammar. The technique operates by applying an LR(k) parser for the reference language to data-flow equations extracted from the program, immediately parsing all the possible string outputs to validate their syntactic well-formedness. In this paper, we extend abstract parsing to do semantic-attribute processing and apply this extension to statically verify that HTML docu- ments generated by JSP or PHP are always valid according to the HTML DTD. This application is necessary because the HTML DTD cannot be fully described as an LR(k) grammar. We completely define the HTML 4.01 Transitional DTD in an attributed LALR(1) grammar, carry out ex- periments for selected real-world JSP and PHP applications, and expose numerous HTML validation errors in the applications. In the process, we experimentally show that semantic properties defined by attribute grammars can also be verified using our technique.","Learning Structural Representations of Text Documents in Large Document Collections ","L2-Stable Nonstandard Finite Differences for Anisotropic DiffusionAnisotropic diffusion filters with a diffusion tensor are successfully used in many image processing and computer vision ap- plications, ranging from image denoising over compression to optic flow computation. However, finding adequate numerical schemes is difficult: Implementations may suffer from dissipative artifacts, poor approxima- tion of rotation invariance, and they may lack provable stability guaran- tees. In our paper we propose a general framework for finite difference discretisations of anisotropic diffusion filters on a 3\u00d7 3 stencil. It is based on a gradient descent of a discrete quadratic energy where the occurring derivatives are replaced by classical as well as the widely unknown non- standard finite differences in the sense of Mickens. This allows a large class of space discretisations with two free parameters. Combining it with an explicit or semi-implicit time discretisation, we establish a general and easily applicable stability theory in terms of a decreasing Euclidean norm. Our framework comprises as many as seven existing space discretisations from the literature. However, we show that also novel schemes are possi- ble that offer a better performance than existing ones. Our experimental evaluation confirms that the space discretisation can have a very sub- stantial and often underestimated impact on the quality of anisotropic diffusion filters.","Building an Integrated System for the Management of Scientific Nature Events through Open Source Software Integration ","Solving Battalion Rescheduling Problem Using Multi-objective Genetic AlgorithmsThere has always been a need to solve real-life large-scale problems, suchas efficiently allocating limited resources, and other complex and conflicting situations related to combinatorial optimization genre. A class of combinato- rial optimization problems is NP-hard and, among many well-known, several of them are assignment, planning and rescheduling problems. Assignment problems can deal with optimal assignment of teams of collaborating agents; planning problems can be effects-based planning that search for promising plans to get desired end states with minimal cost; rescheduling problems can be multi-criteria optimization of rescheduling resources that modify existing original schedule. These large scale optimization problems are complex with intractable and highly complex search spaces. Currently, there are no known algorithms with polynomial time complexity, which can solve these problems. Genetic Algorithms have been successfully applied to solve many complex optimization problems but not to the specific problems mentioned above.The aim of the research, presented in this thesis, is to use Genetic Algo- rithms for large scale optimization of assignment, planning and rescheduling problems. More specifically, the contributions of the thesis are to: (i) adapt existing and develop new efficient Genetic Algorithms to solve large scale as- signment problems, and (ii) adapt existing Genetic Algorithms to solve large scale effects-based planning, and multi-objective rescheduling optimization problems.In case of assignment, we solve a team assignment problem and investigate specific regions in a solution space for assignment problems with huge search spaces.For the team assignment, an existing Genetic Algorithm is adapted and applied for optimal assignment of tasks to teams of collaborating agents. The algorithm is scalable, stable, robust and produces a near optimal solution. The results of the team assignment problem show that the existing Genetic Algorithms are not efficient for optimal assignment of tasks to teams of agents. Hence, to solve larger instances of the problem efficiently, new Genetic Algo- rithms are developed with emphasis on the construction of crossover opera- tors. Since teams assignment can be multi-criteria, a multi-objective model is constructed and two widely used multi-objective evolutionary algorithms are applied. Further, for the assignment problems with huge search spaces, an existing Genetic Algorithm is adapted to extract possible combinations of input parameters from a specified solution space region. To solve the large scale effects-based planning, a multi-objective optimization problem is formu- lated for the evaluation of operational plans and a multi-objective Genetic Algorithm is adapted and applied to the problem. The results show that the suggested algorithm is much more efficient than A*. For the rescheduling problem, a multi-objective optimization model for rescheduling of resources is proposed and a multi-objective Genetic Algorithm is adapted and applied to obtain the Pareto-optimal solutions.The research presented in this thesis confirms that Genetic Algorithms can be used for large scale assignment, planning and rescheduling problems since they have shown to be suitable in solving these problems efficiently.","Region Growing: When Simplicity Meets Theory \u2013 Region Growing Revisited in Feature Space and Variational Framework ","Online Algorithms for Batch Machines Scheduling with Delivery TimesWe consider online scheduling on m batch machines with delivery times. In this paper online means that jobs arrive over time and the characteristics of jobs are unknown until their arrival times. Once the processing of a job is completed it is delivered to the destination. The objective is to minimize the time by which all jobs have been delivered. For each job Jj, its processing time and delivery time are denoted by pj and qj , respectively. We first consider a restricted model: the jobs have agreeable processing and delivery times, i.e., for any two jobs Ji and Jj , pi &gt;p j implies qi \u2265 qj . For the restrict case, we provide a best possible online algorithm with competitive ratio 1 + \u03b1m ,w here\u03b1m &gt; 0 is determined by \u03b1 2 m + m\u03b1m = 1. Then we present an online algorithm with a competitive ratio of 1 + 2/\ufffd \u221a mfor the general case.","A Code-Based Undeniable Signature SchemeIn this work we propose the first code-based undeniable signature scheme and more generally the first post-quantum undeniable signature scheme. The verification protocols for our scheme are 3-pass zero-knowledge protocols derived from the Stern authentication protocol. There are two main ideas in our protocol, first we remark that it is possible to obtain a full-time undeniable signature from a one-time undeniable signature simply by signing the one-time public key by a standard signature. Second, we introduce a zero-knowledge variation on the Stern authentication scheme which permits to prove that one or two different syndromes are associated or not to the same low weight word. We give a polynomial reduction of the security of our scheme to the security of the syndrome decoding problem.","Value-Oriented Solution Development Process: Uncovering the Rationale behind Organization Components ","Evasion Attacks against Machine Learning at Test TimeIn security-sensitive applications, the success of machine learning depends on a thorough vetting of their resistance to adversarial data. In one pertinent, well-motivated attack scenario, an adversary may attempt to evade a deployed system at test time by carefully manipu- lating attack samples. In this work, we present a simple but effective gradient-based approach that can be exploited to systematically assess the security of several, widely-used classification algorithms against eva- sion attacks. Following a recently proposed framework for security eval- uation, we simulate attack scenarios that exhibit different risk levels for the classifier by increasing the attacker's knowledge of the system and her ability to manipulate attack samples. This gives the classifier designer a better picture of the classifier performance under evasion attacks, and allows him to perform a more informed model selection (or parameter setting). We evaluate our approach on the relevant security task of mal- ware detection in PDF files, and show that such systems can be easily evaded. We also sketch some countermeasures suggested by our analysis.","Possibilistic Local Structure for Compiling Min-Based Networks ","A probabilistic template model for finding macromolecules in MET volume imagesWe introduce and investigate probabilistic templates with particular focus on the application of protein identification in electron tomography volumes. We suggest to create templates with a weighte ...","Three SCC-Based Emptiness Checks for Generalized B\u00fcchi AutomataThe automata-theoretic approach for the verification of linear time properties involves checking the emptiness of a B{u}chi automaton. However generalized B{u}chi automata, with multiple acceptance sets, are preferred when verifying under weak fairness hypotheses. Existing emptiness checks for which the complexity is independent of the number of acceptance sets are all based on the enumeration of Strongly Connected Components (SCCs). In this paper, we review the state of the art SCC enumeration algorithms to study how they can be turned into emptiness checks. This leads us to define two new emptiness check algorithms (one of them based on the Union Find data structure), introduce new optimizations, and show that one of these can be of benefit to a classic SCCs enumeration algorithm. We have implemented all these variants to compare their relative performances and the overhead induced by the emptiness check compared to the corresponding SCCs enumeration algorithm. Our experiments shows that these three algorithms are comparable.","Local Community Detection and Visualization: Experiment Based on Student Data ","Integral Geometry of Linearly Combined Gaussian and Student-t, and Skew Student\u2019s t Random FieldsThe integral geometry of random fields has been investigated since the 1980s, and the analytic formulae of the Minkowski functionals (also called Lipschitz-Killing curvatures, shortly denoted LKCs) of their excursion sets on a compact subset  S  in the  n -dimensional Euclidean space have been reported in the specialized literature for Gaussian and student- t  random fields. Very recently, explicit analytical formulae of the Minkowski functionals of their excursion sets in the bi-dimensional case ( n  = 2) have been defined on more sophisticated random fields, namely: the  Linearly Combined Gaussian and Student-t , and the  Skew Student-t random fields . This paper presents the theoretical background, and gives the explicit analytic formulae of the three Minkowski functionals. Simulation results are also presented both for illustration and validation, together with a real application example on an worn engineered surface.","Soft Computing Techniques Applied to a Case Study of Air Quality in Industrial Areas in the Czech Republic ","Shape Curvature Histogram: A Shape Feature for Celiac Disease Diagnosis ","Surrogate Regret Bounds for the Area Under the ROC Curve via Strongly Proper LossesThe area under the ROC curve (AUC) is a widely used performance measure in machine learning, and has been widely studied in recent years particularly in the context of bipartite ranking. A dominant theoretical and algorithmic framework for AUC optimization/bipartite ranking has been to reduce the problem to pairwise classication; in particular, it is well known that the AUC regret can be formulated as a pairwise classication regret, which in turn can be upper bounded using usual regret bounds for binary classication. Recently, Kotlowski et al. (2011) showed AUC regret bounds in terms of the regret associated with \u2018balanced\u2019 versions of the standard (non-pairwise) logistic and exponential losses. In this paper, we obtain such (non-pairwise) surrogate regret bounds for the AUC in terms of a broad class of proper (composite) losses that we term strongly proper. Our proof technique is considerably simpler than that of Kotlowski et al. (2011), and relies on properties of proper (composite) losses as elucidated recently by Reid and Williamson (2009, 2010, 2011) and others. Our result yields explicit surrogate bounds (with no hidden balancing terms) in terms of a variety of strongly proper losses, including for example logistic, exponential, squared and squared hinge losses. An important consequence is that standard algorithms minimizing a (non-pairwise) strongly proper loss, such as logistic regression and boosting algorithms (assuming a universal function class and appropriate regularization), are in fact AUC-consistent; moreover, our results allow us to quantify the AUC regret in terms of the corresponding surrogate regret. We also obtain tighter surrogate regret bounds under certain low-noise conditions via a recent result of Cl emen con and Robbiano (2011).","Effects of Task and Presentation Modality in Detection Response TasksTo assess driver distraction adequately, cognitive workload measurement techniques are necessary that can be used as part of standard in-vehicle testing procedures. Detection response tasks (DRTs) are a simple and effective way of assessing workload. However, as DRTs require cognitive resources themselves, interferences between task modality and DRT modality are possible. In this study, DRT stimuli (auditory, visual, tactile) are varied systematically with secondary task presentation modality (auditory, visual, or purely cognitive tasks). The aim is to infer if different DRT variants remain sensitive to changes in workload even if primary and secondary task convey information using the same presentation modality, thus making resource conflicts likely. Results show that all DRTs successfully discriminate between high and low workload levels in terms of reaction time independent of DRT presentation modality. Differences in discriminability can be found in hit rate measurement.","On learning how to plan content delivery networksThere is a significant lack of integrated Content Delivery Network (CDN) planning tools. P2PCDNSim, a comprehensive CDN simulator, is presented in this work. The result of a three-year project, it allows performance analysis of a wide range of CDN scenarios. The simulator performs similarly to the ns-3 and CDNsim public simulators at the packet and CDN domains respectively. Using CDNP2Psim, highly detailed CDN scenarios can be built and analyzed by an ISP, including customer access such as ADSL link asymmetry and broadband technologies. Overall and cross ISP traffic metrics are captured and shown to the planner in real-time. CDN known metrics, such as the cache hit ratio and startup delay, are also portrayed in real-time. All these metrics are captured during simulation and shown in a multi-layer simulator that can be easily extended and its parts reused. With this simulator, we learned that dynamic selection of a good location for the caches has a great deal of influence on the total network traffic and that traffic asymmetry has a great effect on cross traffic, especially on P2P-based or hybrid CDN-P2P networks. We also learned that a proper evaluation of cache algorithms according to traffic profile can also improve Quality of Experience metrics through selecting the most appropriate algorithm.","The proof-search problem between bounded-width resolution and bounded-degree semi-algebraic proofsIn recent years there has been some progress in our understanding of the proof-search problem for very low-depth proof systems, e.g. proof systems that manipulate formulas of very low complexity such as clauses (i.e. resolution), DNF-formulas (i.e. R(k) systems), or polynomial inequalities (i.e. semi-algebraic proof systems). In this talk I will overview this progress. I will start with bounded-width resolution, whose specialized proof-search algorithm is as easy as uninteresting, but whose proof-search problem is unintentionally solved by certain versions of conflict-driven clause-learning algorithms with restarts. I will continue with R(k) systems, whose proof-search problem turned out to hide the complexity of certain two-player games of interest in the area of systems synthesis and verification. And I will close with bounded-degree semi-algebraic proof systems, whose proof-search problem turned out to hide the complexity of systems of linear equations over finite fields, among other problems.","Artifact-Free Decompression and Zooming of JPEG Compressed Images with Total Generalized Variation ","Better human computation through principled votingDesigners of human computation systms often face the need to aggregate noisy information provided by multiple people. While voting is often used for this purpose, the choice of voting method is typically not principled. We conduct extensive experiments on Amazon Mechanical Turk to better understand how different voting rules perform in practice. Our empirical conclusions show that noisy human voting can differ from what popular theoretical models would predict. Our short-term goal is to motivate the design of better human computation systems; our long-term goal is to spark an interaction between researchers in (computational) social choice and human computation.","Evaluation of Video Quality Monitoring Based on Pre-computed Frame Distortions ","Saliency-Guided Color Transfer between ImagesColor transfer is an image processing technique to transfer the color style from the target image to the source image. Existing algorithms is not perception aligned in the semantic level and could be affected by the sharp differences between subregion of the image. This paper proposes an automatic perception aligned color transfer algorithm. First, saliency map are adopted to softly segment the image into two regions in a perception aligned manner. Second, the region correspondence is defined by the saliency map naturally. Third, a weighted color transfer algorithm is presented.","Dynamic Memory for Robot Control Using Delay-Based Coincidence Detection NeuronesThis paper demonstrates the feasibility of dynamic memory in transmission delay coincidence detection networks. We present a low complexity, procedural algorithm for determining delay connectivity for the control of a simulated e-puck robot to solve the t-maze memory task. This work shows that dynamic memory modules need not undergo structural change during learning but that peripheral structures could be alternate candidates for this. Overall, this supports the view that delay coincidence detection networks can be effectively coupled to produce embodied adaptive behaviours.","Discriminative Data Transform for Image Feature Extraction and ClassificationGood feature design is important to achieve effective image classification. This paper presents a novel feature design with two main contributions. First, prior to computing the feature descriptors, we pro- pose to transform the images with learning-based filters to obtain more representative feature descriptors. Second, we propose to transform the computed descriptors with another set of learning-based filters to fur- ther improve the classification accuracy. In this way, while generic fea- ture descriptors are used, data-adaptive information is integrated into the feature extraction process based on the optimization objective to enhance the discriminative power of feature descriptors. The feature de- sign is applicable to different application domains, and is evaluated on both lung tissue classification in high-resolution computed tomography (HRCT) images and apoptosis detection in time-lapse phase contrast microscopy image sequences. Both experiments show promising perfor- mance improvements over the state-of-the-art.","Trying broadband characterization at homeIn recent years the quantity and diversity of Internet-enabled consumer devices in the home have increased significantly. These trends complicate device usability and home resource management and have implications for crowdsourced approaches to broadband characterization.#R##N##R##N#The UPnP protocol has emerged as an open standard for device and service discovery to simplify device usability and resource management in home networks. In this work, we leverage UPnP to understand the dynamics of home device usage, both at a macro and micro level, and to sketch an effective approach to broadband characterization that runs behind the last meter.#R##N##R##N#Using UPnP measurements collected from over 13K end users, we show that while home networks can be quite complex, the number of devices that actively and regularly connect to the Internet is limited. Furthermore, we find a high correlation between the number of UPnP-enabled devices in home networks and the presence of UPnP-enabled gateways, and show how this can be leveraged for effective broadband characterization.","Group-Valued Regularization for Motion Segmentation of Articulated ShapesMotion-based segmentation is an important tool for the analysis of articulated shapes. As such, it plays an important role in mechanical engineering, computer graphics, and computer vision. In this chapter, we study motion-based segmentation of 3D articulated shapes. We formulate motion-based surface seg- mentation as a piecewise-smooth regularization problem for the transformations between several poses. Using Lie-group representation for the transformation at each surface point, we obtain a simple regularized fitting problem. An Ambrosio- Tortorelli scheme of a generalized Mumford-Shah model gives us the segmentation functional without assuming prior knowledge on the number of parts or even the articulated nature of the object. Experiments on several standard datasets compare the results of the proposed method to state-of-the-art algorithms.","Registration of Temporally Separated CT Colonography CasesRobust registration between prone and supine data acquisitions for CT colonography CTC is a useful tool for assessing clinically significant changes but a challenging problem. This is especially the case for polyp follow-up when scans are temporally separated. We investigated the ability of automatic registration to align CTC cases, acquired several months apart. 26 initial and follow-up cases were investigated and registration measured using the locations of 35 polyps in all available scans. Robust non-rigid feature-based initialization allowed registration of prone and supine CTC scans from patient cases not only acquired on the same day but also when acquired several months apart. A mean registration error of 17.4 std. dev. 12.1 mm median 14.9 mm, range 1.7 to 49.7 mm was achieved when transforming polyp locations between longitudinal scans. The level of accuracy achieved was similar to previous studies that aligned CTC images acquired at the same sitting. Automatic registration of follow-up CTC investigations could be a useful adjunct for radiologists interpreting CTC for surveillance of colonic polyps.","The Trouble with Long-Range Base Pairs in RNA FoldingRNA prediction has long been struggling with long-range base pairs since prediction accuracy decreases with base pair span. We analyze here the empirical distribution of base pair spans in large collection of experimentally known RNA structures. Surprisingly, we find that long-range base pairs are overrepresented in these data. In particular, there is no evidence that long-range base pairs are systematically overpredicted relative to short-range interactions in thermodynamic predictions. This casts doubt on a recent suggestion that kinetic effects are the cause of length-dependent decrease of predictability. Instead of a modification of the energy model we advocate a modification of the expected accuracy model for RNA secondary structures. We demonstrate that the inclusion of a span-dependent penalty leads to improved maximum expected accuracy structure predictions compared to both the standard MEA model and a modified folding algorithm with an energy penalty function. The prevalence of long-range base pairs provide further evidence that RNA structures in general do not have the so-called polymer zeta property. This has consequences for the asymptotic performance for a large class of sparsified RNA folding algorithms.","A Note on Elementary Cellular Automata ClassificationWe overview and compare classifications of elementary cellular automata, including Wolfram's, Wuensche's, Li and Packard, communication complexity, power spectral, topological, surface, compression, lattices, and morphological diversity classifications. This paper summarises several classifications of elementary cellular automata (ECA) and compares them with a newly proposed one, that induced by endowing rules with memory.","Practical extraction of disaster-relevant information from social mediaDuring times of disasters online users generate a significant amount of data, some of which are extremely valuable for relief efforts. In this paper, we study the nature of social-media content generated during two different natural disasters. We also train a model based on conditional random fields to extract valuable information from such content. We evaluate our techniques over our two datasets through a set of carefully designed experiments. We also test our methods over a non-disaster dataset to show that our extraction model is useful for extracting information from socially-generated content in general.","Tool Support for the Quality Assessment of MDWE Methodologies ","Fast Compression of Large-Scale Hypergraphs for Solving Combinatorial ProblemsWe present a fast algorithm to compress hypergraphs into the data structure ZDDs. We furthermore analyze the computational complexity. Our algorithm uses multikey Quicksort given by Bentley and Sedgewick. By conducting experiments with various datasets, we show that our algorithm is significantly faster and requires much smaller memory than an existing method.","The Removal of False Detections from Foreground Regions Extracted Using Adaptive Background Modelling for a Visual Surveillance System ","A card game description languageWe present initial research regarding a system capable of generating novel card games. We furthermore propose a method for computationally analysing existing games of the same genre. Ultimately, we present a formalisation of card game rules, and a context-free grammar Gcardgame capable of expressing the rules of a large variety of card games. Example derivations are given for the poker variant Texas hold 'em, Blackjack and UNO. Stochastic simulations are used both to verify the implementation of these well-known games, and to evaluate the results of new game rules derived from the grammar. In future work, this grammar will be used to evolve completely novel card games using a grammar-guided genetic program.","Optimal Saving and Prudence in a Possibilistic FrameworkIn this paper we study the optimal saving problem in the framework of possibility theory. The notion of possibilistic precautionary saving is introduced as a measure of the way the presence of risk (represented by a fuzzy number) influences a consumer in establishing the level of optimal saving. The equivalence between the prudence condition (in the sense of Kimball) and a positive possibilistic precaution- ary saving is proved. Some relations between possibilistic risk aversion, prudence and possibilistic precautionary saving are established.","Online Exploration and Triangulation in Orthogonal Polygonal RegionsWe consider the problem of exploring and triangulating a region with a swarm of robots with limited vision and communication range. For an unknown polygonal region P , the Online Minimum Relay Triangulation Problem (OMRTP) asks for an exploration strategy that maintains a triangulation with limited edge length and achieves a min- imum number of robots (relays), such that the triangulation covers P ; for a given number n of robots, the Online Maximum Area Triangula- tion Problem (OMATP) asks for maximizing the triangulated area. Both problems have been studied before, with a competitive factor of 3 for the OMRTP in general polygons, and an unbounded competitive factor for the OMATP; the latter holds for polygons with very narrow corridors. In this paper, we study the OMRTP for polygons without such bottle- necks: polyominoes, i.e., orthogonal polygons with integer edge lengths. Based on optimal solutions for small squares, we establish a competitive factor of 17 \u221a 3 16+ \u221a 3 \u2248 1.661 for polyominoes with and 19 \u221a 3","Organizing Ontology Design Patterns as Ontology Pattern LanguagesOntology design patterns have been pointed out as a promising ap- proach for ontology engineering. The goal of this paper is twofold. Firstly, based on well-established works in Software Engineering, we revisit the notion of ontology patterns in Ontology Engineering to introduce the notion of ontolo- gy pattern language as a way to organize related ontology patterns. Secondly, we present an overview of a software process ontology pattern language.","Enabling Entrepreneurship within Virtual Worlds: Theorizing the Role of Governance and Culture ","Open-ended, Extensible System Utterances Are Preferred, Even If They Require Filled PausesIn many environments (e. g. sports commentary), situations incrementally unfold over time and often the future appearance of a relevant event can be predicted, but not in all its details or precise timing. We have built a simulation framework that uses our incremental speech synthesis component to assemble in a timely manner complex commentary utterances. In our evaluation, the resulting output is preferred over that from a baseline system that uses a simpler commenting strategy. Even in cases where the incremental system overcommits temporally and requires a filled pause to wait for the upcoming event, the system is preferred over the baseline.","Intuitionistic Fuzzy Control Based on Association RulesThe task of the standard Mamdani fuzzy logic controller is to find a crisp control action from the fuzzy rule-base and from a set of crisp inputs. In this paper we modify this controller in order to work with intuitionistic fuzzy sets and to activate a set of rules having the same conclusion. Usually, the inference rules used in a fuzzy logic controller are given by a domain expert; in our system, these rules are automatically induced as fuzzy association rules starting from a training set. The fuzzy confidence value associated with each rule is used to obtain the fuzzy set inferred by our system.","Viewing the Viewers: A Novel Challenge for Automated Crowd AnalysisWe focus on the automated analysis of spectator crowd, that is, people watching sport contests alive (in stadiums, amphitheaters etc.), or, more generally, people \"watching the activities of an event ['] interested in watching something specific that they came to see\" [2]. This scenario differs substantially from the typical crowd analysis setting (e.g. pedestrians): here the dynamics of humans is more constrained, due to the architectural environments in which they are situated; people are expected to stay in a fixed location most of the time, limiting their activities to applaud, support/heckle the players or discuss with the neighbors. In this paper, we start facing this challenge by following a social signal processing approach, which grounds computer vision techniques in social theories. More specifically, leveraging on social theories describing expressive bodily conduct, we will show how, by using computer vision techniques, it is possible to distinguish fan groups belonging to different teams by automatically detecting their liveliness in different moments of the match, even when they are merged in the stands. Moreover, we will show how, only by automatically detecting crowd's motions on the stands, it is possible to single out the most salient events of the match, like goals, fouls or shots on goal.","A Local Image Descriptor Robust to Illumination Changes ","Canonical structures for the working coq userThis paper provides a gentle introduction to the art of programming type inference with the mechanism of Canonical Structures. Programmable type inference has been one of the key ingredients for the successful formalization of the Odd Order Theorem using the Coq proof assistant. The paper concludes comparing the language of Canonical Structures to the one of Type Classes and Unification Hints.","A Combination of Hand-Crafted and Hierarchical High-Level Learnt Feature Extraction for Music Genre ClassificationIn this paper, we propose a new approach for automatic music genre classification which relies on learning a feature hierarchy with a deep learning architecture over hand-crafted feature extracted from an audio signal. Unlike the state-of-the-art approaches, our scheme uses an unsupervised learning algorithm based on Deep Belief Networks (DBN) learnt on block-wise MFCC (that we treat as 2D images), followed by a supervised learning algorithm for fine-tuning the extracted features. Experiments performed on the GTZAN dataset show that the proposed scheme clearly outperforms the state-of-the-art approaches.","IS Capabilities For Supporting Post Crisis Regulatory Compliance.The financial crisis of 2007-2009, has precipitated large scale regulatory change. Financial organizations are faced with implementing new regulations of considerable breadth and depth. Firms are faced with engaging in complex and costly change management programs at a time when profits are diminished. Furthermore, investors are becoming increasingly focused on compliance are seeking to ensure that organizations can demonstrate robust compliance practices as part of their due diligence process .The role of IS in underpinning stable, is paramount. IS allows the stable and consistent controls for meeting regulations in order to ensure long term effective compliance. Consequently, our study explores the IS capabilities which support the post crisis regulatory landscape. We identify eight key capabilities: Managing Internal Controls, Measuring Monitoring and Reporting Transactions, IS Development and Procurement, Managing Third Parties, Sharing and Selecting Best Practice, IS Leadership, Data Management and Enabling Cultural Change.","Incremental software design modellingIn this paper we investigate how a software designer can build a complex software design model incrementally by exploiting model interfaces and information hiding to encapsulate different design concerns within model increments. Each model increment either extends or customizes the model it is applied to. When using model extension, each increment adds modelling elements to the existing model to provide additional structure and behaviour. When using model customization, each increment adds modelling elements to adapt the general structure and behaviour of the model to a specific need. We discuss how incremental modelling fits with software development processes, and show how different model composition techniques, i.e. class merge, subclassing, operation in-lining and advising, support the incremental extension and customization of models. Finally, we explain how to generate the complete software design in the end. Practically, we present how we extended the Reusable Aspect Models (RAM) approach to support incremental modelling and show details of an incremental design of a workflow middleware product line.","Enhancing HMD-Based F-35 Training through Integration of Eye Tracking and Electroencephalography Technology ","Interactive Evaluation of Video Browsing Tools ","Learning to Detect Stent Struts in Intravascular UltrasoundIn this paper we tackle the automatic detection of struts el- ements (metallic braces of a stent device) in Intravascular Ultrasound (IVUS) sequences. The proposed method is based on context-aware clas- sification of IVUS images, where we use Multi-Class Multi-Scale Stacked Sequential Learning (M 2 SSL). Additionally, we introduce a novel tech- nique to reduce the amount of required contextual features. The com- parison with binary and multi-class learning is also performed, using a dataset of IVUS images with struts manually annotated by an expert. The best performing configuration reaches a F-measure F =6 3.97% .","QoS-Aware Service VM Provisioning in Clouds: Experiences, Models, and Cost AnalysisRecent studies show that service systems hosted in clouds can elastically scale the provisioning of pre-configured virtual machines VMs with workload demands, but suffer from performance variability, particularly from varying response times. Service management in clouds is further complicated especially when aiming at striking an optimal trade-off between cost i.e., proportional to the number and types of VM instances and the fulfillment of quality-of-service QoS properties e.g., a system should serve at least 30i\u00be?requests per second for more than 90% of the time. In this paper, we develop a QoS-aware VM provisioning policy for service systems in clouds with high capacity variability, using experimental as well as modeling approaches. Using a wiki service hosted in a private cloud, we empirically quantify the QoS variability of a single VM with different configurations in terms of capacity. We develop a Markovian framework which explicitly models the capacity variability of a service cluster and derives a probability distribution of QoS fulfillment. To achieve the guaranteed QoS at minimal cost, we construct theoretical and numerical cost analyses, which facilitate the search for an optimal size of a given VM configuration, and additionally support the comparison between VM configurations.","An Innovative Virtual Enterprise Approach to Agile Micro and SME-Based Collaboration Networks ","When does Abuse of Social Media constitute a Crime? \u2013 A South African Legal Perspective within a Global Context ","Layered RC Circuit Model for Background SubtractionThe background subtraction is a technique widely used for video analysis, mainly moving object detection for surveillance systems. Such algorithms must be robust, fast and it has to be able to deal with dynamic backgrounds like water surface or moving tree branches. Also, they should be able to deal with illumination changes and objects casted shadows. Generally, in computer vision the algorithms with a physical background have the best performance. We propose an algorithm for background subtraction based on a model of layered RC circuits. We tested our method on video sequences acquired from level crossing and on commonly used datasets. Finally, we have compared the proposed method with other frequently used methods.","Predictive Analytics On Public Data - The Case Of Stock Markets ","Improving EU Cohesion Policy: The Spatial Distribution Analysis of Regional Development Investments Funded by EU Structural Funds 2007/2013 in Italy ","Comment on \"robustness and regularization of support vector machines\" by H. Xu, et al., (Journal of Machine Learning Research, vol. 10, pp. 1485-1510, 2009, arXiv:0803.3490)This paper comments on the published work dealing with robustness and regularization of support vector machines (Journal of Machine Learning Research, vol. 10, pp. 1485-1510, 2009) [arXiv:0803.3490] by H. Xu, etc. They proposed a theorem to show that it is possible to relate robustness in the feature space and robustness in the sample space directly. In this paper, we propose a counter example that rejects their theorem.","Service Based Design Solutions - A Case of Migrant Workers' Affective Links with Their Families in Rural Areas of ChinaThe outgoing of migrant workers from China rural areas brings many negative impacts upon their stay-at-home children, most of which are relevant to lack of family love and emotional connections. This joint project of Tsinghua University Design &amp; Human Factors Lab and Nokia Research Center Beijing aims at investigating the daily lives of and interactions between the migrant workers in cities and their children staying at rural homes, and inventing some conceptual solutions to help them to treat this sort of problems. \"DreamSeed\", \"WeMoment\" and \"LinkBoard\" are just three conceptual solutions generated in this joint project, which attempt to contribute to promoting the emotional connections of migrant workers with their families, especially their children at rural home.","Cooperation between logistics service providers based on cloud computingThe paper describes the use of cloud computing in logistics, especially the creation of the multi-modal platform designed for cooperating logistics service providers and their customers. The research conducted within the EU project is presented. The article focuses primarily on the findings of its initial phase --- the analysis of information requirements needed for cloud computing platform. The processes maps and use case are proposed.","Sleep Spindle Detection in EEG Signals Combining HMMs and SVMs ","Irrationality Is Needed to Compute with Signal Machines with Only Three SpeedsSpace-time diagrams of signal machines on finite configu- rations are composed of interconnected line segments in the Euclidean plane. As the system runs, a network emerges. If segments extend only in one or two directions, the dynamics is finite and simplistic. With four directions, it is known that fractal generation, accumulation and any Turing computation are possible. This communication deals with the three directions/speeds case. If there is no irrational ratio (between initial distances between signals or between speeds) then the network follows a mesh preventing accumu- lation and forcing a cyclic behavior. With an irrational ratio (here, the Golden ratio) between initial distances, it becomes possible to provoke an accumulation that generates infinitely many interacting signals in a bounded portion of the Euclidean plane. This behavior is then controlled and used in order to simulate a Turing machine and generate a 25-state 3-speed Turing-universal signal machine.","Combining Spatial and Temporal Information of Eye Movements in Goal-Oriented Tasks ","Innovative Soft Computing Methodologies for Evaluating Risk Factors of Atherosclerosis ","An Experiment on Self-configuring Database Queries ","Various Document Clustering Tasks Using Word ListsThis research investigates whether it is appropriate to use word lists as features for clustering documents to their authors, to the documents' countries of origin or to the historical periods in which they were written. We have defined three kinds of word lists: most frequent words (FW) including function words (stopwords), most frequent filtered words (FFW) excluding function words, and words with the highest variance values (VFW). The application domain is articles referring to Jewish law written in Hebrew and Aramaic. The clustering experiments have been done using The EM algorithm. To the best of our knowledge, performing clustering tasks according to countries or periods are novel. The improvement rates in these tasks vary from 11.53% to 39.43%. The clustering tasks according to 2 or 3 authors achieved results above 95% and present superior improvement rates (between 15.61% and 56.51%); most of the improvements have been achieved with FW and VFW. These findings are surprising and contrast the initial assumption that FFW is the prime word list for clustering tasks.","Leveraging Domain Specificity to Improve Findability in OER RepositoriesThis paper addresses the problem of improving the findability of open educational resources (OER) in Computer Science. It presents a domain- specific OER reference repository and portal aimed at increasing the low OER use. The focus is on enhancing the search and navigation capabilities. A distinc- tive feature is the proposed query-by-navigation method.","Changes in forest habitat classes under alternative climate and land-use change scenarios in the northeast and midwest, USALarge-scale and long-term habitat management plans are needed to maintain the diversity of habitat classes required by wildlife species. Planning efforts would benefit from assessments of potential climate and land-use change effects on habitats. We assessed climate and land-use driven changes in areas of closed- and open-canopy forest across the Northeast and Midwest by 2060. Our assessments were made using projections based on A1B and A2 future scenarios developed by the Intergovernmental Panel on Climate Change. Presently, forest land covers 70.2 million ha and is evenly divided between closed- and open-canopy habitats. Projections indicated that total forest land would decrease by 3.8 or 4.5 million ha for A2 and A1B, respectively. Within persisting forest land, the balance between closed- and open-canopy habitats depended on assumed harvest rates of woody biomass. Standard harvest rates led to closed-canopy habitat attaining a slight majority of total forest land area. Intensive harvest rates resulted in the majority of forest land being in open-canopy habitat for A1B or maintained the even split between closed- and open-canopy habitats for A2. Ultimately, managers need to identify benchmark habitat conditions informed by historical conditions and wildlife population dynamics and plan to meet these benchmarks in dynamic forest landscapes.","NeuroCopter: neuromorphic computation of 6D ego-motion of a quadcopterThe navigation capabilities of honeybees are surprisingly complex. Experimental evidence suggests that honeybees rely on a map-like neuronal representation of the environment. Intriguingly, a honeybee brain exhibits approximately one million neurons only. In an interdisciplinary enterprise, we are investigating models of high-level processing in the nervous system of insects such as spatial mapping and decision making. We use a robotic platform termed NeuroCopter that is controlled by a set of functional modules. Each of these modules initially represents a conventional control method and, in an iterative process, will be replaced by a neural control architecture. This paper describes the neuromorphic extraction of the copter's ego motion from sparse optical flow fields. We will first introduce the reader to the system's architecture and then present a detailed description of the structure of the neural model followed by simulated and real-world results.","Towards learning normality for anomaly detection in industrial control networksRecent trends in automation technology lead to a rising exposition of industrial control systems (ICS) to new vulnerabilities. This requires the introduction of proper security approaches in this field. Prevalent in ICS is the use of access control. Especially in critical infrastructures, however, preventive security measures should be complemented by reactive ones, such as intrusion detection. Beginning from the characteristics of automation networks we outline the implications for a suitable application of intrusion detection in this field. On this basis, an approach for creation of self-learning anomaly detection for ICS protocols is presented. In contrast to other approaches, it takes all network data into account: flow information, application data, and the packet order. We discuss the challenges that have to be solved in each step of the network data analysis to identify future aspects of research towards learning normality in industrial control networks.","Automated grading of DFA constructionsOne challenge in making online education more effective is to develop automatic grading software that can provide meaningful feedback. This paper provides a solution to automatic grading of the standard computation-theory problem that asks a student to construct a deterministic finite automaton (DFA) from the given description of its language. We focus on how to assign partial grades for incorrect answers. Each student's answer is compared to the correct DFA using a hybrid of three techniques devised to capture different classes of errors. First, in an attempt to catch syntactic mistakes, we compute the edit distance between the two DFA descriptions. Second, we consider the entropy of the symmetric difference of the languages of the two DFAs, and compute a score that estimates the fraction of the number of strings on which the student answer is wrong. Our third technique is aimed at capturing mistakes in reading of the problem description. For this purpose, we consider a description language MOSEL, which adds syntactic sugar to the classical Monadic Second Order Logic, and allows defining regular languages in a concise and natural way. We provide algorithms, along with optimizations, for transforming MOSEL descriptions into DFAs and vice-versa. These allow us to compute the syntactic edit distance of the incorrect answer from the correct one in terms of their logical representations. We report an experimental study that evaluates hundreds of answers submitted by (real) students by comparing grades/feedback computed by our tool with human graders. Our conclusion is that the tool is able to assign partial grades in a meaningful way, and should be preferred over the human graders for both scalability and consistency.","A Unified Taxonomy of Hybrid Metaheuristics with Mathematical Programming, Constraint Programming and Machine Learning ","Cognitive Chrono-Ethnography: A Methodology for Understanding Users for Designing Interactions Based on User Simulation with Cognitive Architectures ","Validating Code-Level Behavior of Dynamic Adaptive Systems in the Face of UncertaintyA dynamically adaptive system DAS self-reconfigures at run time in order to handle adverse combinations of system and environmental conditions. Techniques are needed to make DASs more resilient to system and environmental uncertainty. Furthermore, automated support to validate that a DAS provides acceptable behavior even through reconfigurations are essential to address assurance concerns. This paper introduces Fenrir, an evolutionary computation-based approach to address these challenges. By explicitly searching for diverse and interesting operational contexts and examining the resulting execution traces generated by a DAS as it reconfigures in response to adverse conditions, Fenrir can discover undesirable behaviors triggered by unexpected environmental conditions at design time, which can be used to revise the system appropriately. We illustrate Fenrir by applying it to a dynamically adaptive remote data mirroring network that must efficiently diffuse data even in the face of adverse network conditions.","Cryptanalyzing an image encryption scheme based on logistic mapAbstract Recently, an image encryption scheme based 2 on logistic map was proposed. It has been reported by a 3 research group that its equivalent secret key can be re- 4 constructed with only one pair of known-plaintext and 5 the corresponding cipher-text. Utilizing stable distribu- 6 tion of the chaotic states generated by iterating the lo- 7 gistic map, this paper further demonstrates that much 8 more information about the secret key can be derived 9 under the same condition. 10 Keywords cryptanalysis \u00b7 chosen-plaintext attack \u00b7 11 image encryption \u00b7 logistic map 12 1Introduction 13 With the rapid development of information transmis- 14 sion technology and popularization of multimedia cap- 15 ture device, multimedia data are transmitted over all 16 kinds of wired/wireless networks more and more fre- 17 quently. Consequently, the security of multimedia data 18 becomes a serious concern of many people. However, 19 the traditional text encryption schemes cannot protect 20 multimedia data e\ufb03ciently, mainly due to the big dif-","Dissimilarity Increments Distribution in the Evidence Accumulation Clustering FrameworkIn this paper, we combine two concepts. The first is the Evidence Ac- cumulation Clustering framework, which uses a voting scheme to combine clus- tering ensembles and produce a co-association matrix. The second concept are Dissimilarity Increments, which are a high order dissimilarity measure which can identify sparse clusters, since it uses three data points at a time instead of two points, as in Euclidean distance. These two concepts are combined to form a new family of clustering algorithms, where the co-association matrix is used to form a distance which is then used to compute dissimilarity increments. These clustering algorithms are shown to improve the clustering results when compared to the usual Evidence Accumulation Clustering framework.","Requirements engineering in practice: there is no requirements engineer position[Context and motivation] For the requirements engineering (RE) community it is clear that requirements engineering is a specific activity and role within software development. [Question/problem] However: What about practice? Is RE seen there as a separate role? What qualifications do practitioners see as critical for this task? [Principal ideas/results] 141 job advertisements from 2009 and 67 from 2012 were analysed statistically in order to find out how practice perceives and staffs RE: Which official job title do those persons have who do RE? Which further responsibilities do these persons have? Which qualifications are demanded? [Contribution] The study\u00b4s main results are: The position \"requirements engineer\" hardly exists. RE instead is done by consultants, software engineers, architects, developers and project managers, who additionally have an average of 3 further tasks. RE is no task for job beginners: 73% of the job advertisements wish or demand previous job experience. Further important qualifications are: 94% soft skills (the Top 3 soft skills are: capacity for teamwork, English language and communication skills), 76% demand knowledge with respect to the technology used, while only 34% mention RE knowledge. RE is most often combined with solution design (77% respectively 61%).","Extending Successful eBusiness Models to the Mobile Internet: The Case of Sedo's Domain ParkingThe trend of the Internet 'going mobile' is irreversible and proceeding. Many established Internet players are experimenting with extending their business models to the mobile Internet. In this paper, we explore such business development process for the domain parking business of Sedo \u2013 a global leader in domain trading and domain parking. With the case study, we show how Sedo on the one hand benefits from its position as market leader in the stationary domain parking business and, on the other hand, faces severe challenges such as the trend to search-based Internet access, performance-based pricing, the proliferation of smart-phones and mobile applications (apps) \u2013 all of which are typically appreciated in the mobile Internet. We thereby contribute to our understanding of the multifaceted issues that companies face when they transfer their business models from the stationary to the mobile Internet.","From the zones of influence of skeleton branch points to meaningful object partsA 3D object decomposition method is presented, which is based on the decomposition of the linear skeleton guided by the zones of influence. These are the connected components of voxels obtained by applying the reverse distance transformation to the branch points of the skeleton. Their role is to group sufficiently close branch points and to detect perceptually meaningful skeleton branches that are in a one-to-one relation with the object parts.","Crowdsourcing Fact Extraction from Scientific Literature ","A space-time trade off for FUFP-trees maintenanceIn the past, Hong et al. proposed an algorithm to maintain the fast updated frequent pattern tree (FUFP-tree), which was an efficient data structure for association-rule mining. However in the maintenance process, the counts of infrequent items and the IDs of transactions with those items were determined by rescanning all the transactions in the original database. This step might be quite time-consuming depending on the number of transactions in the original database and the number of rescanned items. This study improves that approach by storing 1-items during the maintenance process and based on the properties of FUFP-trees, such that the rescanned items and inserted items are processed more efficiently to reduce execution time. Experimental results show that the improved algorithm needs some more memory to store infrequent 1-items but the performance is better than the original one.","Applying Facebook as a Management Method for the Teaching Platform to Develop Product Design ","A Reference Architecture for an Enterprise Knowledge Infrastructure ","A Multiagent System for Resource Distribution into a Cloud Computing Environment ","Combined effect on accident risk of a dual task and higher driving speed: a simulator studyA study was conducted on a dynamic driving simulator aiming to examine whether the effect of mental effort due to an auditory detection task on accident risk is additive to the effect of higher speed. Two levels of the driving task were employed, a low-demanding and a high-demanding one. Twenty drivers were asked to drive two rounds on a rural road with normal traffic, with unexpected traffic events along the second round. In half of the cases an auditory detection task had to be performed in parallel. The analysis of results showed that higher speed or higher mental effort due to the secondary task lead to more accidents and the effects should be considered as additive. These effects should not be considered as the mere effect of attentional resource availability but as depending on the drivers' skill to manage their attentional control.","How Cloud Computing Impacts Stock Market PricesCloud computing is an evolution of computing technology and re- flects a shift in the way it is delivered to businesses and individuals. Enterprises can significantly lower their cost of ownership, reduce time to value and faster adapt to changing needs in a globalized economy. Despite research and practice predict productivity increases and cost savings when migrating to the cloud one question remains unanswered: Does the adoption of cloud computing increase the market value of the firm? We try to answer this question by applying the event study methodology on companies that recently announced the deployment of cloud computing. Overall, we find significant positive abnormal returns. We find that investors specifically reward innovative and strategically motivated adoption of cloud computing. As a key implication of our results, we recom- mend in particular IT executives in large companies within the service industry to reassess their portfolio and foster the adoption of strategic and innovative cloud services.","Exploring the Potential of Neurophysiological Measures for User-adaptive Visualization.User-adaptive visualization aims to adapt visualized information to the needs and characteristics of the individual user. Current approaches deploy user personality factors, user behavior and preferences, and visual scanning behavior to achieve this goal. We argue that neurophysiological data provide valuable additional input for user-adaptive visualization systems since they contain a wealth of objective information about user characteristics. The combination of neurophysiological data with other information like eye movement data can significantly improve system reliability by reducing the inherent uncertainty in the interpretation of the user data. Moreover, neurophysiological data can be obtained continuously and unobtrusively without disturbing the interaction of the user with the system","A new hierarchical method for markerless human pose estimationWe present a system for markerless human motion capture through a hierarchical method from multiple camera views. In the absence of markers, the task of recovering the human pose is challenging and requires strong image features and robust algorithm. We propose a solution which integrates the 2D posture information and the volumetric reconstruction. Firstly, the model's initia posture is obtained through the method of segmenting silhouette. After that, we track the human pose by using a hierarchical method, which is divided into three steps: head detection, torso prediction and limb matching. In order to gain the robust results, we discard the interior voxel data, use the middle voxel data for motion tracking, and use the surface voxel data for global optimization. The experiment results show that the method is valid and robust.","Statistical error correction methods for domain-specific ASR systemsWhenever an ASR company promises to deliver error-proof transcripts to the end user, manual verification and correction of the raw ASR transcripts cannot be avoided. This manual post-editing process systematically generates new and correct domain-specific data which can be used to incrementally improve the original ASR system. This paper proposes a statistic, SMT-based ASR error correction method, which takes advantage of the past corrected ASR errors to automatically post-process its future transcripts. We show that the proposed method can bring more than 10% WER improvements using only 2000 user-corrected sentences.","Semi-supervised Learning of Action Ontology from Domain-Specific CorporaThe paper presents research results, showing how unsupervised and supervised ontology learning methods can be combined in an action ontology building approach. A framework for action ontology building from domain- specific corpus texts is suggested, using different natural language processing techniques, such as collocation extraction, frequency lists, word space model, etc. The suggested framework employs additional knowledge sources of WordNet and VerbNet with structured linguistic and semantic information. Re- sults from experiments with crawled chemical laboratory corpus texts are given.","Managing Speed in Companies Developing Large-Scale Embedded SystemsAn open issue is how to reach quickness and responsiveness in addressing customer needs within large-scale embedded system product development, where the processes are bound to the physical product development. Speed is a key quality that needs particular attention. We are developing a framework to understand what kinds of speed are important, what factors are determining them, what are the visible effects and what is possible to improve in order to reach speed related business goals.","SOM++: integration of self-organizing map and k-means++ algorithmsData clustering is an important and widely used task of data mining that groups similar items together into subsets. This paper introduces a new clustering algorithm SOM++, which first uses K-Means++ method to determine the initial weight values and the starting points, and then uses Self-Organizing Map (SOM) to find the final clustering solution. The purpose of this algorithm is to provide a useful technique to improve the solution of the data clustering and data mining in terms of runtime, the rate of unstable data points and internal error. This paper also presents the comparison of our algorithm with simple SOM and K-Means + SOM by using a real world data. The results show that SOM++ has a good performance in stability and significantly outperforms three other methods training time.","A Neural Network Model of Visual Attention and Group Classification, and Its Performance in a Visual Search TaskHumans can attend to and categorise objects individually, but also as groups. We present a computational model of how visual attention is allocated to single objects and groups of objects, and how single objects and groups are classified. We illustrate the model with a novel account of the role of stimulus similarity in visual search tasks, as identified by Duncan and Humphreys [1].","Towards a Concept for Integrating IT Innovation Management into Business IT Management ","Identifying dynamic data structures by learning evolving patterns in memoryWe investigate whether dynamic data structures in pointer programs can be identified by analysing program executions only. This paper describes a first step towards solving this problem by applying machine learning and pattern recognition techniques to analyse executions of C programs. By searching for repeating temporal patterns in memory caused by multiple invocations of data-structure operations, we are able to first locate and then identify these operations. Applying a prototypic tool implementing our approach to pointer programs that employ, e.g., lists, queues and stacks, we show that the identified operations can accurately determine the data structures used.","Integrating UIMA Annotators in a Web-based Text Processing Frameworkand Objective The Unstructured Information Management Architecture (UIMA) (1) framework is a growing platform for natural lan- guage processing (NLP) applications. However, such applica- tions may be difficult for non-technical users deploy. This pro- ject presents a web-based framework that wraps UIMA-based annotator systems into a graphical user interface for research- ers and clinicians, and a web service for developers. An anno- tator that extracts data elements from lung cancer radiology reports is presented to illustrate the use of the system. Annota- tion results from the web system can be exported to multiple formats for users to utilize in other aspects of their research and workflow. This project demonstrates the benefits of a lay- user interface for complex NLP applications. Efforts such as this can lead to increased interest and support for NLP work in the clinical domain.","Counting Spanning Trees to Guide Search in Constrained Spanning Tree ProblemsCounting-based branching heuristics such as maxSD were shown to be effective on a variety of constraint satisfaction problems. These heuristics require that we equip each family of constraints with a dedicated algorithm to compute the local solution density of variable assignments, much as what has been done with filtering algorithms to apply local inference. This paper derives an exact polytime algorithm to compute solution densities for a spanning tree constraint, starting from a known result about the number of spanning trees in a graph. We then empirically compare branching heuristics based on that result with other generic heuristics.","Automatic Orientation of Functional Brain Images for Multiplataform SoftwareAn automated method for orientation of functional brain image is proposed. Intrinsec information is captured from the image in three stages: first the volume to identify the anterior to posterior line, second the symmetry to detect the hemisphere dividing plane and third the contour to determine the up-down and front-back orientation. The approach is tested in more than a tousand images from different formats and modalities with high reconition rates.","White dots do matter: rewriting reversible logic circuitsThe increased effort in recent years towards methods for computer aided design of reversible logic circuits has also lead to research in algorithms for optimising the resulting circuits; both with higher-level data structures and directly on the reversible circuits. To obtain structural patterns that can be replaced by a cheaper realisation, many direct algorithms apply so-called moving rules; a simple form of rewrite rules that can only swap gate order.#R##N##R##N#In this paper we first describe the few basic rules that are needed to perform rewriting directly on reversible logic circuits made from general Toffoli circuits. We also show how to use these rules to derive more complex formulas. The major difference compared to existing approaches is the use of negative controls (white dots), which significantly increases the algebraic strength. We show how existing optimisation approaches can be adapted as problems based on our rewrite rules.#R##N##R##N#Finally, we outline a path to generalising the rewrite rules by showing their forms for reversible control-gates. This can be used to expand our method to other gates such as the controlled-swap gate or quantum gates.","Romanian Syllabication Using Machine LearningThe task of finding syllable boundaries can be straightforward or challenging, depending on the language. Text-to-speech applications have been shown to perform considerably better when syllabication, whether orthographic or phonetic, is employed as a means of breaking down the text into units bellow word level. Romanian syllabication is non-trivial mainly but not exclusively due to its hiatus-diphthong ambiguity. This phenomenon affects both phonetic and orthographic syllabication. In this paper, we focus on orthographic syllabication for Romanian and show that the task can be carried out with a high degree of accuracy by using sequence tagging. We compare this approach to support vec- tor machines and rule-based methods. The features we used are simply character n-grams with end-of-word marking.","Mobile App Support for Electric Vehicle Drivers: A Review of Today\u2019s Marketplace and Future DirectionsMobile device applications (apps) are becoming an important source of information, control, and motivation for EV drivers. Here we review the current ecosystem of mobile applications that are available for EV drivers and consumers and find that apps are available in six basic categories: purchase de- cisions, vehicle dashboards, charging availability and payment, smart grid inte- raction, route planning, and driver competitions. The current range of the EV- specific mobile marketplace extends from pre-sale consumer information, charging information and control, and EV specific navigation features among other services. However, the market is highly fragmented, with applications providing niche information, and using various methodologies. In addition, we find that the barriers to more useful apps are a lack of vehicle and charger APIs (application programming interfaces), lack of data availability, reliability, for- mat and types, and proprietary payment and billing methods. We conclude that mobile applications for EVs are a growing market that provide important direct benefits as well as ancillary services to EV owners, although the lack of un- iformity and standards between both vehicle and charger systems is a serious barrier to the broader use of mobile applications for EVs.","Matching Business Process Models Using Positional Passage-Based Language ModelsBusiness operations are often documented by business process models. Use cases such as system validation and process harmonization require the identification of correspondences between activities, which is supported by matching techniques that cope with textual heterogeneity and differences in model granularity. In this paper, we present a matching technique that is tailored towards models featuring textual descriptions of activities. We exploit these descriptions using ideas from language modelling. Experiments with real-world process models reveal that our technique increases recall by up to factor five, largely without compromising precision, compared to existing approaches.","Development of a measurement and evaluation system for bed-making activity for self-trainingThis study proposes a method to automatically measure multiple objects by image processing for constructing a system for nursing trainees of self-training in the skill of bed making. In a previous study, we constructed a system to measure and evaluate trainee performance using three RGB-D (RGB color and depth) sensors. Our previous system had a problem with recognition of equipment such as the bed pad and the sheet because of color change by the light condition, the automatic color correction by the sensors and color variability in one object. In this paper, we used color reduction and cluster selection for equipment recognition. The system reduced the color in images by using k-means clustering and recognized the clusters as separate objects by predetermined thresholds. Compared with the previous method, the recognition accuracy was higher and the accuracy achieved was 70%.","Visual Data Mining Methods for Kernel Smoothed Estimates of Cox ProcessesReal world planning of complex logistical organisations such as the fire service is a complex task requiring synthesis of many different computational techniques, from artificial intelligence and statistical or machine learning to geographical information systems and visualization. A particularly promising approach is to apply established data mining techniques in order to produce a model and make forecasts. The nature of the forecast can then be rendered using visualization techniques in order to assess operational decisions, simultaneously benefiting from generic and powerful data mining techniques, and using visualization to understand these results in the context of the actual problem of interest which may be very specific. Previous approaches to visualization in similar contexts use iso surfaces to visualize densities, these methods ignore recent improvements in interactive 3D visualization such as volume rendering and cut-planes, these methods also ignore what is often a key problem of interest comparing two different stochastic processes, finally previous methods have not paid sufficient attention to differences between estimation of densities and point processes (or Cox processes). This paper seeks to address all of these shortcomings and make recommendations for the trade-offs between visualization techniques for operational decision making. Finally we also demonstrate the ability to include interactive 3D plots within a paper by rendering an iso surface using 3D portable document format (PDF).","Short Communication: A note on intra-supply chain system with multiple sales locations and quality assuranceIn a recent paper, Chiu et al. [Intra-supply chain system with multiple sales locations and quality assurance, Expert Systems with Applications, http://dx.doi.org/10.1016/j.eswa.2012.11.008] used the mathematical modeling and differential calculus to derive the optimal replenishment lot-size and shipment policy that minimizes overall costs for a specific intra-supply chain system. This paper proposes a two-phase straightforward algebraic approach to replace the use of calculus on the cost function for determining the optimal production-shipment policy for such a specific system. This alternative approach enables practitioners who may not have sufficient knowledge of calculus to manage the real-world intra-supply chain systems more effectively.","Diversified recommendation on graphs: pitfalls, measures, and algorithmsResult diversification has gained a lot of attention as a way to answer ambiguous queries and to tackle the redundancy problem in the results. In the last decade, diversification has been applied on or integrated into the process of PageRank- or eigenvector-based methods that run on various graphs, including social networks, collaboration networks in academia, web and product co-purchasing graphs. For these applications, the diversification problem is usually addressed as a bicriteria objective optimization problem of relevance and diversity. However, such an approach is questionable since a query-oblivious diversification algorithm that recommends most of its results without even considering the query may perform the best on these commonly used measures. In this paper, we show the deficiencies of popular evaluation techniques of diversification methods, and investigate multiple relevance and diversity measures to understand whether they have any correlations. Next, we propose a novel measure called expanded relevance which combines both relevance and diversity into a single function in order to measure the coverage of the relevant part of the graph. We also present a new greedy diversification algorithm called BestCoverage, which optimizes the expanded relevance of the result set with (1-1/e)-approximation. With a rigorous experimentation on graphs from various applications, we show that the proposed method is efficient and effective for many use cases.","Enhancing Modularity Optimization via Local Close-Knit Structures ","Consumedia. Functionalities, Emotion Detection and Automation of Services in a ODR PlatformThis paper presents a legal and technological approach to online mediation. It shows the technologies that are usually employed in this field and presents the prototype of Consumedia, an online mediation platform, as well as its functionalities and technological architecture. Moreover, it uncovers the technology implemented as regards the recognition of emotions in the mediation room. Furthermore, it considers that an online mediation platform may automatically provide the parties with all the required documentation of the process. Thus, it unveils the documents that an online mediation platform should automatically provide to the disputants.","Bin Packing Games with Selfish ItemsWe discuss recent work on the subject of selfish bin packing. In these problems, items are packed into bins, such that each item wishes to minimize its own payoff. We survey the known results for a number of variants, focusing on worst-case Nash equilibria and other kinds of equilibria, and mentioning several results regarding issues of complexity and convergence to equilibria.","Adaptive spatio-temporal exploratory models: Hemisphere-wide species distributions from massively crowdsourced ebird dataBroad-scale spatiotemporal processes in conservation and sustainability science, such as continent-wide animal movement, occur across a range of spatial and temporal scales. Understanding these processes at multiple scales is crucial for developing and coordinating conservation strategies across national boundaries. In this paper we propose a general class of models we call AdaSTEM, for Adaptive Spatio-Temporal Exploratory Models, that are able to exploit variation in the density of observations while adapting to multiple scales in space and time. We show that this framework is able to efficiently discover multiscale structure when it is present, while retaining predictive performance when absent. We provide an empirical comparison and analysis, offer theoretical insights from the ensemble loss decomposition, and deploy AdaSTEM to estimate the spatiotemporal distribution of Barn Swallow (Hirundo rustica) across the Western Hemisphere using massively crowdsourced eBird data.","Aggregating Conditionally Lexicographic Preferences Using Answer Set Programming SolversWe consider voting over combinatorial domains, where alternatives are binary tuples. We assume that votes are specified as conditionally lexicographic preference trees, or LP trees for short. We study the aggregation of LP tree votes for several positional scoring rules. Our main goal is to demonstrate that answer-set programming tools can be effective in solving the winner and the evaluation problems for instances of practical sizes. To this end, we propose encodings of the two problems as answer-set programs, design methods to generate LP tree votes randomly to support experiments, and present experimental results obtained with ASP solvers clingo and clingcon.","Using Conceptual Structures in the Design of Computer-Based Assessment SoftwareThis paper discusses the use of conceptual structures in the design of computer-based assessment (CBA) tools for e-assessment of programming exercises. In STEM (science, technology, engineering and maths) subjects, universities often observe high dropout and failure rates among the first year students. There are a number of research initiatives that investigate the use of interactive teaching methods and e-learning technologies for improving STEM education. This paper presents a con- ceptual model of programming exercises and discusses more generally how conceptual structures can be employed for the implementation of CBA tools.","Cloud computing and the internet of things: technology innovation in automobile serviceAiming to explore the transforming role of information technologies in automobile service, this paper first introduces two major technology trends: Cloud Computing and the Internet of Things, as well as their applications in automobile service. After that, the paper focuses on investigating the technology innovations in automobile service, and how the innovations transform the traditional business. Future research directions are discussed finally.","Maintaining alternative values in constraint-based configurationConstraint programming techniques are widely used to model and solve interactive decision problems, and especially configuration problems. In this type of application, the configurable product is described by means of a set of constraints bearing on the configuration variables. The user interactively solves the CSP by assigning the variables according to her preferences. The system then has to keep the domains of the other variables consistent with these choices. Since maintaining the global inverse consistency of the domains is not tractable, the domains are instead filtered according to some level of local consistency, e.g. arc-consistency.#R##N##R##N#The present paper aims at offering a more convenient interaction by providing the user with possible alternative values for the already assigned variables, i.e. values that could replace the current ones without leading to a constraint violation. We thus present the new concept of alternative domains in a (possibly) partially assigned CSP. We propose a propagation algorithm that computes all the alternative domains in a single step. Its worst case complexity is comparable to the one of the naive algorithm that would run a full propagation for each variable, but its experimental efficiency is better.","Advances in 3D Camera: Time-of-Flight vs. Active TriangulationOver the last decade, numerous 3D camera techniques have been pro- posed and advanced dramatically. One main approach is time-of-flight (TOF) and the other is active triangulation. Each has its own strengths and weaknesses. In this paper, we overview the principle of each method and compare the advan- tages and disadvantages in detail, and introduce several commercially available 3D cameras and their characteristics.","An Efficient Update Mechanism for GPU-Based IP Lookup Engine Using Threaded Segment Tree\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd","Association Rules in Web Usage Logfile Data - Empirical Insights into the Use of User-Generated Web Site FeaturesThis study focuses on the innovative and rapidly growing business model of social shopping communities (SSCs). In addition to traditional features, SSCs provide several user-generated social shopping features, such as recommendation lists, ratings, styles (e. g. user-generated assortments), tags, and user profiles. Using association rules, this study identifies structural relations that exist in user sessions of a SSC. Specifically, the analysis identifies which Web site features are used within these sessions to provide insights for both researchers and management, concerning the usability and revenue effects of these new features. The analysis draws on 2.91 million user sessions, revealing significant and interesting association rules between user-generated and direct shopping features.","On the Development of a Reference Framework for ICT for Manufacturing Skills ","On the Complex Nature of MDE EvolutionIn Model-Driven Engineering MDE the employed setting of languages as well as automated and manual activities has major impact on productivity. Furthermore, such settings for MDE evolve over time. However, currently only the evolution of modeling languages, tools, and transformations is studied in research. It is not clear whether these are the only relevant changes that characterize MDE evolution in practice. In this paper we address this lack of knowledge. We first discuss possible changes and then report on a first study that demonstrates that these forms of evolution can be commonly observed in practice. To investigate the complex nature of MDE evolution in more depth, we captured the evolution of three MDE settings from practice and derive eight observations concerning reasons for MDE evolution. Based on the observations we then identify open research challenge concerning MDE evolution.","A Study on the Naturalness of Gesture-Based Interaction for ChildrenThe emergence of new gesture-technologies that use bare-hands without any remote control or tools to hold is a good indicator that the technology is implementing naturalness in an input control system. However, the concept of naturalness that is commonly applied is interpreted from the adult user's perspective without realizing that the equally importance users of gesture-based technology are children. For this reason, this study was undertaken to describe the natural elements of gesture-based interaction in terms of how they influence the behavior of children using gesture-based technology devices, and to what extent the children benefit from their use. This includes the identification of issues and opportunities related to naturalness in using the latest gesture-based technologies, Kinect and iPad. Our observations show that the naturalness in gesture-control devices enabled children to reflect real world situations into the interaction, thus, aiding them to call back (recall and demonstrate) the gesture command easily and sparking positive feelings during the interaction. We conclude that understanding naturalness from a children's perspective can offer potential benefits to children in the utilization of gesture-based technologies.","The Role Of Uncertainty In Cloud Computing Continuance: Antecedents, Mitigators, And Consequences ","Volunteer website for the older adultThe need for volunteering has always been high, and the desire to volunteer has also been equally as significant especially for those who have retired or are nearing retirement. For those in the senior age group, volunteering is one way to give back to the community and to stay active. In this particular study, the ages of the participants ranged from 55 to 70. With this in mind, a prototype website for this particular age group was created that easily and efficiently found volunteer work around the area in which the individuals reside.","Mining Requirements Knowledge from Operational Experience ","Sparseness Controls the Receptive Field Characteristics of V4 Neurons: Generation of Curvature Selectivity in V4Physiological studies have reported that the intermediate-level visual area represents primitive shape by the selectivity to curvature and its direction. However, it has not been revealed that what coding scheme underlies the construction of the selectivity with complex characteristics. We propose that sparse representation is crucial for the construction so that a sole control of sparseness is capable of generating physiological characteristics. To test the proposal, we applied component analysis with sparseness constraint to activities of model neurons, and investigated whether the computed bases reproduce the characteristics of the selectivity. To evaluate the learned bases quantitatively, we computed the tuning properties of single bases and the population, as similar to the physiological reports. The basis functions reproduced the physiological characteristics when sparseness was medium (0.6-0.8). These results indicate that sparse representation is crucial for the curvature selectivity, and that a sole control of sparseness is capable of constructing the representation.","Proactive Supervisory Decision Support from Trend-Based Monitoring of Autonomous and Automated Systems: A Tale of Two Domains ","Energy Minimization via a Primal-Dual Algorithm for a Convex ProgramWe present an optimal primal-dual algorithm for the energy minimization preemptive open-shop problem in the speed-scaling setting. Our algorithm uses the approach of Devanur et al. [JACM 2008], by applying the primal-dual method in the setting of convex programs and KKT conditions. We prove that our algorithm converges and that it returns an optimal solution, but we were unable to prove that it converges in polynomial time. For this reason, we conducted a series of experiments showing that the number of iterations of our algorithm increases linearly with the number of jobs, n, when n is greater than the number of machines, m. We also compared the speed of our method with respect to the time spent by a commercial solver to directly solve the corresponding convex program. The computational results give evidence that for n\u2009&gt;\u2009m, our algorithm is clearly faster. However, for the special family of instances where n\u2009=\u2009m, our method is slower.","The importance of linked media to the future web: lime 2013 keynote talk -- a proposal for the linked media research agendaIf the future Web will be able to fully leverage the scale and quality of online media, a Web scale layer of structured, interlinked media annotations is needed, which we will call Linked Media, inspired by the Linked Data movement for making structured, interlinked descriptions of resources better available online. Mobile and tablet devices, as well as connected TVs, introduce novel application domains that will benefit from broad understanding and acceptance of Linked Media standards. In the keynote, I will provide an overview of current practices and specification efforts in the domain of video and Web content integration, drawing from the LinkedTV 1  and MediaMixer 2  projects. From this, I will present a vision for a Linked Media layer on the future Web will can empower new media-centric applications in a world of ubiquitous online multimedia.","Hybrid Metaheuristics for Medical Data Classification ","Empowering Electronic Divas through Beauty TechnologyThe evolution of Wearable Computers is making it possible for wear- ers to move and interact freely with the world with nearly invisible technology embedded into clothing. Our aim is to create technology that is not just in cloth- ing but on the skin surface as removable and hidden electronics. In this paper, we introduce the term 'Beauty technology' as an emerging field in Wearable Computing that hides electronic components within beauty products. This work outlines the technology used to hide electronic components in eyelashes, make- up, tattoos and nails, and it presents examples of the use of Beauty Technology in everyday beauty products.","Persuading consumers to reduce their consumption of electricity in the homePrevious work has identified that providing real time feedback or interventions to consumers can persuade consumers to change behaviour and reduce domestic electricity consumption. However, little work has investigated what exactly those feedback mechanisms should be. Most past work is based on an in-home display unit, possibly complemented by lower tariffs and delayed use of non-essential home appliances such as washing machines. In this paper we focus on four methods for real time feedback on domestic energy use, developed to gauge the impact on energy consumption in homes. Their feasibility had been tested using an experimental setup of 24 households collecting minute-by-minute electricity consumption data readings over a period of 18 months. Initial results are mixed, and point to the difficulties of sustaining a reduction in energy consumption, i.e. persuading consumers to change their behaviour. Some of the methods we used exploit small group social dynamics whereby people want to conform to social norms within groups they identify with. It may be that a variety of feedback mechanisms and interventions are needed in order to sustain user interest.","Automatic type inference for amortised heap-space analysisWe present a fully automatic, sound and modular heap-space analysis for object-oriented programs. In particular, we provide type inference for the system of refinement types RAJA, which checks upper bounds of heap-space usage based on amortised analysis. Until now, the refined RAJA types had to be manually specified. Our type inference increases the usability of the system, as no user-defined annotations are required.#R##N##R##N#The type inference consists of constraint generation and solving. First, we present a system for generating subtyping and arithmetic constraints based on the RAJA typing rules. Second, we reduce the subtyping constraints to inequalities over infinite trees, which can be solved using an algorithm that we have described in previous work. This paper also enriches the original type system by introducing polymorphic method types, enabling a modular analysis.","Collaborative Business Process Modeling On Interactive Tabletops ","Cardiac motion estimation by optimizing transmural homogeneity of the myofiber strain and its validation with multimodal sequences.Quantitative motion analysis from cardiac imaging is important to study the function of heart. Most of existing image-based motion estimation methods model the myocardium as an isotropically elastic continuum. We propose a novel anisotropic regularization method which enforces the transmural homogeneity of the strain along myofiber. The myofiber orientation in the end-diastolic frame is obtained by registering it with a diffusion tensor atlas. Our method is formulated in a diffeomorphic registration framework, and tested on multimodal cardiac image sequences of two subjects using 3D echocardiography and cine and tagged MRI. Results show that the estimated transformations in our method are more smooth and more accurate than those in isotropic regularization.","Towards a Federated Identity as a Service ModelIdentity management plays a key role in e-Government. Giving the increasing number of cloud applications, also in the field of e-Government, identity management is also vital in the area of cloud computing. Several cloud identity models have already emerged, whereas the so-called \"Identity as a Service\"-model seems to be the most promising one. Cloud service providers currently implement this model by relying on a central identity broker, acting as a hub between different service and identity providers. While the identity broker model has a couple of advantages, still some disadvantages can be identified. One major drawback of the central identity broker model is that both the user and the service provider must rely on one and the same identity broker for identification and authentication. This heavily decreases flexibility and hinders freedom of choice for selecting other identity broker implementations. We bypass this issue by proposing a federated identity as a service model, where identity brokers are interconnected. This federated identity as a service model retains the benefits but eliminates the drawbacks of the central cloud identity broker model.","Designing Urban Experience for Beijing in the Context of Smart City ","Database Similarity Join for Metric SpacesSimilarity Joins are recognized among the most useful data processing and analysis operations. They retrieve all data pairs whose distances are smaller than a predefined threshold e. While several standalone implementations have been proposed, very little work has addressed the implementation of Similarity Join as a physical database operator. In this paper, we focus on the study, design and implementation of a Similarity Join database operator for any dataset that lies in a metric space DBSimJoin. We describe the changes in each query engine module to implement DBSimJoin and provide details of our implementation in PostgreSQL. The extensive performance evaluation shows that DBSimJoin significantly outperforms alternative approaches.","Strategic Resilience Management Model: Complex Enterprise Systems Upgrade ImplementationManaging large and complex enterprise systems (ES) can be challenging due to the complexity of technical and other unforeseen issues. However, most of the existing scenarios are beyond typical safety margins and usually can have significant impacts on the operations and even survivability of the organization. We explore 'resilience management' as the mechanism and process that assists organizations to survive an unscheduled disruption or a major crisis. A strategic resilience management model is derived from extensive utilization of inductively-derived data from the case study. This strategic process model identifies the crucial phases of ES upgrade implementation, and also provides indications on how different strategies, mechanisms and capabilities of resilience management can inspire managers at different stages of the upgrade implementation for a fruitful strategic resilience management.","High-Performance network traffic processing systems using commodity hardwareThe Internet has opened new avenues for information accessing and sharing in a variety of media formats. Such popularity has resulted in an increase of the amount of resources consumed in backbone links, whose capacities have witnessed numerous upgrades to cope with the ever-increasing demand for bandwidth. Consequently, network traffic processing at today's data transmission rates is a very demanding task, which has been traditionally accomplished by means of specialized hardware tailored to specific tasks. However, such approaches lack either of flexibility or extensibility--or both. As an alternative, the research community has pointed to the utilization of commodity hardware, which may provide flexible and extensible cost-aware solutions, ergo entailing large reductions of the operational and capital expenditure investments. In this chapter, we provide a survey-like introduction to high-performance network traffic processing using commodity hardware. We present the required background to understand the different solutions proposed in the literature to achieve high-speed lossless packet capture, which are reviewed and compared.","\u03c9-Petri netsWe introduce \u03c9-Petri nets (\u03c9PN), an extension of plain Petri nets with \u03c9-labeled input and output arcs, that is well-suited to analyse parametric concurrent systems with dynamic thread creation. Most techniques (such as the Karp and Miller tree or the Rackoff technique) that have been proposed in the setting of plain Petri nets do not apply directly to \u03c9PN because \u03c9PN define transition systems that have infinite branching. This motivates a thorough analysis of the computational aspects of \u03c9PN. We show that an \u03c9PN can be turned into a plain Petri net that allows to recover the reachability set of the \u03c9PN, but that does not preserve termination. This yields complexity bounds for the reachability, (place) boundedness and coverability problems on \u03c9PN. We provide a practical algorithm to compute a coverability set of the \u03c9PN and to decide termination by adapting the classical Karp and Miller tree construction. We also adapt the Rackoff technique to \u03c9PN, to obtain the exact complexity of the termination problem. Finally, we consider the extension of \u03c9PN with reset and transfer arcs, and show how this extension impacts the decidability and complexity of the aforementioned problems.","Extensive--form games with heterogeneous populationsThe adoption of Nash equilibrium (NE) in real--world settings is often impractical due to its too restrictive assumptions. Game theory and artificial intelligence provide alternative solution concepts. When knowledge about opponents utilities and types is not available, the appropriate solution concept for extensive--form games is the self--confirming equilibrium (SCE), which relaxes NE allowing agents to have incorrect beliefs off the equilibrium path. In this paper, we extend SCEs to capture situations in which a two--agent extensive--form game is played by heterogeneous populations of individuals that repeatedly match (e.g., eBay).","Online Speaker Adaptation of an Acoustic Model Using Face Recognition ","An Improved Parallel Hybrid Seed Expansion (PHSE) Method for Detecting Highly Overlapping Communities in Social Networks ","Randomized Circle Detection Performance Based on Image Difficulty Levels and Edge Filters ","Supporting the continuum of care for combat wounded patients: adaptive interfaces for personal health recordsIn this paper, we describe a concept for an adaptive interface for a military Personal Health Record (PHR). PHRs are electronic records used by people to manage their personal healthcare information. In the Military Healthcare System, combat wounded patients encounter a range of challenges due to the unique nature of the military environment and the severity of their wartime injuries. These factors affect how people interact with a computer interface. In many instances, combat wounded patients eventually have assistance from family members, professional caregivers, and others. This forms a disparate end-user population. Because the pool of potential users includes people with a wide range of cognitive and physical capabilities, an adaptive interface that considers attributes of health can improve user experiences.","The legacy of a great researcherThis article presents examples of the monumental contributions of Bill McCune to mathematics, logic, computer science, and especially automated reasoning. The examples are presented in the form of short stories and recollections of the author during his long association with Bill. In addition to Bill's accomplishments as a researcher, the author provides personal memories giving glimpses into Bill's complex personality and his generosity as a collaborator.","Fast Causal Network Inference over Event StreamsThis paper addresses causal inference and modeling over event streams where data have high throughput and are unbounded. The availability of large amount of data along with the high data throughput present several new challenges related to causal modeling, such as the need for fast causal inference operations while ensuring consistent and valid results. There is no existing work specifically for such a streaming environment. We meet the challenges by introducing a time-centric causal inference strategy that leverages temporal precedence information to decrease the number of conditional independence tests required to establish the dependencies between the variables in a causal network. Dependency and temporal precedence of cause over effect are the two properties of a causal relationship. We also present the Temporal Network Inference algorithm to model the temporal precedence relations into a temporal network. Then, we propose the Fast Causal Network Inference algorithm for faster learning of causal network using the temporal network. Experiments using synthetic and real datasets demonstrate the efficacy of the proposed algorithms.","WGB: Towards a Universal Graph Benchmark ","Simplified OWL Ontology Editing for the Web: Is WebProt\u00e9g\u00e9 Enough?Ontology engineering is a task that is notorious for its difficulty. As the group that developed Protege, the most widely used ontology editor, we are keenly aware of how difficult the users perceive this task to be. In this paper, we present the new version of WebProtege that we designed with two main goals in mind: (1) create a tool that will be easy to use while still accounting for commonly used OWL constructs; (2) support collaboration and social interaction around distributed ontology editing as part of the core tool design. We designed this new version of the WebProtege user interface empirically, by analysing the use of OWL constructs in a large corpus of publicly available ontologies. Since the beta release of this new WebProtege interface in January 2013, our users from around the world have created and uploaded 519 ontologies on our server. In this paper, we describe the key features of the new tool and our empirical design approach. We evaluate language coverage in WebProtege by assessing how well it covers the OWL constructs that are present in ontologies that users have uploaded to WebProtege. We evaluate the usability of WebProtege through a usability survey. Our analysis validates our empirical design, suggests additional language constructors to explore, and demonstrates that an easy-to-use web-based tool that covers most of the frequently used OWL constructs is sufficient for many users to start editing their ontologies.","Photo forensics on shanzhai mobile phoneThere is an increasing number of crime cases involving mobile phones. In particular, due to the low cost of China shanzhai mobile phone (Chinese pirated mobile phone), a significant portion of these crime cases (all over the world) is related to these shanzhai phones. Quite a number of the cases also involve pictures. The difficulty of conducting forensic investigation on shanzhai phones is the lack of specifications. In this paper, we try to provide some important information of how a photo is stored inside a MTK-based shanzhai phone (one of the most popular platforms for shanzhai phones), and provide a method to recover deleted photos from the physical segments of flash memory of a shanzhai phone. abstract environment.","Analyzing Convergence and Reachability of Asynchronous IterationsAsynchronous iterations are computation schemes suitable for distributed systems with unpredictable delays and occasional loss of data in their communication links. This paper provides novel methods based on fixpoint computations to analyze convergence and reachability of them. They reduce memory usage to avoid the problem of state explosion by exploiting some assumptions on communication delays to eliminate message buffers and to decompose state space into elements.","Focus Group Evaluation of Scenarios for Fall Risk Assessment and Fall Prevention in Two CountriesInformation and communication technologies (ICT) provide means for developing new tools for preventing falls. To enhance adherence to fall prevention interventions, end users need to be engaged from the early phases of the development process. This paper reports the focus group evaluation of five scenarios related to fall risk assessment and fall prevention. There were four focus groups with older adults in both Finland and Spain; 58 participants in all. The most interesting features for the interviewees were usage of intelligent gym equipment, the possibility of peer support and multi-factorial fall risk assessment. The scenario with intelligent gym equipment rose above the others among Finnish participants, while the scenarios were ranked more evenly by Spanish correspondents. The analysis showed that a personal history of falls and a connection to current habits and routines affected the reception of the proposed solutions.","Performance Analysis of Edge Nodes with Multiple Path Routing ","Javanni: a verifier for javascriptJavaScript ranks among the most popular programming languages for the web, yet its highly dynamic type system and occasionally unintuitive semantics make programming particularly error-prone. This paper presents Javanni, a verifier for JavaScript programs that can statically detect many common programming errors. Javanni checks the absence of standard type-related errors (such as accessing undefined fields) without requiring user-written annotations, and it can also verify full functional-correctness specifications. Several experiments with JavaScript applications reported in the paper demonstrate that Javanni is flexibly usable on programs with non-trivial specifications. Javanni is available online within the CloudStudio web integrated environment.","Development of Semantic Knowledge and Its Role in the Development of Category-Based Reasoning ","Accelerating AES in JavaScript with WebGLCryptography is a fundamental building block for security sensitive Web applications. Because the architecture of JavaScript can not provide sufficient performance, the client-side web applications still lacks high performance cryptography primitives. In this paper we studied the feasibility of a new Web standard, i.e., the WebGL API for accelerating AES in JavaScript by exploiting the ability of GPU. We design and implemented AES using 128-bit key length. We compared the performance of our approach to the currently reported fastest pure JavaScript implementation and found our approach runs more than ten times faster in major browsers on all platform. Our work showed the potential optimization of using GPU via WebGL to accelerate JavaScript code.","Analysis of packet transmission processes in peer-to-peer networks by statistical inference methodsApplying advanced statistical techniques, we characterize the peculiarities of a locally observed peer population in a popular P2P overlay network. The latter is derived from a mesh-pull architecture. Using flow data collected at a single peer, we show how Pareto and Generalized Pareto models can be applied to classify the local behavior of the population feeding a peer. Our approach is illustrated both by file sharing data of a P2P session generated by a mobile BitTorrent client in a WiMAX testbed and by video data streamed to a stationary client in a SopCast session. These techniques can help us to cope with an efficient adaptation of P2P dissemination protocols to mobile environments.","An ETL framework for online analytical processing of linked open dataGrowing amount of data are being published online in machinereadable formats, and LOD (Linked Open Data) has emerged as a way to share such data across Web resources. Since LOD data often contain numerical data, such as statistics, there is a growing demand to make OLAP (Online Analytical Processing) analysis over such data. To make it possible to apply off-the-shelf OLAP systems for analyzing LOD data, we propose a framework to streamline the Extract, Transform, and Load (ETL) process from LOD to multidimensional data models for OLAP. Unlike other related approaches, our framework does not require RDF vocabularies dedicated for specifying multidimensional model for OLAP. Instead, given an LOD dataset, we exploit the relationships among entities and external information in the referenced LOD to generate an OLAP data model. In a case study, we demonstrate that our framework can extract OLAP data models from different kinds of real LOD datasets.","Modelling Human Gameplay at Pool and Countering It with an Anthropomorphic RobotInteraction between robotic systems and humans becomes increasingly important in industry, the private and the public sector. A robot which plays pool against a human opponent involves challenges most human robot interaction scenarios have in common: planning in a hybrid state space, numerous uncertainties and a human counterpart with a different visual perception system. In most situations it is important that the robot predicts human decisions to react appropriately. In the following, an approach to model and counter the behavior of human pool players is described. The resulting model allows to predict the stroke a human chooses to perform as well as the outcome of that stroke. This model is combined with a probabilistic search algorithm and implemented to an anthropomorphic robot. By means of this approach the robot is able to defeat a player with better manipulation skills. Furthermore it is outlined how this approach can be applied to other non-deterministic games or to tasks in a continuous state space.","Detection of Anomalous HTTP Requests Based on Advanced N-gram Model and Clustering Techniques ","The Development of Interactive Book Apps to Teach Young Children Mathematical Concepts ","Letters: Neural network based hybrid computing model for wind speed predictionThis paper proposes a Neural Network based hybrid computing model for wind speed prediction in renewable energy systems. Wind energy is one of the renewable energy sources which lower the cost of electricity production. Due to the fluctuation and nonlinearity of wind, the accurate wind speed prediction plays a major role in renewable energy systems. To increase the accuracy of wind speed prediction, a hybrid computing model is proposed. The proposed model is tested on real time wind data. The objective is to predict accurate wind speed based on proposed hybrid computing model which integrates Self Organizing feature Maps and Multilayer Perceptron network. The key advantages include higher accuracy, precision and minimal error. The results are computed by the training and testing methodologies. The experimental result shows that as compared to the conventional neural network models, the proposed hybrid model performs better in terms of minimization of errors.","Development of Car2X Communication and Localization PHY and MAC Protocol Following Iterative Spiral Model Using Simulation and Emulation ","Crowdsourcing backdoor identification for combinatorial optimizationWe will show how human computation insights can be key to identifying so-called backdoor variables in combinatorial optimization problems. Backdoor variables can be used to obtain dramatic speedups in combinatorial search. Our approach leverages the complementary strength of human input, based on a visual identification of problem structure, crowdsourcing, and the power of combinatorial solvers to exploit complex constraints. We describe our work in the context of the domain of materials discovery. The motivation for considering the materials discovery domain comes from the fact that new materials can provide solutions for key challenges in sustainability, e.g., in energy, new catalysts for more efficient fuel cell technology.","Rendering technology of 3d digital chinese ink-wash landscape paintings based on mayaThe work includes analyzing and simulating the techniques of traditional Chinese ink-wash landscape paintings, such as the ways of brush moving and ink painting, exploring the digital rendering modes with the characteristics of wrinkled-texture paintings. Besides realizing the simulation of traditional freehand ink-wash paintings by mixing the wrinkled-texture picture with the technique of modeling and rendering based on particle deposition and stacking. This study inherits and develops the traditional ink-wash painting's aesthetic theory and aesthetics, and has great significance and reference value of the change and development of the Chinese ink-wash landscape paintings.","Web Based Me-Centric Resource Management System for Pervasive EnvironmentThis paper presents a design and implementation of a web-based scalable me-centric resource management platform to support pervasive applications. The proposed system, LinkMe, builds me-centric overlay network, a private network of resources, for managing devices located in the user's situated environment, as permitted resources. A resource may be atomic or a set of fine-grained resources. By this resource hierarchy, pervasive applications can choose a variety of resources combinations based tasks situated in the physical environment. Using web, resources are identified by URI and can be manipulated using HTTP verbs. Pervasive application can access resources using a set of RESTful APIs. To reduce technical barrier, developers can choose proper resources using URI and build a pervasive application easily based on web technologies such as HTML5, CSS and JavaScript.","Recommender narrative visualizationGrowth and trends in recent data visualization research show that fact that after maturity of the tools allowing the end-user to explore through data, the next logical step is to focus on data analysis and presentation. The main criterion of setting up a presentation is to balance the relevancy level of data exposure and interaction within the story arc. Commonly, this is the author's role to write a single story and make it memorable and effective for the targeted audience. Considering the existing level of personal information that can be extracted from social networks, a unique opportunity is to get to know the audience before developing the story. Applying this theory in a system creates the possibility of crafting separate personalized visualization for each targeted individual. In this paper, we propose a foundation to a framework to generate the ultimate recommender story based on the given objectives and balanced level of detail in the visualization using the extracted user's information from social networks. This will be the next rational step towards enhancing the tools to assist the critical role of aiding decision making and education processes using visualization.","Consumer-Oriented Product Conceptualization via a Web-Based Data Mining Approach ","Behavioral Reasoning on Semantic Business Processes in a Rule-Based Framework ","Constrained Multi-objective Biogeography Optimization Algorithm for Robot Path Planning ","Graphic Language Model for Agglutinative Languages: Uyghur as Study CaseThis paper describes a novel, graphic language modeling strategy for morphologically rich agglutinative languages. Different from the linear structure in n-gram language models, graphic modeling or- ganizes the morphemes in a sentence, including stems and affixes, as a directed graph. The graphic language model is verified in two typical application scenarios, morphological analysis and machine translation. We take Uyghur for example, and experiments show that the graphic language model achieves significant improvement in both morphological analysis and machine translation.","Flexible Querying with Linguistic F-Cube FactoryIn this paper a new tool which allows flexible querying on multidimensional data bases is presented. Linguistic F-Cube Factory is based on the use of natural language when querying multidimensional data cubes to obtain linguistic results. Natural language is one of the best ways of presenting results to human users as it is their inherent way of communication. Data warehouses take advantage of the multidimensional data model in order to store big amounts of data that users can manage and query by means of OLAP operations. They are a context where the development of a linguistic querying tool is of special interest.","Using Hamiltonian Totems as Passwords.Physical authentication brings extra security to software authentication by adding real-world input to conventional authentication protocols. Existing solutions such as textual and graphical passwords are subject to brute force and shoulder sur fing attacks, while users are reluctant to use biometrics for identifi cation, due to its intrusiveness. This paper uses Hamiltonian tokens as authentication means. The proposed token structure offers many possible configurations ( i.e., passwords) and is small enough to be carried on a physical keychain. After presenting our general idea, we describe an e fficient algorithm to produce these tokens. Our procedure was validated by running a recognition campaign on a wide batch of synthetic samples, and experimented on prototypes manufactured using a commercial 3D-printer.","Extracting hybrid automata from control code ","A Model-Driven Approach for Web Service Adaptation Using Complex Event ProcessingWeb Services are often developed independently and fol- low different standards or approaches in constructing their interfaces. Therefore, it is likely that most Web Services will be incompatible since many services will not support the same interface. In order to solve it, a model-driven approach is defined in this paper to automatically gen- erate adapters between incompatible web service interfaces. In concrete, a graphical modeling editor is developed to detect such incompatibili- ties, create the adapters between the modeled interfaces and transform these adapters into code. This code will be deployed into a complex event processing engine, the software which will perform the web ser- vice adaptation. We illustrate this approach through a case study for two web services with incompatible interfaces. Results confirm that this approach provides a suitable solution for web service adaptation using complex event processing.","A Concise Review of the Answers to Fundamental Issues of Lexical SemanticsThere is relationship of inheritance and development between different schools of lexical semantics, which have their own emphases on dissimilar language phenomena and try to solve distinct problems of lexical semantics. The understanding of this relationship helps make explicit the drawbacks of existent study and future tendency, which is conducive to the development of natural language processing.","Service-Oriented Approach Supporting Dynamic Manufacturing Networks OperationsIn the current economic crisis, also the manufacturing sector is asked to evolve towards more dynamic organizational structures within which, composing manufacturing processes, almost in real time, will become a need. This work aims at introducing flexibility and dynamisms to current manufacturing processes by separating its tasks from its final performers. With the proposed approach, the performers' replacement can be done almost seamlessly. Additionally, the approach shows how dynamic negotiation and contracting, either for a whole process or a single activity, can be smoother if the task specification is based on a standard service interface defined at the ecosystem level. At the end, a prototype implementation is briefly described.","An Analysis of Social Interaction between Older and Children: Augmented Reality Integration in Table Game DesignDigital information products are already a part of children's everyday lives, but the majority of older are unfamiliar with these products, widening the generational gap and divide between these groups. To resolve this problem, this study used augmented reality (AR) technology to construct a \"barrier-free\" digital environment for older. AR integrated game design was used to increase older' exposure to digital information and promote social interaction between children and older, thus reducing intergenerational separation. Consequently, it was possible to ascertain the usability of the table game design, as well as to pinpoint the subjective experiences and differences between the two groups.","Design of a New OFTM Algorithm towards Abort-Free Execution ","Polynomial Time Optimal Query Algorithms for Finding Graphs with Arbitrary Real WeightsWe consider the problem of nding the edges of a hidden weighted graph and their weights by using a certain type of queries as few times as possible, with focusing on two types of queries with additive property. For a set of vertices, the additive query asks the sum of weights of the edges with both ends in the set. For a pair of disjoint sets of vertices, the cross-additive query asks the sum of weights of the edges crossing between the two sets. These queries are related to DNA sequencing and nding Fourier coecients of pseudo-Boolean functions, and have been paid attention to in computational learning. In this paper, we achieve an ultimate goal of recent years for graph nding, by constructing the rst polynomial time algorithms with optimal query complexity for the general class of graphs with n vertices and at most m edges in which the weights of edges are arbitrary real numbers. The algorithms are randomized and their query complexities areO mlog n log m which improve the best known bounds by a factor of logm. To build a key component for graph nding, we consider coin weighing with a spring scale which itself has been paid attention to in a long history of combinatorial search. We construct the rst polynomial time algorithm with optimal query complexity for the general case in which the weight dierences between counterfeit and authentic coins are arbitrary real numbers. We also construct the rst polynomial time optimal query algorithm for nding Fourier coecients of a certain class of pseudo-Boolean functions.","The small-world phenomenon applied to a self-adaptive resources selection modelSmall-world property is found in a wide range of natural, biological, social or transport networks. The main idea of this phenomenon is that seemingly distant nodes actually have very short path lengths due to the presence of a small number of shortcut edges running between clusters of nodes. In the present work, we apply this principle for solving the resources selection problem in grid computing environments (distributed systems composed by heterogeneous and geographically dispersed resources). The proposed model expects to find the most efficient resources for a particular grid application in a short number of steps. It also provides a self-adaptive ability for dealing with environmental changes. Finally, this selection model is tested in a real grid infrastructure. From the results obtained it is concluded that both a reduction in execution time and an increase in the successfully completed tasks rate are achieved.","Intercultural design for use: extending usage-centered design by cultural aspectsIn this paper the Usage-Centered Design approach is suggested as structured process for Intercultural HCI Design. Usage-Centered Design is extended by cultural models to take into account the cultural aspects in HCI design. The extensions cover as well common cultural aspects as system specific cultural aspects of the system to be designed. This approach makes it possible to track and trace the culture specific requirements and design decisions for internationalized user interfaces.","A Fuzzy Rough Set Approach for Incrementally Updating Approximations in Hybrid Information SystemsIn real-applications, there may exist missing data and many kinds of data e.g., categorical, real-valued and set-valued data in an information system which is called as a Hybrid Information System HIS. A new Hybrid Distance HD between two objects in HIS is developed based on the value difference metric. Then, a novel fuzzy rough set is constructed by using the HD distance and the Gaussian kernel. In addition, the information systems often vary with time. How to use the previous knowledge to update approximations in fuzzy rough sets is a key step for its applications on hybrid data. The fuzzy information granulation methods based on the HD distance are proposed. Furthermore, the principles of updating approximations in HIS under the variation of the attribute set are discussed. A fuzzy rough set approach for incrementally updating approximations is then presented. Some examples are employed to illustrate the proposed methods.","Performance of different techniques applied in genetic algorithm towards benchmark functionsOptimisation is the most interesting problems to be tested by using Artificial Intelligence (AI) methods because different optimal results will be obtained when different methods are implemented. Yet, there is no exact solution from the methods implemented because random function is usually applied. Genetic algorithm is a popular method which is used to solve the optimisation problems. However, no any methods can execute perfectly because the way of the method performs is different. Therefore, this paper proposed to compare the performance of GA with different operation techniques by using the benchmark functions. This can prove that different techniques applied in the operations can let GA produces different result. Based on the experiment result, GA is proved to perform well in the optimisation problems but it highly depends on the techniques implemented. The techniques for each operation have shown different performance in obtaining the time, minimum and average values for benchmark functions.","Goal-Oriented Security Requirements Analysis for a System Used in Several Different ActivitiesBecause an information system is used in different activities simul- taneously today, we have to analyze usages of the system in the existing activi- ties and to-be usages in an intended activity together. Especially, security aspects should be carefully analyzed because existing activities are not always secure. We propose a security requirements analysis method for resolving this problem. To take both existing and intended activities into account together, we integrate them on the basis of the unification of common actors. To explore possible at- tacks under integrated activities, we enumerate achievable attacks on the basis of the possible means in each actor with the help of security knowledge. To avoid or mitigate the attacks and to achieve fundamental goals, we disable some means or narrow down the means to be monitored with the help of propositional logic formulae. Through case studies on insurance business, we illustrated our idea. When an information system is intended to be introduced into some activity such as business or amusements, we have to analyze the activity and define what kinds of func- tionalities and qualities including security needs are required for the system. In many cases, such a system or a part of it has already used in other activities. For example, we are using PC's, Web browsers, emails, social network services (SNS) and free software for our daily activities. Some business person cannot perform his/her business without own smart phones, and he/she also uses SNS for fun via the smart phones. We thus have to take such existing activities into account when an information system is intended to be introduced into an activity. Especially, we have to take them into account carefully for analyzing security requirements because not all existing activities are secure. In this paper, we propose a method for analyzing security requirements for an infor- mation system used in several different activities. When actors and their dependencies in each activity are specified, we can clarify the common parts among different activ- ities. Through such common parts, good or bad impacts are conveyed. We thus use i* notation (1,2) for specifying each activity. In i*, the needs of actors are represented as goals. Although some goals are fundamental for some actor and others are just subcon- tracts, there is no explicit distinction between fundamental goals and others in i*. We","Multi-level Linguistic Knowledge Based Chinese Grapheme-to-Phoneme ConversionThis paper proposes a novel method integrating multi-level linguistic knowledge for Chinese grapheme-to-phoneme(G2P) conversion. Pronunciation prediction of non-standard words(NSWs) and disambigua- tion of polyphonic characters are two important issues in Chinese grapheme-to-phoneme conversion. Considering effect of linguistic knowl- edge, multi-level linguistic cues, including word form, Part-of-Speech (POS), named entity, collocation and syntactic structure, are extracted under a unified syntactic parsing framework and integrated by maxi- mum entropy approach to disambiguate polyphonic characters. Besides, the text normalization is incorporated in this framework to help predict pronunciation of non-standard words. Experiment results show that the proposed method can improve the performance from 95.64% to 99.23%.","Designing Visual Exemplars of 3D Online Store Layout TypesThis paper presents the design issues in the visualization of five distinct store layout types in the context of 3D online retailing and discusses appropriate design decisions. The development of the stores is based on the requirements (layout characteristics) elicited from a three-round Delphi method with 3D expert users and designers which served as the qualitative empirical research vehicle. Along with the visualization of the characteristics of each layout type, the theoretical and practical implications, limitations, and the future research avenues of the study are discussed.","Exploring the Relationships between Design, Students\u2019 Affective States, and Disengaged Behaviors within an ITS ","Exploring the Relationship Between Drug Side-Effects and Therapeutic IndicationsTherapeutic indications and drug side-effects are both measureable human behavioral or physiological changes in response to the treatment. In modern drug development, both inferring potential therapeutic indications and identifying clinically important drug side-effects are challenging tasks. Previous studies have utilized either chemical structures or protein targets to predict indications and side-effects. In this study, we compared indication prediction using side-effect information and side-effect prediction using indication information against models using only chemical structures and protein targets. Experimental results based on 10-fold cross-validation, show that drug side-effects and therapeutic indications are the most predictive features for each other. In addition, we extracted 6,706 statistically highly correlated disease-side-effect pairs from all known drug-disease and drug-side-effect relationships. Many relationship pairs provide explicit repositioning hypotheses (e.g., drugs causing postural hypotension are potential candidates for hypertension) and clear adverse-reaction watch lists (e.g., drugs for heart failure possibly cause impotence). All data sets and highly correlated disease-side-effect relationships are available at http://astro.temple.edu/~tua87106/druganalysis.html.","Orthogonal Nonnegative Matrix Factorization for Blind Image SeparationThis paper describes an application of orthogonal nonnegative matrix factorization (NMF) algorithm in blind image separation (BIS) problem. The algorithm itself has been presented in our previous work as an attempt to provide a simple and convergent algorithm for orthogonal NMF, a type of NMF proposed to improve clustering capability of the standard NMF. When we changed the application domain of the algorithm to the BIS problem, surprisingly good results were obtained; the reconstructed images were more similar to the original ones and pleasant to view compared to the results produced by other NMF algorithms. Good results were also obtained when another dataset that consists of unrelated images was used. This practical use along with its convergence guarantee and implementation simplicity demonstrate the benefits of our algorithm.","Complete Pose Binary SIFT for Face Recognition with Pose Variation ","Three-Dimensional Reconstruction and Characteristics Computation of Corn Ears Based on Machine Vision ","Distributed and Incremental Visual Object Categorization for Humanoid Platform NAORobotics is an essential component of current and future technological existence of mankind. Interaction between human and technology such as robots and their coexistence with humans will be extremely important. In fact, a fully embodied intelligence is one version of the future but another option is distributed intelligence when a part of intelligence is \"somewhere in the Cloud\", and the second part is on the robot itself. Certainly there are several questions about connectivity and reduced activity in case of off-line robot life comparing to life in on-line robot existence. Meanwhile, a notion of Cloud Robotics came out, and it brings new challenges and endless possibilities for the future. The paper gives theoretical and experimental research about utilization of selected Neural technology specifically modified MF-ARTMAP neural network for object categorization. We used the categorization test-bed a Humanoid platform NAO connected to Global framework (MASS), which categorize in distributive and incremental approach objects. This approach creates a power of sharing knowledge among other robots and building collective intelligence. Papers gives the results of a pilot study and refers about preliminary results on different experimental data with building a database of objects on off-robot ecosystem. The system also works with fuzzy logic relations among objects and maintain a list of statements about the relationship between objects seen by the robot.","The vehicle relocation problem in car sharing systems: modeling and simulation in a petri net frameworkThe paper proposes an user-based solution for the vehicle relocation problem in car sharing systems. In particular, the impact of a mechanism of economic incentives based on a real time monitoring of vehicles distribution among the parking areas is assessed. We consider three different operative conditions that are described by the Unified Modeling Language and modeled in a Timed Petri Net (TPN) framework. In order to show and compare the effectiveness of the adopted management strategies, the real case study of an electric-car sharing system is evaluated and simulated in the TPN environment. The results underline how the proposed solution leads to an improvement of the overall system performances, by highlighting at the same time the limits of such a strategy.","User-Generated Content for Image Clustering and Marketing PurposesThe analysis of images for different purposes \u2013 particularly image clustering \u2013 has been the subject of several research streams in the past. Since the 90s query by image content and, somewhat later, content-based image retrieval have been topics of growing scientific interest. A literature review shows that research on image analysis, so far, is primarily related to computer science. However, since the advent of Flickr and other media-sharing platforms there is an ever growing data base of images which reflects individual preferences regarding activities or interests. Hence, these data are promising to observe implicit preferences and complement classical efforts for several marketing purposes (see, e.g., van House 2009 or Baier and Daniel 2011). Against this background, the present paper investigates options for clustering images on the basis of personal image preferences, e.g. to use results for marketing purposes.","Reliability Analysis of Discrete Transportation Systems Using Critical States ","On the Extended Clinical Workflows for Personalized HealthcareThere are many cases in the clinical practice where using personalized medical products could decrease the cost of treatment and risk of possible complications. However, due to the large costs and long manufacturing lead time, the medical products are customized to the individual patient\u2019s needs only in a few critical treatments. One of the main cost factors of the collaboration between the clinical centres and custom medical product suppliers is uptake of human effort in exchange of knowledge between two domains and corresponding issues. In this paper, we use the concepts of the networked enterprises to define the extended clinical workflow which spans the medical and manufacturing practice. We identify the associated systems infrastructure of this workflow and related interoperability issues. The extended workflow is demonstrated on the case study for custom orthopedic implants manufacturing.","Future Locations Prediction with Uncertain DataThe ability to predict future movements for moving objects enables better decisions in terms of time, cost, and impact on the environment. Unfortunately, future location prediction is a challenging task. Existing works exploit techniques to predict a trip destination, but they are effective only when location data are precise (e.g., GPS data) and movements are observed over long periods of time (e.g., weeks).#R##N##R##N#We introduce a data mining approach based on a Hidden Markov Model (HMM) that overcomes these limits and improves existing results in terms of precision of the prediction, for both the route (i.e., trajectory) and the final destination. The model is resistant to uncertain location data, as it works with data collected by using cell-towers to localize the users instead of GPS devices, and reaches good prediction results in shorter times (days instead of weeks in a representative real-world application). Finally, we introduce an enhanced version of the model that is orders of magnitude faster than the standard HMM implementation.","Construction of Injective Mappings Of MeshesThis paper introduces three sets of sufficient conditions, for generating injective simplicial mappings of manifold meshes. A necessary condition for a simplicial mapping of a mesh to be injective is that it consistently preserves or inverts the orientations of all elements. However, these conditions are insufficient to guarantee injectivity. In this paper we provide additional simple conditions that, together with the above mentioned necessary conditions guarantee injectivity of the simplicial map. The first set of conditions generalizes classical global inversion theorems to the mesh (piecewise-linear) case. That is, proves that in case the boundary simplicial map is bijective and the necessary condition holds the map is a bijection. The second set of conditions is concerned with mapping of a mesh to a polytope and replaces the (often hard) requirement of a bijective boundary map with a collection of linear constraints that guarantees that the resulting map is injective over the interior of the mesh. These linear conditions provide a practical tool for optimizing an injective map of the mesh while allowing the boundary map to adjust freely. Allowing more freedom in the boundary conditions is useful for two reasons: a) it circumvents the hard task of providing a bijective boundary map, and b) it allows optimizing the boundary map together with the simplicial map to achieve lower energy levels. The third set of conditions adds to the second set the requirement that the boundary maps are orientation preserving as-well. This set of conditions guarantees that the map is injective on the boundary of the mesh as-well as its interior. Several experiments using the sufficient conditions are shown for mapping triangular meshes injectively. A secondary goal of this paper is to advocate and develop the tool of degree in the context of geometry processing and modeling of meshes.","Automated Extraction of the Barthel Index from Clinical TextsThis paper describes a text mining program that computes the Barthel score of functional status by analyzing clinical notes stored in Electronic Health Record systems(EHR) and comparing them to textual evidence provided by clinical experts. The program demonstrates high accuracy and overall reliability based on a relatively small number of expert-abstracted charts. It offers an efficient and affordable method for estimating functional status using clinical notes. An important feature is an architecture that facilitates interaction between users and the program, allowing the program to improve its performance based on user feedback .","Scalable LCF-Style proof translationAll existing translations between proof assistants have been notoriously sluggy, resource-demanding, and do not scale to large developments, which has lead to the general perception that the whole approach is probably not practical. We aim to show that the observed inefficiencies are not inherent, but merely a deficiency of the existing implementations. We do so by providing a new implementation of a theory import from HOL Light to Isabelle/HOL, which achieves decent performance and scalability mostly by avoiding the mistakes of the past. After some preprocessing, our tool can import large HOL Light developments faster than HOL Light processes them. Our main target and motivation is the Flyspeck development, which can be imported in a few hours on commodity hardware. We also provide mappings for most basic types present in the developments including lists, integers and real numbers. This papers outlines some design considerations and presents a few of our extensive measurements, which reveal interesting insights in the low-level structure of larger proof developments.","Everlasting Multi-party ComputationA protocol has everlasting security if it is secure against ad- versaries that are computationally unlimited after the protocol execution. This models the fact that we cannot predict which cryptographic schemes will be broken, say, several decades after the protocol execution. In clas- sical cryptography, everlasting security is difficult to achieve: even using trusted setup like common reference strings or signature cards, many tasks such as secure communication and oblivious transfer cannot be achieved with everlasting security. An analogous result in the quantum setting excludes protocols based on common reference strings, but not protocols using a signature card. We define a variant of the Universal Composability framework, everlasting quantum-UC, and show that in this model, we can implement secure communication and general multi- party computation using signature cards as trusted setup.","Towards a Human Consistent Analysis of Innovativeness via Linguistic Data Summaries and Their Protoforms ","Enterprise App Stores for Mobile Applications - Development of a Benefits Framework. ","Privacy-Preserving Publish/Subscribe: Efficient Protocols in a Distributed ModelWe consider the problem of modeling and designing efficient and privacy-preserving publish/subscribe protocols in a distributed model where parties can act as publishers or subscribers or both, and there are no brokers or other types of parties. The problem is particularly challenging as privacy demands on such protocols come with efficiency limitations; most notably, the publisher must send messages as long as the publications to all parties, and the cryptographic techniques to perform the publish/subscribe match need to be based on asymmetric cryptographic operation which are known to be less efficient than their symmetric counterpart.#R##N##R##N#Our main result is a distributed publish/subscribe protocol which addresses and essentially nullifies the impact of both efficiency limitations, without sacrificing the required privacy properties. Our construction is based on very efficient design of a novel cryptographic tool, of independent interest, called 'hybrid conditional oblivious transfer protocol', as it resembles hybrid encryption, where asymmetric encryption is only used to transfer a short key, which enables (much more efficient) symmetric encryption of a long message.","A small-sized underactuated biologically inspired aquatic robotThis extended abstract introduces the biologically inspired swimming robot URMELE light. The robot embodies the strategy of massive under-actuation. Propulsion is generated using a central module with one single actuator and coupled passive, compliant tail modules. Therewith this robot differs from other modular swimming robots like e.g. AmphiBot [3] or ACM-R5 [6] which feature motor-gear combinations in each module without defined in- and inter-module compliance. It also differs from fish-like robots like e.g. MT1, a robot which generates propulsion by a single drive and a \"C-bending\" tail structure [8] due to the explicit use of spring elements for locomotion.#R##N##R##N#The swimming behavior of URMELE light is changeable: we aim at a shift between as well anguilliform as thunniform swimming modes due to tunable compliant elements. Therewith URMELE light could be used as reproducibly displaceable experimental platform for investigation of swimming abilities of fishes, e.g. energy efficiency of different swimming modes. Aside it may serve as a mobile sensing unit for control of water quality (e.g. detection and tracking of oil or chemicals) with minimized environmental disturbances. Currently URMELE light performs a thunniform swimming mode.","From search session detection to search mission detectionSearch mission detection aims at identifying those queries a user submits for the same information need. Such knowledge offers interesting insights into behavioral usage patterns and often can help to better support a user. However, most existing query log studies focus on search sessions only (consecutive queries for the same need) and ignore multitasking behavior (interleaved information needs) as well as hierarchies of short-term search goals in multiple sessions that form a long-term search task such as vacation planning. To better understand the dialog between user and search engine we distinguish between (1) physical search sessions, characterized by the time gap between queries, (2) logical search sessions, characterized by consecutive queries for the same information need within a physical session, and (3) search missions, characterized by logical sessions, multitasking behavior, and hierarchical goals.#R##N##R##N#Our contributions are threefold. First, we present a new algorithm for logical session detection, which follows the state-of-the-art cascading method's rationale of combining effectiveness with efficiency. Our approach is applicable within the time-critical online scenario, where a search engine tries to support users by incorporating knowledge about their search history on the fly, as well as within the offline scenario, where the objective is to accurately partition a collected log. We improve several steps of the cascading method, among others by exploiting Linked Open Data information. Second, we demonstrate our new algorithm's applicability to accurately detect search missions. Third, we introduce a new publicly available corpus of 8800 queries labeled with session and mission information.","Automatic Detection and Characterization of Acoustic Plane-Wave Reflections Using Circular Microphone ArraysThe spatial characteristics of the sound field inside a room can be meaningfully described by means of microphone array process- ing techniques. In this context, the set of impulse responses sampled by a microphone array can be seen as an image made of acoustic plane- wave footprints. Due to the circular geometry of the microphone array, these footprints have ac osine-like shape that can be fully described as a function of the direction of arrival (DOA) of the impinging plane wave. This paper proposes a Hough-transform-based approach to plane-wave detection in microphone array multi-trace impulse responses. Experi- ments using a set of real microphone recordings are described, showing the potential of well-known image-processing techniques in sound field analysis.","Eye Location and Eye State Detection in Facial Images Using Circular Hough Transform ","Framework for quantitatively evaluating the quality requirements of software systemQuality requirements (QR) are a description which indicates how well the software's behavior is to be executed. It is widely recognized that quality requirements are vital for the success of software systems. Therefore, to define the quality requirements and to check the quality attributes carefully is necessary for bringing good- quality software and ensuring quality of the service. This paper proposes a framework that measures the quality attributes in the requirements document such as SRS. The effectiveness of this framework was briefly described, we discuss approach was to enrich the representative quality corpora.","Puzzled: Coin flippingEach of these puzzles involves coin flipping. Simple stuff, right? Not necessarily\u2026though solutions will indeed be provided in next month's column.","A Generalized Software Reliability Model Considering Uncertainty and Dynamics in Development ","Knot segmentation in noisy 3d images of woodResolving a 3D segmentation problem is a common challenge in the domain of digital medical imaging. In this work, we focus on another original application domain: the 3D images of wood stem. At first sight, the nature of wood image looks easier to segment than classical medical image. However, the presence in the wood of a wet area called sapwood remains an actual challenge to perform an efficient segmentation. This paper introduces a first general solution to perform knot segmentation on wood with sapwood. The main idea of this work is to exploit the simple geometric properties of wood through an original combination of discrete connected component extractions, 2D contour detection and dominant point detection. The final segmentation algorithm is very fast and allows to extract several geometrical knot features.","Provably secure and subliminal-free variant of schnorr signatureSubliminal channels present a severe challenge to information security. Currently, subliminal channels still exist in Schnorr signature. In this paper, we propose a subliminal-free variant of Schnorr signature. In the proposed scheme, an honest-but-curious warden is introduced to help the signer to generate a signature on a given message, but it is disallowed to sign messages independently. Hence, the signing rights of the signer is guaranteed. In particular, our scheme can completely close the subliminal channels existing in the random session keys of Schnorr signature scheme under the intractability assumption of the discrete logarithm problem. Also, the proposed scheme is proved to be existentially unforgeable under the computational Diffie-Hellman assumption in the random oracle model.","Understanding Software-as-a-Service Performance - A Dynamic Capability Perspective. ","Teaching Low-Functioning Autistic Children: ABCD SWApplied Behavior Analysis ABA is highly effective for teaching subjects with autism. We discuss the design and development of a free open-source customizable software to support ABA intervention in low-functioning children with autism. The software automates the trial setting while enabling the gathering of the children's performance data to monitor learning. The software relies on a Web architecture: using a laptop, the tutor defines the exercises dynamically activated on the child's tablet. Synchronization between these two devices occurs via an Internet connection, obtaining and inserting data through the database. A real-time summary of the actions performed by the child is available on the tutor's device, simplifying decisions about the intervention. In order to make the trial accessible to any child, the software adapts the visual prompt to the child's abilities, i.e., receptive/verbal, using labels in addition to images. A pilot test with several children confirmed the usability of the software.","Gravitational Search Algorithm Design of Posicast PID Control Systems ","Application of an Exact Transversal Hypergraph in Selection of SM-ComponentsThe paper deals with the application of the hypergraph theory in selection of State Machine Components (SM-Components) of Petri nets (1,2).As it is known, Petri nets are widely used for modeling of concurrency processes. However, in order to implement the concurrent automaton, an initial Petri net ought to be decomposed into sequential automata (SM-Components), which can be easily designed as an Finite-State-Machine (FSM) or Microprogrammed Controller (3). The last step of the decomposition process of the Petri nets is selection of SM-Components. This stage is especially important because it determines the final number of sequential automata. In the article we propose a new idea of SM-Components selection. The aim of the method is reduction of the computational complexity from exponential to polynomial. Such a reduction can be done if the selection hypergraph belongs to the exact transversal hypergraphs (xt-hypergraphs) class. Since the recognition and generation of the first transversal in the xt-hypergraphs are both polynomial, the complete selection process can be performed in polynomial time. The proposed ideas are an extension of the concept presented in (1). The proposed method has been verified experimentally. The conducted investigations have shown that for more than 85% of examined Petri nets the selection process can be done via xt-hypergraphs.","Forecasting method of stock price based on polynomial smooth twin support vector regressionThe stock price prediction has become an important research topic in Economics. However, the traditional forecasting methods only can be used in linear system, whose prediction accuracy is not satisfactory. In this paper, a new forecasting method of stock price based on polynomial smooth twin support vector regression is proposed. In the proposed method, we firstly construct the polynomial smooth twin support vector regression (PSTSVR) model and prove its global convergence. Then PSTSVR is used as the opening price of stock prediction model. The experimental results on the stock data from the great wisdom stock software show that the proposed method can obtain the better regression performance compared with SVR and twin support vector regression (TSVR).","Comparative Study between Tank\u2019s Water Level Control Using PID and Fuzzy Logic Controller ","Video Key Frame Extraction through Canonical Correlation Analysis and Graph ModularityKey frame based video summarization has emerged as an important area of multimedia research in recent times. In this paper, we propose a novel automated approach for video key frame extraction in compressed domain using canonical correlation analysis (CCA) and graph modularity. We prune certain edges from the Video Similarity Graph (VSG) using an iterative strategy until there is no improvement in graph modularity. Resulting connected components in the final VSG correspond to separate clusters. The proposed algorithm also uses multi- feature fusion using canonical correlation analysis to achieve higher se- mantic dependency between different video frames. Experimental results on some standard videos of different genre clearly indicate the superiority of the proposed method in terms of theF1 measure.","Time, Trust and Normative Change. On Certain Sources of Complexity in Judicial Decision-MakingThe aim of this paper is to outline a structure of legal knowledge that is involved in resolution of complex legal cases comprising intertemporal issues and constitutional problems. Although the topics of dynamics of legal systems are already well-elaborated in the AI and Law literature, the problem of constitutional admissibility of certain types of changes to the legal systems remains an underexplored issue. The model developed in this paper is designed to fill in this gap. The meta-information concerning admissibility of certain changes to legal systems with regard to relevant constitutional principles should become a standard element of any well-developed database of statutory legal knowledge.","Discovery and analysis of evolving topical social discussions on unstructured microblogsSocial networks have emerged as hubs of user generated content. Online social conversations can be used to retrieve users interests towards given topics and trends. Microblogging platforms like Twitter are primary examples of social networks with significant volumes of topical message exchanges between users. However, unlike traditional online discussion forums, blogs and social networking sites, explicit discussion threads are absent from microblogging networks like Twitter. This inherent absence of any conversation framework makes it challenging to distinguish conversations from mere topical interests. In this work, we explore semantic, social and temporal relationships of topical clusters formed in Twitter to identify conversations. We devise an algorithm comprising of a sequence of steps such as text clustering, topical similarity detection using TF-IDF and Wordnet, and intersecting social, semantic and temporal graphs to discover social conversations around topics. We further qualitatively show the presence of social localization of discussion threads. Our results suggest that discussion threads evolve significantly over social networks on Twitter. Our algorithm to find social discussion threads can be used for settings such as social information spreading applications and information diffusion analyses on microblog networks.","A conceptualisation of management situations relevant for collaborative IS research projects ","Designing Scalable Informal Learning Solutions with Personas: A Pilot Study in the Healthcare SectorDriven by ever shorter cycles of innovation, organizations and individuals nowadays have to acquire, understand and apply new knowledge in shorter periods of time [1]. Much of this rapid learning appears to be achieved by workers learning on the job and from colleagues --- informal learning rather than learning from traditional, curriculum-based training [2]. Mobile technology could potentially provide support to this informal learning as it can provide scalable and flexible learning tools that can be used at any time across a variety of locations: at home, on different work sites, during travel [3]. However, designing learning technology that can support such unstructured, creative and expertise-driven informal learning is challenging, especially as there are likely to be great variations across employees in terms of their perceptions, experiences and expectations regarding technology [4]. These expectations and experiences may also differ from those of the developers and designers. Yet it is the match between user requirements and functionalities that lies at the heart of a successful learning technology. In Learning Layers we are exploring how creating and using Personas may help to design scalable technology for supporting informal learning in healthcare.","Context Awareness for Self-adaptive and Highly Available Production SystemsA new approach for the realization of self-adaptive and highly available production systems based on a context aware approach, allowing self-adaptation of flexible manufacturing processes in production systems and effective knowledge sharing to support maintenance, is presented. The usage of dynamically changing context as basis for adaptation of flexible manufacturing lines/processes and effective knowledge sharing is proposed. The presented solution includes services for context extraction, adaptation and self-learning allowing high adaptation of production systems depending on the identified context. A generic architecture following Service Oriented Principles is presented allowing for integration of the proposed solution into various production systems. A successful initial application of the developed solution in real world manufacturing environment is presented.","Towards Developing an Integrated Quality Map Production Environment in Commercial Cartography ","A Novel Mobility Model for Mobile Ad Hoc NetworksIn this paper, we investigate mobility models in mobile ad hoc networks (MANETs) and propose a novel mobility model for mobile ad hoc nodes with intelligence. The proposed model named Attracting Group Mobility (AGM) Model means mobile node moving from one attracting point to another. Compared to the traditional mobility models, the proposed model has intelligent property. Once a reference point is full, mobile nodes can't enter even they are attracted and the mobile nodes already in the reference point may leave it with a probability. Besides, mobile nodes have inertia that moving speed and direction have only a small variation. Moreover, inhomogeneity is discussed in this paper. Simulation results show that the proposed mobility model can also be a method of generating inhomogeneity distribution.","Empowering People through Mobile Devices for Smarter PlacesIncrease in traffic volumes in urbanized areas of the world has caused a rise in congestion with negative consequences on safety, environment and quality of life of citizens. Only in Europe the cost of traffic congestion is 1% of the GDP, and this does not take into account the cost in terms of deaths caused by road network saturation. On top of this 30% of energy consumed by our population goes into public or private transport system. More than 55000Km of roads and railroads are monitored by webcams or vehicle counters. Some technologies to assess road network state and improve safety and quality of life of travelers already exists but many are limited to small networks or a particular public transport operator. Smart use and harmonization of available data on top of other real-time data acquisition methods can provide a better service to European citizens. Smart use of public transport possibilities can have a huge positive impact on traveling speed, quality and safety. In the last years availability of public transport real time data and the spread of smart mobile devices, allowed us to develop pervasive travel assistant applications for mobile phones. The project presented in this paper, i-Tour, shows how an IT solution for mobile phones can have sensible impact on personal mobility quality by promoting the use of mixed public-private transport. The application takes into account user preferences as well as real-time information on road conditions, weather and public transport network status. I-Tour also promotes a new approach to data collection based on a recommender system where the information provided by the whole user community enriches the trusted-knowledge common database with local up-to-date knowledge consisting of point of interest and real-time road network information. The client can adapt to user preferences to better meet user needs, young users may prefer using bikes or just walking while adults may prefer taking the car or public transports. At the same time some users need to always use the fastest mean of transport while other may prefer a more eco-friendly choice. Innovative user-friendly interfaces have been developed to create new interface metaphors; when a user search for a travel solution a set of possible routes will be given to the user on a graph showing not only each path but also the different meaning of transport, the quality of service, traffic conditions and waiting times of each route. The software also is potentially profitable since many areas of the client are adaptable to integrate ads or provide visibility to sponsored locations or commercial point of interests. The client provides 3 types of map visualization system, top-down 2D Map, full 3D map, and Augmented Reality visualization. To seamlessly switch between different visualization methods an innovative system based on device orientation has been ideated. When the user keeps the device horizontal the client set the visualization to 2D map, when the device is kept vertical the device switch to augmented reality view; in between the map shows full 3D terrain visualization. Questionnaires responses shown that many solutions adopted were well appreciated by the users.","OMPT: An OpenMP Tools Application Programming Interface for Performance Analysis ","Evolutionary Computation Applied to the Automatic Design of Artificial Neural Networks and Associative Memories ","Copyright Infringement Detection of Music Videos on YouTube by Mining Video and Uploader Meta-dataYouTube is one of the largest video sharing website on the Internet. Several music and record companies, artists and bands have official channels on YouTube (part of the music ecosystem of YouTube) to promote and monetize their music videos. YouTube consists of huge amount of copyright violated content including music videos (focus of the work presented in this paper) despite the fact that they have defined several policies and implemented measures to combat copyright violations of content. We present a method to automatically detect copyright violated videos by mining video as well as uploader meta-data. We propose a multi-step approach consisting of computing textual similarity between query video title and video search results, detecting useful linguistic markers (based on a pre-defined lexicon) in title and description, mining user profile data, analyzing the popularity of the uploader and the video to predict the category (original or copyright-violated) of the video. Our proposed solution approach is based on a rule-based classification framework. We validate our hypothesis by conducting a series of experiments on evaluation dataset acquired from YouTube. Empirical results indicate that the proposed approach is effective.","Understanding expansion order and phenotypic connectivity in \u03c0GESince its inception, \u03c0GE has used evolution to guide the order of how to construct derivation trees. It was hypothesised that this would allow evolution to adjust the order of expansion during the run and thus help with search. This research aims to identify if a specific order is reachable, how reachable it may be, and goes on to investigate what happens to the expansion order during a \u03c0GE run. It is concluded that within \u03c0GE we do not evolve towards a specific order but a rather distribution of orders. The added complexity that an evolvable order gives \u03c0GE can make it difficult to understand how it can effectively search, by examining the connectivity of the phenotypic landscape it is hoped to understand this. It is concluded that the addition of an evolvable derivation tree expansion order makes the phenotypic landscape associated with \u03c0GE very densely connected, with solutions now linked via a single mutation event that were not previously connected.","INFORMATION SECURITY AWARENESS : ITS ANTECEDENTS AND MEDIATING EFFECTS ON SECURITY COMPLIANT BEHAVIORAbstract Information security awareness (ISA) is referred to as a state of consciousness and knowledge about security issues and is frequently found to impact security compliant behavior. However, to date we know little about the factors influencing ISA and its mediating effect on behavior. Our study addresses these gaps. We propose a research model that studies ISA\u2019s institutional, individual, and environmental antecedents and investigates the mediating role of ISA. The model was empirically tested with survey data from 475 employees. The model explains a substantial proportion of the variance of ISA (.50) and intention to comply (.41). The results imply that the provision of security policies and employees\u2019 knowledge on information systems are the most influential antecedents of ISA. The study shows that ISA mediates the relationship between ISA\u2019s antecedents and behavioral intention. The findings will be useful for stakeholders interested in encouraging employees\u2019 information security policy compliant behavior.","Event Matching Algorithm to Collaborate Sensor Network and the Cloud through a Middleware ServiceCloud computing and virtual communities have been changing the face of communication. Cloud computing covers almost every services and provides most of data services. On the other hand, wireless sensor networks (WSN) gained attention for their potential supports such as environment monitoring, bio-median acknowledgment, healthcare monitoring, industrial automation etc. But this sensor network is not available to community groups or cloud environment for general purpose research or utilization yet. If we can reduce the gap between real and virtual world by adding this WSN produced data to cloud environment and virtual communities to alert the general researchers about environmental situations, it can gain a remarkable attention all over and we can be benefited in all our ability. To do this we need to make collaboration between sensor networks and the cloud environment. Here we have proposed a pub/sub based middleware service for WSN and Cloud platform collaboration which will provide resource, service, and storage with sensor driven data to the community. We proposed a content based event matching algorithm to analyze subscriptions and match proper content easily to convey WSN driven data to subscribers. The validation shows this content matching algorithm works efficiently compared with previously proposed algorithms to integrate WSN to cloud environment to lower the gap between real and virtual world.","An Interpretation of the Boundary Movement Method for Imbalanced Dataset Classification Based on Data QualityThis paper describes how the classification of imbalanced datasets through support vector machines using the boundary movement method can be easily explained in terms of a cost-sensitive learning algorithm characterized by giving each example a cost in function of its class. Moreover, it is shown that under this interpretation the boundary movement is measured in terms of the squared norm of the separator's slopes in feature space, thus providing practical insights in order to properly choose the boundary surface shift.","Composites ideas in COMPOOL immersion: a semantics engineering innovation network community platformNowadays, organisations and companies collaborate towards interoperable solutions difficult to derive in one closed research and development department. Currently, such concepts started to be implemented within User Innovation Networks, opening a new collective, productive space for the individual and the inter-community collaboration. Also the emergence of Internet platforms that enable and support collaborative innovation research anchored in WEB 03 semantic technologies generate new challenges and opportunities in a period of crisis. Based upon these ideas, COMPOOL Web 3.0 Collaboration Platform is an innovative collaboration research proposal, focusing on developing partnerships between governmental organisations, academia and industry to produce new composite materials based on disruptive and incremental open innovation. COMPOOL &amp;'s main aim and functionality is to synthesize and manage ideas from different disciplines so to reduce time execution as well as high costs and risks associated with technologies in composites research and development. The proposed COMPOOL platform uses Semantic Analysis, Human Computer Interaction Immersive Experience and User Innovation Networks aiming at real micro- and macro-scale industrial implementations for out of the box problem solving within diverse industries, as for example, aerospace, automotive, construction, wind energy and sports.","A Parallel, Distributed-Memory Framework for Comparative Motif DiscoveryThe increasing number of sequenced organisms has opened new possibilities for the computational discovery of cis-regulatory elements ('motifs') based on phylogenetic footprinting. Word-based, exhaustive approaches are among the best performing algorithms, however, they pose significant computational challenges as the number of candidate motifs to evaluate is very high. In this contribution, we describe a parallel, distributed-memory framework for de novo comparative motif discovery. Within this framework, two approaches for phylogenetic footprinting are implemented: an alignment-based and an alignment-free method. The framework is able to statistically evaluate the conservation of motifs in a search space containing over 160 million candidate motifs using a distributed-memory cluster with 200 CPU cores in a few hours. Software available from http://bioinformatics.intec.ugent.be/blsspeller/","The AnIta-Lemmatiser: A Tool for Accurate Lemmatisation of Italian TextsThis paper presents the AnIta-Lemmatiser, an automatic tool to lem- matise Italian texts. It is based on a powerful morphological analyser enriched with a large lexicon and some heuristic techniques to select the most appropri- ate lemma among those that can be morphologically associated to an ambigu- ous wordform. The heuristics are essentially based on the frequency-of-use tags provided by the De Mauro/Paravia electronic dictionary. The AnIta-Lemmatiser ranked at the second place in the Lemmatisation Task of the EVALITA 2011 evaluation campaign. Beyond the official lemmatiser used for EVALITA, some further improvements are presented.","Representation Learning for Cloud Classification ","Estimating and forecasting network traffic performance based on statistical patterns observed in SNMP dataWith scientific data growing to unprecedented volumes and the needs to share such massive amounts of data by increasing numbers of geographically distributed collaborators, the best possible network performance is required for efficient data access. Estimating the network traffic performance for a given time window with a probabilistic tolerance enables better data routing and transfers that is particularly important for large scientific data movements, which can be found in almost every scientific domain. In this paper, we develop a network performance estimation model based on statistical time series approach, to improve the efficiency of network resource utilization and data transfer scheduling and management over networks. Seasonal adjustment procedures are developed for identification of the cycling period and patterns, seasonal adjustment and diagnostics. Compared to the traditional time series models, we show a better forecast performance in our seasonal adjustment model with narrow confidence intervals.","Developing an Interactive Game System for Upper Limb Stroke RehabilitationThe number of cases of stroke has been increasing in Taiwan. Movement disorders such as hemiplegia occur commonly after stroke. Hemip- legic stroke patients are not able to control one side of their body, particularly upper limb. To help stroke patients recovery their lifestyles, rehabilitation plays an important role. This paper introduces the development of a digital system---a personalized interactive game, to help upper limb in hemiplegic stroke patients. Taking patients' needs and emotion into account, the system makes rehabilita- tion therapy more enjoyable. The results show that the system could help stroke patients alleviate mental fatigue and allow doctors to control and monitor the rehabilitation process of patients easily. Incorporating interactive game to stroke rehabilitation could be a feasible and acceptable way.","Exploring Local Optima in Schematic Layout.In search-based graph drawing methods there are#R##N#typically a number of parameters that control the search algorithm.#R##N#These parameters do not affect the \ufb01tness function, but#R##N#nevertheless have an impact on the \ufb01nal layout. One such search#R##N#method is hill climbing, and, in the context of schematic layout, we#R##N#explore how varying three parameters (grid spacing, the starting#R##N#distance of allowed node movement and the number of iterations)#R##N#affects the resultant diagram. Although we cannot characterize#R##N#schematics completely and so cannot yet automatically assign#R##N#parameters for diagrams, we observe that when parameters are#R##N#set to values that increase the search space, they also tend to#R##N#improve the \ufb01nal layout. We come to the conclusion that hillclimbing#R##N#methods for schematic layout are more prone to reaching#R##N#local optima than had previously been expected and that a wider#R##N#search, as described in this paper, can mitigate this, so resulting#R##N#in a better layout.","Copy-Number Alterations for Tumor Progression InferenceCopy-number alterations (CNAs) represent an important component of genetic variations and play a significant role in many hu- man diseases. Such alterations are related to certain types of cancers, including those of the pancreas, colon, and breast, among others. CNAs have been used as biomarkers for cancer prognosis in multiple studies, but few works report on the relation of CNAs with the disease progres- sion. In this paper, we provide cases where the inference on the disease progression improves when exploiting CNA information. To this aim, a specific dissimilarity-based representation of patients is given. The em- ployed framework outperforms a typical approach where patients are represented through a set of available attribute values. Three datasets were employed to validate the results of our analysis.","Rationality in Context: An Analogical PerspectiveAt times, human behavior seems erratic and irrational. Therefore, when modeling human decision-making, it seems reasonable to take the remarkable abilities of humans into account with respect to rational behavior, but also their apparent deviations from the normative standards of rationality shining up in certain rationality tasks. Based on well-known challenges for human rationality, together with results from psychological studies on decision-making and from previous work in the field of computational modeling of analogy-making, I argue that the analysis and modeling of rational belief and behavior should also consider context-related cognitive mechanisms like analogy-making and coherence maximization of the background theory. Subsequently, I conceptually outline a high-level algorithmic approach for a Heuristic Driven Theory Projection-based system for simulating context-dependent human-style rational behavior. Finally, I show and elaborate on the close connections, but also on the significant differences, of this approach to notions of \"ecological rationality\".","On the Design and Analysis of Multiple View DescriptorsWe propose an extension of popular descriptors based on gradient orientation histograms (HOG, computed in a single image) to multiple views. It hinges on interpreting HOG as a conditional density in the space of sampled images, where the effects of nuisance factors such as viewpoint and illumination are marginalized. However, such marginalization is performed with respect to a very coarse approximation of the underlying distribution. Our extension leverages on the fact that multiple views of the same scene allow separating intrinsic from nuisance variability, and thus afford better marginalization of the latter. The result is a descriptor that has the same complexity of single-view HOG, and can be compared in the same manner, but exploits multiple views to better trade off insensitivity to nuisance variability with specificity to intrinsic variability. We also introduce a novel multi-view wide-baseline matching dataset, consisting of a mixture of real and synthetic objects with ground truthed camera motion and dense three-dimensional geometry.","Effective factors in agile transformation process from change management perspectiveAfter introducing agile approach in 2001, several agile methods were founded over the last decade. Agile values such as customer collaboration, embracing changes, iteration and frequent delivery, continuous integration, etc. motivate all software stakeholders to use these methods in their projects. The main issue is that for using these methods instead of traditional methods in software development, companies should change their approach from traditional to agile. This change is a fundamental and critical mutation. Several studies have been done for investigating of barriers, challenges and issues in agile movement process and also in how to use agile methods in companies. The main issue is altering attitude from traditional to agile approach. We believe that before managing agile transformation process, its related factors should be studied in deep. This study focuses on different dimensions of changing approach to agile from change management perspective. These factors are how to being agile, method selection and awareness of challenges and issues. These fundamental factors encompass many items for agile movement and adoption process. However these factors may change in different organization, but they should be studied in deep before any action plan for designing a change strategy. The main contribution of this paper is introducing and these factors and discuss on them deeply.","Stronger semantics for low-latency geo-replicated storageWe present the first scalable, geo-replicated storage system that guarantees low latency, offers a rich data model, and provides \"stronger\" semantics. Namely, all client requests are satisfied in the local datacenter in which they arise; the system efficiently supports useful data model abstractions such as column families and counter columns; and clients can access data in a causally-consistent fashion with read-only and write-only transactional support, even for keys spread across many servers.#R##N##R##N#The primary contributions of this work are enabling scalable causal consistency for the complex columnfamily data model, as well as novel, non-blocking algorithms for both read-only and write-only transactions. Our evaluation shows that our system, Eiger, achieves low latency (single-ms), has throughput competitive with eventually-consistent and non-transactional Cassandra (less than 7% overhead for one of Facebook's real-world workloads), and scales out to large clusters almost linearly (averaging 96% increases up to 128 server clusters).","Accelerating Software Model Checking Based on Program BackboneModel checking technique has been gradually applied to verify the reliability of software systems. However, as to software with large scale and complex structure, the verification procedure suffers from the state space explosion, thus leading to a low efficiency or resource exhaustion. In this paper, we propose a method of accelerating software model checking based on program backbone to verify the properties in ANSI-C source codes. We prune the program with respect to the assertion property, and compress the circular paths by maximal strongly connected components to extract the program backbone. Subsequently, the Hoare theory is used to generate an invariant from the compressed circular nodes, which reduces the length of path encoding. The assertion property is finally translated into a quantifier-free formula and checked for satisfiability by the SMT solver Z3. The experiments show that this method substantially improves the efficiency of program verification.","Read-Aid - an assistive reading tool for children with dyslexiaWe developed a software application, Read-Aid to help improve reading pattern in children with Dyslexia with visual processing problems. We hypothesized that after a dyslexic child's interaction with our application, there will be an improvement in their reading speed and comprehension. We compared our results with existing masked-reading intervention approach. A between-group study was conducted with 15 children. Results were significant (p=0.026) suggesting that our Read-Aid tool has potential as an assistive technology application.","Information Services at the Prelaunch Stage of Information Technology Products ","Exploring Medical Family Tree Data Using Visual Data MiningMedical Family Tree can provide a branch-by-branch indication of the types of diseases that have been present in a family's past. Some of these diseases may be genetic in nature. By exploring a Medical Family Tree we can become more aware of any genetic factors that may put us at risk of developing genetically-linked diseases. The main purpose of this paper is to present a proposal on a study to explore the medical family data using visual data mining techniques. This article seeks to enable reader to basically understand how and why this type of research is being conducted and how it can be used to help medical practitioners in understanding family health and condition based on information gathered for family medical tree. Initial investigation suggest that visual data mining has huge potentials as it can visually help a lot people such as health practitioners, therapist, clinicians, social workers and others in various fields to understand the patient's family medical history and to look for recurring patterns of illness and behaviour.","Emotional McGurk Effect? A Cross-Cultural Investigation on Emotion Expression under Vocal and Facial Conflict ","Sustainability at Home: An Exploratory Study on Monitoring Needs and Energy Management Actions of Solar Power ProducersThis exploratory study focused on the energy consumption practices of customer-producers (prosumers) in relation to their needs in monitoring energy production. Our analysis of both production monitoring activities and domestic activities in real situations revealed the motivations of these producers and demonstrated that the actions of energy management were not dependent on the status of customer-producer. The actions of energy management arose from individual and collective constructions, as well as the appropriation of electrical appliances and attractive pricing offers. These results suggest that the issue of offering incentives for energy management would benefit from greater attention to questions of appropriation, pricing, and technical devices.","On the Homomorphic Computation of Symmetric Cryptographic PrimitivesWe present an analysis on the homomorphic computability of different symmetric cryptographic primitives, with the goal of understanding their characteristics with respect to the homomorphic evaluation according to the BGV scheme. Specifically, we start from the framework presented by Gentry, Halevi and Smart for evaluating AES. We provide an improvement of it, then we perform a detailed evaluation on the homomorphic computation of cryptographic algorithms of different families Salsa20 stream cipher, SHA-256 hash function and Keccak sponge function. After the analysis, we report the performance results of the primitives we have implemented using the recently released HElib. In the conclusions we discuss our findings for the different primitives we have analyzed to draw a general conclusion on the homomorphic evaluation of symmetric cryptographic primitives.","Unified Performance Authoring Tool for Heterogeneous Devices and Protocols ","Finding Critical Thresholds for Defining Bursts in Event Logs ","On Approximate Nearest Neighbour Field Algorithms in Template Matching for Surface Quality Inspection ","Using Map Representations to Visualize, Explore and Understand Large Collections of Dynamically Categorized DocumentsThis paper presents VOROSOM, a novel visualization scheme that supports collection understanding and exploration of large, distributed collections. Using metadata harvested from diverse collections, VOROSOM produces a map representation in which regions are associated with categories of documents. The shape of each region in the map reflects the relationships among documents in each of the categories. Thus, the distance between two regions directly corresponds to their semantic affinity. Maps are produced in such a way that the number of categories is maintained within a manageable size, considering the user's cognitive capabilities. Maps are organized hierarchically, which supports the exploration and navigation within categories and subcategories of documents using map representations consistently. We report initial results of user studies with a prototypical implementation of our visualization scheme over an actual network of digital libraries.","xMOF: Executable DSMLs Based on fUMLThe basic ingredients of a domain-specific modeling language (DSML) are its syntax and semantics. For defining the abstract syntax in terms of metamod- els, MOF constitutes a standardized language. For specifying the behavioral se- mantics, however, no standardized language exists, which hampers the emergence of model execution facilities, such as debugging and simulation support. The con- tribution of this paper is an integrated approach for specifying the abstract syntax and behavioral semantics of DSMLs based exclusively on standardized modeling languages. In particular, we integrate fUML, a standardized executable subset of UML, with MOF leading to a new metamodeling language xMOF. Moreover, we propose a methodology for developing executable DSMLs fostering the separa- tion of abstract syntax and behavioral semantics. To evaluate our approach, we provide an EMF-based implementation and report on lessons learned from per- forming three case studies in which we implemented executable DSMLs using xMOF.","Efficient GCI Detection for Efficient Sparse Linear PredictionWe propose a unified non-linear approach that offers an ef- ficient closed-form solution for the problem of sparse linear prediction analysis. The approach is based on our previous work for minimization of the weighted l2 -norm of the prediction error. The weighting of the l2 -norm is done in a way that less emphasis is given to the prediction error around the Glottal Closure Instants (GCI) as they are expected to attain the largest values of error and hence, the resulting cost function approaches the ideal l0 -norm cost function for sparse residual recovery. As such, the method requires knowledge of the GCIs. In this paper we use our recently developed GCI detection algorithm which is particularly suitable for this problem as it does not rely on residuals themselves for detection of GCIs. We show that our GCI detection algorithm provides slightly better sparsity properties in comparison to a recent powerful GCI detection algorithm. Moreover, as the computational cost of our GCI detection algorithm is quite low, the computational cost of the overall solution is considerably lower.","Multiobjective Path Relinking for Biclustering: Application to Microarray DataIn this work we deal with a multiobjective biclustering problem applied to microarray data. MOBI nsga [21] is one of the multiobjective metaheuristics that have been proposed to solve a new multiobjective formulation of the biclustering problem. Using MOBI nsga , biclusters of good quality can be extracted. However, the generated front approximation contains a lot of gaps. Using path relinking strategies, our aim is to improve the generated front\u2019s quality by filling the gaps with new solutions. Therefore, we propose a general scheme PR-MOBI nsga of different possible hybridization of MOBI nsga with path relinking strategies. A comparison of different PR-MOBI nsga hybridizations is performed. Experimental results on reel data sets show that PR-MOBI nsga allows to extract new interesting solutions and to improve the Pareto front approximation generated by MOBI nsga .","Requirements for an Intelligent Ambient Assisted Living Application for Parkinson PatientsAmbient Assisted Living is attracting the attention of researchers not only for dealing with aging, but also to improve the quality of living of people with other circumstances, like those of Parkinson patients. An Ambient As- sisted Living system for a Parkinson patient has to consider the particularities of this disease. It mainly involves the alteration of the motor capabilities. There are few studies dealing with the problems of Parkinson Disease and how AAL can alleviate them. Some of these problems are centered in the patient and the disease itself, but others are derived by the patient's social context, i.e., the place the patient occupies in the society and how the patient relates to other people. The contribution of this paper consists in an enumeration of issues to consider when creating an AAL application for them and it is part of a research project called SociAAL.","Adapting OSM-3D to the Mobile World: Challenges and Potentials ","Ubiquitous Service Capability Modeling and Similarity Based Searching ","Analysis of Expert Manual Annotation of the Russian Spontaneous Monologue: Evidence from Sentence Boundary DetectionThe paper describes the corpus of Russian spontaneous monologues and the results of its expert manual annotation. The corpus is balanced with respect to speakers' social characteristics and a text genre. The analysis of manual labelling of transcriptions reveals experts' disagreement in sentence boundary detection. The paper demonstrates that labelled boundaries may have different status. We also show that speakers' social characteristics gender and speech usage and a text genre influence inter-labeller agreement.","Graph Compression Strategies for Instance-Focused Semantic Mining ","Relationship Analysis between Subjective Evaluation and NIRS-Based Index on Video Content ","Computational Models of Stress in Reading Using Physiological and Physical Sensor Data ","Autonomous locomotion based on interpersonal contexts of pedestrian areas for intelligent powered wheelchairIn a rapidly aged society, providing mobility aids such as motorized wheelchairs is becoming increasingly important. Although such mobility aids have recently been developed with autonomous locomotion functions, their technologies and locomotive styles are basically based on unmanned vehicles, not on welfare mobility aids. In order to realize harmonious autonomous locomotion, this research proposed the concept of \"Interpersonal Contexts on pedestrian areas\", and developed prototype technologies utilizing the contexts: velocity control based on interaction prediction of surrounding pedestrians, and interactive collision avoidance based on surrounding mobility type. This paper explains briefly their functions and results, and discussed their utilities based on the interpersonal contexts.","Designing a Virtual Reality Software: What Is the Real Contribution of End-Users to the Requirements Prioritization?This paper deals with the requirements prioritization which is a step, or an activity, of design process influencing the decisions for the development of software products. This step is often implemented by designers and uncom- monly by users. The objective of this paper is consequently to characterize the implementation of requirements prioritization by end-users. For that, we exam- ined literatures of requirements engineering and ergonomics and we conducted an empirical study with twenty end-users of a virtual reality software. In this study, we analyze the lists of prioritized functionalities and the functionalities evoked spontaneously by users. Results show that (1) the priority functionalities for users were not systematically implemented by designers, (2) the different priority levels depended on users' profiles, (3) the users who assigned 'im- portant' and 'unimportant' priority levels evoked additional functionalities, and (4) the spontaneously evoked functionalities were mainly precisions of antici- pated functionalities.","Smart Fence: Decentralized Sequential Hypothesis Testing for Perimeter Security ","Scale Space Operators on Hierarchies of Segmentations ","Regional Road Network Shortest Path Algorithm in Vehicle Navigation SystemsAccording to the characteristics of the regional road network, analyze the connectivity among the road sections, and draw to seek the regional road network the shortest path algorithm between two nodes. First, the paper will introduce the research background and significance of the vehicle navigation system, and analyze the research status and development prospects of the issue; secondly, build the regional road network model according to the transportation network map; then further describes Floyd algorithm of the shortest path, and gives the C language code; finally, take actual traffic map in Tangshan city of Hebei province as network model, the paper achieves purpose by the use of Floyd algorithm and provides a scientific and rational calculation basis for system realization.","Beacon-Less Mobility Assisted Energy Efficient Georouting in Energy Harvesting Actuator and Sensor NetworksIn the next years, wireless sensor networks are expected to be more and more widely deployed. In order to increase their performance without increasing nodes' density, a solution is to add some actuators that have the ability to move. However, even actuators rely on batter- ies that are not expected to be replaced. In this paper, we introduce MEGAN (Mobility assisted Energy efficient Georouting in energy har- vesting Actuator and sensor Networks), a beacon-less protocol that uses controlled mobility, and takes account of the energy consumption and the energy harvesting to select next hop. MEGAN aims at prolonging the overall network lifetime rather than reducing the energy consump- tion over a single path. When node s needs to send a message to the sink d, it first computes the \"ideal\" position of the forwarder node based on available and needed energy, and then broadcasts this data. Every node within the transmission range of s in the forward direction toward d will start a backoff timer. The backoff time is based on its available energy and on its distance from the ideal position. The first node whose backoff timer goes off is the forwarder node. This node informs its neighbor- hood and then moves toward the ideal position. If, on its route, it finds a good spot for energy harvesting, it will actually stop its movement and forward the original message by using MEGAN, which will run on all the intermediate nodes until the destination is reached. Simulations show that MEGAN reduces energy consumption up to 50% compared to algorithms where mobility and harvesting capabilities are not exploited.","Directions and Benefits of Using Traffic Modelling Software in the Urban Public Transport ","A Cryptographic Algorithm Analysis for Security Threats of Semantic E-Commerce Web (SECW) for Electronic Payment Transaction System ","Non-negative Sparse Representation Based on Block NMF for Face Recognition ","Narratives of an Outsourced Information Systems Failure in a Small EnterpriseIn this study we investigate a case of an outsourced information sys- tems (IS) failure (OISF) within the collaborative partnership among asymmetric partners. A small and medium-sized enterprise (SME) is dealing with an inde- pendent software vendor (ISV) conducting a project of implementing an IS that fails. We used a narrative research methodology for our enquiry. In the con- struction of our narrative we followed the OISF framework as a theoretical touchstone. As a major conclusion we found that asymmetric collaborations with partners with inadequate managerial and technical IT capabilities are ex- tremely prone to OISF's. We showed that an outcome-based and fixed price contract is not an adequate instrument to conduct such a partnership and to avoid a failure.","Context-Aware Self-adaptations: From Requirements Specification to Code Generation ","Suspicious Object Recognition Method in Video Stream Based on Visual AttentionWe proposed a state-of-art method for intelligent object recognition and video surveillance based on human visual attention. Bottom-up and top-down attention are applied respectively in the process of acquiring interested object (saliency map) and object recognition. The revision of 4-channel PFT method is proposed in bottom-up attention, which enhances the speed and accuracy. Inhibit of return (IOR) is applied in judging the sequence of saliency object \u201cpop-out\u201d. Considering the basic characters of human vision, we also apply the rule that object looks small in the distance and big on the contrary. Euclidean distance of color distribution, object center coordinates and speed are considered in judging whether the target is match and \u201csuspicious.\u201d The extensive test on videos and images show that our method in video analysis has high accuracy and fast speed compared with traditional method. The method can be applied into many fields such as video surveillance and security.","Development of screening visual field test application that use eye movementThe purpose of this study was to develop a screening device for the early detection of glaucoma. We evaluated our proposal system by comparing the results obtained by using the proposed system and Humphrey Field Analyzer (HFA), which was commercially available visual field measurement device. Quantitative evaluation of the proposed system and HFA visual field test results, and calculating the correlation coefficient, we were able to obtain a more moderate positive correlation. This study suggested that the proposed system was potentially useful as an alternate screening device for the detection of the early stage of glaucoma.","Optimal tracking control scheme for discrete-time nonlinear systems with approximation errorsIn this paper, we aim to solve an infinite-time optimal tracking control problem for a class of discrete-time nonlinear systems using iterative adaptive dynamic programming (ADP) algorithm. When the iterative tracking control law and the iterative performance index function in each iteration cannot be accurately obtained, a new convergence analysis method is developed to obtain the convergence conditions of the iterative ADP algorithm according to the properties of the finite approximation errors. If the convergence conditions are satisfied, it is shown that the iterative performance index functions converge to a finite neighborhood of the greatest lower bound of all performance index functions under some mild assumptions. Neural networks are used to approximate the performance index function and compute the optimal tracking control policy, respectively, for facilitating the implementation of the iterative ADP algorithm. Finally, a simulation example is given to illustrate the performance of the present method.","The steady-state control problem for markov decision processesThis paper addresses a control problem for probabilistic models in the setting of Markov decision processes (MDP). We are interested in the steady-state control problem which asks, given an ergodic MDP$\\mathcal{M}$ and a distribution \u03b4goal, whether there exists a (history-dependent randomized) policy \u03c0 ensuring that the steady-state distribution of $\\mathcal{M}$ under \u03c0 is exactly \u03b4goal. We first show that stationary randomized policies suffice to achieve a given steady-state distribution. Then we infer that the steady-state control problem is decidable for MDP, and can be represented as a linear program which is solvable in PTIME. This decidability result extends to labeled MDP (LMDP) where the objective is a steady-state distribution on labels carried by the states, and we provide a PSPACE algorithm. We also show that a related steady-state language inclusion problem is decidable in EXPTIME for LMDP. Finally, we prove that if we consider MDP under partial observation (POMDP), the steady-state control problem becomes undecidable.","Tracking Objects with Rigid Body Templates: An Iterative Constrained Linear Least Squares Approach ","Model for Knowledge Representation of Multidimensional Measurements Processing Results in the Environment of Intelligent GISThe paper describes models for knowledge representation, i.e. extracted at different steps of multidimensional measurements processing procedure, in the context of JDL data fusion model. Models are developed taking into account the requirements of geo information systems environment. As a case study system of conditions lighting which implements the models for oceanographic data processing is described.","The Optimality of Satisficing SolutionsThis paper addresses a prevailing assumption in single-agent heuristic search theory- that problem-solving algorithms should guarantee shortest-path solutions, which are typically called optimal. Optimality implies a metric for judging solution quality, where the optimal solution is the solution with the highest quality. When path-length is the metric, we will distinguish such solutions as p-optimal.","Analysing User Needs for a Unified 3D Metadata Recording and Exploitation of Cultural Heritage Monuments SystemThis research paper aims to address the problem of lack of a unified system for 3D documentation, promotion and exploitation of cultural heritage monuments via complete 3D data acquisition, 3D modeling and metadata re- cording using terrestrial laser scanners. Terrestrial laser scanning is a new fast developing technology that allows for the mapping and exact replication of the entire 3D shape of physical objects through the extraction of a very large num- ber of points in space (point cloud) in short time periods, with great density and precision, and with no actual physical contact with the object of interest. The problem lies on the various types of hardware equipment and software systems used in the whole workflow of the 3D scanning process, including for the ex- traction of point clouds and the building process of the computerized 3D model development and the final products presentation. These often results in a large volume of interim and final products with little if no standardization, multiple different metadata, various user-dependent annotation requirements and vague documentation which often casts repeating a certain process impossible. This paper presents a user requirement analysis for a complete metadata recording during the whole lifecycle of a 3D product, aiming at supporting workflow his- tory and provenance of 3D products of cultural heritage monuments.","Improving the RACAI Neural Network MSD TaggerPart-of-speech (POS) tagging is a key process for various natural language processing related tasks, in which each word of a sentence is assigned a uniquely interpretable label (called a POS tag). There are many proposed methodologies for this task, such as Hidden Markov Models, Conditional Ran- dom Fields, Maximum Entropy classifiers etc. Such methods are primarily in- tended for English which, in comparison to highly inflectional languages has a relatively small tagset inventory. One of the well-known methods used for large tagset labeling (referred to as morpho-syntactic descriptors or MSDs) is called Tiered Tagging (Tufis, 1999), (Tufi\u0219 and Dragomirescu, 2006) and it exploits a reduced set of tags from which context irrelevant features (e.g. gender infor- mation) which can be deduced trough the word form's flectional analysis are stripped. In our previous work we presented an alternative method to Tiered Tagging, in which we performed multi-class classification with a feed-forward neural network. Our methodology has the advantage that it does not require ex- tensive linguistic knowledge as implied by the previously mentioned approach. We extend our work by testing our tool on Czech and successfully experiment- ing with a genetic algorithm designed to find a better network topology.","Active Learning by Selecting New Training Samples from Unlabelled Data ","Experiments with semantic similarity measures based on LDA and LSAWe present in this paper experiments with several semantic similarity measures based on the unsupervised method Latent Dirichlet Allocation. For comparison purposes, we also report experimental results using an algebraic method, Latent Semantic Analysis. The proposed semantic similarity methods were evaluated using one dataset that includes student answers from conversational intelligent tutoring systems and a standard paraphrase dataset, the Microsoft Research Paraphrase corpus. Results indicate that the method based on word representations as topic vectors outperforms methods based on distributions over topics and words. The proposed evaluation methods can also be regarded as an extrinsic method for evaluating topic coherence or selecting the number of topics in LDA models, i.e. a task-based evaluation of topic coherence and selection of number of topics in LDA.","Coping with Stress Using Social Robots as Emotion-Oriented Tool: Potential Factors Discovered from Stress Game ExperimentIt is known from psychology that humans cope with stress by either changing stress-induced situations (which is called problem-oriented coping strategy) or by changing his/her internal perception about the stress-induced situations (which is called emotion-oriented coping strategy). Social robots, as emerging tools that have abilities to socially interact with humans, can be of great use to help people coping with stress. The paper discusses some recent studies about ways of dealing with stress in stressful situations by using social robots. Moreover, we focus on presenting our experimental design and the discovered factors that can allow social robots to assist humans in dealing with stress in an emotion-oriented manner.","A Cascadic Alternating Krylov Subspace Image Restoration MethodThis paper describes a cascadic image restoration method which at each level applies a two-way alternating denoising and deblur- ring procedure. Denoising is carried out with a wavelet transform, which also provides an estimate of the noise-level. The latter is used to deter- mine a suitable regularization parameter for the Krylov subspace iter- ative deblurring method. The cascadic multilevel method proceed from coarse to fine image resolution, using suitable restriction and prolonga- tion operators. The choice of the latter is critical for the performance of the multilevel method. We introduce a special deblurring prolongation procedure based on TV regularization. Computed examples demonstrate the effectiveness of the method proposed for determining image restora- tions of high quality.","Potential-based reward shaping for POMDPsWe address the problem of suboptimal behavior caused by short horizons during online POMDP planning. Our solution extends potential-based reward shaping from the related field of reinforcement learning to online POMDP planning in order to improve planning without increasing the planning horizon. In our extension, information about the quality of belief states is added to the function optimized by the agent during planning. This information provides hints of where the agent might find high future rewards, and thus achieve greater cumulative rewards.","An Internet-Based Architecture Supporting Ubiquitous Application User InterfacesMaintaining a viable balance between development costs and market coverage has turned out to be a challenging issue when develop- ing mobile software applications. The diversity of devices running third- party developed software applications is rapidly expanding from PC, to mobile, home entertainment systems, and even the automotive indus- try. With the help of Web technology and the Internet infrastructure, ubiquitous applications have become a reality. Nevertheless, the vari- ety of presentation and interaction modalities still limit the number of targetable devices. In this chapter we present webinos, a multi-device ap- plication platform founded on the Future Internet infrastructure. Hereto we describe webinos' model-based user interface framework as a means to support context-aware adaptiveness for applications that are executed in such ubiquitous computing environments.","Balancing Recall and Precision in Stock Market Predictors Using Support Vector Machines ","Face Alignment Based on 3D Face Shape Model and Markov Random FieldThis paper presents a novel method for face alignment under unknown head poses and nonrigid warp, within the framework of markov random field. The proposed method learns a 3D face shape model com- prised of 31 facial features and a texture model for each facial feature from a 3D face database. The models are combined to serve as the unary, pairwise and high order constraints of the markov random field. The fa- cial features are located by minimizing the potential function of markov random field, which is solved with dual decomposition. The main contri- bution of this paper is composed of three aspects. First, Random Project Tree is utilized to learn the manifold structure of the facial feature ap- pearance under different view points. Second, a 3D face shape model is learned to capture the linear part of face shape distribution due to the change of identity and expression, which is served as the high order constraints. Third, Markov random field is introduced to model the non- linear part of the face shape distribution, and also to deal with occlusion of facial features due to head pose variation or ornaments. Experiments was taken on the Texas 3D face database and face images downloaded from the Internet, results shows capability of adapting large head pose variations of the method.","The Research on Knowledge Diffusion Based on Small World Network ","Partition Sort versus Quick Sort: A Comparative Average Case Analysis with Special Emphasis on Parameterized Complexity ","Data Ranking and Clustering via Normalized Graph Cut Based on Asymmetric AffinityIn this paper, we present an extension of the state-of-the- art normalized graph cut method based on asymmetry of the affinity matrix. We provide algorithms for classification and clustering problems and show how our method can improve solutions for unequal and over- lapped data distributions. The proposed approaches are based on the theoretical relation between classification accuracy, mutual information and normalized graph cut. The first method requires a priori known class labeled data that can be utilized, e.g., for a calibration phase of a brain- computer interface (BCI). The second one is a hierarchical clustering method that does not involve any prior information on the dataset.","Ergonomics Study of Direct and Indirect Visibility Evaluation at Uncontrolled Intersections Based on Three-Dimensional Computer SimulationCrossing collisions at intersections account for one-fourth of the total accidents in Japan. This type of accident could be caused by the poor visual en- vironment at intersections, including the lack of indirect visibility provided by traffic convex mirrors. However, no available desk methods have been reported on the proper installation method for such mirrors. This paper discusses the ap- propriate conditions for direct and indirect visibility. These include mirror visi- bility simulation technology, which was developed by applying three- dimensional computer graphics software. The simulated mirror images were found to be highly consistent with actual images. The mirror visibility obtained by an optimal mirror installation was found to be desirable in both a simulation and field study. The simulation demonstrated that a slight change in the mirror plate angle greatly influenced the visible distance. In conclusion, the 3DCG si- mulation method was effective for examining conditions for good direct and in- direct visibility at intersections.","A unified framework for linear function approximation of value functions in stochastic controlThis paper contributes with a unified formulation that merges previous analysis on the prediction of the performance (value function) of certain sequence of actions (policy) when an agent operates a Markov decision process with large state-space. When the states are represented by features and the value function is linearly approximated, our analysis reveals a new relationship between two common cost functions used to obtain the optimal approximation. In addition, this analysis allows us to propose an efficient adaptive algorithm that provides an unbiased linear estimate. The performance of the proposed algorithm is illustrated by simulation, showing competitive results when compared with the state-of-the-art solutions.","Universal Entanglers for Bosonic and Fermionic SystemsA universal entangler (UE) is a unitary operation which maps all pure product states to entangled states. It is known that#R##N#for a bipartite system of particles 1,2 with a Hilbert space C^{d_1} otimes C^{d_2}, a UE exists when min(d_1,d_2) &gt;= 3 and (d_1,d_2) != (3,3). It is also known that whenever a UE exists, almost all unitaries are UEs; however to verify whether a given unitary is a UE is very difficult since solving a quadratic system of equations is NP-hard in general. This work examines the existence and construction of UEs of bipartite bosonic/fermionic systems whose wave functions sit in the symmetric/antisymmetric subspace of C^d otimes C^d. The development of a theory of UEs for these types of systems needs considerably different approaches from that used for UEs of distinguishable systems. This is because the general entanglement of identical particle systems cannot be discussed in the usual way due to the effect of (anti)-symmetrization which introduces \"pseudo entanglement\" that is inaccessible in practice. We show that, unlike the distinguishable particle case, UEs exist for bosonic/fermionic systems with Hilbert spaces which are symmetric (resp. antisymmetric) subspaces of C^d otimes C^d if and only if d &gt;= 3 (resp. d &gt;= 8). To prove this we employ algebraic geometry to reason about the different algebraic structures of the bosonic/fermionic systems. Additionally, due to the relatively simple coherent state form of unentangled bosonic states, we are able to give the explicit constructions of two bosonic UEs. Our investigation provides insight into the entanglement properties of systems of indistinguishable particles, and in particular underscores the difference between the entanglement structures of bosonic, fermionic and distinguishable particle systems.","A Hybrid Robust Image Watermarking Scheme Using Integer Wavelet Transform, Singular Value Decomposition and Arnold TransformThis paper presents new hybrid robust digital image watermarking scheme based on Integer Wavelet Transform (IWT), Singular Value Decomposition (SVD) and Arnold Transform (AT). The scheme employed the properties of those transforms to achieve the watermarking requirements (robustness, imperceptibility and security). The property of IWT which map integer to integer offers a high robustness and a good imperceptibility. The good stability and the descending order of singular values of S of SVD transform also contributed significantly in robustness and imperceptibility. Finally the scheme which applied scrambling of watermark by AT enhanced the security aspect of the scheme. The experimental results showed that the proposed scheme achieved good imperceptibility and high resistance against geometrical and non-geometrical attacks and outperformed some state of the art schemes.","An Efficient Method for Fundamental Frequency Determination of Noisy SpeechIn this paper, we present a fundamental frequency determination method dependent on the autocorrelation compression of the multi-scale product of speech signal. It is based on the multiplication of compressed copies of the original autocorrelation operated on the multi-scale product. The multi- scale product is based on realising the product of the speech wavelet transform coefficients at three successive dyadic scales. We use the quadratic spline wavelet function. We compress the autocorrelation of the multi-scale product a number of times by integer factors (downsampling). Hence, when the obtained functions are multiplied, we obtain a peak with a clear maximum corresponding to the fundamental frequency. We have evaluated our method on the Keele database. Experimental results show the effectiveness of our method presenting a good performance surpassing other algorithms. Besides, the proposed approach is robust in noisy environment.","A Neural Network Model for Online Multi-Task Multi-Label Pattern RecognitionThis paper presents a new sequential multi-task learning model with the following functions: one-pass incremental learning, task allocation, knowledge transfer, task consolidation, learning of multi-label data, and active learning. This model learns multi-label data with incomplete task information incrementally. When no task information is given, class labels are allocated to appropriate tasks based on prediction errors; thus, the task allocation sometimes fails especially at the early stage. To recover from the misallocation, the proposed model has a backup mechanism called task consolidation, which can modify the task allocation not only based on prediction errors but also based on task labels in training data (if given) and a heuristics on multi-label data. The experimental results demonstrate that the proposed model has good performance in both classification and task categorization.","Data Mining as Search: Theoretical Insights and Policy Responses ","Repairing Disengagement in Collaborative Dialogue for Game-Based LearningSuccessfully promoting engagement within learning environments is a subject of increasing attention within the AI in Education community. Evi- dence is mounting that game-based learning environments hold great potential to engage students, but disengaged behavior is still observed. Devising adaptive strategies to re-engage students in the learning task is a key open research ques- tion. Toward that end, this paper examines the collaborative behavior of pairs of middle school students solving game-based computer science problems. We ex- amine the dialogue moves that were used by a more engaged learner to repair a partner's disengagement and consider the implications that these strategies may have for designing collaborative game-based learning environments.","Generic Local Search (Memetic) Algorithm on a Single GPGPU Chip ","Spoken language processing: where do we go from here?Recent years have seen steady improvements in the quality and performance of speech-based human-machine interaction driven by a significant convergence in the methods and techniques employed. However, the quantity of training data required to improve state-of-the-art systems seems to be growing exponentially, and yet performance appears to be reaching an asymptote that is not only well short of human performance, but which may also be inadequate for many real-world applications. This situation suggests that there may be a fundamental flaw in the underlying architecture of contemporary speech-based systems, and the future direction for research into spoken language processing is currently uncertain. This chapter addresses these issues by stepping outside the familiar domains of speech science and technology, and instead draws inspiration from recent findings in fields of research that are concerned with the neurobiology of living systems in general. In particular, four areas are highlighted: the growing evidence for an intimate relationship between sensor and motor behaviour in living organisms, the power of negative feedback control to accommodate unpredictable disturbances in real-world environments, mechanisms for imitation and mental imagery for learning and modelling, and hierarchical models of temporal memory for predicting future behaviour and anticipating the outcome of events. The chapter shows how these results point towards a novel architecture for speech-based human-machine interaction that blurs the distinction between the core components of a traditional spoken language dialogue system; an architecture in which cooperative and communicative behaviour emerges as a by-product of a model of interaction where the system has in mind the needs and intentions of a user, and a user has in mind the needs and intentions of the system. It concludes with a roadmap of technical pre-requisites and desiderata that would seem to be necessary if voice-based interaction with an autonomous agent such as a virtual butler is to become a practical reality.","Determination of Dependence of Performance from Specifications of Separate Components of the Hybrid Personal Computing System Based on GPU-ProcessorsIn this paper selection of electronic component base as one of issues of development of personal hybrid computing system is reviewed. Test results of performance of experimental prototype of personal hybrid computing system based on 3 NVidia Tesla C2050 graphic processors have been explained. Row of experiments for evaluating system performance has been carried out with different RAM clock frequency 1066 and 1333MHz and memory volume from 2 up to 24 GB with 2GB step, also the dependence of performance from bandwidth of PCI-Express x8 and PCI-Express x16 slots has been studied.#R##N##R##N#Results of this research laid down in a basis of development process of experimental prototype of the personal hybrid computing system.","Evaluation of wikitalk: user studies of human-robot interactionThe paper concerns the evaluation of Nao WikiTalk, an application that enables a Nao robot to serve as a spoken open-domain knowledge access system. With Nao WikiTalk the robot can talk about any topic the user is interested in, using Wikipedia as its knowledge source. The robot suggests some topics to start with, and the user shifts to related topics by speaking their names after the robot mentions them. The user can also switch to a totally new topic by spelling the first few letters. As well as speaking, the robot uses gestures, nods and other multimodal signals to enable clear and rich interaction. The paper describes the setup of the user studies and reports on the evaluation of the application, based on various factors reported by the 12 users who participated. The study compared the users' expectations of the robot interaction with their actual experience of the interaction. We found that the users were impressed by the lively appearance and natural gesturing of the robot, although in many respects they had higher expectations regarding the robot's presentation capabilities. However, the results are positive enough to encourage research on these lines.","Evolution of Contours for Topology OptimizationTopology optimization is used to find a preliminary structural configura- tion that meets a predefined criterion. It involves optimizing both the external bound- ary and the distribution of the internal material within a structure. Usually, counters are used a posteriori to the topology optimization to further adapt the shape of the topology according to manufacturing needs. Here we suggest optimizing topologies by evolving counters. We consider both outer and inner counters to allow for holes in the structure. Due to the difficulty of defining a reliable measure for the differ- ences among shapes, little research attention has been focused on simultaneously finding diverse sets of optimal topologies. Here, niching is implemented within a suggested evolutionary algorithm in order to find diverse topologies. The niching is then embedded within the algorithm through the use of our recently introduced partitioning algorithm. For this algorithm to be used, the topologies are represented as functions. Two examples are given to demonstrate the approach. These examples show that the algorithm evolves a set of diverse optimal topologies.","Fine-Grained Access Control for RDF Data on Mobile Devices ","A Shallow Embedding of Resolution and Superposition Proofs into the \u03bb\u03a0-Calculus Modulo.The \u03bb\u03a0-calculus modulo is a proof language that has been proposed as a proof standard for (re-)checking and interoperability. Resolution and superposition are proof-search methods that are used in state-of-the-art first-order automated theorem provers. We provide a shallow embedding of resolution and superposition proofs in the \u03bb\u03a0-calculus modulo, thus offering a way to check these proofs in a trusted setting, and to combine them with other proofs. We implement this embedding as a back-end of the prover iProver Modulo.","A Framework for Modeling and Verifying Biological Systems Using Membrane Computing ","Efficient 3D multi-region prostate MRI segmentation using dual optimizationEfficient and accurate extraction of the prostate, in particular its clinically meaningful sub-regions from 3D MR images, is of great interest in image-guided prostate interventions and diagnosis of prostate cancer. In this work, we propose a novel multi-region segmentation approach to simultaneously locating the boundaries of the prostate and its two major sub-regions: the central gland and the peripheral zone. The proposed method utilizes the prior knowledge of the spatial region consistency and employs a customized prostate appearance model to simultaneously segment multiple clinically meaningful regions. We solve the resulted challenging combinatorial optimization problem by means of convex relaxation, for which we introduce a novel spatially continuous flow-maximization model and demonstrate its duality to the investigated convex relaxed optimization problem with the region consistency constraint. Moreover, the proposed continuous max-flow model naturally leads to a new and efficient continuous max-flow based algorithm, which enjoys great advantages in numerics and can be readily implemented on GPUs. Experiments using 15 T2-weighted 3D prostate MR images, by inter- and intra-operator variability, demonstrate the promising performance of the proposed approach.","Early Experiences from a guideline-based computerized clinical decision support for stroke prevention in atrial fibrillation. ","Reading together as a Leisure Activity: Implications for E-reading ","Bipolar Querying of Valid-Time Intervals Subject to UncertaintyDatabases model parts of reality by containing data representing properties of real-world objects or concepts. Often, some of these properties are time-related. Thus, databases often contain data representing time-related information. However, as they may be produced by humans, such data or information may contain imperfections like uncertainties. An important purpose of databases is to allow their data to be queried, to allow access to the information these data represent. Users may do this using queries, in which they describe their preferences concerning the data they are not interested in. Because users may have both positive and negative such preferences, they may want to query databases in a bipolar way. Such preferences may also have a temporal nature, but, traditionally, temporal query conditions are handled specifically. In this paper, a novel technique is presented to query a valid-time relation containing uncertain valid-time data in a bipolar way, which allows the query to have a single bipolar temporal query condition.","Large-scale computation not at the cost of expressivenessWe present Celias, a new concurrent programming model for data-intensive scalable computing. Celias supports many virtues commonly found in existing distributed programming frameworks, such as elastic scaling and fault tolerance, without sacrificing expressiveness. The key design idea of Celias is the concept of a microtask, as a scalable, fault-tolerant, and completely data-driven unit of computation. By combining Tuplespace and microtasks, Celias provides an intuitive yet powerful programming abstraction for large and complex problems.","The emergence and role of strong ties in time-varying communication networks ","Collaborative Discriminant Locality Preserving Projections With its Application to Face RecognitionAbstractWe present a novel Discriminant Locality Preserving Projections (DLPP) algorithm named Collaborative Discrim-inant Locality Preserving Projection (CDLPP). In our algorithm, the discriminating power of DLPP are furtherexploited from two aspects. On the one hand, the global optimum of class scattering is guaranteed via using thebetween-class scatter matrix to replace the original denominator of DLPP. On the other hand, motivated by the sparserepresentation and collaborative representation, a L 2 -norm constraint is imposed to the projections to discover thecollaborations of dimensions in the sample space. We apply our algorithm to face recognition. Three popular facedatabases, namely AR, ORL and LFW-a, are employed for evaluating the performance of CDLPP. Extensive experi-mental results demonstrate that CDLPP signi\ufb01cantly improve the discriminating power of DLPP and outperform thestate-of-the-arts.Keywords: Discriminant Locality Preserving Projections, Face recognition, Dimensionality reduction, Featureextraction, Collaborative representation1. IntroductionSubspace learning is a useful technique in computer vision, pattern recognition and machine learning, particularlyfor solving the dimensionality reduction, feature selection, feature extraction and face recognition tasks. Subspacelearning aims to learn a speci\ufb01c subspace of the original sample space, which has some particular desired properties.This topic has been studied for decades and many impressive algorithms have been proposed. The representativesubspace learning algorithms include Principle Component Analysis (PCA) [1, 2, 3], Linear Discriminant Analysis(LDA) [4], Non-negative Matrix factorization (NMF) [5, 6], Independent Component Analysis (ICA) [7], LocalityPreserving Projections (LPP) and so on. In face recognition, subspace learning is also known as appearance-basedface recognition. For example, PCA is known as Eigenfaces, LDA is known as Fisherfaces and LPP is known asLaplacianfaces.Some recent studies show the high-dimensional samples may reside on low-dimensional manifolds [8, 9] and suchmanifold structures are essential for data clustering and classi\ufb01cation [10, 11]. The manifold-based subspace learningalgorithms may start from Locality Preserving Projections (LPP). LPP constructs an adjacency matrix to weightingthe distance between each two sample points for learning a projection which can preserve the local manifold structuresof data. The weight between two nearby points is much greater than the weight between two remote points. So if twopoints are close in the original space then they will be close in the learned subspace as well. However, the conventionalLPP only takes the manifold information into consideration. Many researchers make e orts to improve LPP fromdi erent perspectives. Discriminant Locality Preserving Projections (DLPP) [12, 13, 14] is deemed as one of the mostsuccessful extension of LPP. It improves the discriminating power of LPP via simultaneously maximizing the distancebetween each two nearby classes and minimizing the original LPP objective. Orthogonal Laplacianfaces (OLPP) [15]imposes an orthogonality constraint to LPP to ensure that the learned projections are mutually orthogonal. Parametric","Answer Set Programming: Boolean Constraint Solving for Knowledge Representation and ReasoningAnswer Set Programming ASP; [1,2,3] is a declarative problem solving approach, combining a rich yet simple modeling language with high-performance Boolean constraint solving capacities. ASP is particularly suited for modeling problems in the area of Knowledge Representation and Reasoning involving incomplete, inconsistent, and changing information. As such, it offers, in addition to satisfiability testing, various reasoning modes, including different forms of model enumeration, intersection or unioning, as well as multi-criteria and -objective optimization. From a formal perspective, ASP allows for solving all search problems in NP and NP NP in a uniform way. Hence, ASP is wellsuited for solving hard combinatorial search problems, like system design and timetabling. Prestigious applications of ASP include composition of Renaissance music [4], decision support systems for NASA shuttle controllers [5], reasoning tools in systems biology [6,7,8] and robotics [9,10], industrial team-building [11], and many more. The versatility of ASP is nicely reflected by the ASP solver clasp [12], winning first places at various solver competitions, such as ASP,MISC, PB, and SAT competitions. The solver clasp is at the heart of the open source platform Potassco hosted at      potassco.sourceforge.net       . Potassco stands for the \"Potsdam Answer Set Solving Collection\" [13] and has seen more than 30000 downloads world-wide since its inception at the end of 2008.#R##N##R##N#The talk will start with an introduction to ASP, its modeling language and solving methodology, and portray some distinguished ASP systems.","Study on the Barriers to the Industrial Adoption of Formal MethodsThe authors conducted an informal survey of contractors, customers, and certification authorities in the United States aerospace domain to identify barriers to the adoption of formal methods and suggested mitigations for those barriers. We surveyed 31 individuals from the following nine organizations: United States Army, Boeing, FAA, Galois, Honeywell, Lockheed Martin, NASA, Rockwell Collins, and Wind River. The top three barrier categories were education, tools, and the industrial environment (i.e., non-technical barriers with respect to personnel changes, contracts, and schedules) The top three mitigation categories were education, improving tool integration, and creating and disseminating evidence of the benefits of formal analysis. Strategies to accelerate adoption of formal methods include making formal methods a part of the undergraduate software engineering curriculum, hosting courses in formal methods for working engineers, funding the integration of tools, funding improvements to tool interfaces, and promoting/requiring the use of formal methods on future contracts.","Advances in the protection of critical infrastructure by improvement in industrial control system securityThis paper describes an international research effort that has been working toward identification of vulnerabilities in industrial control systems, mitigation strategies to address vulnerabilities, and development of tools to prevent intrusion on such systems. The research represents over five years of externally funded work within the United States and a strong partnership between the U.S. institution and both Queensland University of Technology (QUT) and the University of South Australia (UniSA). The authors introduce the security problem with such systems, discoveries to date, and the development of tools to provide intrusion detection, intrusion prevention, and forensic data capture within industrial control systems.","Multibit Embedding Algorithm for Steganography of Palette-Based ImagesWe propose a high-capacity data hiding scheme for palette- based images that does not seriously degrade the image quality in this paper. The proposed scheme can embed a multiple-bit message within the unit of a pixel matrix by using Euclidean distance, while some con- ventional schemes can embed only a one-bit message per pixel. The stego- images created by using our scheme offer a better quality compared to those by the conventional scheme. Moreover, we have obtained these re- sults with low implementation cost. The experimental results show that the proposed scheme is efficient.","On Two-Dimensional Lyndon WordsA Lyndon word is a primitive string which is lexicographically smallest among cyclic permutations of its characters. Lyndon words are used for constructing bases in free algebras, constructing de Bruijn sequences, finding the lexicographically smallest or largest substring in a string, and succinct suffix-prefix matching of highly periodic strings. In this paper, we extend the concept of the Lyndon word to two dimensions. We introduce the 2D Lyndon word and use it to capture 2D horizontal periodicity of a matrix in which each row is highly periodic, and to efficiently solve 2D horizontal suffix-prefix matching among a set of patterns. This yields a succinct and efficient algorithm for 2D dictionary matching. We present several algorithms that compute the 2D Lyndon word that represents a matrix. The final algorithm achieves linear time complexity even when the least common multiple of the periods of the rows is exponential in the matrix width.","4G Femtocells: Resource Allocation and Interference ManagementThis brief examines resource allocation and interference management for 4G femtocells. It introduces 4G femtocells in the context of 4G mobile networks and discusses related technical challenges in resource allocation and interference management. Topics include ant colony algorithm based downlink resource allocation, intelligent scheduling and power control, uplink and downlink for two-tier networks, quality of service (QoS) constraints and the cross-tier interference constraint. The authors present algorithms to alleviate common femtocell-related problems such as subchannel power allocation. The complexity of the proposed resource allocation algorithms is analyzed, and the effectiveness of the proposed algorithms is verified by simulations. This concise and practical book directly addresses common problems relating to femtocells and resource management. It serves as a useful tool for researchers in the field. Advanced-level students or professionals interested in femtocells and networks will also find the content helpful.","Model-based animation of micro-traffic simulation (WIP)Testing discrete-event simulation models is often done at the level of traces. However, visual feed-back to the modeler is crucial as he is very often a domain expert with limited computing knowledge. We propose a generic framework for graphically animating the visualization of DEVS simulations to enable testing of the simulation model at the domain-specific level. This paper reports initial work for animating micro-traffic simulation with our framework.","Efficient Computation of Mean Truncated Hitting Times on Very Large GraphsPrevious work has shown the effectiveness of random walk hitting times as a measure of dissimilarity in a variety of graph-based learning problems such as collaborative filtering, query suggestion or finding paraphrases. However, application of hitting times has been limited to small datasets because of computational restrictions. This paper develops a new approximation algorithm with which hitting times can be computed on very large, disk-resident graphs, making their application possible to problems which were previously out of reach. This will potentially benefit a range of large-scale problems.","Competing Histories of Technology: Recognizing the Vital Role of International Scientific Communities behind the Innovation of the InternetOne way to make the history of computing relevant is to explain how different histories are in competition with each other and how they support quite different technology policy. The prevalent history that the US military created the Internet hides the international spirit of goodwill and cooperation that made a particular implementation of Internet happen. This is not just an academic issue. The success of the Internet encourages us to ask how we can continue to innovate the technologies of the Internet or new technologies of a similar power. The myth that the military created the Internet also supports the idea that it was designed on purpose according to a plan. This could not be further from the truth. In fact, the most interesting thing about the Internet is that, in its history, it had a tendency to violate the plans set forth. The international community invigorated the kind of inquiry that would lead to the Internet, not the United States in isolation. In order to create something like the Internet, then, we need to provide an environment for international exchange and cooperation, not maintain proprietary secrets and work in a disciplined environment of practical research.","Non Maximal Suppression in Cascaded Ranking ModelsRanking models have recently been proposed for cascaded object detection, and have been shown to improve over regression or binary classification in this setting [1, 2]. Rather than train a classifier in a binary setting and interpret the function post hoc as a ranking objective, these approaches directly optimize regularized risk objectives that seek to score highest the windows that most closely match the ground truth. In this work, we evaluate the effect of non-maximal suppression (NMS) on the cascade architecture, showing that this step is essential for high performance. Furthermore, we demonstrate that non-maximal suppression has a significant effect on the tradeoff between recall different points on the overlap-recall curve. We further develop additional objectness features at low computational cost that improve performance on the category independent object detection task introduced by Alexe et al. [3]. We show empirically on the PASCAL VOC dataset that a simple and efficient NMS strategy yields better results in a typical cascaded detection architecture than the previous state of the art [4, 1]. This demonstrates that NMS, an often ignored stage in the detection pipeline, can be a dominating factor in the performance of detection systems.","Adapting to node failure in sensor network query processingThe typical nodes used in mote-level wireless sensor networks (WSNs) are often brittle and severely resource-constrained. In particular, nodes are often battery-powered, thereby making energy depletion a significant risk. When changes to the connectivity graph occur as a result of node failure, the overall computation may collapse unless it is capable of adapting to the new WSN state. Sensor network query processors (SNQPs) construe a WSN as a distributed, continuous query platform where the streams of sensed values constitute the logical extents of interest. Crucially, in the context of this paper, they must make assumptions about the connectivity graph of the WSN at compile time that are likely not to hold for the lifetime of the compiled query evaluation plans (QEPs) the SNQPs generate. This paper address the problem of ensuring that a QEP continues to execute even if some nodes fail. The goal is to extend the lifetime of the QEP, i.e., the period during which it produces results, beyond the point where node failures start to occur. We contribute descriptions of two different approaches that have been implemented in an existing SNQP and present experimental results indicating that each significantly increases the overall lifetime of a query compared with non adaptive approach.","Diversity in Classifier Ensembles: Fertile Concept or Dead End? ","Engineering Business Processes: Comparing Prescriptive Guidelines from EO and NSBP ","Computational Intelligence Methods Based Design of Closed-Loop System ","Topic Model Kernel: An Empirical Study towards Probabilistically Reduced Features for ClassificationProbabilistic topic models have become a standard in modern machine learning with wide applications in organizing and summarizing 'documents' in high-dimensional data such as images, videos, texts, gene expression data, and so on. Representing data by dimensional reduction of mixture proportion extracted from topic models is not only richer in semantics than bag-of-word interpretation, but also more informative for classification tasks. This paper describes the Topic Model Kernel TMK, a high dimensional mapping for Support Vector Machine classification of data generated from probabilistic topic models. The applicability of our proposed kernel is demonstrated in several classification tasks from real world datasets. We outperform existing kernels on the distributional features and give the comparative results on non-probabilistic data types.","Pairwise Similarity for Line Extraction from Distorted ImagesClustering a given set of data is crucial in many fields in- cluding image processing. It plays important roles in image segmenta- tion and object detection for example. This paper proposes a framework of building a similarity matrix for a given dataset, which is then used for clustering the dataset. The similarity between two points are defined based on how other points distribute around the line connecting the two points. It can capture the degree of how the two points are placed on the same line. The similarity matrix is considered as a kernel matrix of the given dataset, and based on it, the spectral clustering is performed. Clustering with the proposed similarity matrix is shown to perform well through experiments using an artificially designed problem and a real- world problem of detecting lines from a distorted image.","Insiders Trapped in the Mirror Reveal Themselves in Social MediaSocial media have widened society's opportunities for communicati- on, while they offer ways to perform employees' screening and profiling. Our goal in this paper is to develop an insider threat prediction method by (e)valuat- ing a users' personality trait of narcissism, which is deemed to be closely con- nected to the manifestation of malevolent insiders. We utilize graph theory tools in order to detect influence of and usage deviation. Then, we categorize the users according to a proposed taxonomy. Thus we detect individuals with nar- cissistic characteristics and manage to test groups of people under the prism of group homogeneity. Furthermore, we compare and classify users to larger sub- communities consisting of people of the same profession. The analysis is based on an extensive crawling of Greek users of Twitter. As the application of this method may lead to infringement of privacy rights, its use should be reserved for exceptional cases, such as the selection of security officers or of critical in- frastructures decision-making staff.","A method for DEVS simulation of e-commerce processes for integrated business and technology evaluation (WIP)Performance evaluation of electronic commerce processes requires an integrated vision of the capacities offered by computational resources, website functionalities, and resulting financial outcomes. Simulation allows trying out alternative business configurations before implementation. This requires a method that articulates models construction of business and technological resources. DEVS is a modeling framework for discrete event simulation based on systems theory, with resources to model complexity and stochastic behavior. This work is intended to propose a DEVS models design method for simulating electronic commerce processes. This method is implemented in DEVSJAVA tool and is proved by developing a B2C real case study involving a retail company of electronic items, information technology, and household goods.","A Film-Type Vibrotactile Actuator for Hand-Held DevicesVibrotactile actuators for small consumer electronic products, such as mobile devices, have been widely used for conveying haptic sensation to users. One of the most important things in vibrotactile actuators is to be developed in the form of thin actuator which can be easily embedded into mobile devices and to provide vibrotactile signals with wide frequency band to users. Thus, this paper proposes a thin film type haptic actuator with an aim to convey vibrotactile information with high frequency bandwidth to users in mobile devices. To this end, a vibrotactile actuator which creates haptic sensation is designed and constructed based on cellulose acetate material. A cellulose acetate material charged with an electric potential can generate vibration under the AC voltage input. It is found that the motion of the actuator can have concave or convex shape by controlling a polarity of both charged membranes and the actuator performance can be modulated by increasing level of biased electric potential. The experiment clearly shows that the proposed actuator creates enough output force to stimulate human skin with a large frequency bandwidth and to simulate various vibrotactile sensations to users.","The role of complex network dynamics in the emergence of multiagent coalitionEmergence of a single coalition among self-interested agents operating on large scale-free networks is a challenging task. Many existing approaches assume a given static network platform and do not use the network dynamics to facilitate the dynamics of agent interactions. In this paper, we present a decentralized game-theoretic approach to this single coalition emergence problem in which agent communications are limited only to their immediate neighbors. Our coalition emergence algorithm is based on the heuristic that agents benefit by forming coalitions with wealthy (higher payoff) and influential (higher accumulated coupling strength) neighbors. Simulation results show that the emergence phenomenon is significantly enhanced when the topological insights, such as increasing degree-heterogeneity and clustering, are embedded into the agent partner selection strategy.","Identifying Overlapping Communities and Their Leading Members in Social Networks ","Real-Time Marker-Free Patient Registration and Image-Based Navigation Using Stereovision for Dental SurgerySurgical navigation techniques have been evolving rapidly in the field of oral and maxillofacial surgery (OMS). However, challenges still exist in the current state of the art of computer-assisted OMS especially from the viewpoint of dental surgery. The challenges include the invasive patient regis- tration procedure, the difficulty of reference marker attachment, navigation error caused by patient movement, bulky optical markers and maintenance of line of sight for commercial optical tracking devices, inaccuracy and suscepti- bility of electromagnetic (EM) sensors to magnetic interference for EM tracking devices. In this paper, a new solution is proposed to overcome the mentioned challenges. A stereo camera is designed as a tracking device for both instrument tracking and patient tracking, which is customized optimally for the limited surgical space of dental surgery. A small dot pattern is mounted to the surgical tool for instrument tracking, which can be seen by the camera at all times during the operation. The patient registration is achieved by patient tracking and 3D contour matching with the preoperative patient model, requiring no fiducial marker and reference marker. In addition, the registration is updated in real-time. Experiments were performed to evaluate our method and an average overall error of 0.71 mm was achieved.","Addressing animated transitions already in mobile app storyboardsAnimated transitions are key elements that contribute to the user experience (UX) of mobile Apps. Unfortunately, animated transitions are usually addressed too late in software development. We recommend to consider animated transitions already during user interface (UI) storyboarding. Typically, UI storyboards do not address the kind of transition, they focus on the screens and visualize a transition just with a simple arrow. Therefore, we investigated the leading mobile phone operating systems iOS 5, Windows Phone 7.5 and Android 4 with respect to their utilization of animated transitions. We developed a catalog consisting of 21 different types of animated transitions. Based on this catalog of 21 different types of animated transition we developed a vocabulary of 66 simple icons. These icons enhance the abilities of storyboards to the extent that they are now able to illustrate animated transitions.","Modeling situation-dependent nonverbal expressions for a pair of embodied agent in a dialogue based on conversations in TV programsMathematical model for controlling nonverbal expressions of a pair of embodied agents designed for presenting various information through their dialogue is discussed. Nonverbal expressions of a human during conversation with others depend on those of them as well as the situation of the conversation. The proposed model represents the relationship between nonverbal expressions of a pair of embodied agents in different situations of conversation by a constraint function, so that the nonverbal expression of each agent reproduces the characteristic of nonverbal expressions observed in human conversation with various situations in TV programs by minimizing the function.","Faster GPU-Accelerated Smith-Waterman Algorithm with Alignment Backtracking for Short DNA Sequences ","Rhythms of the domestic soundscape: Ethnomethodological soundwalks for phatic technology designThe importance of the domestic soundscape as a context for technological interventions has received little attention in HCI research. In this paper, we discuss how an ethnomethodological soundwalk method facilitated design principles for a phatic technology probe for seniors living alone. Taking soundscape concepts as a starting point, we suggest that the soundwalk works much like a breaching experiment, changing the participant's role in engaging with their soundscape from reactive automatic agent to proactive reflective agent. This enables participants to reveal their own systematic orderliness when accounting for everyday sounds. We find that sounds are accounted for in terms of people placed in narratives. As such, we argue that phatic technologies use new sounds and rhythms to augment the domestic soundscape to take advantage of people's abilities to create social narratives from limited cues.","The Kendall Rank Correlation between Intuitionistic Fuzzy Sets: An Extended Analysis ","Implications of Internet Governance Issues for the end Users ","Learning Sequences: An Efficient Data Structure for Learning Spaces ","Ontology-Based Model and Procedure Creation for Topic Analysis in Chinese Language ","Quicker Similarity Joins in Metric SpacesWe consider the join operation in metric spaces. Given two sets A and B of objects drawn from some universe    $\\mathbb U$   , we want to compute the set    $A \\Join B = \\{a,b \\in A \\times B\\;|\\;da,b \\leq r\\}$    efficiently, where    $d : \\mathbb U \\times \\mathbb U \\to \\mathbb R^+$    is a metric distance function and r\u2208\u211d+ is user supplied query radius. In particular we are interested in the case where we have no index available nor we can afford to build it for either A or B. In this paper we improve the Quickjoin algorithm Jacox and Samet, 2008, based on the well-know Quicksort algorithm, by i replacing the low level component that handles small subsets with essentially brute-force nested loop with a more efficient method; ii showing that, contrary to Quicksort, in Quickjoin unbalanced partitioning can improve the algorithm; and iii making the algorithm probabilistic while still obtaining most of the relevant results. We also show how to use Quickjoin to compute k-nearest neighbor joins. The experimental results show that the method works well in practice.","Learning without Labeling: Domain Adaptation for Ultrasound Transducer Localization ","Application and Study of Three in One Gas Forecast Technology in Non-excavated Area of Gas TunnelThe super colossal gas explosion accident happened in Dong-Jiashan tunnel of Du (Jiangyan) - Wen (Chuan) expressway, 2005. It led 44 people to die and shocked at home and abroad. From then on, increasing numbers public and the related functional sectors have paid more attention to gas safety managements during the gas tunnel excavated. It is well known gas existence in stratum should meet three necessary conditions, gas sources, channels and sealing conditions. The gas forecast technology by TGP geophysical, geological drilling and borehole gas emission content estimate composed can predict the gas sources and gas channels and gas sealing conditions. The borehole gas emission content estimate can predict the gas content in non-excavated area of gas tunnel. It is successfully applied to the non-excavated area of Le-Tunnel, the gas emission content: 0.164m 3 /min&lt;0.5m 3 /min. The forecast segment belongs to the low gas work area. Practice has proved that the three in one gas forecast technology can offer a further reference method for the same type of gas tunnel prediction technology.","On Two Approaches to Constructing Optimal Algorithms for Multi-objective Optimization ","Overview of Hyperspectral Remote Sensing of Impervious Surfaces in Urban EnvironmentIn this paper we provide a concise overview of hyperspectral studies of impervious surface in urban environment. We highlight socio-ecological impact of urban conglomerate on the surroundings. We present few important techniques of material detection using spectral matching methods - a unique opportunity provided by hyperspectral data. The paper then discusses signatures of urban materials and reviews how various investigators have utilized hyperspectral data to study impervious surface in urban area.","A Formal Characterization of the Outcomes of Rule-Based Argumentation SystemsRule-based argumentation systems are developed for reasoning about defeasible information. As a major feature, their logical language distinguishes between strict rules and defeasible ones. This paper presents the first study on the outcomes of such systems under various semantics such as naive, stable, preferred, ideal and grounded. For each of these semantics, it characterizes both the extensions and the set of plausible inferences drawn by these systems under a few intuitive postulates.","Exploiting thermal coupling information in MPSoC dynamic thermal managementTemperature profile optimization is one of the most relevant and challenging problems in modern multi-core architectures. Several Dynamic Thermal Management approaches have been proposed in literature, and run-time policies have been designed to direct the allocation of tasks according to temperature constraints. Thermal coupling is recognized to have a role of paramount importance in determining the thermal envelope of the processor, nevertheless several works in literature do not take directly into account this aspect while determining the status of the system at run-time. Without this information, the DTM design is not able to fully redistribute the roles that each core have on the system-level temperature, thus neglecting important information for temperature-constrained workload allocation.#R##N##R##N#Purpose of this work is to provide a novel mechanism to better support DTM policies, focusing on the estimation of the impact of thermal coupling in determining the appropriate status from a thermal stand-point. The presented approach is based on two stages: off-line characterization of the target architecture estimates thermal coupling coefficients, that will be used at run-time for proper DTM decisions.","Human Adaptation, Plasticity and Learning for a New Sensory-Motor World in Virtual Reality ","Designing Educational Interfaces for Saudi Students ","A hybrid topology discovery protocol for mobile backhaulIn this paper, we propose a hybrid topology discovery protocol for mobile backhaul. As a distributed neighbor discovery protocol, we use IEEE 802.1AB LLDP protocol. For collecting the neighbor information and topology construction, we utilize a centralized control and management control protocol as an extension of PCEP protocol (RFC 5440). We demonstrate the efficiency of the proposed protocol on an emulated test-bed.","UW SPF: The University of Washington Semantic Parsing FrameworkThe University of Washington Semantic Parsing Framework (SPF) is a learning and inference framework for mapping natural language to formal representation of its meaning.","Future Directions and New Technology in Peritoneal Dialysis ","Consumer Learning to Promote Behavioral Intention Toward IT Innovation: Is Word of Mouth Needed?Adoption of innovation is an on-going process involving persuasive communication and learning. However, the idea of marketing of IT innovation from consumer learning perspective has long been neglected. Based on consumer learning theory, we develop a model suggesting that word of mouth (WOM) stimulates individual consumers\u2019 learning and in turn affect their intention to adopt mobile payment. Data about users and potential users of mobile payment was collected from China through a questionnaire survey. The results indicate that consumers first sense the WOM and obtain relevant information from the surrounding environment. Their information searching will affect their perceived knowledge and self-efficacy about mobile payment. Then attitude about mobile payment is formed, which in turn, affects their behavioral intention toward mobile payment. Differences of model path coefficients between users and potential users of mobile payment are explored, and implications and limitations are also discussed.","Dynamic Tangible User Interface PalettesGraphics editors often suffer from a large number of tool palettes that compete with valuable document space. To address this problem and to bring back physical affordances similar to a painter's palette, we propose to augment a digital tabletop with spatially tracked handheld displays. These displays are dynamically updated depending on their spatial location. We introduce the con- cept of spatial Work Zones that take up distinct 3D regions above the table sur- face and serve as physical containers for digital content that is organized as stacks of horizontal layers. Spatial Work Zones are represented either by physi- cal objects or on-screen on the tabletop. Associated layers can be explored fluently by entering a spatial Work Zone with a handheld display. This provides quick access and seamless changes between tools and parts of the document that are instantly functional, i.e., ready to be used by a digital pen. We discuss several use cases illustrating our techniques and setting them into context with previous systems. Early user feedback indicates that combining dynamic GUI functionality with the physicality of spatially tracked handheld displays is promising and can be generalized beyond graphics editing.","Exploiting the diversity of user preferences for recommendationDiversity as a quality dimension for Recommender Systems has been receiving increasing attention in the last few years. This has been paralleled by an intense strand of research on diversity in search tasks, and in fact converging views on diversity theories and techniques from Information Retrieval and Recommender Systems have been put forward in recent work. In this paper we research diversity not only as a target property for a recommender system, but as an element in the input data, within and between user behaviors, that a recommender system can leverage to enhance the quality of its output in terms of the balance between accuracy and diversity. We propose an adaptation of search result diversification methods to recommender systems based on query reformulation: we identify the diversity within user profiles and generate partial recommendations based on homogeneous subsets of user preferences (sub-profiles), which we combine later to produce a final recommendation. We report experiments on movie and music recommendation datasets showing that our approach improves indeed the quality of state-of-the-art recommenders, and is competitive against diversification methods that use explicitly item categories as the units for diversification. Our approach shows further advantages in cases where the high cardinality of the explicit category spaces can pose a problem in terms of computational cost.","Medical Ontology Validation through Question Answering ","Durative Graph Transformation Rules for Modelling Real-Time Reconfiguration ","Indoor Augmented Reality Based on Ultrasound Localization SystemsAugmented reality applications are beginning to reach the general public due to the widespread use of smartphones and tablet devices. Most AR systems require the use of image processing techniques to superimpose the vir- tual information over the image of the real world. However, this may quickly consume the battery of the user's device. In this paper, we design and imple- ment an AR system for indoor environments that relies on an external ultra- sound localization system and on the inertial sensors embedded in the device to estimate the position and orientation of the user. The system was implemented on a tablet device, offers several functionalities, such as visualization of virtual objects and interaction with the virtual view, and aims at providing appropriate accuracy for a satisfactory user experience without the need of using costly vision-based techniques.","Model identification of an unmanned helicopter using ELSSVMThe dynamic model of unmanned helicopter is a coupled nonlinear system. With respect to the identification problem for this model, extended least squares support vector machine (ELSSVM) is proposed. ELSSVM extends the solution space of structure parameters to improve the convergence performance. Base width of kernel function and regularization parameter of ELSSVM are minimized by differential evolution (DE). As compared to the traditional identification method for helicopter dynamic model, the proposed method omits the linear process and the trained model is closer to the helicopter dynamic model. The data-driven based experiments show that the proposed method takes a short training time and has a high identification accuracy.","Video exploration tool based on semantic networkWe present a browser and an effective retrieval video system based on semantic network. The semantic network is given by a similarity distance computation between the elements of the video data corpus. The similarity distance is obtained by combination between conceptual similarity and contextual similarity.","Massive media event data analysis to assess world-wide political conflict and instabilityMining massive daily news media data to infer patterns of cultural trends, including political conflicts and instabilities, is an important goal of computational social science and the new interdisciplinary field called \"culturnomics.\" While the sheer size of media data makes this task challenging, a greater hurdle is the nonstationarity of data, manifested in several ways, which invalidates surge in media coverage as a reliable indicator of political change. We demonstrate the use of advanced statistical, information-theoretic, and random fractal methods to analyze CAMEO-encoded political events data. In particular, we show that on the country level, event distributions obey a Zipf-Mandelbrot law, and interactions among countries follow an exponential law, indicating that local or prioritized events dominate the political environment of a country. Most importantly, we find that world-wide political instabilities, such as the Arab Spring, are associated with breakdown or enhancement of long-range correlations in political events.","Discovering patterns in social networks with graph matching algorithmsSocial media data are amenable to representation by directed graphs. A node represents an entity in the social network such as a person, organization, location, or event. A link between two nodes represents a relationship such as communication, participation, or financial support. When stored in a database, these graphs can be searched and analyzed for occurrences of various subgraph patterns of nodes and links. This paper describes an interactive visual interface for constructing subgraph patterns called the Graph Matching Toolkit (GMT). GMT searches for subgraph patterns using the Truncated Search Tree (TruST) graph matching algorithm. GMT enables an analyst to draw a subgraph pattern and assign labels to nodes and links using a mouse and drop-down menus. GMT then executes the TruST algorithm to find subgraph pattern occurrences within the directed graph. Preliminary results using GMT to analyze a simulated collection of text communications containing a terrorist plot are reported.","Leveraging arabic-english bilingual corpora with crowd sourcing-based annotation for arabic-hebrew SMTRecent studies in Statistical Machine Translation (SMT) paradigm have been focused on developing foreign language to English translation systems. However as SMT systems have matured, there is a lot of demand to translate from one foreign language to another language. Unfortunately, the availability of parallel training corpora for a pair of morphologically complex foreign languages like Arabic and Hebrew is very scarce. This paper uses active learning based data selection and crowd sourcing technique like Amazon Mechanical Turk to create Arabic-Hebrew parallel corpora. It then explores two different techniques to build Arabic-Hebrew SMT system. The first one involves the traditional cascading of two SMT systems using English as a pivot language. The second approach is training a direct Arabic-Hebrew SMT system using sentence pivoting. Finally, we use a phrase generalization approach to further improve our performance.","Performance evaluation over indoor channels of an unsupervised decision-aided method for OSTBC systemsUnsupervised algorithms can be used in digital communications to estimate the channel at the receiver without using pilot symbols, thus obtaining a considerable improvement in terms of data rate, spectral efficiency, and energy consumption. Unfortunately, the computational load is considerably high since they require to estimate Higher Order Statistics. For addressing this issue, it has been recently presented a decision-aided channel estimation strategy, which implemented a decision rule to determine if a new channel estimate was required or not. If channel estimation is not needed, a previous estimate was used to recover the transmitted signals. Based on this idea, we propose a lower-complexity decision criterion and we evaluate its performance over real-world indoor channels measured using a hardware platform working at the Industrial, Scientific and Medical band at 5 GHz.","CPK Based IO AC Timing Closure to Reduce Yield Loss and Test Time ","Sparse Uncorrelated Linear Discriminant AnalysisIn this paper, we develop a novel approach for sparse uncorrelated linear discriminant analysis (ULDA). Our proposal is based on characterization of all solutions of the generalized ULDA. We incorporate sparsity into the ULDA transformation by seeking the solution with minimum l1-norm from all minimum dimension solutions of the generalized ULDA. The problem is then formulated as a l1-minimization problem and is solved by accelerated linearized Bregman method. Experiments on high-dimensional gene expression data demonstrate that our approach not only computes extremely sparse solutions but also performs well in classification. Experimental results also show that our approach can help for data visualization in low-dimensional space.","Topicaliazation in the Model of Sentence FormationThis paper explains Chinese topicalization phenomena from the perspective of the process of sentence formation. We propose a presupposed flow chart model to show the process by which the speaker arranges information materials into a sentence and explain many kinds of topic phenomena on it. We consider that topic itself is a complex component which exists in many layers in the sentence formation process, so we can get several different points of view on it. The so called \"topicalization\" is the process in which topic emerges from the information layer to the functional layer, the syntactic forms layer and the phonology layer one by one. This model not only explains the phenomena of topic but also can provides a theoretical basis for natural language processing.","Organizational design of innovative education: insights from a combined design and action research projectThis research aims to contribute to an emerging area of organizational design research, focusing on educational innovation. Our contribution comes in a form of an innovative organizational design solution for on-campus large lecture instruction, here named the Team Net Based Learning (TNBL) model, designed by the author and later independently adopted by other educators. The paper reports on a combined design and action research project of initiating, designing, implementing and evaluating the TNBL model (design research artifact), over a period of two years in a real-life setting, from a standpoint of a reflective practitioner/designer, engaged in action research in the context of her own practice. The model continues to be used to this day. Even though this project was implemented in the information systems domain, the main design artifact is discipline- and content- agnostic, and as such could be used in any other discipline. The outcomes of this research further strengthen the argument previously made by organization studies researchers that scholars researching organization systems and processes can use their knowledge and experience to organise and manage student activities.","3D segmentation of curved needles using doppler ultrasound and vibrationA method for segmenting the 3D shape of curved needles in solid tissue is described. An actuator attached to the needle outside the tissue vibrates at frequencies between 600 Hz and 6500 Hz, while 3D power Doppler ultrasound imaging is applied to detect the resulting motion of the needle shaft and surrounding tissue. The cross section of the vibrating needle is detected across the series of 2D images produced by a mechanical 3D ultrasound transducer, and the needle shape is reconstructed by fitting a 3D curve to the resulting points. The sensitivity of segmentation accuracy to tissue composition, vibration frequency, and Doppler pulse repetition frequency (PRF) was examined. Comparison with manual segmentation demonstrates that this method results in an average error of 1.09 mm in ex vivo tissue. This segmentation method may be useful in the future for providing feedback on curved needle shape for control of robotic needle steering systems.","Guided Depth Enhancement via Anisotropic DiffusionIn this paper, we propose to conduct inpainting and upsampling for defective depth maps when aligned color images are given. These tasks are referred to as the guided depth enhancement problem. We formulate the problem based on the heat diffusion framework. The pixels with known depth values are treated as the heat sources and the depth enhancement is performed via diffusing the depth from these sources to unknown regions. The diffusion conductivity is designed in terms of the guidance color image so that a linear anisotropic diffusion problem is formed. We further cast the steady state problem of this diffusion into the famous random walk model, by which the enhancement is achieved efficiently by solving a sparse linear system. The proposed algorithm is quantitatively evaluated on the Middlebury stereo dataset and is applied to inpaint Kinect data and upsample Lidar's range data. Comparisons to the commonly used bilateral filter and Markov Random Field based methods are also presented, showing that our algorithm is competent.","Transducer-based speech recognition with dynamic language models. ","A Fuzzy Filter for High-Density Salt and Pepper Noise Removal ","Imagen: runtime migration of browser sessions for javascript web applicationsDue to the increasing complexity of web applications and emerging HTML5 standards, a large amount of runtime state is created and managed in the user's browser. While such complexity is desirable for user experience, it makes it hard for developers to implement mechanisms that provide users ubiquitous access to the data they create during application use. This paper presents our research into browser session migration for JavaScript-based web applications. Session migration is the act of transferring a session between browsers at runtime. Without burden to developers, our system allows users to create a snapshot image that captures all runtime state needed to resume the session elsewhere. Our system works completely in the JavaScript layer and thus snapshots can be transfered between different browser vendors and hardware devices. We report on performance metrics of the system using five applications, four different browsers, and three different devices.","An Ant Colony Optimization Algorithm for the Min-Degree Constrained Minimum Spanning Tree ProblemGiven a connected edge-weighted undirected graph, the min-degree constrained minimum spanning tree (MDCMST) problem seeks on this graph a spanning tree of least cost in which every non-leaf node have a degree of at least d in the spanning tree. This problem is    $\\mathcal{NP}$   -Hard for    $3 \\leq d \\leq \\lfloor \\frac{n}{2} \\rfloor$    where n is the number of nodes in the graph. In this paper, we have proposed an ant colony optimization based approach to this problem. The proposed approach has been tested on Euclidean and random instances both. Computational results show the effectiveness of the proposed approach.","Mobile User Authentication Scheme Based on Minesweeper Game ","Development and evaluation of a mobile search system for science experiments to connect school knowledge to common knowledgeIn this paper, we propose a method that connects school knowledge to common knowledge through a mobile search system that enables users to think about and perform science experiments relevant to their everyday life. We developed the system and tested it in an evaluation experiment with 15 participants who used the system in everyday life over the course of a week. The evaluation results revealed that the users began to consider appropriate experiments, describe appropriate locations, and understand scientific concepts and methods. Participants' questionnaire responses showed that they became interested in science experiments and formed a strong connection between school knowledge and common knowledge.","Obstacle Avoidance Based on Plane Estimation from 3D Edge Points by Mobile Robot Equipped with Omni-directional Camera ","Fuzzy Clustering of Image Pixels with a Fitness-Based Adaptive Differential Evolution ","A fuzzy logic based reputation model against unfair ratingsReputation systems have become more and more important in facilitating transactions in online systems. However, the accuracy of reputation systems has always been a concern for the users due to the existence of unfair ratings. Though many approaches have been proposed to mitigate the adverse effect of unfair ratings, most of them use the credibility of the rating provider alone to decide whether the rating is unfair without considering other aspects of the rating itself. Models that do consider multiple aspects often combine them through arbitrarily set weights. Therefore, they cannot work well when the credibility is not evaluated accurately or when the weights are not set properly. To resolve this problem, in this paper, we propose a reputation model which considers and combines the temporal, similarity and quantity aspects of the user ratings based on fuzzy logic to improve the accuracy of reputation evaluation. Experimental results based on a set of real user data from a cyber competition show that the proposed model is more robust against unfair ratings than the existing approaches, especially under Sybil attack conditions.","Reifying Concurrency for Executable MetamodelingCurrent metamodeling techniques can be used to specify the syntax and semantics of domain specific modeling languages (DSMLs). However, there is currently very little support for explicitly specifying concurrency semantics using metamodels. Often, such semantics are provided through implicit concurrency models embedded in the underlying execution environment supported by the language workbench used to implement the DSMLs. The lack of an explicit concurrency model has several drawbacks: it not only prevents from developing a complete understanding of the behavioral semantics, it also prevents development of effective concurrency-aware analysis techniques, and effective techniques for producing semantic variants in the cases where the semantic base has variation points. This work reifies concurrency as a metamodeling facility, leveraging formalization work from the concurrency theory and models of computation (MoC) community. The essential contribution of this paper is a proposed language workbench for binding domain-specific concepts and models of computation through an explicit event structure at the metamodel level. We illustrate these novel metamodeling facilities for designing two variants of a concurrent and timed final state machine, and provide other experiments to validate the scope of our approach.","File Fragment Analysis Using Normalized Compression DistanceThe first step when recovering deleted files using file carving is to identify the file type of a block, also called file fragment analysis. Several researchers have demonstrated the applicability of Kolmogorov complexity methods such as the normalized compression distance (NCD) to this problem. NCD methods compare the results of compressing a pair of data blocks with the compressed concatenation of the pair. One parameter that is required is the compression algorithm to be used. Prior research has identified the NCD compressor properties that yield good performance. However, no studies have focused on its applicability to file fragment analysis. This paper describes the results of experiments on a large corpus of files and file types with different block lengths. The experimental results demonstrate that, in the case of file fragment analysis, compressors with the desired properties do not perform statistically better than compressors with less computational complexity.","MASFA: mass-collaborative faceted search for online communitiesFaceted search combines faceted navigation with direct keyword search, providing exploratory search capacities allowing progressive query refinement. It has become the de facto standard for e-commerce and product-related websites such as amazon.com and ebay.com. However, faceted search has not been effectively incorporated into non-commercial online community portals such as craigslist.org. This is mainly because unlike keyword search, faceted search systems require metadata that constantly evolve, making them very costly to build and maintain. In this paper, we propose a framework MASFA that utilizes a set of non-domain-specific techniques to build and maintain effective, portable, and cost-free faceted search systems in a mass-collaborative manner. We have implemented and deployed the framework on selected categories of Craigslist to demonstrate its utility.","Measuring Supportiveness of the Internet and Mobile Platforms for Personalized Ad ","Concurrent process planning and scheduling applied into production of turned parts\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd!\ufffd\" \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \"\ufffd\ufffd\ufffd\ufffd\ufffd #\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd$\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd %\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \"\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd&amp;\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \"\ufffd\ufffd\ufffd%\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd $\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd '\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd [%]","Example based entity search in the web of dataThe scale of today's Web of Data motivates the use of keyword search-based approaches to entity-oriented search tasks in addition to traditional structure-based approaches, which require users to have knowledge of the underlying schema. We propose an alternative structure-based approach that makes use of example entities and compare its effectiveness with a text-based approach in the context of an entity list completion task. We find that both the text and structure-based approaches are effective in retrieving relevant entities, but that they find different sets of entities. Additionally, we find that the performance of the structure-based approach is dependent on the quality and number of example entities given. We experiment with a number of hybrid techniques that balance between the two approaches and find that a method that uses the example entities to determine the weights of approaches in the combination on a per query basis is most effective.","A Type-2 FML-Based Meeting Scheduling Support SystemScheduling meetings in organizations involves many considerations such as scheduling conflicts and even personal preferences. The host of an organizational meeting typically expends substantial time conferring with potential attendees to determine the optimal time slot. To minimize the time and effort required for this scheduling process, this chapter introduces a novel type-2 FML-based personal ontology, a type-2 meeting scheduling ontology, and a decision supported system. The Fuzzy markup language (FML) is also used to describe the knowledge base and rule base of the proposed meeting scheduling system, and a fuzzy inference mechanism is then used to infer the probability of attendance for each potential attendee. Finally, the system generates a semantic description that indicates the estimated probability of attendance for each potential attendee. The experimental results show that the proposed approach is feasible for meeting scheduling.","Bone tumor resection: analysis about 3D preoperative planning and navigation method using a virtual specimen. ","Computing Entry-Wise Bounds of the Steady-State Distribution of a Set of Markov Chains ","Partitioning Approach to Collocation Pattern Mining in Limited Memory Environment Using Materialized iCPI-Trees ","Sequential Monte Carlo Tracking for Marginal Artery Segmentation on CT Angiography by Multiple Cue FusionIn this work we formulate vessel segmentation on contrast-enhanced CT angiogram images as a Bayesian tracking problem. To obtain posterior probability estimation of vessel location, we employ sequential Monte Carlo tracking and propose a new vessel segmentation method by fusing multiple cues extracted from CT images. These cues include intensity, vesselness, organ de- tection, and bridge information for poorly enhanced segments from global path minimization. By fusing local and global information for vessel tracking, we achieved high accuracy and robustness, with significantly improved precision compared to a traditional segmentation method (p=0.0002). Our method was applied to the segmentation of the marginal artery of the colon, a small bore vessel of potential importance for colon segmentation and CT colonography. Experimental results indicate the effectiveness of the proposed method.","A Novel Graph Based Clustering Technique for Hybrid Segmentation of Multi-spectral Remotely Sensed ImagesThis paper proposes a novel unsupervised graph based clustering method for the purpose of hybrid segmentation of multi-spectral satellite images. In hybrid image segmentation framework, the source image is initially (over)segmented while preserving the fine image details. A region merging strategy has to be adopted next for further refinement. Here mean-shift (MS) based technique has been considered for initially segmenting the source image as it performs edge preserving smoothing beforehand hence eliminates noise. The objects found after this step are merged together in a low-level image feature space using the proposed graph based clustering algorithm. A graph topology combining k-nearest-neighbor (KNN) and minimum spanning tree has been considered on which the proposed iterative algorithm has been applied to eliminate the edges which span different clusters. It results in a set of connected components where each component represents a separate cluster. Comparison with two other hybrid segmentation techniques establishes the comparable accuracies of the proposed framework.","Adaptive NN tracking control of double inverted pendulums with input saturationIn this paper, the adaptive control problem with input saturation is investigated for double inverted pendulums. Based on Lyapunov stability theory and backstepping technique, incorporating dynamic surface control (DSC) technique into neural network based adaptive control, an adaptive neural controller is developed by explicitly considering uncertainties, unknown disturbances and input saturation. An auxiliary system is presented to tackle input saturation, and the states of auxiliary design system are utilized to develop the tracking control. It is proved that all the signals in the closed-loop system are uniformly ultimately bounded (UUB) via Lyapunov analysis. Finally, simulation studies are given to demonstrate the effectiveness of the proposed method.","Set Distance Functions for 3D Object RecognitionOne of the key steps in 3D object recognition is the matching between an input cloud and a cloud in a database of known objects. This is usually done using a distance function between sets of descriptors. In this paper we propose to study how several distance functions some already available and other new proposals behave experimentally using a large freely available household object database containing 1421 point clouds from 48 objects and 10 categories. We present experiments illustrating the accuracy of the distances both for object and category recognition and find that simple distances give competitive results both in terms of accuracy and speed.","Efficient Querying of Correlated Uncertain Data with Cached ResultsAlthough there have been many efforts for management of uncertain data, evaluating probabilistic inference queries, a known NP- hard problem, is still a big challenge, especially for querying data with highly correlations. The state-of-art exact algorithms for accelerating the evaluation of inference queries are based on special indices. Besides, with the observation of the existence of many frequent queries, some researchers try to improve efficiency by reusing previously queried re- sults. Indexing depends on the static properties like data distributions, whereas caching is in favor of the dynamic features like query workload. In this paper we propose a new approach for speeding up the evaluation of inference queries by caching frequent results in a junction tree-based hierarchical index. To the best of our knowledge, this is the first effort on utilizing both the static (data) and dynamic (query workload) properties to efficiently evaluate probabilistic inference queries. Moreover, according to our experience, different caching strategies may significantly affect the query performance. Basically a good caching strategy needs to have high cache hit ratio with limited space budget.Based on these considerations, we propose a novel caching approach, called FVEC, and present corre- sponding algorithms for efficiently querying correlated uncertain data. We further conduct a series of extensive experiments on large uncertain datasets in order to illustrate the effectiveness and efficiency of our pro- posed approaches. As illustrated by the results, compared with previous solutions, our method could greatly improve the query performance.","The Program Download Problem: Complexity and AlgorithmsIn this paper, we consider the Program Download Problem (PDP) which is to download a set of desired programs from multiple channels. When the problem is to decide whether the download can be done by a given deadline d and each program appears in each of the n channels at most once, denoted as PDP(n, 1,d), we prove that PDP(n, 1,d) is NP-Complete by a reduction from 3-SAT(3). We can extend the NP-hardness proof to PDP(2, 2,d) where there are only two channels but each program could appear in each channel at most twice. We show that the aligned version of the problem (APDP) is polynomi- ally solvable by reducing it to a maximum flow problem. For a different version of the problem, MPDP, where the objective is to maximize the number of program downloaded before a given deadline d ,w e prove that it is fixed-parameter tractable.","Multiscale discriminant saliency for visual attentionThe bottom-up saliency, an early stage of humans' visual attention, can be considered as a binary classification problem between center and surround classes. Discriminant power of features for the classification is measured as mutual information between features and two classes distribution. The estimated discrepancy of two feature classes very much depends on considered scale levels; then, multi-scale structure and discriminant power are integrated by employing discrete wavelet features and Hidden markov tree (HMT). With wavelet coefficients and Hidden Markov Tree parameters, quad-tree like label structures are constructed and utilized in maximum a posterior probability (MAP) of hidden class variables at corresponding dyadic sub-squares. Then, saliency value for each dyadic square at each scale level is computed with discriminant power principle and the MAP. Finally, across multiple scales is integrated the final saliency map by an information maximization rule. Both standard quantitative tools such as NSS, LCC, AUC and qualitative assessments are used for evaluating the proposed multiscale discriminant saliency method (MDIS) against the well-know information-based saliency method AIM on its Bruce Database wity eye-tracking data. Simulation results are presented and analyzed to verify the validity of MDIS as well as point out its disadvantages for further research direction.","Density-Based Clustering in Cloud-Oriented Collaborative Multi-Agent SystemsThe development of new reliable data processing and min- ing methods based on the synergy between cloud computing and the multi-agent paradigm is of great importance for contemporary and fu- ture software systems. Cloud computing provides huge volumes of data and computational resources, whereas the agents make the system com- ponents more autonomous, cooperative, and intelligent. This creates the need and gives a very good basis for the development of data analysis, processing, and mining methods to enhance the new agent-based cloud computing (ABCC) architecture. Ad-hoc networks of virtual agents are created in the ABCC architecture to support the dynamic functionality of provided services, and data processing methods are very important at the input data processing and network parameter estimation stage. In this study, we present a decentralized kernel-density-based clustering algorithm that fits with the general architecture of ABCC systems. We conduct several experiments to demonstrate the capabilities of the new approach and analyse its efficiency.","Developing the GEA Method - Design Science and Case-Study Research in ActionThis paper is concerned with the research methodology that was used in the GEA (General Enterprise Architecting) research programme. The goal of this programme was the development of a new approach for doing enterprise architecture. We discuss the motivations for starting the GEA programme, its focus, as well as its objectives. Based on this, the research methodology as it was used by the GEA programme is discussed and motivated. This involves a combination of design science and case study based research. The paper also discusses the way the GEA programme went about to actually implement the research methodology in a real-world situation, while also highlighting its results.","Pupil Detection Using Stereo-Matching Method and a Constant Interpupillary Distance Condition for a Solution of Glasses Reflection Problem in the Video-Based Gaze Detection System ","Outsourcing of \u2018On-Site\u2019 User Support \u2013 A Case Study of a European Higher Education Centre ","Discrete Transportation Systems Quality Performance Analysis by Critical States Detection ","From supply chain formation to multi-agent coordinationSupply Chain Formation is the process of determining the participants in a supply chain, who will exchange what with whom, and the terms of the exchanges. Decentralized supply chain formation appears as a highly intricate task because agents only possess local information and have limited knowledge about the capabilities of other agents. The decentralized supply chain formation problem has been recently cast as an optimization problem that can be efficiently approximated using max-sum loopy belief propagation. This mapping can be improved by encoding the problem into a binary factor graph (containing only binary variables) and deriving model-specific equations for max-sum. First, this paper introduces the state-of-the art methods for decentralized supply chain formation. Second, it presents future short-term lines of research in this problem. Finally, it argues that the binary model can be extended to other problems than that of the supply chain formation.","Enabling Cloud Connectivity Using SDN and NFV TechnologiesCloud environments play an important role for network and service providers. Cloud network providers require ubiquitous, broad- band and minimum-delay connectivity from network providers. There are different realizations of cloud connectivity based on the Software De- fined Networking (SDN) and the Network Function Virtualization (NFV) paradigm. In this paper we introduce a new concept based on the OConS architecture developed within the SAIL FP7 project. Our advanced con- nectivity concept focuses on interdomain connectivity.","Smart energy efficient buildings. A Living Lab approachIn this paper we provide an overview of current research trends, challenges and issues in the domain of smart energy efficient buildings. Based on current research and literature we discuss topics like technology integra- tion, semantic interoperability, automation, and the importance of considering user needs. Furthermore, we introduce a living lab approach, which allows us to conduct research on these topics in a real smart building environment. This living lab actually is a system for enabling smart energy efficient building applications, based on a middleware approach. We describe the software design and the real-world deployment of this system in ten rooms of a university and eight rooms of an office building","Human-Computer Interaction and Knowledge Discovery (HCI-KDD): What Is the Benefit of Bringing Those Two Fields to Work Together?A major challenge in our networked world is the increasing amount of data, which require efficient and user-friendly solutions. A timely example is the biomedical domain: the trend towards personalized medicine has resulted in a sheer mass of the generated (-omics) data. In the life sciences domain, most data models are characterized by complexity, which makes manual analysis very time-consuming and frequently practically impossible. Computational methods may help; however, we must acknowledge that the problem-solving knowledge is located in the human mind and - not in machines. A strategic aim to find solutions for data intensive problems could lay in the combination of two areas, which bring ideal pre-conditions: Human-Computer Interaction (HCI) and Knowledge Discovery (KDD). HCI deals with questions of human perception, cognition, intelligence, decision-making and interactive techniques of visualization, so it centers mainly on supervised methods. KDD deals mainly with questions of machine intelligence and data mining, in particular with the development of scalable algorithms for finding previously unknown relationships in data, thus centers on automatic computational methods. A proverb attributed perhaps incorrectly to Albert Einstein illustrates this perfectly: \"Computers are incredibly fast, accurate, but stupid. Humans are incredibly slow, inaccurate, but brilliant. Together they may be powerful beyond imagination\". Consequently, a novel approach is to combine HCI &amp; KDD in order to enhance human intelligence by computational intelligence.","Software Streams: Big Data Challenges in Dynamic Program Analysis ","Design and Interaction in a Smart Gym: Cognitive and Bodily Mastering ","Trismegistos: An Interdisciplinary Platform for Ancient World Texts and Related Information ","Testing the lipschitz property over product distributions with applications to data privacy ","Geodesic Distances to Landmarks for Dense Correspondence on Ensembles of Complex ShapesEstablishing correspondence points across a set of biomedi- cal shapes is an important technology for a variety of applications that rely on statistical analysis of individual subjects and populations. The inherent complexity (e.g. cortical surface shapes) and variability (e.g. cardiac chambers) evident in many biomedical shapes introduce signifi- cant challenges in finding a useful set of dense correspondences. Appli- cation specific strategies, such as registration of simplified (e.g. inflated or smoothed) surfaces or relying on manually placed landmarks, provide some improvement but suffer from limitations including increased com- putational complexity and ambiguity in landmark placement. This paper proposes a method for dense point correspondence on shape ensembles using geodesic distances to a priori landmarks as features. A novel set of numerical techniques for fast computation of geodesic distances to point sets is used to extract these features. The proposed method mini- mizes the ensemble entropy based on these features, resulting in isometry invariant correspondences in a very general, flexible framework.","Exploring Extrinsic Motivation for Better Security: A Usability Study of Scoring-Enhanced Device PairingWe explore the use of extrinsic motivation to improve the state of user-centered security mechanisms. Specifically, we study applications of scores as user incentives in the context of secure device pairing. We develop a scoring functionality that can be integrated with traditional pairing approaches. We then report on a usability study that we performed to evaluate the effect of scoring on the performance of users in comparison operations. Our results demonstrate that individuals are likely to commit fewer errors and show more acceptance when working with the scoring based pairing approach. Framing pairing as a game and providing feedback to users in the form of a score is an efficient way to improve pairing security, particularly among users such as children who may not be aware of the consequences of their decisions while performing security tasks.","A comprehensive approach to trust managementTrust has been recognized as a key component of agent decision making in the context of multiagent systems (MASs). Though diverse trust models and mechanisms, influenced by various fields of study, have been proposed, implemented, and evaluated, we believe that the literature has ignored key aspects of pragmatic and holistic trust based reasoning. In particular, the focus of trust research has been on a posteriori evaluation of the trustworthiness of another agent and relatively few efforts have investigated the issue of establishment, engagement, and usage of trusted relationships. We envision that a holistic agent architecture will not use a trust module as a black-box for evaluating others but as a core component that will inform and shape interactions with other agents in the environment to best serve the decision-makers interests. Accordingly, we present a general and comprehensive trust management scheme (CTMS) that addresses key issues surrounding trust development, maintenance, and use. We present an operational definition of trust motivated by uncertainty management and utility optimization. We identify the various components required of a CTMS and their relationships and overview their use in the existing literature on trust in MAS. We welcome the MAS community to develop on the ideas presented here and build effective agent designs and implementations with fully-integrated CTMS cores.","On the Usage of Different Work Analysis Methods for Collaborative Review of Large Scale 3D CAD ModelsHuman work interaction design is an emerging discipline that aims to encourage empirical studies and conceptualizations of the interaction among humans, their variegated social contexts and the technology they use both within and across these contexts. In this paper we describe and elaborate around the usage of different work analysis methods in a complex, real world work domain: collaborative review of large-scale 3D engineering models. The analysis is based on (i) input from experts in the oil platform engineering field, (ii) previous and related work and (iii) application of different methods considering the recent ad- vances in technology. We conclude that hierarchical task analysis was not effec- tive in obtaining a clear, common vision about the work domain. Storyboarding was the most useful technique as it allowed discovering novelty factors that dif- ferentiate the solution and improve the usability of the product, thereby support- ing the human work at offshore engineering design and review sessions.","Letters: Dynamic classifier ensemble using classification confidenceHow to combine the outputs from base classifiers is a key issue in ensemble learning. This paper presents a dynamic classifier ensemble method termed as DCE-CC. It dynamically selects a subset of classifiers for test samples according to classification confidence. The weights of base classifiers are learned by optimization of margin distribution on the training set, and the ordered aggregation technique is exploited to estimate the size of an appropriate subset. We examine the proposed fusion method on some benchmark classification tasks, where the stable nearest-neighbor rule and the unstable C4.5 decision tree algorithm are used for generating base classifiers, respectively. Compared with some other multiple classifier fusion algorithms, the experimental results show the effectiveness of our approach. Then we explain the experimental results from the view point of margin distribution.","Processing probabilistic range queries over gaussian-based uncertain dataProbabilistic range query is an important type of query in the area of uncertain data management. A probabilistic range query returns all the objects within a specific range from the query object with a probability no less than a given threshold. In this paper we assume that each uncertain object stored in the databases is associated with a multi-dimensional Gaussian distribution, which describes the probability distribution that the object appears in the multi-dimensional space. A query object is either a certain object or an uncertain object modeled by a Gaussian distribution. We propose several filtering techniques and an R-tree-based index to efficiently support probabilistic range queries over Gaussian objects. Extensive experiments on real data demonstrate the efficiency of our proposed approach.","Semi - supervised Remote Sensing Image Segmentation Using Dynamic Region MergingThis paper introduces a remote sensing image segmentation approach by using semi-supervised and dynamic region merging. In remote sensing im- ages, the spatial relationship among pixels has been shown to be sparsely represented by a linear combination of a few training samples from a structured dictionary. The sparse vector is recovered by solving a sparsity-constrained op- timization problem, and it can directly determine the class label of the test sam- ple. Through a graph-based technique, unlabeled samples are actively selected based on the entropy of the corresponding class label. With an initially seg- mented image based semi-supervised, in which the many regions to be merged for a meaningful segmentation. By taking the region merging as a labeling problem, image segmentation is performed by iteratively merging the regions according to a statistical test. Experiments on two datasets are used to evaluate the performance of the proposed method. Comparisons with the state-of-the-art methods demonstrate that the proposed method can effectively investigate the spatial relationship among pixels and achieve better remote sensing image seg- mentation results.","Modelling and Analysis of Social Contagion Processes with Dynamic NetworksIn this paper an agent-based social contagion model with an underlying dynamic network is proposed and analysed. In contrast to the existing social contagion models, the strength of links between agents changes gradually rather than abruptly based on a threshold mechanism. An essential feature of the model \u0097 the ability to form clusters \u0097 is extensively investigated in the paper analytically and by simulation. Specifically, the distribution of clusters in random and scale-free networks is investigated, the dynamics of links within and between clusters are determined, the minimal distance between two clusters is identified.","Weighed Aging Ensemble of Heterogenous Classifiers for Incremental Drift ClassificationNowadays simple methods of data analysis are not sufficient for efficient management of an average enterprize, since for smart decisions the knowledge hidden in data is highly required, among them methods of collective decision making called classifier ensemble are the focus of intense research. Unfortunately the great disadvantage of traditional classification methods is that they \"assume\" that statistical properties of the discovered concept (which model is predicted) are being unchanged. In real situation we could observe so-called concept drift, which could be caused by changes in the probabilities of classes or/and conditional probability distributions of classes. The paper presents extension of Weighted Aging Classifier Ensemble (WAE), which is able to adapt to the changes in data stream. It assumes that the classified data stream is given in a form of data chunks, and the concept drift could appear in the incoming data chunks. Instead of drift detection WAE tries to construct self-adapting classifier ensemble. Therefore on the basis of the each chunk one individual is trained and WAE checks if it could form valuable ensemble with the previously trained models. The presented extension uses the ensemble of heterogeneous classifiers, what boosts the classification accuracy, what was confirmed on the basis of the computer experiments.","Temporal Query Answering in the Description Logic DL-Lite ","Leveraging Historical Experience to Evaluate and Adapt Courses of Action ","Investigating Privacy and Security Challenges of mHealth ApplicationsPrivacy and mHealth are fast becoming an important influence on the U.S. healthcare system. The most visible element of mHealth is the profusion of mobile phone applications, especially ones related to wellness. Before researchers can fully examine the impact of mHealth on healthcare, barriers to use need to be addressed. One of the barriers most cited by medical professionals and patients is lack of adequate privacy and security policies and regulation for mHealth apps. In this paper the current state of data security in mobile apps is investigated by conducting a physical forensics analysis of several widely used mHealth applications. We report on the kinds of personal data that can be uncovered both before and after applications are removed and/or secured on a mobile device. These results can be used to develop a set of recommendations that can help to inform users, developers and policy stakeholders of best practices. We also introduce a policy framework for mHealth apps and discuss future work.","Pattern Formation in Neural Population Models ","An interaction concept for public displays and mobile devices in public transportPublic displays increasingly find their way into public space and offer a wide range of information to the user. Currently, most of these displays just represent information without the chance to explore them or interact with them. In general, by technical enhancements in this field, more and more possibilities of interaction are given in different domains. This work presents interaction opportunities between public displays and users with mobile devices in the field of public transport. As a basis for understanding the usage and benefits of public displays it is necessary to have a closer look at different types of displays in the public domain, too.","Gesture-based applications for elderly peopleAccording to the literature, normal ageing is associated with a decline in sensory, perceptual, motor and cognitive abilities. When designing applications for elderly people, it is crucial to take into consideration the decline in functions. For this purpose, gesture-based applications that allow for direct manipulations can be useful, as they provide natural and intuitive interactions. This paper examines gesture-based applications for the elderly and studies that have investigated these applications, and it identifies opportunities and challenges in designing such applications.","An App a Day Keeps the Doctor\u2026Informed: User Evaluation of a Patient Mobile Health Application and Clinician Dashboard ","Multi-modal distance metric learningMulti-modal data is dramatically increasing with the fast growth of social media. Learning a good distance measure for data with multiple modalities is of vital importance for many applications, including retrieval, clustering, classification and recommendation. In this paper, we propose an effective and scalable multi-modal distance metric learning framework. Based on the multi-wing harmonium model, our method provides a principled way to embed data of arbitrary modalities into a single latent space, of which an optimal distance metric can be learned under proper supervision, i.e., by minimizing the distance between similar pairs whereas maximizing the distance between dissimilar pairs. The parameters are learned by jointly optimizing the data likelihood under the latent space model and the loss induced by distance supervision, thereby our method seeks a balance between explaining the data and providing an effective distance metric, which naturally avoids overfitting. We apply our general framework to text/image data and present empirical results on retrieval and classification to demonstrate the effectiveness and scalability.","Medical Image Segmentation Based on FCM and Wavelets ","M\u00f6bius shell: a command-line interface for m\u00f6biusThe Mobius modeling environment is a mature, multi-formalism modeling and solution tool. Mobius provides a user-friendly graphical interface for creating discrete-event models, defining metrics, and solving for the metrics using a variety of solution techniques. For certain research needs, the graphical interface can become a limiting use pattern. This paper describes recent work that adds a comprehensive text-based interface for interacting with the Mobius tool, called the Mobius Shell. The Mobius Shell provides an interactive command shell and scriptable command language that can leverage all the existing and future features of Mobius.","Automatic Graph Building Approach for Spectral ClusteringSpectral clustering techniques have shown their capability to identify the data relationships using graph analysis, achieving better accuracy than traditional algorithms as k-means. Here, we propose a methodology to build automatically a graph representation over the input data for spectral clustering based approaches by taking into account the local and global sample structure. Regarding this, both the Euclidean and the geodesic distances are used to identify the main relationships between a given point and neighboring samples around it. Then, given the information about the local data structure, we estimate an affinity matrix by means of Gaussian kernel. Synthetic and real-world datasets are tested. Attained results show how our approach outperforms, in most of the cases, benchmark methods.","Automatic Morphological Annotation in a Text-to-Speech System for HebrewThe paper presents the module for automatic morphological annotation within a text synthesizer for Hebrew, based on an efficient combination of two approaches. The first approach includes the selection of lexemes from appropriate lexica, while the other approach involves automatic morphological analysis of text input using a complex expert algorithm relying on a set of transformational rules and using 6 types of scoring procedures. The module operates on a set of 30 part-of-speech tags with more than 3000 corresponding morphological categories. The paper discusses the advantages of the proposed method in the context of an extremely morphologically complex language such as Hebrew, with particular emphasis given to the relative importance of individual scoring procedures. When all 6 scoring procedures are applied, the accuracy of 99.6% is achieved on a corpus of 3093 sentences 55046 words.","Content-Based Design and Implementation of Ambient Intelligence ApplicationsOptimal support of professionals in complex ambient task environments requires a system that delivers the Right Message at the Right Moment in the Right Modality: (RM)3. This paper describes a content-based design methodology and an agent-based architecture to enable real time decisions of information presentation according to (RM)3. We will describe the full development cycle of design, development, and evaluation. Ontologies are regarded as key enablers as they define the classes and attributes to allow (RM)3 delivery. As a case study, we describe an ambient computing application for human-robot interaction in the Urban Search and Rescue domain. \u00a9 Springer International Publishing Switzerland 2013.","Parallel Curved Mesh Adaptation for Large Scale High-Order Finite Element Simulations ","Some Higher Order Functions on Binary Relations ","Using Ontologies in the Integration of Structural, Functional, and Process Perspectives in the Development of Safety Critical Systems ","Energy Efficient Wireless Sensor Network Design and Simulation for Water Environment Monitoring ","Linguistic processing of implied information and connotative features in multilingual HCI applicationsImplied information and connotative features may not always be easily detected or processed in multilingual Human-Computer Interaction Systems for the International Public, especially in applications related to the Service Sector. The proposed filter concerns the detection of implied information and connotative features in HCI applications processing online texts and may be compatible with Interlinguas including the signalization of connotative features, if necessary. The proposed approach combines features detected in the lexical and morpho-syntactic level, and in the prosodic and paralinguistic levels.","Approximate Reasoning about Generalized Conditional Independence with Complete Random VariablesThe implication problem of conditional statements about the independence of finitely many sets of random variables is studied in the presence of controlled uncertainty. Uncertainty refers to the possibility of missing data. As a control mechanism random variables can be de- clared complete, in which case data on these random variables cannot be missing. While the implication of conditional independence statements is not axiomatizable, a finite Horn axiomatization is established for the expressive class of saturated conditional independence statements under controlled uncertainty. Complete random variables allow us to balance the expressivity of sets of saturated statements with the efficiency of de- ciding their implication. This ability can soundly approximate reasoning in the absence of missing data. Delobel's class of full first-order hierarchi- cal database decompositions are generalized to the presence of controlled uncertainty, and their implication problem shown to be equivalent to that of saturated conditional independence.","ARS module of contents management system using cell phonesI developed an ARS (Audience Response System) module of Xoops CMS (Contents Management System) using cell phones. The module has already been used in some lectures. When we analyze data of the users, we can confirm a statistically significant effect. This paper will first explain the background of this research. Then, the functions and use of the module are explained. Thirdly, this paper explains, how the module is used in association with practice module. Lastly, the effects of the modules are analyzed.","Usability evaluation of the touch screen user interface designWith the advancement of ICT technologies, touch-screen interface mobile devices become a standard feature. This study aims to evaluate the Popover interface design under different age groups. The UI elements being considered for evaluation include location, window length and font size of the popover in three visual search tasks. The results show that there were significant differences in reaction time and accuracy rate between age groups. The worst performance was found in the older group. The best button position was on the bottom screen. In addition, significant performance differences between popover window length and font size were also found. Generally speaking, it is recommended to use the popover window with long cell length, and bigger font size for better readability, especially for the older age group users.","An Approach for the Reuse of Learning Annotations Based on Ontology Techniques ","Parametric Interrupt Timed AutomataParametric reasoning is particularly relevant for timed models, but very often leads to undecidability of reachability problems. We propose a parametrised version of Interrupt Timed Automata (an expressive model incomparable to Timed Automata), where polynomials of parameters can occur in guards and updates. We prove that different reachability problems, including robust reachability, are decidable for this model, and we give complexity upper bounds for a fixed or variable number of clocks and parameters.","Towards Trust-Aware and Self-adaptive SystemsThe Future Internet (FI) comprises scenarios where many heterogeneous and dynamic entities must interact to provide services (e.g., sensors, mobile devices and information systems in smart city scenarios). The dynamic conditions under which FI applications must execute call for self-adaptive software to cope with unforeseeable changes in the application environment. Software engineering currently provides frameworks to develop reasoning engines that automatically take reconfiguration decisions and that support the runtime adaptation of distributed, heterogeneous applications. However, these frameworks have very limited support to address security concerns of these application, hindering their usage for FI scenarios. We address this challenge by enhancing self-adaptive systems with the concepts of trust and reputation. Trust will improve decision-making processes under risk and uncertainty, in turn improving security of self-adaptive FI applications. This paper presents an approach that includes a trust and reputation framework into a platform for adaptive, distributed component-based systems, thus providing software components with new abilities to include trust in their reasoning process.","A task complexity assessment tool for single-operator multi-robot control scenarios ","An approach to abductive reasoning in equational logicAbduction has been extensively studied in propositional logic because of its many applications in artificial intelligence. However, its intrinsic complexity has been a limitation to the implementation of abductive reasoning tools in more expressive logics. We have devised such a tool in ground flat equational logic, in which literals are equations or disequations between constants. Our tool is based on the computation of prime implicates. It uses a relaxed paramodulation calculus, designed to generate all prime implicates of a formula, together with a carefully defined data structure storing the implicates and able to efficiently detect, and remove, redundancies. In addition to a detailed description of this method, we present an analysis of some experimental results.","Interactive Image Retrieval Based on Relevance FeedbackThis chapter presents a prototype of a web image search engine that im- plements four approaches to improve the performance of interactive image retrieval systems. The first approach is classic relevance feedback, which relies on user feed- back to provide better retrievals in an iterative process. It adopts a probabilistic model which leads to maximizing the relevance of the images retrieved. The second approach is based on user relevance feedback as well, but the attention is focused on combining several information sources to the retrieval mechanism. In particular, we propose a retrieval technique that combines both visual and textual features us- ing dynamic late fusion. The third and fourth approaches are query refinement and tag cloud, both consisting of leveraging the information derived from the relevance feedback and the (textual) image annotations. In the former, a refinement of the ini- tial textual query is suggested. In the latter, a tag cloud is given to provide an overall topic formation related to the user's image selection.","Weak read/write Registers \u22c6In (14), Lamport has defined three classes of shared registers which support read and write operations, called \u2014safe, regular and atomic\u2014depending on their properties when several reads and/or writes are executed concurrently. We consider generalizations of Lamport's notions, called k-safe, k-regular and k-atomic. First, we provide constructions for implementing 1-atomic registers (the strongest type) in terms of k-safe registers (the weakest type). Then, we demonstrate how the constructions enable to easily and efficiently solve classi- cal synchronization problems, such as mutual exclusion and l-exclusion, using single-writer multi-reader k-safe bits, for any k 1. We also explain how, by us- ing k-registers, it is possible to provide some level of resiliency against memory reordering.","Respecting relations: Memory access and antecedent retrieval in incremental sentence processing ","The Formal Metabasis For Conformity Assessment of Information Security Software and HardwareAn approach to the development of security test procedures for information security controls is presented. The recommendations for optimizing the test procedure are obtained","Game Theoretical Approach to Supply Chain MicrofinanceThis paper considers a supply chain microfinance model in which a manufacturer acts as a lender and a raw material supplier as a borrower. Using a game theoretical analysis, the study investigates how investment levels, raw material prices, and profit margins are influenced by loan interest rates under two types of decentralized channel policies: manufacturer Stackelberg and ver- tical Nash game. In addition, the study shows how the profits of a manufacturer and a supplier are changed under each supply chain channel structure.","A retrospective on aliasing type systems: 2012-2022Introduction. Over the last ten years, type systems for reasoning about aliasing have begun to be adopted into mainstream languages and tools. The most obvious benefits came in the area of concurrency, expanding on pioneering work that applied ownership [8], regions [6], and permissions [9,4] to ensure the safety of concurrent programs. However, concurrency alone was insufficient to drive adoption. Aliasing type systems really caught on when researchers found common abstractions that were also useful for other purposes: providing encapsulation [17], enhancing security [7,2], and assisting verification [16,10]-though verification remains a niche application due to the engineering time required to specify and verify code.","Rough Set-Based Information Dilution by Non-deterministic InformationWe have investigated rough set-based concepts for a given Non-deterministic Information System NIS. In this paper, we consider generating a NIS from a Deterministic Information System DIS intentionally. A NIS    $\\varPhi$    is seen as a diluted DIS i\u00be?, and we can hide the actual values in i\u00be? by using    $\\varPhi$   . We name this way of hiding Information Dilution by non-deterministic information. This paper considers information dilution and its application to hiding the actual values in a table.","A GPU Accelerated Local Polynomial Approximation Algorithm for Efficient Denoising of MR ImagesThis paper presents a parallelized implementation of the Local Poly- nomial Approximation algorithm targetted at CUDA-enabled GPU hardware. Al- though the application area of LPA in the image processing domain is very wide, here the focus is put on magnetic resonance image de-noising. In this case, LPA serves as a pre-processing step in the method based on Shape-Adaptive Discrete Cosine Transform. It is shown, how the designed efficient implementation of LPA substantially reduces the execution time of SA-DCT.","Universal design and accessibility standards in online learning objectsThis article notes that the media used in distance learning mode can create barriers to access such content for people who have some form of disabilities. Introduces the principles of universal design, aggregates the standards, guidelines and recommendations for creating accessible web content, developing a set of guidelines for creating accessible learning objects, aiming to support content-developing teachers in creating learning objects accessible to people with disabilities.","Beehive Based Machine to Give Snapshot of the Ongoing Stories on the WebIn this paper we present an approach, inspired by honey bees, that allows us to take a glance at current events by exploring a portion of the Web and extracting keywords, relevant to current news stories. Not unlike the bees, that cooperate together to retrieve little bits of food, our approach uses agents to select random keywords and carry them from one article to another, landing only on the articles relevant to the keyword. Keywords that best represent multiple articles are selected, while keywords not relevant to articles are subsequently discarded and not explored further. Our results show, that with this approach, it is possible to extract keywords relevant to news stories, without utilizing learning methods, or analysis of a data corpus.","Desirability of a teaching and learning tool for thai dance body motionThis paper investigates the desirability of using a teaching and learning tool for Thai dance in the context of higher education. Unlike the Western dances where dance notation have been widely used for recording the dance body movement, students in Thai dance classes have to memorize a series of body movements by observation from their teachers. In Thai dance communities, dance notation is very new, and few of professional people in Thai dance understand and use it to record the Thai dance body movement. In this paper, we demonstrate the adaption of a notation system to describe Thai dance and introduce a learning tool for facilitate students to understand the notation. Our presented tool for teaching and learning Thai dance is as a result from a collaboration research between researchers from performing arts and computer science. We measure the desirability of our tool with four Thai dance schools dispersedly located in the north and middle of Thailand, and we receive a promising feedback from them.","Dynamic Programming for Bayesian Logistic Regression Learning under Concept DriftA data stream is an ordered sequence of training instances arriving at a rate that does not permit to permanently store them in memory and leads to the necessity of online learning methods when try- ing to predict some hidden target variable. In addition, concept drift often occurs, what means that the statistical properties of the target variable may change over time. In this paper, we present a framework of solving the online pattern recognition problem in data streams under concept drift. The framework is based on the application of the Bayesian approach to the probabilistic pattern recognition model in terms of lo- gistic regression, hidden Markov model and dynamic programming.","Verifying data authenticity and integrity in server-aided confidential forensic investigationWith the rapid development of cloud computing services, it is common to have a large server shared by many different users. As the shared server is involved in a criminal case, it is hard to clone a copy of data in forensic investigation due to the huge volume of data. Besides, those users irrelevant to the crime are not willing to disclose their private data for investigation. To solve these problems, Hou et al. presented a solution to let the server administrator (without knowing the investigation subject) cooperate with the investigator in performing forensic investigation. By using encrypted keyword(s) to search over encrypted data, they realized that the investigator can collect the necessary evidence while the private data of irrelevant users can be protected from disclosing. However, the authenticity and integrity of the collected evidence are not considered there. The authenticity and integrity are two fundamental requirements for the evidence admitted in court. So in this paper, we aim to prove the authenticity and integrity of the evidence collected by the existing work. Based on commutative encryption, we construct a blind signature and propose a \"encryption-then-blind signature with designated verifier\" scheme to tackle the problem.","Extremal Values of Ratios: Distance Problems vs. Subtree Problems in TreesThe authors discovered a dual behaviour of two tree indices, the Wiener index and the number of subtrees, for a number of extremal problems\u00a0 [Discrete Appl. Math. 155 (3) 2006, 374-385;\u00a0 Adv. Appl. Math. 34 (2005), 138-155]. Barefoot, Entringer and Szekely [Discrete Appl. Math. 80 (1997), 37-56] determined extremal values of $\\sigma_T(w)/\\sigma_T(u)$,\u00a0\u00a0 $\\sigma_T(w)/\\sigma_T(v)$, $\\sigma(T)/\\sigma_T(v)$, and $\\sigma(T)/\\sigma_T(w)$, where $T$ is a tree on $n$ vertices, $v$ is in the centroid of the tree $T$, and $u,w$ are leaves in $T$.  In this paper\u00a0 we test how far the negative correlation between distances and subtrees go if we look for the\u00a0\u00a0 extremal values of $F_T(w)/F_T(u)$, $F_T(w)/F_T(v)$, $F(T)/F_T(v)$, and $F(T)/F_T(w)$, where $T$ is a tree on $n$ vertices, $v$ is in the subtree core of the tree $T$, and $u,w$ are leaves in $T$-the complete analogue of\u00a0 [Discrete Appl. Math. 80 (1997), 37-56], changing distances to the number of subtrees.\u00a0 We include a number of open problems, shifting the interest towards the number of subtrees in graphs.","Trade area analysis using user generated mobile location dataIn this paper, we illustrate how User Generated Mobile Location Data (UGMLD) like Foursquare check-ins can be used in Trade Area Analysis (TAA) by introducing a new framework and corresponding analytic methods. Three key processes were created: identifying the activity center of a mobile user, profiling users based on their location history, and modeling users' preference probability. Extensions to traditional TAA are introduced, including customer-centric distance decay analysis and check-in sequence analysis. Adopting the rich content and context of UGMLD, these methods introduce new dimensions to modeling and delineating trade areas. Analyzing customers' visits to a business in the context of their daily life sheds new light on the nature and performance of the venue. This work has important business implications in the field of mobile computing.","Indoor Route Planning with Volunteered Geographic Information on a (Mobile) Web-Based Platform ","DICE: A Novel Platform to Support Massively Distributed Clouds ","Ziggy: Very Interactive TrigonometryIn this paper we describe a highly interactive touch-based application to teach the basics of#N#trigonometry to secondary school students. The application, called Ziggy, lets students \u201ctouch\u201d and#N#\u201cpush\u201d triangles, dynamically modifying the shape and size, and observe the effect on the angles, sides and the trigonometric ratios. We describe the pedagogical rationale behind Ziggy, the user interface and provide details on the implementation. An early version of Ziggy has been tested in small-scale experiments in the classroom.","Modelling Behaviour SemanticallyContext is only one of several strata of meaning and we can not predict realisation at the lexical or grammatical level from context alone. Yet, there is a tendency to confuse contextual patterning with semantic patterning and allocate patterning to the contextual level that might better be dealt with on other levels. While much work has been done on theorising lexis and grammar and, more recently, on seeing these in context, much remains to be done on theorising semantics as a separate level mediating between context and lexis and grammar. This paper examines the problem of modelling behaviour and the challenge of understanding behaviour in context as well as on a semantical level. By understanding the descriptive responsibilities allocated to each level of language, we are better able to see what remains to be covered by context within a model.","A Workflow Model and Architecture for Content and Metadata Management Based on Grid ComputingLarge scale multimedia services such as social networks, content delivery networks, online service archives provide access to huge amount of content with several hundreds of descriptors fields associated with and file ver- sions, thus really complex content management systems. They have a great need of and orchestrated workflow system and automated process management system that allow managing content and metadata, in order to automate as much as possible the activities (thus reducing the costs) and increasing the quality and accessibility. Grid computing technology may aid at integrating and improving existing content management and workflow systems in order to efficiently or- ganize and manage large amount of data and processes to cope with them. In this context, the workflow model and architecture base on grid computing adopted by ECLAP network is presented.","Planar Evasive Aircrafts Maneuvers Using Reinforcement LearningIn this paper, the reinforcement learning technique is proposed to implement evasive strategies for aircrafts during engagement. A simplified point-mass model is used to describe the aircraft and the missile equations of motion. The missile follows the pure proportional navigation guidance (PPNG) law to attack the aircraft. Q-learning algorithm which is a form of reinforcement learning is suggested to learn the evasive maneuvers. The performance of the proposed approach is analyzed with numerical simulations. It is shown that the aircraft evades from a missile properly by reinforcement learning with bang- bang type action profiles.","Globalizing Constraint ModelsWe present a method that, given a constraint model, suggests global constraints to replace parts of it. This helps non-expert users to write higher-level models that are easier to reason about and may result in better solving performance. Our method exploits the structure of the model by considering combinations of the constraints, collections of variables, parameters and loops already present in the model, as well as parameter data from several data files. We assign a score to a candidate global constraint by comparing a sample of its solution space with that of the part of the model it is intended to replace. The top-scoring global constraints are presented to the user through an interactive display, which shows how they could be incorporated into the model. The MiniZinc Globalizer, our implementation of the method for the MiniZinc modelling language, is available on the web.","Towards Quantifying Interaction Networks in a Football Match ","Meaning as collective use: predicting semantic hashtag categories on twitterThis paper sets out to explore whether data about the usage of hashtags on Twitter contains information about their semantics. Towards that end, we perform initial statistical hypothesis tests to quantify the association between usage patterns and semantics of hashtags. To assess the utility of pragmatic features - which describe how a hashtag is used over time - for semantic analysis of hashtags, we conduct various hashtag stream classification experiments and compare their utility with the utility of lexical features. Our results indicate that pragmatic features indeed contain valuable information for classifying hashtags into semantic categories. Although pragmatic features do not outperform lexical features in our experiments, we argue that pragmatic features are important and relevant for settings in which textual information might be sparse or absent (e.g., in social video streams).","Integrated Multi-aspect Visualization of 3D Fluid Flows ","Kernel Optimal Unsupervised Discriminant Projection and Its Application to Face Recognition ","Losing Weight by Gaining EdgesWe present a new way to encode weighted sums into unweighted pairwise constraints, obtaining the following results. #R##N#- Define the k-SUM problem to be: given n integers in [-n^2k, n^2k] are there k which sum to zero? (It is well known that the same problem over arbitrary integers is equivalent to the above definition, by linear-time randomized reductions.) We prove that this definition of k-SUM remains W[1]-hard, and is in fact W[1]-complete: k-SUM can be reduced to f(k) * n^o(1) instances of k-Clique. #R##N#- The maximum node-weighted k-Clique and node-weighted k-dominating set problems can be reduced to n^o(1) instances of the unweighted k-Clique and k-dominating set problems, respectively. This implies a strong equivalence between the time complexities of the node weighted problems and the unweighted problems: any polynomial improvement on one would imply an improvement for the other. #R##N#- A triangle of weight 0 in a node weighted graph with m edges can be deterministically found in m^1.41 time.","Career Paths Training for the First Year Students in Information Systems Science-Motivational viewA gap between real life and theory usually exists in education. However, this gap can be crossed in all levels of an ICT curriculum. The constructivist learning theory and the concept of professional growth can be the building blocks for a career path course in which students can meet their professional needs since the beginning of studies. At the University of Jyvaskyla we ran the career path of ICT course for new information systems students during the first month of their studies. The course included expert lectures of ICT professionals representing the different aspects of ICT work. Additionally, the students were expected to discuss these issues in their assignment. In this paper we clarify why and how we ran our career path course. In addition, we present how students\u2019 motivation was developed during the course. According our results, the students were more motivated to study to a programmer\u2019s, a system analyst\u2019s, a project manager\u2019s, and a system maintainer than to a job of a database designer, a data communications professional, and a web and multimedia designer. The result gives the guidelines to the next evaluation round of the information systems science curriculum at the University of Jyvaskyla and other academic entities. However, qualitative research on the subject is needed to support these curriculum development efforts.","Collective matrix factorization for co-clusteringWe outline some matrix factorization approaches for co- clustering polyadic data (like publication data) using non-negative factorization (NMF). NMF approximates the data as a product of non-negative low-rank matrices, and can induce desirable clustering properties in the matrix factors through a flexible range of constraints. We show that simultaneous factorization of one or more matrices provides potent approaches for co-clustering.","On the efficiency modelling of cryptographic protocols by means of the quality of protection modelling language (QoP-ML)The problem of efficiency in the IT systems is now widely discussed. One of the factors affecting the performance of IT systems is implementation and maintaining a high level of security. In many cases the guaranteed security level is too high in relation to the real threats. The implementation and maintenance of this protection level is expensive in terms of both productivity and financial costs.#R##N##R##N#The paper presents the analysis of TLS Handshake protocol in terms of quality of protection performed by the Quality of Protection Modelling Language (QoP-ML). The analysis concerns efficiency.","Fast and Robust Edge-Guided Exemplar-Based Image Inpainting ","On the Detectability of Weak DoS Attacks in Wireless Sensor Networks ","Issues of Security and Informational Privacy in Relation to an Environmental Scanning System for Fighting Organized CrimeThis paper clarifies privacy challenges related to the EU project, ePOOLICE, which aims at developing a particular kind of open source information filtering system, namely a so-called environmental scanning system, for fighting organized crime by improving law enforcement agencies opportunities for strategic proactive planning in response to emerging organized crime threats. The environmental scanning is carried out on public online data streams, focusing on modus operandi and crime trends, not on individuals. Hence, ethical and technical issues --- related to societal security and potential privacy infringements in public online contexts --- are being discussed in order to safeguard privacy all through the system design process.","Navigation Recommendations for Exploring Hierarchical Graphs ","Design and Simulation of a 3D Actuation System for Magnetic Nano-Particles Delivery System ","Using animation as an information tool to advance health research literacy among minority participants.Lack of adequate consumer health information about clinical research contributes to health disparities among low health literate minority multicultural populations and requires appropriate methods for making information accessible. Enhancing understanding of health research can enable such minority multicultural consumers to make informed, active decisions about their own health and research participation. This qualitative study examines the effectiveness and acceptability of an animated video to enhance what we call health research literacy among minority multicultural populations. A team analyzed the transcripts of 58 focus groups of African Americans, Latinos, Native Hawaiians, and Filipinos in Los Angeles/Hawaii. Participants were accepting of animation and the video\u2019s cultural appropriateness. Communicating information about health research via animation improved participants\u2019 ability to identify personal information-gaps, engage in meaningful community-level dialogue, and ask questions about health research.","A Semi-automatic Negotiation Strategy for Multi-attribute and Multiple Participants ","On weighted hybrid track recommendationsMusic is a highly subjective domain, which makes it a challenging research area for recommender systems. In this paper, we present our TRecS ( T rack  Rec ommender  S ystem) prototype, a hybrid recommender that blends three different recommender techniques into one score. Since traceability is an important issue for the acceptance of recommender systems by users, we have implemented a detailed explanation feature that supports transparency about the contribution of each sub-recommender for the overall result. To avoid overspecialization, TRecS peppers the result list with recommendations that are based on a serendipity metric. This way, users can benefit from both recommendations aligned with their current taste while gaining some diversification.","Completeness Statements about RDF Data Sources and Their Use for Query AnsweringWith thousands of RDF data sources available on the Web covering disparate and possibly overlapping knowledge domains, the problem of providing high-level descriptions (in the form of metadata) of their content becomes crucial. In this paper we introduce a theoretical framework for describing data sources in terms of their completeness. We show how existing data sources can be described with completeness statements expressed in RDF. We then focus on the problem of the completeness of query answering over plain and RDFS data sources augmented with completeness statements. Finally, we present an extension of the completeness framework for federated data sources.","Analyzing Incentives for Protocol Compliance in Complex Domains: A Case Study of Introduction-Based RoutingFormal analyses of incentives for compliance with network protocols often appeal to gametheoretic models and concepts. Applications of game-theoretic analysis to network security have generally been limited to highly stylized models, where simplified environments enable tractable study of key strategic variables. We propose a simulation-based approach to gametheoretic analysis of protocol compliance, for scenarios with large populations of agents and large policy spaces. We define a general procedure for systematically exploring a structured policy space, directed expressly to resolve the qualitative classification of equilibrium behavior as compliant or non-compliant. The techniques are illustrated and exercised through an extensive case study analyzing compliance incentives for introduction-based routing. We find that the benefits of complying with the protocol are particularly strong for nodes subject to attack, and the overall compliance level achieved in equilibrium, while not universal, is sufficient to support the desired security goals of the protocol.","A new crossover for solving constraint satisfaction problemsIn this paper we investigate the applicability of Genetic Algorithms (GAs) for solving Constraint Satisfaction Problems (CSPs). Despite some success of GAs when tackling CSPs, they generally suffer from poor crossover operators. In order to overcome this limitation in practice, we propose a novel crossover specifically designed for solving CSPs. Together with a variable ordering heuristic and an integration into a parallel architecture, this proposed crossover enables the solving of large and hard problem instances as demonstrated by the experimental tests conducted on randomly generated CSPs based on the model RB. We will indeed demonstrate, through these tests, that our proposed method is superior to the known GA based techniques for CSPs. In addition, we will show that we are able to compete with the efficient MAC-based Abscon 109 solver for random problem instances.","Pilot preferences on displayed aircraft control variablesThe experiments described here explored how pilots want available maneuver authority information transmitted and how this information affects pilots before and after an aircraft failure. The aircraft dynamic variables relative to flight performance were narrowed to energy management variables. A survey was conducted to determine what these variables should be. Survey results indicated that bank angle, vertical velocity, and airspeed were the preferred variables. Based on this, two displays were designed to inform the pilot of available maneuver envelope expressed as bank angle, vertical velocity, and airspeed. These displays were used in an experiment involving control surface failures. Results indicate the displayed limitations in bank angle, vertical velocity, and airspeed were helpful to the pilots during aircraft surface failures. However, the additional information did lead to a slight increase in workload, a small decrease in perceived aircraft flying qualities, and no effect on aircraft situation awareness.","An Improved Semidefinite Programming Hierarchies Rounding Approximation Algorithm for Maximum Graph Bisection Problems ","A Density-Based Backward Approach to Isolate Rare Events in Large-Scale ApplicationsWhile significant work in data mining has been dedicated to the detection of single outliers in the data, less research has approached the problem of isolating a group of outliers, i.e. rare events representing micro-clusters of less - or significantly less - than 1% of the whole dataset. This research issue is critical for example in medical applications. The problem is difficult to handle as it lies at the frontier between outlier detection and clustering and distinguishes by a clear challenge to avoid missing true positives. We address this challenge and propose a novel two-stage framework, based on a backward approach, to isolate abnormal groups of events in large datasets. The key of our backward approach is to first identify the core of the dense regions and then gradually augments them based on a density-driven condition. The framework outputs a small subset of the dataset containing both rare events and outliers. We tested our framework on a biomedical application to find micro-clusters of pathological cells. The comparison against two common clustering (DBSCAN) and outlier detection (LOF) algorithms show that our approach is a very efficient alternative to the detection of rare events - generally a recall of 100% and a higher precision, positively correlated wih the size of the rare event - while also providing a O(N) solution to the existing algorithms dominated by a O(N2) complexity.","Digital Identity into Practice: The Case of UniCamIdentity management is a set of technologies and processes supporting identity information. Its adoption in Public Administration, in particular in the domain of university, maintains organization autonomy giving at the same time students and staff support to access the services that are delivered. In this paper we present a project lead by University of Camerino with the Italian Banking Group UBI and the Namirial Certification Authority. The project consists in the issue of Enjoy my UniCam card allowing users to have, on a single physical card, several functionalities about facilitated banking account, university services and digital signature certificate. First results about the testing phase are presented as well as the next steps of the project.","Scalable NIC Architecture to Support Offloading of Large Scale MPI BarrierMPI collective communication overhead dominates the communication cost for large scale parallel computers, scalability and operation latency for collective communication is critical for next generation computers. This paper proposes a fast and scalable barrier communication offload approach which supports millions of compute cores. Following our approach, the barrier operation sequence is packed by host MPI driver into the barrier \"descriptor\", which is pushed to the NIC Network-Interfaces. The NIC can complete the barrier automatically following its algorithm descriptor. Our approach leverages an enhanced dissemination algorithm which is suitable for current large scale networks. We show that our approach achieves both barrier performance and scalability, especially for large scale computer system. This paper also proposes an extendable and easy-to-implement NIC architecture supporting barrier offload communication and also other communication pattern.","Greedy Sparsification WM Algorithm for Endmember Induction in Hyperspectral ImagesThe Linear Mixing Model (LMM) of hyperspectral images asumes that pixel spectra are affine combinations of basic spectral sig- natures, called endmembers, which are the vertices of a convex polytope covering the image data. Endmember induction algorithms (EIA) ex- tract the endmembers from the image data, obtaining a precise spectral characterization of the image. The WM algorithm assumes that a set of Affine Independent vectors can be extracted from the rows and columns of dual Lattice Autoassociative Memories (LAAM) built on the image spectra. Indeed, the set of endmembers induced by this algorithm defines a convex polytope covering the hyperspectral image data. However, the number of induced endmembers obtained by this procedure is too high for practical purposes, besides they are highly correlated. In this paper, we apply a greedy sparsification algorithm aiming to select the minimal set of endmembers that explains the data in the image. We report results on a well known benchmark image.","Real-Time RGB-D Mapping and 3-D Modeling on the GPU Using the Random Ball Cover ","Formal Models for Digital Archives: NESTOR and the 5SArchives are a valuable part of our cultural heritage but despite their importance, the models and technologies that have been developed over the past two decades in the Digital Library (DL) field have not been specifically tailored to them. This is especially true when it comes to formal and foundational frameworks, as the Streams, Struc- tures, Spaces, Scenarios, Societies (5S) model is. Therefore, we propose an innovative formal model, called NEsted SeTs for Object hieRarchies (NESTOR), for archives, explicitly built around the concepts of context and hierarchy which play a central role in the archival realm. We then use NESTOR to extend the 5S model offering the possibility of opening up the full wealth of DL methods to archives. We provide account for this by presenting two concrete applications.","Set Based Concurrent Engineering Innovation RoadmapSBCE (Set Based Concurrent Engineering) is an element of lean practice in product development (PD), and it composes theoretical principles to apply it at early phase of a design process. However, executing principles of SBCE in practice require extensive efforts. Thus, a systematic methodology is required to identify and priorities potential areas (product's subsystems, com- ponents, features) where SBCE brings its utmost benefits. This paper proposes such a methodology called SBCE Innovation Roadmap (SBCE IR) that is used as a guideline by product designers to begin SBCE processes. A case study on Adiabatic Humidification System (AHS) is discussed to elaborate the SBCE IR methodology. Furthermore, an experimental SBCE process has been conducted on rack subsystem that shows a significant cost reduction.","Decidability and Complexity Results for Verification of Asynchronous Broadcast NetworksWe study decidability and complexity of verification prob- lems for networks in which nodes communicate via asynchronous broadcast messages. This type of communication is achieved by using a distributed model in which nodes have a local buffer. We consider here safety properties expressed as a coverability problem with an arbitrary initial configuration. This formulation naturally models the search of an initial topology that may lead to an error state in the protocol. We present (un)decidability and complexity results for the coverability prob- lem of Asynchronous Broadcast Networks (ABN), a mathematical model of distributed systems in which processes interact via topology-dependent and asynchronous communication. Our formal model of asynchronous broadcast com- munication combines three main features: a graph representation of a network configuration decoupled from the specification of individual process behaviour, a topology-dependent semantics of synchronization, and the use of local mailboxes to deliver messages to individual nodes. Our main abstraction comes from con- sidering protocols defined via a communicating finite-state automaton replicated on each node of the network. In our setting the coverability problem is formulated as follows. We first define an initial configuration as any graph in which nodes have labels that represent the initial state of the protocol (and no constraints on edges). Coverability con- sists then in checking whether there exists an initial configuration that can reach a target configuration that contains a given process state. A similar decision problem is considered in (8) for a mathematical model with synchronous com- munication and dynamic reconfiguration of the topology called Reconfigurable Broadcast Network (RBN). Our analysis is carried out with different policies to handle buffers, namely unordered bags (an abstraction of a tuple space), and perfect or lossy FIFO channels. Our technical contribution is as follows. We first show that, in con- trast with the synchronous case discussed in (9,10), coverability is decidable when","High Efficiency Isolated Bidirectional AC-DC Power ConverterIn this paper, the high efficiency isolated bidirectional AC-DC converter system with several improved techniques will be discussed to improve the performance of a low voltage DC distribution system. In order to increase the efficiency of the non-isolated full-bridge AC-DC rectifier, the switching devices are designed by using IGBTs without an antiparallel diode, MOSFETs, and SiC diodes. Through the analysis of operational modes, each switch is selected by considering switch stresses. Finally, design guides and gain characteristics of the bidirectional full-bridge CLLC resonant converter with the symmetric structure of the primary inverting stage and secondary rectifying stage will be discussed for low voltage DC distribution system. Experimental results will verify the performance of the proposed methods using a 5kW prototype converter.","Upgrade Your Robot Competition, Make a Festival! [Competitions]Keywords: [mobots] ; educational robotics ; robots competitions ; NCCR Robotics Reference EPFL-ARTICLE-188462doi:10.1109/MRA.2013.2272203 Record created on 2013-09-12, modified on 2016-08-09","Using an agent-based friend circle creator model to analyze drivers of consumer choice: network effects vs. value propositionNetwork industry products and services rely on designing competitive business models including aspects of consumers influencing other consumers. Consumer decision-making is a complex process involving rich attributes that include value consideration and network effects. Using compatible products within an organization or home, or between friends results in greater utility and satisfaction, emphasizing the consumer decisions are not just based on value but also on what their peers recommend and use. This paper presents a generic Friend Circle Creator (FCC) Agent Based Model (ABM), which leverages network formation theory to create and evolve friend circles within the consumer agent population. These friend circles can be used to simulate consumer decision-making scenarios for cases consisting network externalities. We apply the FCC model to a mobile phone plan case study. The results of this case study demonstrate how the presence of network effects is able to retain a large population of consumers in an inefficient deal. FCC can be used as a module to complement larger ABMs to enhance analysis in studying drivers of consumer decision-making.","Managing Corrective Actions to Closure in Open Source Software Test Process. ","Prior Disambiguation of Word Tensors for Constructing Sentence VectorsRecent work has shown that compositionaldistributional models using element-wise operations on contextual word vectors benefit from the introduction of a prior disambiguation step. The purpose of this paper is to generalise these ideas to tensor-based models, where relational words such as verbs and adjectives are represented by linear maps (higher order tensors) acting on a number of arguments (vectors). We propose disambiguation algorithms for a number of tensor-based models, which we then test on a variety of tasks. The results show that disambiguation can provide better compositional representation even for the case of tensor-based models. Furthermore, we confirm previous findings regarding the positive effect of disambiguation on vector mixture models, and we compare the effectiveness of the two approaches.","Developments in the Khintchine-Meinardus Probabilistic Method for Asymptotic EnumerationA theorem of Meinardus provides asymptotics of the number of weighted partitions under certain assumptions on associated ordinary and Dirichlet generating functions. The ordinary generating functions are closely related to Euler's generating function $\\prod_{k=1}^\\infty S(z^k)$ for partitions, where $S(z)=(1-z)^{-1}$. By applying a method due to Khintchine, we extend Meinardus' theorem to find the asymptotics of the Taylor coefficients of generating functions of the form $\\prod_{k=1}^\\infty S(a_kz^k)^{b_k}$ for sequences $a_k$, $b_k$ and general $S(z)$. We also reformulate the hypotheses of the theorem in terms of the above generating functions. This allows novel applications of the method. In particular, we prove rigorously the asymptotics of Gentile statistics and derive the asymptotics of combinatorial objects with distinct components.","A novel geodesic distance based clustering approach to delineating boundaries of touching cellsIn this paper, we propose a novel geodesic distance based clustering approach for delineating boundaries of touching cells. In specific, the Riemannian metric is firstly adopted to integrate the spatial distance and intensity variation. Then the distance between any two given pixels under this metric is computed as the geodesic distance in a propagational way, and the K-means-like algorithm is deployed in clustering based on the propagational distance. The proposed method was validated to segment the touching Madin-Darby Canine Kidney (MDCK) epithelial cell images for measuring their N-Ras protein expression patterns inside individual cells. The experimental results and comparisons demonstrate the advantages of the proposed method in massive cell segmentation and robustness to the initial seeds selection, varying intensity contrasts and high cell densities in microscopy images.","RSOL: A Trust-Based Recommender System with an Opinion Leadership Measurement for Cold Start UsersThe cold start problem is a potential issue in computer-based information systems that involve a degree of automated data modeling. Specifically, the system cannot infer a rating for users or items that are new to the recommender system when no sufficient information has been gathered. Currently, more websites are providing the relationships between users, e.g., the trust relationships, to help us alleviate the cold start problem. In this paper, we proposed a trust-based recommender model (RSOL) that is able to recognize the user's recommendation quality for different items. A user's recommendation quality contains two parts: \"Rating Confidence\"- an indicator of the user's reliability when rating an item, and \"Proximity Prestige\"- an indicator of the user's influence on a trust network. In our experimental results, the proposed method outperforms the Collaborative Filtering and trust-based methods on the Epinions dataset.","Visual Attention and Gaze Behavior in Games: An Object-Based ApproachThis chapter presents state-of-the-art methods that tap the potential of psychophysics for the purpose of understanding game players' behavior. Studying gaze behavior in gaming environments has recently gained momentum as it affords a better understanding of gamers' visual attention. However, while knowing where users are attending in a computer game would be useful at a basic level, it does not provide insight into what users are interested in, or why. An answer to these questions can be tremendously useful to game designers, enabling them to improve gameplay, selectively increase visual fidelity, and optimize the distribution of computing resources. Furthermore, this could be useful in verifying game mechanics, improving game AI and smart positioning of advertisements within games, all being applications widely desirable across the games industry. Techniques are outlined to collect gaze data, and map fixation points back to semantic objects in a gaming environment, enabling a deeper understanding of how players interact with games.","Information systems strategic planning for a naval hospitalThis article discusses the Information System (IS) strategic planning for a naval hospital in Indonesia. Its purpose is to improve competitive advantage among hospitals through the addition of new services and products that would lead to improvements in the current patient services. The merging of Hospital Information System (HIS), Radiology Information System (RIS), and Laboratory Information System (LIS) into a single network with a concept of telemedicine is the main topic of this article. The hospital's website is also developed with medical tourism in mind, which attracts more patients, generating more revenue for the hospital.","Pervasive and intelligent decision support in critical health care using ensembles ","Australian sign language recognition using moment invariantsHuman Computer Interaction is geared towards seamless human machine integration without the need for LCDs, Keyboards or Gloves. Systems have already been developed to react to limited hand gestures especially in gaming and in consumer electronics control. Yet, it is a monumental task in bridging the well-developed sign languages in different parts of the world with a machine to interpret the meaning. One reason is the sheer extent of the vocabulary used in sign language and the sequence of gestures needed to communicate different words and phrases. Auslan the Australian Sign Language is comprised of numbers, finger spelling for words used in common practice and a medical dictionary. There are 7415 words listed in Auslan website. This research article tries to implement recognition of numerals using a computer using the static hand gesture recognition system developed for consumer electronics control at the University of Wollongong in Australia. The experimental results indicate that the numbers, zero to nine can be accurately recognized with occasional errors in few gestures. The system can be further enhanced to include larger numerals using a dynamic gesture recognition system.","Evaluation of Traffic Sign Recognition Methods Trained on Synthetically Generated DataMost of today's machine learning techniques requires large manually labeled data. This problem can be solved by using synthetic images. Our main contribution is to evaluate methods of traffic sign recognition trained on synthetically generated data and show that results are comparable with results of classifiers trained on real dataset. To get a representative synthetic dataset we model different sign image variations such as intra-class variability, imprecise localization, blur, lighting, and viewpoint changes. We also present a new method for traffic sign segmentation, based on a nearest neighbor search in the large set of synthetically generated samples, which improves current traffic sign recognition algorithms.","A self-evaluation tool for quantitative user research within the digital.me projectFor upcoming validations within the di.me project, the technical evaluation components will be an important instrument for monitoring overall key usage indicators and serve as the basis for the further analysis of usage data. Consolidated findings acquired from the evaluation components shall serve as the basis for further improvements on the developed clients and overall di.me system. This paper states a list of related requirements as well as a technical overview of the employed system.","Detection of Covert Botnet Command and Control Channels by Causal Analysis of Traffic Flows ","ESCAPE FROM WINCHESTER MANSION - TOWARD A SET OF DESIGN PRINCIPLES TO MASTER COMPLEXITY IN IT ARCHITECTURESAlthough the management of complexity is a central task of CIOs and IT architects, in-depth examinations and the development of design theory in this area is, to the best of our knowledge, underrepresented in existing IS literature. Especially theory-based guidelines and information systems for the management of IT architecture complexity are missing. In a joint team of practitioners and researchers, we applied the action design research (ADR) method in order to tackle this class of problems, i.e., IT architecture complexity management. We derived a set of seven design principles (that guide the design of an information system that supports IT architects to manage IT architecture complexity), which we evaluated and enriched during multiple \u2018building, intervention and evaluation\u2019 cycles, according to ADR. In addition, we simultaneously implemented and evaluated a material artifact (i.e., a piece of software) for IT architecture complexity management.","Painting Scene Recognition Using Homogenous ShapesThis paper addresses the problem of semantic analysis of paintings by automatic detection of the represented scene type. The solution comes as an incipient effort to fill the gap already stated in the literature between the low level computational analysis and the high level semantic dependent human analysis of paintings. Inspired by the way humans perceive art, we first decompose the image in homogenous regions, follow by a step of region merging, in order to obtain a painting description by the extraction of perceptual features of the dominant objects within the scene. These features are used in a classification process that discriminates among 5 possible scene types on a database of 500 paintings.","Khresmoi - Multilingual Semantic Search of Medical Text and Images.Khresmoi is a European Integrated Project developing a multilingual multimodal search and access system for medical and health information and documents. It addresses the challenges of searching through huge amounts of medical data, including general medical information available on the internet, as well as radiology data in hospital archives. It is developing novel semantic search and visual search techniques for the medical domain. At the MIE Village of the Future, Khresmoi proposes to have two interactive demonstrations of the system under development, as well as an overview oral presentation and potentially some poster presentations.","Multi-spectral Material Classification in Landscape Scenes Using Commodity HardwareWe investigate the advantages of a stereo, multi-spectral#R##N#acquisition system for material classication in ground-level landscape#R##N#images. Our novel system allows us to acquire high-resolution, multi-#R##N#spectral stereo pairs using commodity photographic equipment. Given#R##N#additional spectral information we obtain better classication of vege-#R##N#tation classes than the standard RGB case. We test the system in two#R##N#modes: splitting the visible spectrum into six bands; and extending the#R##N#recorded spectrum to near infra-red. Our six-band design is more prac-#R##N#tical than standard multi-spectral techniques and foliage classication#R##N#using acquired images compares favourably to simply using a standard#R##N#camera.","Mapping PASS Graphs to Petri-Nets: Possibilities and Limits for Converting PASS Graphs to Petri-NetsThis paper presents a concept for mappings that can be applied to form a Petri-Net-Graph from the information of a business process model created with the Parallel Activity Specification Schema (PASS). Furthermore the possible uses as well as the shortcomings of this approach are discussed. In the appendix a formal specification for such a converter is given.","Qualitative combination of independence modelsWe deal with the problem of combining sets of independence statements coming from different experts. It is known that the independence model induced by a strictly positive probability distribution has a graphoid structure, but the explicit computation and storage of the closure (w.r.t. graphoid properties) of a set of independence statements is a computational hard problem. For this, we rely on a compact symbolic representation of the closure called fast closure and study three different combination strategies of two sets of independence statements, working on fast closures. We investigate when the complete DAG representability of the given models is preserved in the combined one.","Perceptual and Technological Issues in the Design of Vibrotactile-Augmented Interfaces for Music Technology and MediaIn this paper we present tactile feedback and stimulation design principles for applications in music technology and media. We discuss features and limitations of the human sense of touch, in the context of conveying musical content solely via the tactile sense. These factors should be firmly taken into account when designing a tactile-augmented interface. Applications of tactile displays in the field of music and media are then presented using a three-fold taxonomy of tactile feedback.","Polynomial Systems Solving by Fast Linear AlgebraPolynomial system solving is a classical problem in mathematics with a wide range of applications. This makes its complexity a fundamental problem in computer science. Depending on the context, solving has different meanings. In order to stick to the most general case, we consider a representation of the solutions from which one can easily recover the exact solutions or a certified approximation of them. Under generic assumption, such a representation is given by the lexicographical Grobner basis of the system and consists of a set of univariate polynomials. The best known algorithm for computing the lexicographical Grobner basis is in $\\widetilde{O}(d^{3n})$ arithmetic operations where $n$ is the number of variables and $d$ is the maximal degree of the equations in the input system. The notation $\\widetilde{O}$ means that we neglect polynomial factors in $n$. We show that this complexity can be decreased to $\\widetilde{O}(d^{\\omega n})$ where $2 \\leq \\omega &lt; 2.3727$ is the exponent in the complexity of multiplying two dense matrices. Consequently, when the input polynomial system is either generic or reaches the Bezout bound, the complexity of solving a polynomial system is decreased from $\\widetilde{O}(D^3)$ to $\\widetilde{O}(D^\\omega)$ where $D$ is the number of solutions of the system. To achieve this result we propose new algorithms which rely on fast linear algebra. When the degree of the equations are bounded uniformly by a constant we propose a deterministic algorithm. In the unbounded case we present a Las Vegas algorithm.","Sensitive edges protection in social networksWith the increasing popularity of online social networks, such as twitter and weibo, privacy preserving publishing of social network data has raised serious concerns. In this paper, we focus on the problem of preserving the sensitive edges in social network data. We call a graph is k-sensitive anonymous if the probability of an attacker can re-identify a sensitive node or a sensitive edge is at most $\\frac{1}{k}$. To achieve this objective, we devise two efficient heuristic algorithms to respectively group sensitive nodes and create non-sensitive edges. Finally, we verify the effectiveness of the algorithm through experiments.","A Cross Industry Study: Differences in Information Security Policy Compliance between the Banking Industry and Higher EducationAbstract This study adopts Neo-Institutional Theory (NIT) to address the underlying differences in information security policy compliance between the banking industry and the higher education. Drawing on NIT, this study examines how regulative, normative, and cognitive expectations influence the internal organizational efforts of staying compliant across both industries. Using the Partial Least Square (PLS) method, the analysis results suggest that both industries rely on the normative expectation to propel their organizational efforts of attaining compliance. However, the main difference lies within the cognitive expectation. In the institution of higher education, cognitive expectation has an indirect effect on information security policies compliance through regulative expectation. On the other hand, cognitive expectation reflects the severity of regulatory pressure in the banking industry. Given these findings, this study presents theoretical implication and provides suggestions to policy makers on the basis of managerial implication.","RAIDER: Rapid Ab Initio Detection of Elementary RepeatsHere we present RAIDER, a tool for the de novo identification of elementary repeats. The problem of searching for genomic repeats without reference to a compiled profile library is important in the annotation of new genomes and the discovery of new repeat classes. Several tools have attempted to address the problem, but generally suffer either an inability to run at the whole-genome scale or loss of sensitivity due to sequence variation between repeat copies. To address this, Zheng and Lonardi define elementary repeats: building blocks that can be assembled into a repeat library, but allow for the filtering of spurious fragments. However, their tool was too slow for use on large input, and subsequent attempts to improve efficiency have been unable to deal with the expected variation between repeat instances. RAIDER addresses both these problems, implementing a novel algorithm for elementary repeat detection and incorporating the spaced seed strategy of PatternHunter to allow for copy variation. Able to process the human genome in under 6.4 hours, initial results indicate a coverage rate comparable to or better than that achieved by competing de novo search tool when paired with the library-based RepeatMasker.","Fuzzy Based CRRM for Load Balancing in Heterogeneous Wireless NetworksThe ever increasing user QoS demands and emergence of new user applications make job of network operators and manufacturers more challenging for efficiently optimisation and managing radio resources in radio the radio resources pools of different wireless networks. A group of strategies or mechanisms which are collectively responsible for efficient utilisation of radio resources available within the Radio Access Technologies (RAT) are termed as Radio Resource Management (RRM). The traditional RRM strategies are implemented independently in each RAT, as each RRM strategy considers attributes of a particular access technology. Therefore traditional RRM strategies are not suitable for heterogeneous wireless networks. Common Radio Resource Management (CRRM) or joint radio resource management (JRRM) strategies are proposed for coordinating radio resource management between multiple RATs in an improved manner. In this paper a fuzzy algorithm based CRRM strategy is presented to efficiently utilise the available radio resources in heterogeneous wireless networks. The proposed CRRM strategy balances the load in heterogeneous wireless networks and avoids the unwanted congestion situation. The results such as load distribution, packet drop rate and average throughput at mobile nodes are used to demonstrate the benefits of load balancing in heterogeneous wireless networks using proposed strategy.","The marketcast method for aggregating prediction market forecastsWe describe a hybrid forecasting method called marketcast. Marketcasts are based on bid and ask orders from prediction markets, aggregated using techniques associated with survey methods, rather than market matching algorithms. We discuss the process of conversion from market orders to probability estimates, and simple aggregation methods. The performance of marketcasts is compared to a traditional prediction market and a traditional opinion poll. Overall, marketcasts perform approximately as well as prediction markets and opinion poll methods on most questions, and performance is stable across model specifications.","A Model-Driven Approach to Enhance Tool Interoperability Using the Theory of Models of ComputationIn the context of embedded systems design, the growing het erogeneity of systems leads to increasingly complex and unreliable tool chains. The Model Driven Engineering (MDE) community has been mak-ing considerable eff orts to abstract tool languages in meta-models, and to o ffer model transformation mechanisms for models exchanges. However, the interoperability problems are recurring and still not consistently addressed. For instance, when it comes to executable models exchanges, it is very di fficult to ensure the preservation of the models behavior from one tool to another. This is mainly due to a lack of understanding of the Models of Computation (MoC) and execution semantics behind the models within di erent environments. In this paper, we introduce a methodology and a framework to: make explicit the execution semantics of models (based on the theory of MoC); provide semantics enrichment mechanisms to ensure the preservation of the execution semantics of models between tools. Our case study is an integration between a UML speci cation tool and an industrial Intensive Data Flow processing tool. This contribution helps to highlight execution semantics concerns within tool integration context.","An Adaptive Comprehensive Learning Bacterial Foraging Optimization for Function Optimization ","Conversion Method in Comparative Analysis of e-Banking Services in PolandThe main objective of this article is to identify the best elec- tronic banking websites from the point of view of an individual client. After a short introduction the authors determined the assumptions for the study. Particular attention is paid to provide conversion method and the way of its practical implementation. Subsequently, they carried out multilateral analyses and presented the conclusions of the study.","On Collaborative Aerial and Surface Robots for Environmental Monitoring of Water BodiesRemote monitoring is an essential task to help maintaining Earth ecosystems. A notorious example is the monitoring of riverine environments. The solution purposed in this paper is to use an electric boat (ASV - Autonomous Surface Vehicle) operating in symbiosis with a quadrotor (UAV \u2013 Unmanned Air Vehicle). We present the architecture and solutions adopted and at the same time compare it with other examples of collaborative robotics systems, in what we expected could be used as a survey for other persons doing collaborative robotics systems. The architecture here purposed will exploit the symbiotic partnership between both robots by covering the perception, navigation, coordination, and integration aspects.","Cooperative Community Detection Algorithm Based on Random WalksCommunity Detection is a significant tool for understand- ing the structures of real-world networks. Although many novel meth- ods have been applied in community detection, as far as we know, co- operative method has not been applied into community detection to improve the performance of discovering community structure of social networks. In this paper, we propose a cooperative community detection algorithm, named cooperative community detection algorithm based on random walks. Firstly, it uses random walks to calculate the similarities between adjacent nodes, and then translates a given unweighted net- works into weighted networks based on the similarities between adjacent nodes. Secondly, it detects community structures of networks by activat- ing the neighbors a node whose community label is known. Thirdly, it cooperates running results of many times of our community detection algorithm to improve its accuracy and stability. Finally, we demonstrate our community detection algorithm with three real networks, and the experimental results show that our cooperative semi-supervised method has a higher accuracy and more stable results compared with other ran- dom community detection algorithms.","Power Consumption Constrained Task Scheduling Using Enhanced Genetic Algorithms ","Research on the Semantic Features of Dimensional Adjective gao \u2018high/tall\u2019 and di/ai \u2018low/short\u2019 in ChineseIn this paper, firstly, we mainly discuss the use of dimensional adjectives gao 'high/tall' and di/ai 'low/short'. Secondly, we analyze the inherent semantic features of gao 'high/tall' and of nouns combined with gao 'high/tall'. Finally, we study the differences between di 'low' and ai 'short'. Gao 'high/tall' can both have a dimensional use, and have a positional use. Di 'low' only has a positional sense, and ai 'short' only has a dimensional sense.","Design and Implementation of Sensor Modules Enabling Round-the-Clock Underwater Operations ","Assessing Structural Organization and Functional Interaction in Gyral, Sulcal and Cortical NetworksLiterature studies showed that the fibers connected to gyri are significantly denser than those connected to sulci. Therefore, we hypothesize that gyral, sulcal and cortical brain networks might exhibit different graph properties and functional interactions that reflect the organizational principles of cortical architecture. In this way, we evaluated the graphical properties of the structural brain networks and the functional connectivities among brain networks which are composed of gyral regions of interest (ROI) (G-networks), sulcal ROIs (S-networks) and mixed gyral and sulcal ROIs (C-networks). The results demonstrated that G-networks have the highest global and local economical properties and the strongest small-worldness. In contrast, S-networks have the lowest global and local economical properties and the weakest small-worldness. Meanwhile, the overall functional connectivity strength among G-networks is stronger than those in S-networks, and those in C-networks are in between. The results indicate that gyri may play a hub role in human brains.","Putting logic in modeling of biological neuron: a new frameworkIn this paper, we discuss various frameworks used for modeling communications among biological neurons and their networks. We also present a novel framework in which a neuron is viewed as a node in a heterogeneous network of neuron clusters. In the proposed framework, we view a neuron as constituting organelles that together generate a composite signal (action potential) consisting of physiological and logical groups of signals. These groups are responsible for specific tasks, such as physiological signaling, signal routing and mental function coding (neural code) with 'standard' interfaces between signal groups. We contend that despite the variety of signals that a neuron processes, the interfaces between same signal groups are standardized for all communications. The benefits of such a framework are that (i) it assumes that the mental function is coded in only a subset of the neuronal signals that suggests that research on mental functions could be restricted to certain parts of neuronal signals, and (ii) it assume standardized interfaces between logical signal groups that makes it possible to have common models of different mental functions, such as cognition, memory, neuro-muscular and audiovisual functions. We will present various experimental set ups possible for deriving quantitative models under this framework.","Rule Based Preferential Context Sharing in Location Aware Mobile AdvertisingThis paper introduces a novel context management system for mobile phone users that allows them to control which part of context data they want to reveal to their service provider and which part to keep on their device. With the use of semantic rules, users can set their custom privacy and preference profile in a way that targeted advertisements can still be served despite them not wanting to reveal these details to the provider. By shifting some part of the reasoning task to user device, the mobile service provider is still able to provide highly targeted advertisements by combining the private and publicly available parts of user information.","Free Web Mapping Tools to Characterise Landscape Dynamics and to Favour e-ParticipationGIS methodologies in combination with Remote Sensing data and techniques are fundamental to analyse and characterise Land Use/Land Cover (LULC) and their evolutionary dynamics. The case study here described, has been conducted in two study-areas: the Serre Regional natural Park and the so- called Conca of Avellino (Southern Italy). This study is part of a wider research allowed to understand how the landscape changes dynamics are linked and have been influenced by several causes (demography, economy, transportation net- work, people preferences, policies, etc.). A multi-temporal set of images (aerial photos and Landsat scenes) has been processed LULC. Then, through a GIS approach, change detection and spatiotemporal analysis has been integrated to characterise LULC dynamics, focusing on urban growth/sprawl phenomenon and loss of rural/natural lands. This paper focuses the attention on the WebGIS application based on free online tools which has been implemented with the aim to publish and to share with local communities all geospatial data produced. This platform will be further implemented in order to favour e-participation in the planning tools.","Dynamic EM in Neologism EvolutionResearch on unsupervised word sense discrimination typically ignores a notable dynamic aspect, whereby the prevalence of a word sense varies over time, to the point that a given word such as 'tweet' can acquire a new usage alongside a pre-existing one such as 'a Twitter post' alongside 'a bird noise'. This work applies unsupervised methods to text collections within which such neologisms can reasonably be expected to occur. We propose a probabilistic model which conditions words on senses, and senses on times and an EM method to learn the parameters of the model using data from which sense labels have been deleted. This is contrasted with a static model with no time dependency. We show qualitatively that the learned and the observed time-dependent sense distributions resemble each other closely, and quantitatively that the learned dynamic model achieves a higher tagging accuracy 82.4% than the learned static model does 76.1%.","On Solving the Small Sample Size Problem for Marginal Fisher AnalysisMarginal Fisher Analysis (MFA) was introduced to remedy some of the shortcomings of the Fisher Discriminant Analysis (FDA). It performs local discrimination between classes. Whenever the training data set is small, MFA cannot directly be used with the original high- dimensional samples. This is referred to as the small sample size (SSS) phenomenon that happens whenever the feature dimension is higher than the number of examples. The classic remedy was using the projection of the raw data (e.g., using (PCA)). This paper introduces two regulariza- tion schemes that overcome the singularity and near singularity of the locality preserving scatters. The first scheme uses ridge regression reg- ularization. The second scheme uses matrix exponential and introduces an implicit distance diffusion mapping. The experiments are conducted on four face data sets. These experiments demonstrate that the intro- duced schemes can enhance the performance of the MFA framework much better than the widely used PCA based regularization.","Transformation of Multi-level Systems - Theoretical Grounding and Consequences for Enterprise Architecture ManagementIn this paper, we investigate the support of enterprise architecture management (EAM) for enterprise transformation. Conceptualizing enterprises as systems, we draw on two theories that investigate static and dynamic system aspects, respectively  the theory of hierarchical, multi-level systems and control theory. From the theory of hierarchical, multi-level systems, we first introduce three orthogonal dimensions of hierarchy  layers, strata, and echelons. We then position EAM as a cross-dimensional transformation support function in this there-dimensional hierarchy space. Finally, we draw on control theory to derive a model of control and feedback loops that enables a designed EAM support of system-wide transformations. Using this model, we propose to extend the multi-level systems theory by a set of interlinked feedback loops as a fourth dimension. A case study of transformation in the Portuguese air force serves as an example illustrating the usefulness of the two theories for describing enterprise transformation.","Reasonably rational: reasoning about reasons behind preferences using modal logicReasoning about preferences is a fundamental component of rationality, and therefore central in AI and computational social choice. Most logic-based frameworks for representing and reasoning about preferences assume that preferences are arbitrarily given, typically as a ranking of a set of alternatives or using utilities, with little concern about how preferences are formed or where they come from. Recent work in rational choice theory, however, has devoted attention to giving more internal structure to the notion of rationality, focusing more on the faculties of individual agents, such as their mood, mindset, and motivating reasons. In this paper we develop a modal logic for reasoning about preferences that depend on a set of motivationally salient properties, based on recent work on reasons behind preferences by Dietrich and List. The main result is that we show how the problem of reasoning in this logic can be translated to reasoning in a standard modal logic (KT with universal modality), and consequently that reasoning systems and algorithms developed for modal logic (with universal modality) can be employed for reasoning about reason-based preferences.","Estimating the breadth of search queriesThis paper proposes a novel method to estimate the breadth of a search query. Using the spatial distribution of relevant categories in a taxonomy, together with an 'importance' score obtained using a ranked list of search results, we derive a metric that represents the breadth of a query. Several experiments have been performed on the DMOZ hierarchy with two different sets of queries and benchmarked with state-of-the-art results. Evaluation of the method based on metrics such as F-measure and accuracy indicate better agreement with human judgements.","Prediction of non-genotoxic hepatocarcinogenicity using chemical-protein interactionsThe assessment of non-genotoxic hepatocarcinogenicity of chemicals is currently based on 2-year rodent bioassays. It is desirable to develop a fast and effective method to accelerate the identification of potential hepatocarcinogenicity of non-genotoxic chemicals. In this study, a novel method CPI is proposed to predict potential hepatocarcinogenicity of non-genotoxic chemicals. The CPI method is based on chemical-protein interactions and interpretable decision tree classifiers.The interpretable rules generated by the CPI method are analyzed to provide insights into the mechanism and biomarkers of non-genotoxic hepatocarcinogenicity. The CPI method with an independent test accuracy of 86% using only 1 protein biomarker outperforms the state-of-the-art methods of gene expression profile-based toxicogenomics using 90 gene biomarkers. A protein ABCC3 was identified as a potential protein biomarker for further exploration. This study presents the potential application of CPI method for assessing non-genotoxic hepatocarcinogenicity of chemicals.","A Game Theoretical Perspective on Small-Cell Open Capacity Sharing in Cognitive Radio EnvironmentsSmall-cell, open capacity sharing scenarios in Cognitive Radio (CR) environments are studied from a game theoretical (GT) perspective. Simultaneous capacity requests in small-cell scenarios are modelelled as strategic interactions between CRs and analysed as re- source access games. CR capacity access competition is modelled based on discrete reformulations of the Bertrand GT model. Detected equilib- ria describe stable game situations. Numerical simulations identify sit- uations where Nash equilibrium (NE) is both fair and Pareto efficient or where there are multiple NE solutions to choose from, indicating a flexible range for CR strategies. Adding to the analysis are the joint Nash-Pareto solutions (intermediate between Nash and Pareto) captur- ing heterogeneous behaviour of players. Stable and equitable states are detected even when players have different biases.","Translation of EEG-Based Performance Prediction Models to Rapid Serial Visual Presentation Tasks ","Guaranteed Sparse Recovery under Linear TransformationWe consider the following signal recovery problem: given a measurement matrix \u03a6 \u2208 Rn\u00d7p and a noisy observation vector c \u2208 Rn constructed from c = \u03a6\u03b8* + e where e \u2208 Rn is the noise vector whose entries follow i.i.d. centered sub-Gaussian distribution, how to recover the signal \u03b8* if D\u03b8* is sparse under a linear transformation D \u2208 Rm\u00d7p? One natural method using convex optimization is to solve the following problem: min \u03b8 1/2||\u03a6\u03b8 - c||2 + \u03bb||D\u03b8||1. This paper provides an upper bound of the estimate error and shows the consistency property of this method by assuming that the design matrix \u03a6 is a Gaussian random matrix. Specifically, we show 1) in the noiseless case, if the condition number of D is bounded and the measurement number n \u2265 \u03a9(s log(p)) where s is the sparsity number, then the true solution can be recovered with high probability; and 2) in the noisy case, if the condition number of D is bounded and the measurement increases faster than s log(p), that is, s log(p) = o(n), the estimate error converges to zero with probability 1 when p and s go to infinity. Our results are consistent with those for the special case D = Ip\u00d7p (equivalently LASSO) and improve the existing analysis. The condition number of D plays a critical role in our analysis. We consider the condition numbers in two cases including the fused LASSO and the random graph: the condition number in the fused LASSO case is bounded by a constant, while the condition number in the random graph case is bounded with high probability if m/p (i.e., #edge/#vertex) is larger than a certain constant. Numerical simulations are consistent with our theoretical results.","An Exploration of Figures and Text in Visual Narration: Visual Flow and Preference Factors ","Multivariate Signature Scheme Using Quadratic FormsMultivariate Public Key Cryptosystems (MPKC) are candi- dates for post-quantum cryptography. MPKC has an advantage in that its encryption and decryption are relatively efficient. In this paper, we propose a multivariate signature scheme using quadratic forms. For a finite dimensional vector space V , it is known that there are exactly two equivalence classes of non-degenerate quadratic forms over V. We utilize the method to transform any non-degenerate quadratic form into the nor- mal form of either of the two equivalence classes in order to construct a new signature scheme in MPKC. The signature generation of our scheme is between eight and nine times more efficient more than the multivariate signature scheme Rainbow at the level of 88-bit security. We show that the public keys of our scheme can not be represented by the public keys of other MPKC signature schemes and this means our scheme is immune to many attacks that depend on the form of the central map used by these schemes.","Computational Methods for the Parallel 3D Simulation of Biochemical Kinetics at the Microscopic ScaleThis work takes place in the context of biochemical kinetics simulation for the understanding of complex biological systems such as haemostasis. The classical approach, based on the numerical solving of differential systems, cannot satisfactorily handle local geometrical constraints, such as membrane binding events. To address this problem, we propose a particle-based system in which each molecular species is represented by a three-dimensional entity which diffuses and may undergo reactions. Such a system can be computationaly intensive, since a small time step and a very large number of entities are required to get significant results. Therefore, we propose a model that is suitable for parallel computing and that can especially take advantage of recent multicore and multiprocessor architectures. We present our particle-based system, detail the behaviour of our entities, and describe our parallel computing algorithms. Comparisons between simulations and theoretical results are exposed, as well as a performance evaluation of our algorithms.","Effect of Light Priming and Encouraging Feedback on the Behavioral and Neural Responses in a General Knowledge TaskThe increase of cognitive demands in society nowadays requires new ways to deal with problems, such as burnout and mental fatigue. Lately, more and more scientifically-based rigorous research in the area of brain-computer interfaces has been done in the quest for restoring and augmenting cognition. The current research work investigates light-based priming and positive rein- forcement as possible mediators of cognitive enhancement.","A Geo-ontology Design Pattern for Semantic TrajectoriesTrajectory data have been used in a variety of studies, including human behavior analysis, transportation management, and wildlife tracking. While each study area introduces a different perspective, they share the need to integrate positioning data with domain-specific information. Semantic annotations are necessary to improve discovery, reuse, and integration of trajectory data from different sources. Consequently, it would be beneficial if the common structure encountered in trajectory data could be annotated based on a shared vocabulary, abstracting from domain-specific aspects. Ontology design patterns are an increasingly popular approach to define such flexible and self-contained building blocks of annotations. They appear more suitable for the annotation of interdisciplinary, multi-thematic, and multi-perspective data than the use of foundational and domain ontologies alone. In this paper, we introduce such an ontology design pattern for semantic trajectories. It was developed as a community effort across multiple disciplines and in a data-driven fashion. We discuss the formalization of the pattern using the Web Ontology Language (OWL) and apply the pattern to two different scenarios, personal travel and wildlife monitoring.","Tool Support for Checking Consistency of UML Model ","Versatile XQuery Processing in MapReduceThe MapReduce MR framework has become a standard tool for performing large batch computations--usually of aggregative nature--in parallel over a cluster of commodity machines. A significant share of typical MR jobs involves standard database-style queries, where it becomes cumbersome to specify map and reduce functions from scratch. To overcome this burden, higher-level languages such as HiveQL, PigLatin, and JAQL have been proposed to allow the automatic generation of MR jobs from declarative queries. We identify two major problems of these existing solutions: i they introduce new query languages and implement systems from scratch for the sole purpose of expressing MR jobs; and ii despite solving some of the major limitations of SQL, they still lack the flexibility required by big data applications. We propose BrackitMR, an approach based on the XQuery language with extended JSON support. XQuery not only is an established query language, but also has a more expressive data model and more powerful language constructs, enabling a much greater degree of flexibility. From a system design perspective, we extend an existing single-node query processor, Brackit, adding MR as a distributed coordination layer. Such heavy reuse of the standard query processor not only provides performance, but also allows for a more elegant design which transparently integrates MR processing into a generic query engine.","Contextual Synchronization for Efficient Social Collaborations: A Case Study on TweetPulse ","Modelling of Things on the Internet for the Search by the Human BrainThe Internet has become the main source of information for business and research activities. Despite the value of libraries supported by computational cataloging, there are far more opportunities to retrieve information on the Internet than in paper books. However, when we seek the Internet we get essentially chunks of text with titles and descriptors resulting from search engine\u2019s activity. Albeit some information may contain sensorial or emotional contents, the search results come essentially from algorithmic execution over keywords by relevance. Our brain retrieves information about things in real world by capturing sensorial information and storing it with emotional experience. We can question why things in Internet are not represented in a similar way to human brain. The present research aims to support a new type of search by sensations and emotions in a path to model Things in Internet towards a human-like representation of objects and events, based on lessons learned from the human brain.","Spatio-temporal Features for Efficient Video Copy DetectionContent-Based Video Copy Detection (CBVCD) aims at de- tecting whether or not a query video is a copy or part of a reference video from database. In this paper, we present a CBVCD system based on spatio- temporal features that can competitively deal with large database in terms of both performance and efficiency. Instead of selecting keyframes or uni- formly sampling from original videos and then extracting global or local visual features for frames, we first divide a video into segments with fixed length and then extract 3D spatio-temporal features for the whole seg- ment. After that, we perform similarity search comparing all the reference segments with query segments and apply a copy verifying to decide the fi- nal copy detection result. The experimental results on the TRECVID 2011 video copy detection dataset show that the proposed system is effective and efficient.","A Novel Diversity Maintenance Scheme for Evolutionary Multi-objective OptimizationRecently, decomposition-based multi-objective evolutionary algorithm MOEA/D has received increasing attentions due to its simplicity and decent optimization performance. In the presence of the deceptive optimum, the weight vector approach used in MOEA/D may not be able to prevent the population traps into local optimum. In this paper, we propose a new algorithm, namely Diversity Preservation Multi-objective Evolutionary Algorithm based on Decomposition DivPre-MOEA/D, which uses novel diversity maintenance scheme to enhance the performance of MOEA/D. The proposed algorithm relaxes the dependency of the weight vector approach on approximated ideal vector to maintain diversity of the population. The proposed algorithm is evaluated on CEC-09 test suite and compared the optimization performance with MOEA/D. The experiment results show that DivPre-MOEA/D can provide better solutions spread along the Pareto front.","Exploring Strategic Organizational Engagement in Social Media: A Revelatory Case ","Editorial: Special issue on Advances in fuzzy knowledge systems: Theory and application ","A More Efficient and Secure Authentication Scheme over Insecure Networks Using Smart Cards ","Towards causal modeling of human behaviorThis article proposes experiments on decision making based on the \u201cWinter Survival Task\u201d, one of the scenarios most commonly applied in behavioral and psychological studies. The goal of the Task is to identify, out of a predefined list of 12 items, those that are most likely to increase the chances of survival after the crash of a plane in a polar area. In our experiments, 60 pairs of unacquainted individuals (120 subjects in total) negotiate a common choice of the items to be retained after that each subject has performed the task individually. The results of the negotiations are analyzed in causal terms and show that the choices made by the subjects individually act as a causal factor with respect to the outcome of the negotiation.","Towards a design guideline of visual cryptography on stereoscopic displaysThis paper proposed a new visual cryptography scheme with the stereoscopic display which showed and accurately decrypted the hidden information for gray images. Results indicated that contrast ratio and pixel disparity of the decrypted stereo-image were key problems that would impact on the perceived quality of the decrypted image. Next, this research performed a subjective experiment of shifting pixels between both of left and right images to investigate the disparity effects of decrypted information on a full HD stereo-display with film-pattern-retarder technology. In addition, the effects of font size and contrast ratio were addressed as well. Results revealed that the thresholds of pixel disparity were between 2 and 7 pixels. To alphabets, the font size of 50 points was lower boundary to show the decrypted information. To numeric, the font size of 45 points was lower boundary over different contrast ratios.","Data-Driven Methods for SMS-Based FAQ RetrievalSMS text messaging is one of the most popular data applica- tions on mobile phones these days. Other than personal communication, text messaging can also be used for various purposes like bill payment, banking, inquiry, etc. However these messages are extremely noisy and contain misspellings, abbreviations, transliterations, etc. Keeping this in mind, FIRE 2011 introduced a new retrieval task called SMS-based FAQ retrieval in English, Hindi and Malayalam. Within-language and cross- language tasks were designed for this retrieval problem. As solutions we propose various data-driven retrieval techniques that includes noise re- duction in the SMS queries and the FAQ corpora. Overall, we find that our methods work well for the retrieval experiments in the different lan- guages. For English, the use of Google Spelling Suggestions and term expansion strategies improve retrieval scores. For Hindi and Malayalam retrieval experiments, we find that translation of queries and corpus to English increases retrieval accuracy.","Symbiotic Simulation of Assembly Quality Control in Large Gas Turbine Manufacturing ","Solving existentially quantified horn clausesTemporal verification of universal (i.e., valid for all computation paths) properties of various kinds of programs, e.g., procedural, multi-threaded, or functional, can be reduced to finding solutions for equations in form of universally quantified Horn clauses extended with well-foundedness conditions. Dealing with existential properties (e.g., whether there exists a particular computation path), however, requires solving forall-exists quantified Horn clauses, where the conclusion part of some clauses contains existentially quantified variables. For example, a deductive approach to CTL verification reduces to solving such clauses. In this paper we present a method for solving forall-exists quantified Horn clauses extended with well-foundedness conditions. Our method is based on a counterexample-guided abstraction refinement scheme to discover witnesses for existentially quantified variables. We also present an application of our solving method to automation of CTL verification of software, as well as its experimental evaluation.","Synthetic Social Network Based on Competency-Based Description of Human Resources ","Application of Knowledge Driven Mobile Robots for Disassembly Tasks ","Motor experience interacts with effector information during action prediction ","Patterns amongst competing task frequencies: Super-Linearities and the Almond-DG modelIf Alice has double the friends of Bob, will she also have dou- ble the phone-calls (or wall-postings, or tweets)? Our first contribution is the discovery that the relative frequencies obey a power-law (sub-linear, or super-linear), for a wide variety of diverse settings: tasks in a phone- call network, like count of friends, count of phone-calls, total count of minutes; tasks in a twitter-like network, like count of tweets, count of followees etc. The second contribution is that we further provide a full, digitized 2-d distribution, which we call the Almond-DG model, thanks to the shape of its iso-surfaces. The Almond-DG model matches all our empirical observations: super-linear relationships among variables, and (provably) log-logistic marginals. We illustrate our observations on two large, real network datasets, spanning \u223c 2.2M and \u223c 3.1M individu- als with 5 features each. We show how to use our observations to spot clusters and outliers, like, e.g., telemarketers in our phone-call network.","A Guide to Implement Open Data in Public AgenciesThis article presents a guide to implement open data in Public Agencies PAs. The guide is the result of a worldwide proposal's study, of the application of a maturity model to diagnose the situation of PAs in Latin American countries, the opinion of experts in different excellence centers, e-government authorities, and developers of open data application in the world. The guide is simple and orients decision makers so that PAs following the actions of the guide can see their capacities improved when facing a diagnosis of their institutional maturity in implementation of open data.","Quantitative Analysis of AODV and Its Variants on Dynamic Topologies Using Statistical Model Checking ","A Fast Algorithm for Predicting Topics of Scientific Papers Based on Co-authorship Graph Model ","New Algorithm for Evolutionary Selection of the Dynamic Signature Global Features ","Temporalizing Modal Epistemic LogicTimed Modal Epistemic Logic, tMEL, is a newly introduced logical framework for reasoning about the modeled agent's knowledge. The framework, derived from the study of Justification Logic, is adapted from the traditional Modal Epistemic Logic, MEL, to serve as a logi- cally non-omniscient epistemic logic and dealing with problems where the temporal constraint is an unavoidable factor. In this paper we will give a semantic proof for the formal connection between MEL and tMEL, the Temporalization Theorem, which states that every MEL theorem can be turned into a tMEL theorem if suitable time labels can be found for each knowledge statement involved in the MEL theorem. As a result, the proof also gives us a better understanding of the semantics on the both sides of the theorem.","A fast agglomerative community detection method for protein complex discovery in protein interaction networksProteins are known to interact with each other by forming protein complexes and in order to perform specific biological functions. Many community detection methods have been devised for the discovery of protein complexes in protein interaction networks. One common problem in current agglomerative community detection approaches is that vertices with just one neighbor are often classified as separate clusters, which does not make sense for complex identification. Also, a major limitation of agglomerative techniques is that their computational efficiency do not scale well to large protein interaction networks (PINs). In this paper, we propose a new agglomerative algorithm, FAC-PIN, based on a local premetric of relative vertex-to-vertex clustering value and which addresses the above two issues. Our proposed FAC-PIN method is applied to eight PINs from different species, and the identified complexes are validated using experimentally verified complexes. The preliminary computational results show that FAC-PIN can discover protein complexes from PINs more accurately and faster than the HC-PIN and CNM algorithms, the current state-of-the-art agglomerative approaches to complex prediction.","A versatile tool for privacy-enhanced web searchWe consider the problem of privacy leaks suffered by Internet users when they perform web searches, and propose a framework to mitigate them. Our approach, which builds upon and improves recent work on search privacy, approximates the target search results by replacing the private user query with a set of blurred or scrambled queries. The results of the scrambled queries are then used to cover the original user interest. We model the problem theoretically, define a set of privacy objectives with respect to web search and investigate the effectiveness of the proposed solution with a set of real queries on a large web collection. Experiments show great improvements in retrieval effectiveness over a previously reported baseline in the literature. Furthermore, the methods are more versatile, predictably-behaved, applicable to a wider range of information needs, and the privacy they provide is more comprehensible to the end-user.","Keep Querying and Tag on: Collaborative Folksonomy Using Model-Based RecommendationTags are terms commonly used in collaborative media systems like Flickr, Youtube and Picasa to classify a subject, image, video, music or any related content. Despite its popularity, tagging is a repetitive task and that may affect the quality and reuse of tags in collaborative systems. In this paper we use a model-based tag recommendation approach to perform an experiment and analyze the vocabulary homogeneity of queries tags provided by users, the recommended tags and their reuse. Results show that the use of recommendation improves the quality and reuse of tags. Furthermore, based on users attribution behavior, we conclude with a proposal for personalized tag recommendation.","Modeling Component Erroneous Behavior and Error Propagation for Dependability Analysis ","Novel Measures for Reciprocal Behavior and Equivalence in Signed NetworksSigned Networks allow explicit show of trust/distrust relationships between actors. In this poster, we provide novel measures for analyzing the following phenomena in signed networks: (i) reciprocal behavior between pairs of actors in terms of trusting/distrusting each other, and (ii) equivalence of actors in terms of their patterns of trusting/distrusting other actors.","Flexible Combinatory Categorial Grammar Parsing Using the CYK Algorithm and Answer Set ProgrammingCombinatory Categorial Grammar CCG is a grammar formalism used for natural language parsing. CCG assigns structured lexical categories to words and uses a small set of combinatory rules to combine these categories in order to parse sentences. In this work we describe and implement a new approach to CCG parsing that relies on Answer Set Programming ASP -- a declarative programming paradigm.Different from previous work, we present an encoding that is inspired by the algorithm due to Cocke, Younger, and Kasami CYK. We also show encoding extensions for parse tree normalization and best-effort parsing and outline possible future extensions which are possible due to the usage of ASP as computational mechanism. We analyze performance of our approach on a part of the Brown corpus and discuss lessons learned during experiments with the ASP tools dlv, gringo, and clasp. The new approach is available in the open source CCG parsing toolkit AspCcgTk which uses the C&amp;C supertagger as a preprocessor to achieve wide-coverage natural language parsing.","Privacy Management and Accountability in Global Organisations ","Review Article: Design of nearly perfect reconstructed non-uniform filter bank by constrained equiripple FIR techniqueIn this paper, an efficient iterative algorithm is proposed for the design of multi-channel nearly perfect reconstructed non-uniform filter bank. The method employs the constrained equiripple FIR technique to design the prototype filter for filter banks with novelty of exploiting a new perfect reconstruction condition of the non-uniform filter banks instead of using complex objective functions. In the proposed algorithm, passband edge frequency (@w\"p) is optimized using linear optimization technique such that the filter coefficients values at quadrature frequency are approximately equal to 0.707. Several design examples are included to illustrate the efficacy of this methodology for designing non-uniform filter bank (NUFB). It was found that the proposed methodology performs better as compared to earlier reported results in terms of reconstruction error (RE), number of iteration (NOI) and computation time (CPU time). The proposed algorithm is very simple, linear in nature, and easy to implement.","Latent feature models for dyadic predictionFollowing the Netflix prize, the collaborative filtering problem has gained significant attention within machine learning, spawning novel models and theoretical analyses. In parallel, the growth of social media has driven research in link prediction, with the aim of determining whether two individuals in a network are likely to know each other. Both problems involve the prediction of label (star ratings or friendship) between a pair of entities (user-movie or user-user). We call this general problem dyadic prediction. The problem arises in several other guises: predicting student responses to test questions, military disputes between nations, and clickthrough rates of webpages on ads, to name a few. #R##N#In general, each such domain employs a markedly different approach, obscuring the underlying similarity of the problems being solved. This dissertation aims to explore the use of a single general method, based on latent feature modelling, for generic dyadic prediction problems. To this end, we make three contributions. First, we propose a generic framework with which to analyze dyadic prediction problems. This lets one reason about seemingly disparate problems in a unified manner. Second, we propose a model based on the log-linear framework, which is applicable to each of the aforementioned problems. The model learns latent features from dyadic data, and estimates a probability distribution over labels. Third, we systematically explore applications of our latent feature model to domains such as collaborative filtering, link prediction, and clickthrough rate prediction. In all cases, we show performance comparable or superior to existing state-of-the-art methods. For clickthrough rate prediction, ours represents the first application of latent feature modelling to the problem, demonstrating the value in a single framework with which to reason about these problems. We also show that latent feature modelling is scalable to datasets with hundreds of millions of observations on a single machine (the Netflix prize dataset), and hundreds of billions of observations on a small cluster (Yahoo! ad click data). #R##N#We conclude with a discussion of future research directions, including transferring information from one network to another, and adapting to domains with extreme label sparsity.","Distributed Coordination of Multiple Robot Systems Based on Hierarchical Petri Net ModelsThe paper presents a systematic methodology for modeling multi-robot production tasks based on extended Petri nets. To overcome some difficulties in the modeling of complex discrete event systems with a large number of elements in basic Petri nets, extended high-level Petri nets are introduced based on condition-event Petri nets. The high-level net representation of the conceptual task flows and detailed control functions with a top-down refinement methodology can provide more synthetic specifications for consistent management and distributed coordination of multi-robot systems.","Software Implementation of Linear Feedback Shift Registers over Extended Fields ","A Survey Of Mobile Health System Infusion Among Healthcare Practitioners ","A formal framework for property-driven obfuscation strategiesWe study the existence and the characterization of function transformers that minimally or maximally modify a function in order to reveal or conceal a certain property. Based on this general formal framework we develop a strategy for the design of the maximal obfuscating transformation that conceals a given property while revealing the desired observational behaviour.","Understanding Status Update in Microblog: A Perspective on Media Needs ","The Small Loop Problem: A Challenge for Artificial Emergent Cognition ","Exploiting Multi-Objective Evolutionary Algorithms for Designing Energy-Efficient Solutions to Data Compression and Node Localization in Wireless Sensor NetworksWireless sensor network (WSN) technology promises to have a high po- tential to tackle environmental challenges and to monitor and reduce energy and greenhouse gas emissions. Indeed, WSNs have already been successfully employed in applications such as intelligent buildings, smart grids and energy control sys- tems, transportation and logistics, and precision agriculture. All these applications generally require the exchange of a large amount of data and the localization of the sensor nodes. Both these two tasks can be particularly energy-hungry. Since sensor nodes are typically powered by small batteries, appropriate energy saving strategies have to be employed so as to prolong the lifetime of the WSNs and to make their use attractive and effective. To this aim, the study of data compression algorithms suitable for the reduced storage and computational resources of a sensor node, and the exploration of node localization techniques aimed at estimating the positions of all sensor nodes of a WSN from the knowledge of the exact locations of a re- stricted number of these nodes, have attracted a large interest in the last years. In this chapter, we discuss how multi-objective evolutionary algorithms can success- fully be exploited to generate energy-aware data compressors and to solve the node localization problem. Simulation results show that, in both the tasks, the solutions produced by the evolutionary processes outperform the most interesting approaches recently proposed in the literature.","Review article: Achieving maximum reliability in fault tolerant network design for variable networksThe objective of this paper is to present a novel method to achieve maximum reliability for fault tolerant optimal network design when network has variable size. Reliability calculation is most important and critical component when fault tolerant optimal network design is required. A network must be supplied with certain parameters that guarantee proper functionality and maintainability under worse situations. Many alternative methods for measuring reliability have been stated in literature for optimal network design. Most of these methods mentioned in literature for evaluating reliability may be analytical and simulation based. These methods provide significant way to compute reliability when network has limited size. Also, significant computational effort is required for growing variable sized networks. Therefore, a novel neural network method is presented to achieve significant high reliability for fault tolerant optimal network design in highly growing variable networks. This paper computes reliability with improved learning rate gradient descent based neural network method. The result shows that improved optimal network design with maximum reliability is achievable by novel neural network at manageable computational cost.","Industrial Software Engineering and Formal Methods ","A Model Driven Security Engineering Approach to Support Collaborative Tools Deployment Over Clouds ","Towards Trustworthy Network Measurements ","Model of Syntactic Recognition of Distorted String Patterns with the Help of GDPLL(k)-Based Automata ","Single line train scheduling with ACOIn this paper we study a train scheduling problem on a single line that may be traversed in both directions by trains with different priorities travelling with different speeds. We propose an ACO approach to provide decision support for tackling this problem. Our results show the strong performance of ACO when compared to optimal solutions provided by CPLEX for small instances as well as to other heuristics on larger instances.","Spatio-temporal Change Detection of Urban Heat Islands Using Spatial Interpolation ","Examining the Effect of Rear Leg Specialization on Dynamic Climbing with SCARAB: A Dynamic Quadrupedal Robot for Locomotion on Vertical and Horizontal Surfaces ","RelicPad: A Hands-On, Mobile Approach to Collaborative Exploration of Virtual Museum ArtifactsIn an ideal world, physical museum artefacts could be touched, handled, examined and passed between interested viewers by hand. Unfortunately, this is not always possible \u2013 artefacts may be too fragile to handle or pass around, or groups of people with mutual interests in objects may not be in the same location. This can be problematic when attempting to explain or make#R##N#sense of the physical properties of artefacts. #R##N##R##N# To address these problems, we propose that direct manipulation of 3D content based on real-world interaction metaphors can help collaborators (both co and remotely located) to construct personal and mutual physical and spatial awareness of artefacts, while networked communication and collaboration allow for ideas and knowledge to be exchanged and shared. #R##N##R##N# We present our interpretations from two studies of  RelicPad , a tablet-based#R##N#application that allows users to manually manipulate museum artefacts and to \u2018point out\u2019 areas of interest to each other using 3D annotations, facilitating a mutual awareness of spatial properties and referencing during discussion.","A Survey of Core Research in Information SystemsThe Information Systems (IS) discipline was founded on the intersection of computer science and organizational sciences, and produced a rich body of research on topics ranging from database design and the strategic role of IT to website design and online consumer behavior. In this book, the authors provide an introduction to the discipline, its development, and the structure of IS research, at a level that is appropriate for emerging and current IS scholars. Guided by a bibliometric study of all research articles published in eight premier IS research journals over a 20-year period, the authors identify and present the top 51 IS research topics. For each topic, they provide a brief overview, time trends, and references to related influential research works. The topics are organized into an IS research framework that includes research on the IT artifact and IS development, IT and organizations, IT and individuals, IT and markets, and IT for teamwork and collaboration.","The local Hamiltonian problem on a line with eight states is QMA-completeThe Local Hamiltonian problem is the problem of estimating the least eigenvalue of a local Hamiltonian, and is complete for the class QMA. The 1D problem on a chain of qubits has heuristics which work well, while the 13-state qudit case has been shown to be QMA-complete. We show that this problem remains QMA-complete when the dimensionality of the qudits is brought down to 8.","BioCyberUrban parq: an ubiquitous and pervasive computing system for environmental integrationThe goal of BioCyberUrban parQ project is to connect the living things, objects and environment in order to enable their cybernetic communication/coexistence in Sarah Kubitschek Park (Brasilia's city park). Art and society context aim the processes of physical, intellectual and moral users consciousness development, along with all living beings in the City Park. Therefore we seek for a better ecosystem coexistence, integration and communication through the crowd-collected data as the foundation of this cyber community.","PRIVATE EQUITY , TECHNOLOGICAL INVESTMENT , AND LABOR OUTCOMESThis paper uses novel data on the employment histories of a large fraction of the US workforce to present empirical evidence that corporate technological investment has a significant impact on workers\u2019 subsequent labor market outcomes. Exploiting leveraged buyouts as shocks to firms\u2019 production technologies, we find that employees retained after a private equity acquisition experienced increased long run employment tenures, reductions in short run unemployment durations, and higher rates of within-occupation mobility. The evidence supports the view that private equity investment, by upgrading the technology and operations of the firm, imparts valuable and transferable human capital to retained workers. The effects are especially pronounced for workers in occupations complementary to IT-enabled work practices, and for those who are employed at the acquired firm for longer durations before exit. The findings suggest that employers\u2019 investments in information technology are a critical determinant of human capital stock and subsequent labor outcomes for workers.","Provisioning Quality-Aware Social Compute Units in the CloudTo date, on-demand provisioning models of human-based services in the cloud are mainly used to deal with simple human tasks solvable by individual compute units ICU. In this paper, we propose a framework allowing the provisioning of a group of people as an execution service unit, a so-called Social Compute Unit SCU, by utilizing clouds of ICUs. Our model allows service consumers to specify quality requirements, which contain constraints and objectives with respect to skills, connectedness, response time, and cost. We propose a solution model for tackling the problem in quality-aware SCUs provisioning and employ some metaheuristic techniques to solve the problem. A prototype of the framework is implemented, and experiments using data from simulated clouds and consumers are conducted to evaluate the model.","Adaptive Sequential Prefetching for Multiple StreamsModern storage systems are becoming increasingly consoli- dated. As a result, there exists a competition for resources among con- current streams. Sequential prefetching is widely used in modern storage system. Most of them always ignore the impact of diversified access rate of concurrent streams. However the concurrent streams with diversified access rate will introduce several problems. The streams with fast ac- cess rate may evict the cache blocks of the streams with slow access rate and lead the slow streams re-fetch the evicted cache blocks in future access, which makes the prefetching wastage and unfairness to the slow streams. We design and implement a novel, adaptive algorithm, named ASPM to solve these problems. Our experiments show that, compared with LRU and AMP, ASPM can achieve significantly improvement in fairness among concurrent streams and slightly in performance (average on 6.8%).","Distant supervision for emotion classification with discrete binary valuesIn this paper, we present an experiment to identify emotions in tweets. Unlike previous studies, which typically use the six basic emotion classes defined by Ekman, we classify emotions according to a set of eight basic bipolar emotions defined by Plutchik (Plutchik's \"wheel of emotions\"). This allows us to treat the inherently multi-class problem of emotion classification as a binary problem for four opposing emotion pairs. Our approach applies distant supervision, which has been shown to be an effective way to overcome the need for a large set of manually labeled data to produce accurate classifiers. We build on previous work by treating not only emoticons and hashtags but also emoji, which are increasingly used in social media, as an alternative for explicit, manual labels. Since these labels may be noisy, we first perform an experiment to investigate the correspondence among particular labels of different types assumed to be indicative of the same emotion. We then test and compare the accuracy of independent binary classifiers for each of Plutchik's four binary emotion pairs trained with different combinations of label types. Our best performing classifiers produce results between 75-91%, depending on the emotion pair; these classifiers can be combined to emulate a single multi-label classifier for Plutchik's eight emotions that achieves accuracies superior to those reported in previous multi-way classification studies.","Evaluation of a personal mobile coaching service for health tracking.Yukendu is a personal mobile coaching service that supports people in reaching good levels of psychological and physical wellbeing. The aim of this contribution is to describe the peculiarities of Yukendu and its multi-step evaluation process.","Recognizing and Tagging Vietnamese Words Based on Statistics and Word Order Patterns ","Drug Intervention Response Predictions with PARADIGM (DIRPP) identifies drug resistant cancer cell lines and pathway mechanisms of resistance. ","The Cross-Cultural Knowledge Sharing Challenge: An Investigation of the Co-location Strategy in Software Development OffshoringCross-cultural offshoring in software development challenges effec- tive knowledge sharing. While research has suggested temporarily co-locating participants to address this challenge, few studies are available on what knowledge sharing practices emerge over time when co-locating cross-cultural software developers. This paper presents a longitudinal case study of an off- shoring project with co-location of Indian and Danish software developers for 10\u00bd months. A community-of-practice (CoP) analysis is offered of what knowledge sharing practices emerge over time and how these where facilitated. The study supports previous studies' suggestion of co-location in offshoring for helping cross-cultural knowledge sharing. However, the short initial period of co-location suggested in these studies, was insufficient for achieving knowledge sharing practices indicating a CoP. In conjunction with a longer period of co- location four facilitators of cross-cultural knowledge sharing were shared of- fice, shared responsibility for tasks and problems, shared prioritization of team spirit, and a champion of social integration.","Efficient Data Aggregation with CCNx in Wireless Sensor NetworksCCNx is the reference implementation for a content centric networking (CCN) protocol developed by the Palo Alto Research Cen- ter CCNx group. It serves also as reference for our CCN-WSN, a CCNx implementation for wireless sensor networks (WSN). Efficient data ag- gregation with CCN-WSN is a challenge. In order to collect data from source in the network data sinks have to poll data sources with inter- ests and exclude fields in interests are necessary bloating the interest messages. We solve the problem by introducing three building blocks in CCN-WSN: unicast faces for packet filtering and \"link\" abstraction, a forwarding service for creating network overlay structures used by ap- plications and an intra-node protocol providing an API for applications to interact with the forwarding service. For evaluation purpose we im- plement an application using a forwarding service implementing a tree topology to collect data in the WSN.","Optimizing cross traffic with an adaptive CDN replica placement strategyContent Distribution Networks (CDN) are a popular technology used to deliver content and have attracted great interest in recent years. CDNs place content replicas closer to end users by geographically distributing replica servers. One important research point concerning the CDN universe concerns decisions about where replica servers should be placed. Algorithms that try to tackle this problem are Replica Placement Algorithms (RPA). In this paper we propose a new dynamic RPA strategy, very similar to the Greedy strategy, based on the count of data flows through network nodes. Our experiments show better results using the proposed Flow Count Strategy than using Greedy or Hotspot algorithms when considering cross traffic with a similar quality of experience. Also, the obtained results show that Flow Count seems to place replica servers more efficiently during local flash crowd events.","Explicit Untainting to Reduce Shadow Memory Usage and Access Frequency in Taint AnalysisSoftware vulnerabilities weaken the security of a system in- creasing possibility of being attacked by exploits in the wild. There are a lot of researches being done on efficiently finding software vulnerabili- ties to eliminate them. General program testing method for finding flaws in software can be categorized into whitebox and blackbox testing. In whitebox testing, tester examines the internals of the target program such as source codes while in blackbox testing, tester is not aware of the internal structure. Taint analysis is a blackbox testing method efficient for prioritizing exploitable crashes by tracking external input to the pro- gram. However due to memory usage and large amount of computation, taint analysis is slow to be used for commercial programs. There has been heuristic approaches to speed up the analysis process but it is not in state of practical use yet. In this paper, we propose a method to reduce resource usage by selectively not tracking certain memories and registers which we call untainting. Our evaluation results show that by untainting we can reduce number of taint operation by considerable amount.","Land cover/land use multiclass classification using GP with geometric semantic operatorsMulticlass classification is a common requirement of many land cover/land use applications, one of the pillars of land science studies. Even though genetic programming has been applied with success to a large number of applications, it is not particularly suited for multiclass classification, thus limiting its use on such studies. In this paper we take a step forward towards filling this gap, investigating the performance of recently defined geometric semantic operators on two land cover/land use multiclass classification problems and also on a benchmark problem. Our results clearly indicate that genetic programming using the new geometric semantic operators outperforms standard genetic programming for all the studied problems, both on training and test data.","An intelligent tutoring system based on speech assessment for spoken english learning in chinaWith the development of mobile Internet, speech technology has matured. In education, automatic speech assessment technology has been gradually applied in language learning. Since intelligent tutoring system is distinguished by its one-on-one individualized teaching effects, this paper has proposed an intelligent tutoring system based on speech assessment for spoken English learning in China. The system provides context of situation for English learning as well as automatic assessment services. The results show that the assessment is of high validity and reliability and the system is greatly helpful for Chinese middle school students to learn spoken English.","Using a Cross-Language Approach to Acquire New Mappings between Two Biomedical TerminologiesThe exploitation of clinical reports for generating alerts especially re- lies on the alignment of the dedicated terminologies, i.e., MedDRA (exploited in the pharmacovigilance area) and SNOMED International (exploited recently in France for encoding clinical documents). In this frame, we propose a cross- language approach for acquiring automatically alignments between terms from MedDRA and SNOMED International. We had the hypothesis that using addi- tional languages could be helpful to complement the mappings obtained be- tween French terms. Our approach is based on a lexical method for aligning MedDRA terms to those from SNOMED International. The concomitant use of multiple languages resulted in several hundreds of new alignments and success- fully validated or disambiguated some of these alignments.","Time and Personality Based Behaviors under Cognitive Approach to Control the Negotiation Process with Incomplete Information ","Ergonomic evaluation of usability with users: application of the technique of cooperative evaluationThis paper presents the application of a cooperative evaluation, technical evaluation performed ergonomic usability with users in the Learning Management Systens (LMS) used at the Instituto Federal de Pernambuco (IFPE). The data collected in the assessments were analyzed with users from Nielsen usability heuristics. The results showed that the environment has evaluated a large number of usability problems.","A Preliminary Study on Neural Basis of Collaboration as Mediated by the Level of Reasoning ","Proposta do uso de t\u00e9cnicas de visualiza\u00e7\u00e3o da informa\u00e7\u00e3o para an\u00e1lise do comportamento de alunos em ambientes e-learningThis paper describes a proposal of using information visualization techniques to analyze navigation data from students' logs in the AdaptWeb\u00ae e-learning environment. The navigational data are collected by a web analytics tool that does not allow a visual exploratory analysis of this data, making a difficult task discovering the navigation patterns of students.","Inter-warp instruction temporal locality in deep-multithreaded GPUsGPUs employ thousands of threads per core to achieve high throughput. These threads exhibit localities in control-flow, instruction and data addresses and values. In this study we investigate inter-warp instruction temporal locality and show that during short intervals a significant share of fetched instructions are fetched unnecessarily. This observation provides several opportunities to enhance GPUs. We discuss different possibilities and evaluate filter cache as a case study. Moreover, we investigate how variations in microarchitectural parameters impacts potential filter cache benefits in GPUs.","Exploring Foundations for Using Simulations in IS ResearchSimulation has been adopted in many disciplines as a means for understanding the behavior of a system by imitating it through an artificial object that exhibits a nearly identical behavior. Although simulation approaches have been widely adopted for theory building in disciplines such as engineering, computer science, management, and social sciences, their potential in the IS field is often overlooked. The aim of this paper is to understand how different simulation approaches are successfully used in IS research, thereby providing hypotheses that allow deriving methodological guidelines for subsequent studies. A survey of 69 pieces of IS research provides the grounding for defining a taxonomy of simulation approaches and for identifying possible application patterns linking simulation approaches to their theory contributions, research domains and information views.","Instance Selection in Logical Rule Extraction for Regression Problems ","Visualization and Analysis of Lumbar Spine Canal Variability in Cohort Study DataAbstractLarge-scale longitudinal epidemiological studies, such as the Study of Health in Pomerania (SHIP), investigatethousands of individuals with common characteristics or experiences (a cohort) including a multitude of socio-demographic and biological factors. Unique for SHIP is the inclusion of medical image data acquired via anextensive whole-body MRI protocol. Based on this data, we study the variability of the lumbar spine and itsrelation to a subset of socio-demographic and biological factors. We focus on the shape of the lumbar spinal canalwhich plays a crucial role in understanding the causes of lower back pain.We propose an approach for the reproducible analysis of lumbar spine canal variability in a cohort. It is basedon the centerline of each individual canal, which is derived from a semi-automatic, model-based detection of thelumbar spine. The centerlines are clustered by means of Agglomerative Hierarchical Clustering to form groupswith low intra-group and high inter-group shape variability. The number of clusters is computed automatically.The clusters are visualized by means of representatives to reduce visual clutter and simplify a comparison betweensubgroups of the cohort. Special care is taken to convey the shape of the spinal canal also orthogonal to the viewplane. We demonstrate our approach for 490 individuals drawn from the SHIP data. We present preliminary resultsof investigating the clusters with respect to their associated socio-demographic and biological factors.Categories and Subject Descriptors","Non-Linear Effects of Information Systems InnovationThis study investigates the impact of innovation on users of an evolving Information Systems (IS) product. Building on two different streams of research, Levitts (1980) Total Product Concept and the Three Factor theory (Kano. 1984) this study identifies three types of innovation: Basic, Expected and Augmented. The impact of introducing these innovations on user satisfaction was found to be dependent on the level of user satisfaction (performance) before the innovations were introduced and the type of innovation. Basic innovations impacted user satisfaction positively when the current level of performance of the IS product was low but not when the current level of performance was high. Expected and Augmented innovations impacted user satisfaction when the current level of performance was high but not when the current level of performance was low. This finding has interesting implications for practice and future research.","Network Aware Resource Allocation Scheme for Mobile Ad Hoc Computational GridMobile ad hoc computational Grids are characterized by unreliable and dynamic communication environment. The bandwidth at different network portions varies over the time and different nodes often experience different connection quality at the same time due to traffic load and constrained communication environment. Therefore, an effective and robust resource allocation scheme should consider connection quality between nodes in addition to other factors such as transmission power, processing speed and task size. In this paper, two resource allocation schemes are described with their pros and cons. The first resource scheme exploits transmission power control mechanism in order to improve energy efficiency and network capacity whereas the second resource allocation scheme takes into account the connection quality and traffic load in order to reduce data transfer time. The relationship between data transfer time and transmission energy consumption has also been investigated in detail. The schemes are validated in a simulated environment using various workloads and parameters.","A predictive model for advertiser value-per-click in sponsored searchSponsored search is a form of online advertising where advertisers bid for placement next to search engine results for specific keywords. As search engines compete for the growing share of online ad spend, it becomes important for them to understand what keywords advertisers value most, and what characteristics of keywords drive value. In this paper we propose an approach to keyword value prediction that draws on advertiser bidding behavior across the terms and campaigns in an account. We provide original insights into the structure of sponsored search accounts that motivate the use of a hierarchical modeling strategy. We propose an economically meaningful loss function which allows us to implicitly fit a linear model for values given observables such as bids and click-through rates. The model draws on demographic and textual features of keywords and takes advantage of the hierarchical structure of sponsored search accounts. Its predictive quality is evaluated on several high-revenue and high-exposure advertising accounts on a major search engine. Besides the general evaluation of advertiser welfare, our approach has potential applications to keyword and bid suggestion.","Putting the lab in the lab book: supporting coordination in large, multi-site researchLarge and distributed science projects present researchers with a challenging environment for interaction and collaboration. While digital technologies offer promises in supporting these difficulties, researchers appear reluctant to discontinue their use of analogue resources. We present a study of communication practices in very large-scale collaborative scientific research programmes that involve multidisciplinary and multinational research consortia. Qualitative data collection with researchers, principal investigators and project coordinators were carried out to examine the conduct and coordination of biological, biomedical and chemistry experiments that were distributed over multiple geographical locations. Results show that many problems in collaboration appear to result from the collective documentation of experimental operating procedures, tracking of experimental samples, and the sharing and cross-association of physical and digital experimental materials. Our analysis highlights the crucial but problematic role of the laboratory notebook as a driver for collaboration, most notably in supporting traceability of the distributed experimental process. We identify opportunities for improving experimental coordination, scientific communication and project synchronisation, drawing implications for digital interaction design that offers opportunities to enhance research coordination.","Mining Clinical Pathway Based on Clustering and Feature SelectionSchedule management of hospitalization is important to maintain or improve the quality of medical care and application of a clinical pathway is one of the important solutions for the management. This research proposed an data-oriented maintenance of existing clinical pathways by using data on histories of nursing orders. If there is no clinical pathway for a given disease, the method will induce a new clinical care plan from the data. The method was evaluated on 10 diseases. The results show that the reuse of stored data will give a powerful tool for management of nursing schedule and lead to improvement of hospital services.","Group Fused LassoWe introduce the Group Total Variation (GTV) regularizer, a modification of Total Variation that uses the l2,1 norm instead of the l1 one to deal with multidimensional features. When used as the only regularizer, GTV can be applied jointly with iterative convex optimization algorithms such as FISTA. This requires to compute its proximal operator which we derive using a dual formulation. GTV can also be combined with a Group Lasso (GL) regularizer, leading to what we call Group Fused Lasso (GFL) whose proximal operator can now be computed combining the GTV and GL proximals through Dykstra algorithm. We will illustrate how to apply GFL in strongly structured but ill-posed regression problems as well as the use of GTV to denoise colour images.","Securing Access to Complex Digital Artifacts \u2013 Towards a Controlled Processing Environment for Digital Research Data ","Efficient Low Complexity SVC Video Transrater with Spatial ScalabilityIn this paper we propose a new H.264 SVC transrating architecture for spatially scalable SVC compressed video streams. The algorithm is low complexity based, it applies to spatially scalable pre-encoded video streams and allows fine bit rate granularity while keeping highest spatial resolution. Simulation results demonstrate that transcoded bit streams produce satisfying picture quality even at bit rate reduction up to 66%. The comparison with MGS compressed video streams shows that the proposed transrating aslgorithm offers satisfying performances compared to MGS when bit rate reduction remains limited. Moreover quality scalability is obtained thanks to our algorithm even if the SVC compressed video bitstream has not been processed using MGS scalability right from the start.","Teaching Computational Thinking Skills in C3STEM with Traffic Simulation ","A qualitative investigation of the SECI model's knowledge conversions in the applications development contextThe Theory of Knowledge Creation generally suggests that tacit and explicit knowledge are converted through the four modes known as the SECI Model (Nonaka 1991; Nonaka &amp; Takeuchi 1995). In applications development, the knowledge conversions are mobilized through the use of tools (video conference, development editor) and practices (code review, design patterns, pair programming) (Henninger 1997; Avram 2007). However, the model is criticized for having strong Japanese cultural influence and little empirical basis in practice resulting in several debates on its applicability, existence/non-existence of the SECI cycle and unidirectional/multidirectional property of the conversions (Gourlay 2003; Rice &amp; Rice 2005; Hong 2010). Therefore, we studied how tacit and explicit knowledge are converted (tacit-tacit, tacit-explicit, explicit-explicit, and explicit-tacit) in an empirical setting and explored what the implications are within the context of applications development using the Theory of Knowledge Creation's SECI Model. We did this by immersion in a non-Japanese organization where applications development tools and practices were employed. Interviews, document reviews, and observations were used as primary data gathering techniques, which consequently required qualitative study analysis, specifically phenomenological, and discourse analysis techniques.","Interactive Photographic Shooting Assistance Based on Composition and SaliencyWhen taking photographs, compositions support them to clarify the subject. The preliminary survey indicated that the profes- sional photographers apply 1.7 types of composition on average; they tend to apply multiple types of compositions, such as triangular, diagonal and contrasting compositions in one photo. The proposed method con- siders co-occurrence of recognized compositions and candidate proposing compositions. We propose a novel photo shooting method which suggests one or more types of compositions and superimposes the suggestions on the photo being taken. Semantic differential method revealed that the proposed method increases compositional effects on the photograph.","Ontological model for CDSS in knee injury managementDue to the increased adoption of Electronic Health Records (EHR) and its integrated clinical decision support (CDS) tools, health information technology (HIT) is a key influence in Medicine. The main challenges in healthcare are to integrate the information across care units and to increase the quality of continuity of patient care. There are three types of knowledge sources in medicine: (1) Evidence Based Practice (EBP), (2) Practice Based Evidence, and (3) Medical Textbooks. Information in these sources is presented and organized in different formats. Ontology may allow us to integrate knowledge discovered from two separate data sources without platform restrictions. The knowledge can be reusable and sharable without the need of technology. Further, this paper also combines the strengths from both EBP and PBE on knee treatment. The hybrid knowledge model will derived from real practices while integrating existing external knowledge discovered and reported in published literatures.","A Divide-and-Conquer Method Based Ensemble Regression Model for Water Quality PredictionThis paper proposes a novel ensemble regression model to predict time series data of water quality. The proposed model consists of multiple regressors and a classifier. The model transforms the original time series data into subsequences by sliding window and divides it into several parts according to the fitness of regressor so that each regressor has advantages in a specific part. The classifier decides which part the new data should belong to so that the model could divide the whole prediction problem into small parts and conquer it after computing on only one part. The ensemble regression model, with a combination of Support Vector Machine, RBF Neural Network and Grey Model, is tested using 450-week observations of CODMn data provided by Ministry of Environmental Protection of the People's Republic of China during 2004 and 2012. The results show that the model could approximately convert the problem of prediction into a problem of classification and provide better accuracy over each single model it has combined.","Fair allocation of multiple resources using a non-monetary allocation mechanismThe fair allocation of scarce resources is relevant to a wide field of applications. For example, cloud resources, such as CPU, RAM, disk space, and bandwidth, have to be shared. This paper presents a mechanism to find fair allocations of multiple divisible resources, which, contrary to other mechanisms, is applicable to but not limited to the example above. Wide applicability of the mechanism is achieved by designing it (1) to scale with the number of consumers and resources, (2) to allow for arbitrary preference functions of consumers, and (3) to not rely on monetary compensation. The mechanism uses a mathematical definition of greediness to balance resources consumers receive and thereby to compute a fair allocation.","Multifold Bayesian Kernelization in Alzheimer\u2019s DiagnosisThe accurate diagnosis of Alzheimer\u2019s Disease (AD) and Mild Cognitive Impairment (MCI) is important in early dementia detection and treatment planning. Most of current studies formulate the AD diagnosis scenario as a classification problem and solve it using various machine learners trained with multi-modal biomarkers. However, the diagnosis accuracy is usually constrained by the performance of the machine learners as well as the methods of integrating the multi-modal data. In this study, we propose a novel diagnosis algorithm, the Multifold Bayesian Kernelization (MBK), which models the diagnosis process as a synthesis analysis of multi-modal biomarkers. MBK constructs a kernel for each biomarker that maximizes the local neighborhood affinity, and further evaluates the contribution of each biomarker based on a Bayesian framework. MBK adopts a novel diagnosis scheme that could infer the subject\u2019s diagnosis by synthesizing the output diagnosis probabilities of individual biomarkers. The proposed algorithm, validated using multi-modal neuroimaging data from the ADNI baseline cohort with 85 AD, 169 MCI and 77 cognitive normal subjects, achieves significant improvements on all diagnosis groups compared to the state-of-the-art methods.","Problem-Based Consideration of Privacy-Relevant Domain KnowledgeEspecially for a privacy analysis, an adequate and accurate considera- tion of domain knowledge is needed. Domain knowledge is often only implicitly given and mainly stored in the minds of domain experts. It is important to make this implicit knowledge explicit and to use it in the privacy analysis of a software system. To our knowledge, no privacy-aware requirements engineering approach exists yet which explicitly considers the elicitation of privacy-relevant domain knowledge. This paper presents an extension of the problem-based privacy anal- ysis (ProPAn) method. The extension consists of three parts. First, we elicit the relevant domain knowledge based on questionnaires which are derived from the stakeholder analysis literature. Second, we present generic patterns which can be instantiated to represent the elicited knowledge. Last, we extend the definitions of ProPAn's privacy graphs to take into account the domain knowledge.","NEVE: A Neuro-Evolutionary Ensemble for Adaptive LearningThis work describes the use of a quantum-inspired evolutionary algorithm (QIEA-R) to construct a weighted ensemble of neural network classifiers for adaptive learning in concept drift problems. The proposed algo- rithm, named NEVE (meaning Neuro-EVolutionary Ensemble), uses the QIEA- R to train the neural networks and also to determine the best weights for each classifier belonging to the ensemble when a new block of data arrives. After running eight simulations using two different datasets and performing two dif- ferent analysis of the results, we show that NEVE is able to learn the data set and to quickly respond to any drifts on the underlying data, indicating that our model can be a good alternative to address concept drift problems. We also compare the results reached by our model with an existing algorithm, Learn++.NSE, in two different nonstationary scenarios.","Development of a Game Engine for Accessible Web-Based Games ","A Survey of Cervix Segmentation Methods in Magnetic Resonance ImagesRadiotherapy is an effective therapy in the treatment of cervix cancer. However tumor and normal tissue motion and shape deformation of the cervix, the bladder and the rectum over the course of the treatment can limit the efficacy of radiotherapy and safe delivery of the dose. A number of studies have presented the potential benefits of adaptive radiotherapy for cervix cancer with high soft tissue contrast magnetic resonance images. To enable practical implementation of adaptive radiotherapy for the cervix, computer aided segmentation is necessary. Accurate computer aided automatic or semi-automatic segmentation of the cervix is a challenging task due to inter patient shape variation, soft tissue deformation, organ motion, and anatomical changes during the course of the treatment. This article reviews the methods developed for cervix segmentation in magnetic resonance images. The objective of this work is to present different methods for cervix segmentation in the literature highlighting their similarities, differences, strengths and weaknesses.","Factors Affecting Online Consumer's Behavior: An Investigation Across GenderGender effects remain poorly understood in the E-commerce setting. Using social roles theory, this research further investigates gender differences in consumer Web-based purchase decisions. Specifically, gender differences in the effects of interactivity, vividness, diagnosticity, and perceived risk on subsequent consumer attitude and online purchase intentions are investigated and explained. An empirical survey-based research study in the e-commerce context found that gender differences exist in the relative influence of each antecedent. Specifically, interactivity and perceived risk influenced attitude formation more for males than females, while vividness and diagnosticity influenced attitude formation more for females than males. In addition, attitude toward online product presentation influenced purchase intention more strongly for males than females. For e-Commerce web-site designers and brand managers, our results highlight the importance of being gender aware when developing their web presence. While some sites may benefit from a gender-neutral design, others may benefit from a design based on results reported here.","Adopting a Knowledge Management Concept in Securing the Privacy of Electronic Medical Record SystemsAs the enhancement of Information Technology (IT) in various management fields escalates, the realization of knowledge management (KM) concept is considered as significant. This concept can be applied in considering information privacy as a component in designing a computerized system. Consequently, this paper proposes the adoption of explicit and tacit knowledge concepts in identifying the privacy of information components in order to construct a secured electronic medical record (EMR) system. A preliminary investigation involving interviews with a selected group of hospital information system (HIS) developers has been conducted earlier on. The findings of this study revealed four important components to be factored in any privacy preservation framework for HIS. They are namely, legislation, ethical, technology and cultural. By applying the KM concept into these four components, it can further derive more systematic guidelines in order to achieve the privacy preservation of information. Nevertheless, further research must be developed as to yield a more inclusive guideline in designing an EMR system that is reliable, specifically in addressing the need of securing patient\u2019s personal medical information privacy.","On Mining Sensitive Rules to Identify Privacy Threats ","Many-Valued Relation Lifting and Moss' Coalgebraic LogicThe notion of relation lifting can be generalised to work with many-valued relations while retaining many vital properties of the \"clas- sical\" relation lifting. We show that polynomial endofunctors of the cat- egory of sets and mappings admit V -relation lifting for relations taking values from a commutative quantale V. Using the technique of functor presentations, we then show that every finitary weak pullback preserving functor admits a V -relation lifting for V being a complete Heyting alge- bra. As an application of the many-valued lifting we inspect the notion of many-valued bisimulation and we introduce an expressive many-valued variant of Moss' logic for T-coalgebras, parametric in the functor T.","Designing a diabetes mobile application with social network support.Abstract Although mobile applications and social media have emerged as important facets of the Internet, their role in healthcare is still not well-understood. We present design artefacts, inspired by persuasive technology concepts, from a study of social media as part of a diabetes mHealth application. We used the design science approach for mobile application design, and real-life user testing and focus group meetings to test the application over a 12-week period with 7 participants. Based on the System Usability Score (SUS), the mobile application scored an average of 84.6 (SD=13.2), which represents a fairly high usability score compared to the literature. Regression analysis on the daily blood glucose levels showed significant decreases for some patients, and although the study is not powered, the HbA1c showed a promising trend, and self-efficacy marginally increased. Incorporating persuasive elements such as blood glucose tracking and visualisation, and social media access directly from the mobile application produced promising results that warrant a larger study of behaviour change for people with diabetes.","Image Super Resolution via Visual Prior Based Digital Image CharacteristicsDesigning effective image priors is a key issue to image super-resolution. However, obtaining analytical forms for evaluating the smoothness of the priors is still a difficult and significant task. In this paper, we propose a prior-based method that divides image edges based on the hardness value, replacing the traditional binary classification of edges with a more detailed classification method. Through this partition, we can achieve smoother and better visual effect. Furthermore, we propose a non-uniform refinement approach to effectively improve the speed and reduce the processing time. Experimental results on multiple real world images have demonstrated the advantages of the proposed method over other existing prior methods both in visual effect and processing speed.","Time Variability-Based Hierarchic Recognition of Multiple Musical Instruments in Recordings ","A Linguistic-Based Method for Automatically Extracting Spatial Relations from Large Non-Structured DataThis paper presents a Lexicon-Grammar based method for automatic extraction of spatial relations from Italian non-structured data. We used the software Nooj to build sophisticated local grammars and electronic dictionaries associated with the lexicon-grammar classes of the Italian intransitive spatial verbs (i.e. 234 verbal entries) and we applied them to the Italian text Il Codice da Vinci ('The Da Vinci Code', by Dan Brown) in order to parse the spatial predicate-arguments structures. In addition, Nooj allowed us to automatically annotate (in XML format) the words (or the sequence of words) that in each sentence (S) of the text play the 'spatial roles' of Figure (F), Motion (M) and Ground (G). Finally the results of the experiment and the evaluation of this method will be discussed.","Named entities in judicial transcriptions: extended conditional random fieldsThe progressive deployment of ICT technologies in the courtroom is leading to the development of integrated multimedia folders where the entire trial contents (documents, audio and video recordings) are available for online consultation via web-based platforms. The current amount of unstructured textual data available into the judicial domain, especially related to hearing transcriptions, highlights therefore the need to automatically extract structured data from the unstructured ones for improving the efficiency of consultation processes. In this paper we address the problem of extracting structured information from the transcriptions generated automatically using an ASR (Automatic Speech Recognition) system, by integrating Conditional Random Fields with available background information. The computational experiments show promising results in structuring ASR outputs, enabling a robust and efficient document consultation.","Uncertainty-Encoded Augmented Reality for Robot-Assisted Partial Nephrectomy: A Phantom StudyIn most robot-assisted surgical interventions, multimodal fu- sion of pre- and intra-operative data is highly valuable, affording the surgeon a more comprehensive understanding of the surgical scene ob- served through the stereo endoscopic camera. More specifically, in the case of partial nephrectomy, fusing pre-operative segmentations of kid- ney and tumor with the stereo endoscopic view can guide tumor localiza- tion and the identification of resection margins. However, the surgeons are often unable to reliably assess the levels of trust they can bestow on what is overlaid on the screen. In this paper, we present the proof- of-concept of an uncertainty-encoded augmented reality framework and novel visualizations of the uncertainties derived from the pre-operative CT segmentation onto the surgeon's stereo endoscopic view. To verify its clinical potential, the proposed method is applied to an ex vivo lamb kid- ney. The results are contrasted to different visualization solutions based on crisp segmentation demonstrating that our method provides valuable additional information that can help the surgeon during the resection planning.","Video feedback system for teaching improvement using students' sequential and overall teaching evaluationsWe propose a system that allows university teachers to check the effectiveness of their lecture videos and to grasp points for improvement in the lectures. The system offers two functions: time-series graphing, which visualizes real-time changes in students' evaluation during a lecture, and teaching behavior estimation, which shows teachers information on their own teaching behaviors estimated from the overall evaluation by students of a lecture. The system was developed and evaluation experiments of each function were conducted. The subjective evaluation of each function by teachers showed the following: (1) the time series graph function was useful to narrow down which portion of the lecture videos contained points for improvement and (2) the teaching behavior estimation function was useful to determine the tendency of teaching behavior in a lecture.","An Efficient Biomechanical Cell Model to Simulate Large Multi-cellular Tissue Morphogenesis: Application to Cell Sorting Simulation on GPUIn the context of tissue morphogenesis study, in silico simula- tions can be seen as experiments in a virtual lab bench. Such simulations can facilitate the comprehension of a system, the test of hypotheses or the incremental refining of a model and its parameters. In silico simulations must be efficient and provide the possibility to simulate large tissues, containing thousands of cells. We propose to study tissue morphogene- sis at the cellular level using our virtual biomechanical cell model. This model is based on a mass/spring system and coupled to a multi-agent system. We validated the relevance of our model through a case study: a cell sorting. Moreover, we took advantage of the large parallelism offered by graphics processing units (GPU), which contain up to thousands of cores: we implemented our model with the OpenCL framework. We ran large scale simulations, with up to 10 6 of our virtual cells. We studied the performance of our system on a CPU Intel Core i7 860, and two GPUs: a NVidia GeForce GT440 and a Nvidia GeForce GTX 690. The absence of synchronization in our implementation allowed the full benefits of the parallelism of these hardwares.","Cost-benefit analysis of digital rights management products using stochastic modelsAlthough Digital Rights Management (DRM) has been proven effective and successful in protecting the confidentiality of sensitive documents by providing access control, DRM products have not been widely adopted and used to their potential. One reason for this could be that cost and benefit of these products have not been analyzed in a systematic and quantitative manner to date. As a result, companies do not have an established procedure to evaluate the cost and benefit of implementing these products. In this document, the benefits of implementing DRM products in enterprises are quantified using stochastic Petri-net models and are compared with the security needs of a corporation and potential costs incurred by the implementation process. An evaluating procedure for implementing DRM products is established. This procedure has the potential to be used to improve the ability of a corporation to make sensible security investment decisions.#R##N##R##N#The implementation of MS IRM (Microsoft Information Rights Management), one of the DRM products, was studied as a type case. In this case study, the MS IRM system was analyzed; a group of security metrics were developed for measuring and evaluating the effectiveness of the MS IRM system, in terms of increased security provided. Stochastic models are a core part of the process. It was found that the business process is a critical factor in determining document security. Although DRM products improve security, they typically increase the cost to the company and potentially reduce the productivity of staff. Therefore, for a successful deployment of the DRM system, it is recommended that a company evaluate the benefit and cost of DRM systems quantitatively using the procedures described in this document.","Heuristic role detection of visual elements of web pagesWeb pages are typically designed for visual interaction --- they include many visual elements to guide the reader. However, when they are accessed in alternative forms such as in audio, these elements are not available and therefore they become inaccessible. This paper presents our ontology-based heuristic approach that automatically identifies visual elements of web pages and their roles. Our architecture has three major components: 1. automatic identification of visual elements of web pages, 2. automatic generation of heuristics as Jess rules from an ontology and 3. application of these heuristic rules to web pages for automatic annotation of visual elements and their roles. This paper first explains our architecture in detail and then presents our both technical and user evaluations of the proposed approach and architecture. Our technical evaluation shows that complexity is an important performance factor in role detection and our user evaluation shows that our proposed system has around 80% receptive accuracy, but the proposed knowledge base could be further improved for better accuracy.","A Self-configurable Agent-Based System for Intelligent Storage in Smart GridNext generation of smart grid technologies demand intel- ligent capabilities for communication, interaction, monitoring, storage, and energy transmission. Multiagent systems are envisioned to provide autonomic and adaptability features to these systems in order to gain advantage in their current environments. In this paper we present a mechanism for providing distributed energy storage systems (DESSs) with intelligent capabilities. In more detail, we propose a self-configurable mechanism which allows a DESS to adapt itself according to the future environmental requirements. This mechanism is aimed at reducing the costs at which electricity is purchased from the market.","Constraint Programming in Community-Based Gene Regulatory Network InferenceGene Regulatory Network GRN inference is a major objective of Systems Biology. The complexity of biological systems and the lack of adequate data have posed many challenges to the inference problem. Community networks integrate predictions from individual methods in a \"meta predictor\", in order to compose the advantages of different methods and soften individual limitations. This paper proposes a novel methodology to integrate prediction ensembles using Constraint Programming, a declarative modeling paradigm, which allows the formulation of dependencies among components of the problem, enabling the integration of diverse forms of knowledge. The paper experimentally shows the potential of this method: the addition of biological constraints can offer improvements in the prediction accuracy, and the method shows promising results in assessing biological hypothesis using constraints.","The Semantics of Aggregate Queries in Data Exchange RevisitedDefining \"good\" semantics for non-monotonic queries and for aggregate queries in the context of data exchange has turned out to be a challenging problem for a number of reasons, including the de- pendence of the semantics of the concrete syntactic representation of the schema mapping at hand. In this paper, we revisit the semantics of aggre- gate queries in data exchange by introducing the aggregate most-certain answers, a new semantics that is invariant under logical equivalence. Informally, the aggregate most-certain answers are obtained by taking the intersection of the aggregate certain answers over all schema map- pings that are logically equivalent to the given schema mapping. Our main technical result is that for schema mappings specified by source- to-target tuple-generating dependencies only (no target constraints), the aggregate most-certain answers w.r.t. a schema mapping coincide with the aggregate certain answers w.r.t. the schema mapping in normal form associated with the given schema mapping. This result provides an in- trinsic justification for using schema mappings in normal form and, at the same time, implies that the aggregate most-certain answers are com- putable in polynomial time. We also consider the semantics of aggre- gate queries w.r.t. schema mappings whose specification includes target constraints, and discuss some of the delicate issues involved in defining rigorous semantics for such schema mappings.","Access Structure in Graphs in High Dimension and Application to Secret SharingWe give graphical characterisation of the access structure to both classical and quantum information encoded onto a multigraph defined for prime dimension q, as well as explicit decoding operations for quantum secret sharing based on graph state protocols. We give a lower bound on $k$ for the existence of a ((k,n))_q scheme and prove, using probabilistic methods, that there exists alpha such that a random multigraph has an accessing parameter k =&gt; alpha*n with high probability.","Hyperspectral Image Classification by Using Pixel Spatial CorrelationThis paper introduces a hyperspectral image classification approach by using pixel spatial relationship. In hyperspectral images, the spatial relation- ship among pixels has been shown to be important in the exploration of pixel labels. To better employ the spatial information, we propose to estimate the cor- relation among pixels in a hypergraph structure. In the constructed hypergraph, each pixel is denoted by a vertex, and the hyperedge is constructed by using the spatial neighbors of each pixel. Semi-supervised learning on the constructed hy- pergraph is conducted for hyperspectral image classification. Experiments on two datasets are used to evaluate the performance of the proposed method. Compar- isons with the state-of-the-art methods demonstrate that the proposed method can effectively investigate the spatial relationship among pixels and achieve better hy- perspectral image classification results.","Towards design principles for pharmacist-patient health information systemsA significant drawback of communications between patients and health professionals is their restriction to face-to-face encounters within healthcare institutions. This limits the support health professionals can provide to ensure patient adherence, which is a significant contributor to therapeutic outcome and overall healthcare expenses. Pharmacist-patient health information systems (PPHIS) have the potential to address existing non-adherence behaviors by enabling pharmacist-patient communication over the time of therapy. Due to the lack of prior research, design principles for PPHIS are derived from the information-, motivation-, and strategy model [4] and feedback from pharmacists in 21 Swiss pharmacies. To demonstrate the feasibility of the design principles, we implement and preliminarily evaluate a PPHIS.","Computational soundness of symbolic zero-knowledge proofs: weaker assumptions and mechanized verificationThe abstraction of cryptographic operations by term algebras, called symbolic models, is essential in almost all tool-supported methods for analyzing security protocols. Significant progress was made in proving that symbolic models offering basic cryptographic operations such as encryption and digital signatures can be sound with respect to actual cryptographic realizations and security definitions. Even abstractions of sophisticated modern cryptographic primitives such as zero-knowledge (ZK) proofs were shown to have a computationally sound cryptographic realization, but only in ad-hoc formalisms and at the cost of placing strong assumptions on the underlying cryptography, which leaves only highly inefficient realizations.#R##N##R##N#In this paper, we make two contributions to this problem space. First, we identify weaker cryptographic assumptions that we show to be sufficient for computational soundness of symbolic ZK proofs. These weaker assumptions are fulfilled by existing efficient ZK schemes as well as generic ZK constructions. Second, we conduct all computational soundness proofs in CoSP, a recent framework that allows for casting computational soundness proofs in a modular manner, independent of the underlying symbolic calculi. Moreover, all computational soundness proofs conducted in CoSP automatically come with mechanized proof support through an embedding of the applied \u03c0-calculus.","An Automatic Marking System for Interactive Exercises on Blind Search AlgorithmsAbstract. In this paper, we present a web-based automatic marking system that aims to assist the tutor in assessing the performance of students in interactive exercises related to breadth-first search (BFS) and depth-first search (DFS) al-gorithms. The system has been tested on a number exercises for BFS and DFS search algorithms and its performance has been compared against that of an ex-pert tutor. The experimental results are quite promising. Keywords: Web-based e-learning system, automated marking, e-assessment, blind search algorithms. 1 Introduction Student assessment via tests is an important and complex part of learning process. Automatic assessment can assist the tutor in evaluating student\u2019s work and also ena-ble more regular and prompt feedback [3][5][9]. In an artificial intelligence (AI) course, a fundamental topic is \"search algorithms\". It is considered necessary for stu-dents to get a strong understanding of the way search algorithms work and also of their implementation for solving various problems. Usually in an AI course, for teach-ing a search algorithm and evaluating the students\u2019 comprehension, the tutor creates and gives a set of assignments asking the students to provide their hand-made solu-tions. Afterwards, the tutor has to mark all students\u2019 answers, present the correct ones and discuss the common errors. This process is time demanding for the tutor. So, an automatic marking system, which helps the tutor reduce the time spent in marking and use this time efficiently for more creative work, is desirable. Moreover, the automati-cally marking system allows every student to have his/her test immediately evaluated. In this paper, we present a system that has been developed to support automatic mark-ing of student answers to interactive exercises concerning blind search (i.e. BFS and DFS) algorithms.","Design and Evaluation of HTTP Protocol Parsers for IPFIX MeasurementClanek zkouma syntakticke analyzatory HTTP protokolu, ktere rozsi\u0159uji si\u0165ove toky o informace z weboveho provozu. V\u00fdpocetn\u011b narocne ziskavani informaci z aplikacni vrstvy ma vliv na v\u00fdkon m\u011b\u0159icich sond a m\u016f\u017ee vest k v\u00fdraznemu poklesu jejich v\u00fdkonu. Tvorba rychleho analyzatoru pro hloubkovou anal\u00fdzu HTTP protokolu je narocn\u00fd proces s ohledem na spravne a vcasne zpracovani dat ze sit\u011b. Clanek porovnava nasi implementaci vybran\u00fdch metod pro anal\u00fdzu HTTP provozu, ktere jsou v soucasnosti pou\u017eivany v sondach na m\u011b\u0159eni si\u0165ov\u00fdch tok\u016f. Provedena m\u011b\u0159eni ukazuji mno\u017estvi paket\u016f, ktere je sonda schopna zpracovat p\u0159i zapnute anal\u00fdze HTTP a jak toto mno\u017estvi klesa oproti sondam, ktere anal\u00fdzu aplikacnich protokol\u016f neprovad\u011bji. Jedna se o v\u00fdznamnou informaci pro nasazeni m\u011b\u0159icich sond ve vysokorychlostnich sitich.","Detection of Disk-Like Particles in Electron Microscopy ImagesQuantitative and qualitative description of particles is one of the most important tasks in the Electron Microscopy (EM) analysis. In this paper, we present an algorithm for identifying ball-like nanostructures of gahnite in the Transmission Electron Microscopy (TEM) images. Our solution is based on the cross-entropy clustering which allows to count and measure disk-like objects which are not nec- essary disjoint or with not smooth borders.","Interactive doodles: a comparative analysis of the usability and playability of google trademark games between 2010 and 2012By using artistic mutations, called Doodles, Google has been commemorating important events and personalities. This fun approach started with still images, evolved to increasingly complex interactions, and has resulted in games based on the configurations of its logo. Thus, the company which was born in the digital world has introduced a new interactive approach to its logo in cyberspace, thus offering new experiences to the user. This article sets out to present a comparative analysis of usability and playability of five interactive Doodles by applying the RITE (Rapid Interation Testing and Evaluation) approach so as to investigate ergonomic criteria of invitation, suitability immediate feedback and user control.","The Emergence of Useful Bias in Self-focusing Genetic Programming for Software OptimisationThe use of Genetic Programming GP to optimise increasingly large software code has been enabled through biasing the application of GP operators to code areas relevant to the optimisation of interest. As previous approaches have used various forms of static bias applied before the application of GP, we show the emergence of bias learned within the GP process itself which improves solution finding probability in a similar way. As this variant technique is sensitive to the evolutionary lineage, we argue that it may more accurately provide bias in programs which have undergone heavier modification and thus find solutions addressing more complex issues.","\u201cProduct-Process-Machine\u201d System Modeling: Approach and Industrial Case Studies ","Tools for Collection, Analysis and Visualization of Data from the Stockholm Convention Global Monitoring Plan on Persistent Organic PollutantsThe Global Monitoring Plan for persistent organic pollutants is an important component of the effectiveness evaluation of the Stockholm Conven- tion and its main objective is assessment of long-term changes in POPs concen- trations in core matrices - ambient air and human tissues (milk, blood). This paper summarizes results of activities of the Research Centre for Toxic Com- pounds in the Environment and the Institute of Biostatistics and Analyses, Ma- saryk University, Czech Republic, which have been performed on the basis of the mandate given by Global Coordination Group for GMP and Secretariat of the Stockholm Convention: content analysis of the GMP monitoring reports published in 2009, on-line visualization tool for browsing and analyzing col- lected data from the monitoring reports, and proposal of a design of future data collection campaigns.","Lower and Upper Bounds for Long Induced Paths in 3-Connected Planar Graphs ","Introduction to Image Processing Using R: Learning by ExamplesThis book introduces the statistical software R to the image processing community in an intuitive and practical manner. R brings interesting statistical and graphical tools which are important and necessary for image processing techniques. Furthermore, it has been proved in the literature that R is among the most reliable, accurate and portable statistical software available. Both the theory and practice of R code concepts and techniques are presented and explained, and the reader is encouraged to try their own implementation to develop faster, optimized programs. Those who are new to the field of image processing and to R software will find this work a useful introduction. By reading the book alongside an active R session, the reader will experience an exciting journey of learning and programming.","Measuring Sandy Bottom Dynamics by Exploiting Depth from Stereo Video Sequences ","Multilingual number transcription for text-to-speech conversionThis paper describes the text normalization module of a text to speech fully-trainable conversion system and its application to number transcription. The main target is to generate a language independent text normalization module, based on data instead of on expert rules. This paper proposes a general architecture based on statistical machine translation techniques. This proposal is composed of three main modules: a tokenizer for splitting the text input into a token graph, a phrase-based translation module for token translation, and a post-processing module for removing some tokens. This architecture has been evaluated for number transcription in several languages: English, Spanish and Romanian. Number transcription is an important aspect in the text normalization problem.","Structuring E-Participation in Policy Making through ArgumentationAn important feature of democracies is that citizens can engage their Governments in dialogues about policies. They tend to do so in one of three ways: they may seek a justification of some policy or action; they may object to all or some aspects of a policy; or they may make policy proposals of their own.","An error tolerant memory aid for reduced cognitive load in number copying tasksNumber copying tasks are still common despite increased digitalization of services. Number copying tasks are cognitively and visually demanding, errors are easily introduced and the process is often perceived as laborious. This study proposes an alternative scheme based on dictionary coding that reduces the cognitive load on the user by a factor of five. The strategy has several levels of error detection and error correction characteristics and is easy to implement.","Multi-Agent Systems Platform for Mobile Robots Collision Avoidance ","Solving Steel Alloying Using Differential Evolution and SOMAThis paper proposes method for solving steel alloying prob- lem using evolution algorithms SOMA and differential evolution. Both algorithms belong to the family of the evolution algorithms but the main ideas of these algorithms are different. In differential evolution new off- spring is created during the evolution, the individuals are crossed and mutated, while in SOMA the individuals move in the space of the pos- sible solutions and the mutation is replaced by perturbation. The main goal of this paper is to discover how much these algorithms are usable and suitable to solve the problem of steel alloying.","Random Walks with Efficient Search and Contextually Adapted Image Similarity for Deformable Registration ","A Novel Layer-Scanning Method for Improving Real-Time People Counting ","Learning precise local boundaries in images from human tracings ","Agents in Simulation of Cyberattacks to Evaluate Security of Critical Infrastructures ","Who Are We Talking About? Identifying Scientific Populations Online ","Human-Robot Natural Interaction with Collision Avoidance in Manufacturing OperationsThe paper discusses a new method of tracking and controlling robots that interact with humans (natural interaction) to provide assistance services in manufacturing tasks. Using depth sensors the robots are able to assist the human operator and to avoid collisions. Natural interaction is implemented using a depth sensor which monitors the activity outside and inside the robot system workspace. The sensor extracts depth data from the environment and then uses the processing power of a workstation in order to detect both humans and robot arms. This is done by detecting skeletons which represent the position and pos- ture of the humans and manipulators. Using skeleton tracking, a software agent is able to monitor the movements of the human operators and robotic arms and to detect possible collisions in order to stop the robot motion at the right time. Also the agent can interpret the posture (or full body gesture) of the human operator in order to send basic commands to the robot.","Social movements on the Internet : together alone or alone together? ","Systematic assessment of analytical methods for drug sensitivity prediction from cancer cell line data.Large-scale pharmacogenomic screens of cancer cell lines have emerged as an attractive pre-clinical system for identifying tumor genetic subtypes with selective sensitivity to targeted therapeutic strategies. Application of modern machine learning approaches to pharmacogenomic datasets have demonstrated the ability to infer genomic predictors of compound sensitivity. Such modeling approaches entail many analytical design choices; however, a systematic study evaluating the relative performance attributable to each design choice is not yet available. In this work, we evaluated over 110,000 different models, based on a multifactorial experimental design testing systematic combinations of modeling factors within several categories of modeling choices, including: type of algorithm, type of molecular feature data, compound being predicted, method of summarizing compound sensitivity values, and whether predictions are based on discretized or continuous response values. Our results suggest that model input data (type of molecular features and choice of compound) are the primary factors explaining model performance, followed by choice of algorithm. Our results also provide a statistically principled set of recommended modeling guidelines, including: using elastic net or ridge regression with input features from all genomic profiling platforms, most importantly, gene expression features, to predict continuous-valued sensitivity scores summarized using the area under the dose response curve, with pathway targeted compounds most likely to yield the most accurate predictors. In addition, our study provides a publicly available resource of all modeling results, an open source code base, and experimental design for researchers throughout the community to build on our results and assess novel methodologies or applications in related predictive modeling problems.","Proactively Approaching Pedestrians with an Autonomous Mobile Robot in Urban Environments ","Knowledge-Based e-Contract Negotiation among Agents Using Semantic Web TechnologiesE-Commerce enabled new ways of transactions. Companies and individuals negotiate and make contracts every day. Practically, contracts are agreements between parties that must be kept. These agreements affect the involved parties irretrievably. Hence, negotiating them efficiently is proved vital. To this end we propose the use of intelligent agents, which benefit from Semantic Web technologies, such as RDF and RuleML, for data and policy exchanges. Each agent encounter is characterized by the interaction or negotiation protocol and each party's strategy. This study defines a knowledge-based negotiation procedure where protocols and strategies are separated enabling reusability and thus enabling agent participation in interaction processes without the need of reprogramming. In addition, we present the integration of this methodology into a multi-agent knowledge-based framework and next a use case scenario using the contract net protocol that demonstrates the added value of the approach.","Simulating a Collective Intelligence Approach to Student Team Formation ","Energy Optimization of a Dynamic System Controller ","Self-timed Scheduling and Execution of Nonlinear Pipelines with Parallel StagesApplications that process continuous streams of data, e.g., sensor signals, video images, network packets, etc. are well-suited for pipelined execution on multicore processors. In many cases, however, the applications are subject to real-time constraints, especially in embedded systems. Besides maximizing the throughput, it is therefore important to minimize deviations in the timing. To solve this problem, we propose a method for self-timed scheduling and parallel execution of stream-based applications in soft real-time environments. Our experimental results show significantly lower latencies compared to state-of-the-art approaches, while achieving high throughput.","An Interactive 3D Social Graphs for Social Learning ","Designing discovery experience for big data interaction: a case of web-based knowledge mining and interactive visualization platformThe exponentially growing data in every aspect of human lives is offering both opportunities to gain unprecedented insights and challenges for designing efficient discovery experiences. To respond to the challenge of dealing with big data, our work is designing a web-based, knowledge mining and interactive visualization platform that allows users to interactively synthesize, mine, and visualize large-scale data. In this paper, we extend the classic information retrieval concept of information seeking to more general insight discovery behavior. Our approach is to focus on user's insight discovery workflow rather than data per se. User interviews were conducted to extract workflows and specific requirements to inform and direct design decisions.","Using smartphone bases biodevices for analyzing physiological, psychological and behavioral user\u2019s habitsAs a consequence of increasing life expectancy, the promotion of lifestyles that allow aging wellbeing guarantees has acquired great importance in the developed countries. However, the adherence to healthy#R##N#behaviors in young and adult people remains as a big problem in the community health field. The development of markers of adherence to healthy lifestyles and the evaluation its effectiveness is a goal of#R##N#many research groups. This paper presents a system for analyzing physiological, psychological and behavioural user\u2019s habits using a smartphone and externals biodevices. We use an Android smartphone with an internal tri-axial accelerometer and GPS to monitor physical activity. The smartphone is connected via Bluetooth to a respiratory sensor for breath monitoring. In addition, Android application contains psychological questionnaires to analyze user\u2019s mood state and at the same, social interaction is analyzed tracking phone usage and user\u2019s social network. Finally, the collected information is sent to a remote server#R##N#for a long-term processing.","WTF: the who to follow service at TwitterWTF (\"Who to Follow\") is Twitter's user recommendation service, which is responsible for creating millions of connections daily between users based on shared interests, common connections, and other related factors. This paper provides an architectural overview and shares lessons we learned in building and running the service over the past few years. Particularly noteworthy was our design decision to process the entire Twitter graph in memory on a single server, which significantly reduced architectural complexity and allowed us to develop and deploy the service in only a few months. At the core of our architecture is Cassovary, an open-source in-memory graph processing engine we built from scratch for WTF. Besides powering Twitter's user recommendations, Cassovary is also used for search, discovery, promoted products, and other services as well. We describe and evaluate a few graph recommendation algorithms implemented in Cassovary, including a novel approach based on a combination of random walks and SALSA. Looking into the future, we revisit the design of our architecture and comment on its limitations, which are presently being addressed in a second-generation system under development.","Letter to the Editor: Correction to Steady-state saturated groundwater flow modeling with full tensor conductivities using finite differences ","Lazy Symbolic Execution through Abstraction and Sub-space Search ","An Optimal Control Approach to Find Sparse Data for Laplace InterpolationFinding optimal data for inpainting is a key problem in the context of partial differential equation-based image compression. We present a new model for optimising the data used for the reconstruction by the underlying homogeneous diffusion process. Our approach is based on an optimal control framework with a strictly convex cost functional containing an L 1 term to enforce sparsity of the data and non-convex constraints. We propose a numerical approach that solves a series of convex optimisation problems with linear constraints. Our numerical examples show that it outperforms existing methods with respect to quality and computation time.","Face recognition under ageing effect: a comparative analysisPrevious studies indicate that performance of the face recog- nition system severely degrades under the ageing effect. Despite the rising attention to facial ageing, there exist no comparative evaluation of the existing systems under the impact of ageing. Moreover, the compound effect of ageing and other variate such as glasses, gender etc, that are known to influence the performance, remain overlooked till date. To this aim, the contribution of this work are as follows: 1) evaluation of six baseline facial representations, based on local features, under the age- ing effect, and 2) analysis of the compound effect of ageing with other variates, i.e., race, gender, glasses, facial hair etc.","Continuous Topically Related Queries Grouping and Its Application on Interest Identification ","SMI 2013: Point cloud normal estimation via low-rank subspace clusteringIn this paper, we present a robust normal estimation algorithm based on the low-rank subspace clustering technique. The main idea is based on the observation that compared with the points around sharp features, it is relatively easier to obtain accurate normals for the points within smooth regions. The points around sharp features and smooth regions are identified by covariance analysis of their neighborhoods. The neighborhood of a point in a smooth region can be well approximated by a plane. For a point around sharp features, some of its neighbors may be in smooth regions. These neighbor points' normals are estimated by principal component analysis, and used as prior knowledge to carry out neighborhood clustering. An unsupervised learning process is designed to represent the prior knowledge as a guiding matrix. Then we segment the anisotropic neighborhood into several isotropic neighborhoods by low-rank subspace clustering with the guiding matrix, and identify a consistent subneighborhood for the current point. Hence the normal of the current point near sharp features is estimated as the normal of a plane fitting the consistent subneighborhood. Our method is capable of estimating normals accurately even in the presence of noise and anisotropic samplings, while preserving sharp features within the original point data. We demonstrate the effectiveness and robustness of the proposed method on a variety of examples.","QuPreSS: A Service-Oriented Framework for Predictive Services Quality AssessmentNowadays there are lots of predictive services for several domains such as stock market and bookmakers. The value delivered by these services relies on the quality of their predictions. This paper presents QuPreSS, a general framework which measures predictive service quality and guides the selection of the most accurate predictive service. To do so, services are monitored and their predictions are compared over time by means of forecast verification with observations. A systematic literature review was performed to design a service-oriented framework architecture that fits into the current body of knowledge. The service-oriented nature of the framework makes it extensible and interoperable, being able to integrate existing services regardless their heterogeneity of platforms and languages. Finally, we also present an instantiation of the generic framework architecture for the weather forecast domain, freely available at http://gessi.lsi.upc. edu/qupress/","Estimation Methods of Presumed IncomeThis paper will be presented regression models to estimate the assumed income that is of utmost importance to the credit market since the client does not prove your income. The proposed models are lognormal and gamma which is a generalized linear model, both will be compared who perform better will be chosen, where the result of the chosen model will undergo an addition of a noise to get a better estimated. Every analysis and simulation were implemented in [7].","A Study of Human Flesh Search Based on SIR Flooding on Scale-Free Networks ","X-TIER: Kernel Module InjectionIn spite of the fact that security applications can greatly benefit from virtualization, hypervisor-based security solutions remain sparse. The main cause for this is the semantic gap, which makes the development of hypervisor-based security applications cumbersome, error-prone, and time-consuming. In this paper, we present X-TIER, a framework that enables hypervisor-based security applications to bridge the semantic gap by injecting kernel modules from the outside into a running virtual machine (VM). While previous approaches bridge the semantic gap by reading kernel objects from memory, X-TIER goes be- yond such work and allows the injected code to manipulate the guest operating system (OS) state and even call kernel functions without sacri- ficing the overall security. We have implemented a prototype of X-TIER on the x86 architecture that supports module injection for Windows and Linux guests. The evaluation of our system shows that kernel mod- ule injection only incurs a very small performance overhead, leaves no traces within the guest system, and provides access to all exported guest OS data structures and functions. Consequently, the mechanism is well- suited for creating hypervisor-based security applications.","Phenotyping on EHR data using OWL and semantic web technologiesObjective: In this paper, we introduce our efforts on using semantic web technologies to execute phenotyping algorithms on Electronic Health Records (EHR) data.","MISUP: Multiple-Instance Learning via Immunological Suppression MechanismIn multiple-instance learning MIL, examples are sets of instances named bags and labels are associated with bags rather than instances. A bag is labeled as positive if it contains at least one positive instance; otherwise, labeled as negative. Recently, several instance selection-based MIL ISMIL algorithms show their power in solving the MIL problem. In this paper, we propose a new ISMIL algorithm based on the self-regulation and suppression mechanisms found in the biological immune system. Experimental results show that our MIL algorithm is highly comparable with other ISMIL ones in terms of classification accuracy and computation time.","Biologically Sound Neural Networks for Embedded Systems Using OpenCLIn this paper, we present an OpenCL implementation of a biologically sound spiking neural network with two goals in mind: First, applied neural dynamics should be accurate enough for bio-inspired training methods, thus resulting network data is reproducible in \"in vitro\" experiments. The second is that the implementation produces code that runs adequately on up-to-date embedded graphical chips for fast on-board classification applications, e.g., video image processing. We describe the necessary steps required to implement an efficient algorithm using the OpenCL framework and present evaluation results of the execution time compared to traditional serial CPU code. We show that an optimized GPU kernel code can perform sufficiently fast to be used for future embedded neural processing.","CFD Challenge: Predicting Patient-Specific Hemodynamics at Rest and Stress through an Aortic CoarctationThe here presented work is part of a CFD challenge investigating the potential for computational fluid dynamics CFD simulations to predicted pressures and flows in an aortic coarctation during stress when conditions for the rest case are known. In our approach, we choose to couple a three element Windkessel model to the outlet boundary conditions. Good reproducibility of flow and pressures for the rest case were achieved. In the stress case, where only the inflow boundary condition was changed, baseline pressure was too high, indicating that the total resistance in the Windkessel models may need to be reduced. This would correspond to dilating the blood vessels as might be the result of a pharmacological stress test. Future work is needed to develop an optimization strategy to tune the Windkessel data for matching the clinical results.","Design of a Time-Delayed Controller for Attitude Control of a Quadrotor SystemThis paper presents the design of the time-delayed controller for the attitude control of a quadrotor system. Based on the measurement of acceleration data, the time-delayed control algorithm is implemented. Performances of the time-delayed control method are compared with the PD control method through empirical studies. Experimental results of the attitude control of a quadrotor system on the test platform verify that the performance of the time-delayed control method is better than that of the PD control method.","Designing Technology for Older People \u2013 The Role of Technical Self-confidence in Usability of an Inclusive Heating ControlThe ageing population of the UK is providing a large market opportunity for inclusive products and services. Yet older people are often excluded from using new technology due to inadequate consideration of their needs during the design process. This study focused specifically on including older people (aged 50-80) in the testing of a novel heating control interface under development. Recent studies have used two scalar methods to assess self-confidence; building upon this a technical self-confidence questionnaire was developed and completed by participants prior to attempting a usability task using the prototype. This study found that high technical self-confidence was inversely correlated to successful task performance. The participants who rated themselves as most technically self-confident were not successful in completing the task. Whereas, participants that rated themselves less confident had greater success completing the task. In general older people reported high levels of technical self-confidence and they were found to be willing to engage with the technical prototype. This highlights the high expectations of the older users group to be able to effectively engage with new technological systems. Designers should aim to instil further confidence amongst older users and provide systems that both support and include older people.","Exact top-k feature selection via l 2,0 -norm constraintIn this paper, we propose a novel robust and pragmatic feature selection approach. Unlike those sparse learning based feature selection methods which tackle the approximate problem by imposing sparsity regularization in the objective function, the proposed method only has one l2,1-norm loss term with an explicit l2,0-Norm equality constraint. An efficient algorithm based on augmented Lagrangian method will be derived to solve the above constrained optimization problem to find out the stable local solution. Extensive experiments on four biological datasets show that although our proposed model is not a convex problem, it outperforms the approximate convex counterparts and state-of-art feature selection methods evaluated in terms of classification accuracy by two popular classifiers. What is more, since the regularization parameter of our method has the explicit meaning, i.e. the number of feature selected, it avoids the burden of tuning the parameter, making it a pragmatic feature selection method.","Polygon-Constrained Motion Planning ProblemsWe consider the following class of polygon-constrained motion planning problems: Given a set of k centrally controlled mobile agents (say pebbles) initially sitting on the vertices of an n -vertex simple polygon P , we study how to plan their vertex-to-vertex motion in order to reach with a minimum (either maximum or total) movement (either in terms of number of hops or Euclidean distance) a final placement enjoying a given requirement. In particular, we focus on final configurations aiming at establishing some sort of visual connectivity among the pebbles, which in turn allows for wireless and optical intercommunication. Therefore, after analyzing the notable (and computationally tractable) case of gathering the pebbles at a single vertex (i.e., the so-called rendez-vous), we face the problems induced by the requirement that pebbles have eventually to be placed at: (i) a set of vertices that form a connected subgraph of the visibility graph induced by P , say G(P) (connectivity), and (ii) a set of vertices that form a clique of G(P) (clique-connectivity). We will show that these two problems are actually hard to approximate, even for the seemingly simpler case in which the hop distance is considered.","Anomaly Detection in Beacon-Enabled IEEE 802.15.4 Wireless Sensor Networks ","Repeatability Measurements for 2D Interest Point Detectors on 3D Models ","Threats and Challenges to Security of Electronic Health Records ","Algorithm for Generating Decision Tree Based on Adjoint Positive Region ","Trust Based Secure and Energy Efficient Clustering in Wireless Sensor Network: A Bee Mating ApproachIn this paper we have proposed a trust based secure and en- ergy efficient clustering algorithm in wireless sensor network using Honey Bee Mating Algorithm (TBCR-BMA). The proposed TBCR-BMA de- prives the malicious node to act as cluster head, thus prolong the life time of the network. Moreover, we reveal that this proposed scheme out- performs the most popular hierarchical Low Energy Adaptive Cluster- ing Hierarchy (LEACH) and Advertisement timeout driven bee's mating approach to maintain fair energy level in sensor networks (TBCMA) in terms of average residual energy of nodes and total energy of the network.","m-Transportability: transportability of a causal effect from multiple environmentsWe study m-transportability, a generalization of transportability, which offers a license to use causal information elicited from experiments and observations in m \u2265 1 source environments to estimate a causal effect in a given target environment. We provide a novel characterization of m- transportability that directly exploits the completeness of do-calculus to obtain the necessary and sufficient conditions for m-transportability. We provide an algorithm for deciding m- transportability that determines whether a causal relation is m-transportable; and if it is, produces a transport formula, that is, a recipe for estimating the desired causal effect by combining experimental information from m source environments with observational information from the target environment.","An Experimental Comparison of Trust Region and Level SetsHigh-order (non-linear) functionals have become very popular in segmentation, stereo and other computer vision problems. Level sets is a well established general gradient descent framework, which is directly applicable to optimization of such functionals and widely used in practice. Recently, another general optimization approach based on trust region methodology was proposed for regional non-linear functionals. Our goal is a comprehensive experimental comparison of these two frameworks in regard to practical efficiency, robustness to parameters, and optimality. We experiment on a wide range of problems with non-linear constraints on segment volume, appearance and shape.","Are the Sorites and Liar Paradox of a KindIn this paper I consider attempts to unify the liar and sorites paradoxes. I argue that while they both may be said to exhibit indeterminacy and be alike in this respect, attempts to model the indeterminacy by way of a paracomplete logic result in the two paradoxes diverging in their logical structure in the face of extended paradoxes. If, on the other hand, a paraconsistent logic is invoked then the paradoxes and associated extended paradoxes may be seen to be of a kind in having their source in the indeterminacy of the relevant predicates involved. Paraconsistency then offers the prospect of a unified treatment of these vexing puzzles.","Managing HMI quality in embedded system developmentWe have developed HMI metrics to evaluate the usability of software products. System engineers who are not usability professional can design basic HMI software by using this metrics. The HMI metrics is expected to be applied for the Software Quality Auditing System in the future.","Local topological signatures for network-based prediction of biological functionIn biology, similarity in structure or sequence between molecules is often used as evidence of functional similarity. In protein interaction networks, structural similarity of nodes (i.e., proteins) is often captured by comparing node signatures (vectors of topological properties of neighborhoods surrounding the nodes).#R##N##R##N#In this paper, we ask how well such topological signatures predict protein function, using protein interaction networks of the organism Saccharomyces cerevisiae. To this end, we compare two node signatures from the literature --- the graphlet degree vector and a signature based on the graph spectrum --- and our own simple node signature based on basic topological properties.#R##N##R##N#We find the connection between topology and protein function to be weak but statistically significant. Surprisingly, our node signature, despite its simplicity, performs on par with the other more sophisticated node signatures. In fact, we show that just two metrics, the link count and transitivity, are enough to classify protein function at a level on par with the other signatures suggesting that detailed topological characteristics are unlikely to aid in protein function prediction based on protein interaction networks.","Green IT Logistics in a Greek Retailer: Grand Successes and Minor FailuresEnvironmental sustainability is one of the issues that organizations need to face today. Nevertheless, Green IT practices have their disadvantages, especially financial ones, which make the green logistic topic controversial to organizations. Achieving zero emissions while receiving financial benefits is idealistic thus companies need to adapt specific green strategies according to their particular needs. This study analyzes a specific company in terms of its green logistics strategy in order to discover any shortcomings and to depict how issues from literature review can influence the operation of the organization. This company is a super market chain dominant in the market of northern Greece. Focusing on the e-logistics of the firm, issues such as warehouse management system, inventory control, transportation, distribution and reverse logistics are examined in combination with the environmental consciousness. Our results could be useful to companies looking to exploit Green IT logistics.","Semantic Shared Spaces for Task Allocation in a Robotic Fleet for Precision AgricultureTask allocation is a fundamental problem in multi-robot systems where heterogeneous robots cooperate to perform a complex mission. A general requirement in a task allocation algorithm is to find an optimal set of robots to execute a certain task. This paper describes how coordination capabilities of the space-based middleware are extended with the semantic model of robot capabilities to improve the process of selection in terms of flexibility, scalability and reduced communication overhead during task allocation. We developed a framework that translates resources into a newly defined semantic model and performs automatic reasoning to assist the task allocation. We con- ducted performance tests in a specific precision agriculture use case based on the robotic fleet for weed control elaborated within European Project RHEA- Robot Fleets for Highly Effective Agriculture and Forestry Management.","Complex Manufacturing and Service Enterprise Systems: Modeling and Computational Framework ","A Shadow Touching Technique for Interactive Projector Devices ","Energy Efficient Array Initialization Using Loop Unrolling with Partial Gray Code Sequence ","A Review: What Matters for Ecosystem Business StrategyEcosystem is probably one of the most discussed terms in recent telco discussions. But are the common questions about new APIs and industry standards enough to lead telcos towards a telco ecosystem? This chapter discusses, which other elements are essential for an ecosystem and which aspects might be missing in the current discussion of telcos. The model of the shaping strategy is introduced to describe successful ecosystems such as Apple, Google or i-mode, which typically requires three essential components: First the shaping view, second shaping platform and third shaper acts and assets. This leads to a better understanding where the shortcomings of telcos are so far and where still potential opportunities are.","Availability Assessment of a Vision Cloud Storage Cluster ","Twinlist: Novel User Interface Designs for Medication ReconciliationMedication reconciliation is an important and complex task for which careful user interface design has the potential to help reduce errors and improve quality of care. In this paper we focus on the hospital discharge scenario and first describe a novel interface called Twinlist. Twinlist illustrates the novel use of spatial layout combined with multi-step animation, to help medical providers see what is different and what is similar between the lists (e.g., intake list and hospital list), and rapidly choose the drugs they want to include in the reconciled list. We then describe a series of variant designs and discuss their comparative advantages and disadvantages. Finally we report on a pilot study that suggests that animation might help users learn new spatial layouts such as the one used in Twinlist.","Enforcing spectrum access rules in cognitive radio networks through cooperative jammingIn Cognitive Radio Networks (CRNs) with dynamic spectrum access, it is of paramount importance to ensure the spectrum access rules are honestly followed by each secondary user. Existing approaches either require significant modifications to the system hardware, or can only deter the spectrum abuse from happening by punishing abusers after-the-fact, which is ineffective in reality as there lacks universal identification for each device. In this paper, we propose a novel spectrum access rule enforcing scheme by introducing a \"spectrum guardian\", who punishes abusers immediately on-the-scene through optimally jamming their signals using multiple antennas while without affecting the communication between primary users, thus removing abusers' incentive to exploit the spectrum for their own benefit. Our scheme requires no modifications to Commercial-Off-The-Shelf (COTS) CR devices, nor the need of device identification.","Improving Management of Medical Equipment ","Comprehensive Blended Learning Concept for Teaching Micro Controller Technology Utilising HomeLab Kits and Remote Labs in a Virtual Web Environment ","MUST: MUlti agent simulation of multi-modal urban trafficLarge cities with multi-modal traffic systems are complex that need to be understood to help analyze and make policy decisions. Understanding such complex systems requires simulation, experimentation and observation. We have built a MUST system to simulate big cities with multi-modal traffic system with large number of agents (humans), each participating in many movement activities. Building such a system would require high performance back-end, and a user friendly front-end. In this paper, we give a brief description of the system, and its functional components. The demonstration will show the system's capabilities.","Extending Term Subsumption systems for Uncertainty ManagementA major difficulty in developing and maintaining very large knowledge bases originates from the variety of forms in which knowledge is made available to the KB builder. The objective of this research is to bring together two complementary knowledge representation schemes: term subsumption languages, which represent and reason about defining characteristics of concepts, and proximate reasoning models, which deal with uncertain knowledge and data in expert systems. Previous works in this area have primarily focused on probabilistic inheritance. In this paper, we address two other important issues regarding the integration of term subsumption-based systems and approximate reasoning models. First, we outline a general architecture that specifies the interactions between the deductive reasoner of a term subsumption system and an approximate reasoner. Second, we generalize the semantics of terminological language so that terminological knowledge can be used to make plausible inferences. The architecture, combined with the generalized semantics, forms the foundation of a synergistic tight integration of term subsumption systems and approximate reasoning models.","On the power of correlated randomness in secure computationWe investigate the extent to which correlated secret randomness can help in secure computation with no honest majority. It is known that correlated randomness can be used to evaluate any circuit of size s with perfect security against semi-honest parties or statistical security against malicious parties, where the communication complexity grows linearly with s. This leaves open two natural questions: (1) Can the communication complexity be made independent of the circuit size? (2) Is it possible to obtain perfect security against malicious parties?#R##N##R##N#We settle the above questions, obtaining both positive and negative results on unconditionally secure computation with correlated randomness. Concretely, we obtain the following results.#R##N##R##N#Minimizing communication. Any multiparty functionality can be realized, with perfect security against semi-honest parties or statistical security against malicious parties, by a protocol in which the number of bits communicated by each party is linear in its input length. Our protocol uses an exponential number of correlated random bits. We give evidence that super-polynomial randomness complexity may be inherent.#R##N##R##N#Perfect security against malicious parties. Any finite 'sender-receiver' functionality, which takes inputs from a sender and a receiver and delivers an output only to the receiver, can be perfectly realized given correlated randomness. In contrast, perfect security is generally impossible for functionalities which deliver outputs to both parties. We also show useful functionalities (such as string equality) for which there are efficient perfectly secure protocols in the correlated randomness model.#R##N##R##N#Perfect correctness in the plain model. We present a general approach for transforming perfectly secure protocols for sender-receiver functionalities in the correlated randomness model into secure protocols in the plain model which offer perfect correctness against a malicious sender. This should be contrasted with the impossibility of perfectly sound zero-knowledge proofs.","A facial expression recognition method by fusing multiple sparse representation based classifiersWe develop a new method to recognize facial expressions. Sparse representation based classification (SRC) is used as the classifier in this method, because of its robustness to occlusion. Histograms of Oriented Gradient (HOG) descriptors and Local Binary Patterns are used to extract features. Since the results of HOG+SRC and LBP+SRC are complimentary, we use a classifier combination strategy to fuse these two results. Experiments on Cohn-Kanade database show that the proposed method gives better performance than existing methods such as Eigen+SRC, LBP+SRC and so on. Furthermore, the proposed method is robust to assigned occlusion.","The complexity of finding a large subgraph under anonymity constraints ","Multilingual Media Monitoring and Text Analysis \u2013 Challenges for Highly Inflected Languages ","Corrosion Protection Using High-Voltage and High-Frequency SystemThe corrosion of ships and equipment is the issue of shipping transportation and marine pollution. The organotin compound paint such as TBT(Tributyl Tin) or sinking of the ship which has been negligent in maintenance for a long time cause massive contamination of ocean. Therefore, to proof corrosion, maintain and manage the equipment from the electrical corrosion in the seawater becomes more and more significant. The corrosion in the ocean has many causes and there are several ways to prevent the corrosion by now. The main cause of corrosion is the oxidation of metals. Regarding this point, we want to know that application of high-voltage, high-frequency pulsed power technology is how much effective to electrical corrosion in environment of electrolyte that can cause corrosion easily.","Feature Weight Optimization and Pruning in Historical Text RecognitionIn handwritten text recognition, \"sliding window\" feature extraction represent the visual information contained in written text as feature vector sequences. In this paper, we explore the parameter  ...","Toward the Development of a Psycholinguistic-based Measure of Insider Threat Risk Focusing on Core Word Categories Used in Social MediaThe development of a psycholinguistic measure of insider threat risk faces many challenges. Prior research suggests that psycholinguistic analysis has potential for identifying individuals who are high risks for insider/criminal activity, but testing and validation of proposed methods is hampered by lack of available data. For example, analytic tools can discriminate text samples authored by known criminals from e-mail text produced in an organization, but a robust risk assessment tool must be able to handle heterogeneous text sources that come from a diverse population with wide differences in word use across age and other demographic variables. The current study seeks to advance the state of psycholinguistic insider threat research by among other things, augmenting word analysis dictionaries used in current practice and accommodating linguistic characteristics of social media, focusing on a core set of differentially-weighted word categories that represent an intersection of critical personality traits related to behaviors of concern.","Does access modality matter? Evaluation of validity in reusing clinical care data.Self-service database portals may improve access to institutional data resources for clinical research or quality improvement, but questions remain about the validity of this approach. We tested the accuracy of data extracted from a clinical data repository using a self-service portal by comparing three approaches to measuring medication use among patients with coronary disease: (1) automated extraction using a portal, (2) extraction by an experienced data architect, and (3) manual chart abstraction. Outcomes included medications and diagnoses (e.g., myocardial infarction, heart failure). Charts were manually reviewed for 200 patients. Using matched criteria, self-service query identified 7327 of 7358 patients identified by the data analyst. For patients in both cohorts, agreement rates ranged from 0.99 for demographic data to 0.94 for laboratory data. Based on chart review, the self-service portal and the analyst had similar sensitivities and specificities for comorbid diagnoses and statin use.","Implementing Efficient Updates in Compressed Big Text DatabasesText compression techniques like bzip2 lack the possibility to insert or to delete strings at a given position into a text that has been compressed without prior decompression of the compressed text. We present a technique called DICIRT that supports fast insertion into and deletion from compressed texts without full decompression of the compressed text. For inserted fragments up to a size of 8% of the original text size, and for deleted fragments up to 15% of the original text DICIRT is faster than modifying uncompressed text pre- ceded by a decompression step and followed by a compression step.","VisSecAnalyzer: A Visual Analytics Tool for Network Security Assessment ","Extraction of Partial Skeletons for Semi-Automatic Segmentation of Cortical Structures ","From OWL to DL \u2212 Lite through efficient ontology approximationOntologies provide a conceptualization of a domain of interest which can be used for different objectives, such as for providing a formal description of the domain of interest for documentation purposes, or for providing a mechanism for reasoning upon the domain. For instance, they are the core element of the Ontology-Based Data Access (OBDA) [3,8] paradigm, in which the ontology is utilized as a conceptual view, allowing user access to the underlying data sources. With the aim to use an ontology as a formal description of the domain of interest, the use of expressive languages proves to be useful. If instead the goal is to use the ontology for reasoning tasks which require low computational complexity, the high expressivity of the language used to model the ontology may be a hindrance. In this scenario, the approximation of ontologies expressed in very expressive languages through ontologies expressed in languages which keep the computational complexity of the reasoning tasks low is pivotal.","Recursive Profiles of Businesses and Reviewers on Yelp.comThis paper uses a novel recursive meta-profiling technique where profiles from one set of objects dynamically change the representation of another set of objects. Two profiling schemes evolve in parallel influencing each other through indirect recursion. This is demonstrated with the help of a yelp.com dataset consisting of businesses and reviewers. A business is represented by static information obtained from the database and dynamic information obtained from clustering of reviewers who reviewed the business. Similarly, the reviewer representation augments the static representation from the database with profiles of businesses who are reviewed by these reviewers. The resulting service provides a facility for users to find similar businesses/reviewers based on the grading of the business, easy/hard grading, and types of businesses. It also provides a succinct profile of business/reviewer based on these factors, so users can put the reviews in context.","Fast Approximation Method for Gaussian Process Regression Using Hash Function for Non-uniformly Distributed DataGaussian process regression (GPR) has the ability to deal with non-linear regression readily, although the calculation cost increases with the sample size. In this paper, we propose a fast approximation method for GPR using both locality-sensitive hashing and product of experts models. To investigate the performance of our method, we apply it to regression problems, i.e., artificial data and actual hand motion data. Results indicate that our method can perform accurate calculation and fast approximation of GPR even if the dataset is non-uniformly distributed.","The Continuing Mismatch Between IT Governance Theory and Practice: Results from a Delphi Study with CIO\u2019sDespite all efforts in the last decennium, IT governance continues to be a \"top 10\" issue for CIO\u2019s. The goal of our research program is to determine which disciplines and frameworks are used for IT governance and which streams in IT governance literature do best align with current practices. This study describes the results of a literature review and Delphi study of IT governance effectiveness and maturity and assesses the (mis)match between IT governance theory and practice. The Delphi study was conducted with a group of 14 CIO\u2019s of mid-sized and larger organizations. Based on the literature review and Delphi study, results show that six IT governance streams can be distinguished. We conclude that these six streams are an effective way to study the variety of IT governance practices. The study further concludes that there still exists a mismatch between IT governance theory and practice.","Automatic Annotation of Leishmania Infections in Fluorescence Microscopy Images ","Elements of Play for Cognitive, Physical and Social Health in Older Adults ","E-Court: Technology Diffusion in Court ManagementCourt workflow automation has been proliferating in justice system of almost all jurisdictions around the world. The reasons, among others, are its efficiency in managing case files, retrieving case information within seconds, the effective integration between organizations and speedy justice dispensation. It allows justice to take place virtually using the advanced technologies electronic case management system (ECMS), electronic filing system, court recording and transcribing, immersive virtual environment for re-creation of crime scene, forensic investigation and so on. This paper divulges a result of a case study conducted in Malaysian court environment which adopts an integrated electronic court management system named E-Court. This qualitative case study focuses on the four main types of applications within E-Court project, namely the Electronic Filing System (EFS), the Case Management System (CMS), the Court Recording and Transcribing (CRT) and the Queue Management System (QMS). Data was collected through interview, survey and document analysis, in the busiest court in the country. The result demonstrates a significant improvement in terms of court workflow management, court information and records management and integration with other agencies. At the same time, a number of technological, operational and people issues arise out of this electronic court implementation.","Domain Types: Abstract-Domain Selection Based on Variable UsageThe success of software model checking depends on finding an ap- propriate abstraction of the program to verify. The choice of the abstract domain and the analysis configuration is currently left to the user, who may not be fa- miliar with the tradeoffs and performance details of the available abstract do- mains. We introduce the concept of domain types, which classify the program variables into types that are more fine-grained than standard declared types (e.g., 'int' and 'long') to guide the selection of an appropriate abstract domain for a model checker. Our implementation on top of an existing verification framework determines the domain type for each variable in a pre-analysis step, based on the usage of variables in the program, and then assigns each variable to an abstract domain. Based on a series of experiments on a comprehensive set of verification tasks from international verification competitions, we demonstrate that the choice of the abstract domain per variable (we consider one explicit and one symbolic domain) can substantially improve the verification in terms of performance and precision.","A New Paradigm for Pattern Classification: Nearest Border TechniquesThere are many paradigms for pattern classification. As opposed to these, this paper introduces a paradigm that has not been reported in the literature earlier, which we shall refer to as the Nearest Border (NB) paradigm. The philosophy for developing such a NB strategy is as follows: Given the training data set for each class, we shall first attempt to create borders for each individual class. After that, we advocate that testing is accomplished by assigning the test sample to the class whose border it lies closest to. This claim is actually counter-intuitive, because unlike the centroid or the median, these border samples are often \"outliers\" and are, really, the points that represent the class the least. However, we have formally proven this claim, and the theoretical results have been verified by rigorous experimental testing.","Evaluating the premises and results of four metaphor identification systemsThis study first examines the implicit and explicit premises of four systems for identifying metaphoric utterances from unannotated input text. All four systems are then evaluated on a common data set in order to see which premises are most successful. The goal is to see if these systems can find metaphors in a corpus that is mostly non-metaphoric without over-identifying literal and humorous utterances as metaphors. Three of the systems are distributional semantic systems, including a source-target mapping method [1-4]; a word abstractness measurement method [5], [6, 7]; and a semantic similarity measurement method [8, 9]. The fourth is a knowledge-based system which uses a domain interaction method based on the SUMO ontology [10, 11], implementing the hypothesis that metaphor is a product of the interactions among all of the concepts represented in an utterance [12, 13].","Pruning False Positives of Static Data-Race Detection via Thread SpecializationStatic data-race detection is a powerful tool by providing clues for dynamic approaches to only instrument certain memory accesses. However, static data-race analysis suffers from high false positive rate. A key reason is that static analysis overestimates the set of shared objects a thread can access. We propose thread specialization to distinguish threads statically. By fixing the number of threads as well as the ID assigned to each thread, a program can be transformed to a simplified version. Static data-race analysis on this simplified program can infer the range of addresses accessed by each thread more accurately. Our approach prunes false positives by an average of 89.2% and reduces dynamic instrumentation by an average of 63.4% in seven benchmarks.","Towards a Technology for Caregivers\u2019 Emotional Expression and Self-reflection ","Fast and Parallel Algorithm for Population-Based Segmentation of Copy-Number Profiles ","The Discrete Orthonormal Stockwell Transform and Variations, with Applications to Image CompressionWe examine the so-called Discrete Orthonormal Stockwell Transform (DOST) and show that a number of quite simple modifica- tions can be made to obtain various desired properties. For example, we introduce a real-valued Discrete Cosine-based DOST (DCST). The coef- ficients of the DOST and its variations are shown to exhibit a directed graph structure as opposed to the tree-like structure demonstrated by wavelet coefficients. Finally, we employ the DOST and DCST in a se- ries of simple compression experiments and compare the results to those obtained with biorthogonal wavelets and the DCT.","Integrated Cloud Application Provisioning: Interconnecting Service-Centric and Script-Centric Management TechnologiesModern Cloud applications employ a plethora of components and XaaS offerings that need to be configured during provisioning. Due to increased heterogeneity, complexity is growing and existing approaches reach their limits if multiple different provisioning and configuration tech- nologies are involved. They are not able to integrate them in an auto- mated, flexible, and customizable way. Especially combining proprietary management services with script-centric configuration management tech- nologies is currently a major challenge. To enable automated provisioning of such applications, we introduce Generic Lifecycle Management Plan- lets that provide a means to combine custom provisioning logic with com- mon provisioning tasks. We implemented planlets for provisioning and customization of components and XaaS offerings based on both SOAP and RESTful Web services as well as configuration management tech- nologies such as Chef to show the feasibility of the approach. By using our approach, multiple technologies can be combined seamlessly.","Adaptive Voting Algorithms for Group and Social Recommender Systems ","Length Estimation for Exponential Parameterization and \u03b5-Uniform SamplingsThis paper discusses the problem of estimating the length of the unknown curve \u03b3 in Euclidean space, from e-uniformly for ei\u00be?0 sampled reduced data    $Q_m=\\{q_i\\}_{i=0}^m$   , where \u03b3t i =q i . The interpolation knots    $\\{t_i\\}_{i=0}^m$    are assumed here to be unknown yielding the so-called non-parametric interpolation. We fit Q m with the piecewise-quadratic interpolant    $\\hat \\gamma_2$    combined with the so-called exponential parameterization characterized by the parameter \u03bb\u2208[0,1]. Such parameterization applied e.g. in computer graphics for curve modeling [1], [2] uses estimates of the missing knots    $\\{t_i\\}_{i=0}^m\\approx\\{\\hat t_i\\}_{i=0}^m$   . The asymptotic orders \u03b2 e \u03bb for length estimation    $d\\gamma\\approx d\\hat \\gamma_2$    in case of \u03bb=0 uniformly guessed knots read as \u03b2 e 0= min {4,4e} for e&gt;0 - see [3]. On the other hand \u03bb=1 cumulative chords renders \u03b2 e 1= min {4,3+e} see [4]. A recent result [5] proves that for all \u03bb\u2208[0,1 and e-uniform samplings, the respective orders amount to \u03b2 e \u03bb= min {4,4e}. As such \u03b2 e \u03bb are independent of \u03bb\u2208[0,1. In addition, the latter renders a discontinuity in asymptotic orders \u03b2 e \u03bb at \u03bb=1. In this paper we verify experimentally the above mentioned theoretical results established in [5].","A Biologically Inspired Approach for Fast Image ProcessingAs features within an image may be present at many scales, application of feature detectors at multiple scales can improve accuracy of the detected localisation and orientation. As the scale and size of a feature detector increases, so does the computational complexity of implementation across the image domain. To address this issue we present a novel integral image for hexagonal pixel based images and associated multi-scale operator implementation that significantly speeds up the feature detection process. We demonstrate that this framework enables significantly faster computation than the use of conventional spiral convolution, the use of a neighbourhood address look-up table on hexagonal images.","Dynamic Principal Component Analysis: A Banking Customer Satisfaction Evaluation ","Approaching Cross-Domain Search in Environmental Applications \u2013 Towards Linked Data ","Interventional digital tomosynthesis from a standard fluoroscopy system using 2D-3D registration.Interventional fluoroscopy provides guidance in a variety of minimally invasive procedures. However, three-dimensional (3D) clinically relevant information is projected onto a two-dimensional (2D) image which can make image interpretation difficult. Moreover, vasculature visualisation requires the use of iodinated contrast media which is nephrotoxic and is the primary cause of renal complications. In this article, we demonstrate how digital tomosynthesis slices can be produced on standard fluoroscopy equipment by registering the preoperative CT volume and the intraoperative fluoroscopy images using 2D-3D image registration. The proposed method automatically reconstructs patient-anatomy-specific slices and removes clutter resulting from bony anatomy. Such slices could provide additional intraoperative information which cannot be provided by the preoperative CT volume alone, such as the deformed aorta position offering improved guidance precision. Image acquisition would fit with interventional clinical workflow and would not require a high X-ray dose. Experiments are carried out using one phantom and four clinical datasets. Phantom results showed a 3351% contrast-to-noise improvement compared to standard fluoroscopy. Patient results showed our method enabled visualization of clinically relevant features: outline of the aorta, the aortic bifurcation and some aortic calcifications.","Combining acquisition and debugging of business rule modelsBusiness rules (BR) can be acquired from complex texts such as laws, regulations or contracts. However knowledge extraction and formalization is a complex task that involves business experts as well as Information Technology engineers and that is error-prone. Instead of waiting until the rule base is completed or the BR decision system is put into production to detect problems, we propose to detect inconsistencies and errors at an early stage, before the formalization work is completed. This paper presents the quality procedures that can be implemented in the process of BR acquisition from NL regulations. We show that the documented business rule models under construction are useful to detect potential anomalies at a semi-formal level of the BR base, where the rules exploit a formal vocabulary but are simply structured into premises and conclusions. Even at the prior and textual level, these documented models give the business experts a global and structured view over the NL regulation, which helps the formalization process.","A Framework for Combining Problem Frames and Goal Models to Support Context Analysis during Requirements Engineering ","Saturated Semantics for Coalgebraic Logic ProgrammingA series of recent papers introduces a coalgebraic semantics for logic programming, where the behavior of a goal is represented by a parallel model of computation called coinductive tree. This semantics fails to be compositional, in the sense that the coalgebra formalizing such behavior does not commute with the substitutions that may apply to a goal. We suggest that this is an instance of a more general phenomenon, occurring in the setting of interactive systems (in particular, nominal process calculi), when one tries to model their semantics with coalgebrae on presheaves. In those cases, compositionality can be obtained through saturation. We apply the same approach to logic programming: the re- sulting semantics is compositional and enjoys an elegant formulation in terms of coalgebrae on presheaves and their right Kan extensions.","Beyond Bag of Words for Concept Detection and Search of Cultural Heritage ArchivesSeveral local features have become quite popular for concept detection and search, due to their ability to capture distinctive details. Typically a Bag of Words approach is followed, where a codebook is built by quantizing the local features. In this paper, we propose to represent SIFT local features extracted from an image as a multivariate Gaussian distribution, obtaining a mean vector and a covariance matrix. Differently from common techniques based on the Bag of Words model, our solution does not rely on the construction of a visual vocabulary, thus removing the dependence of the image descriptors on the specific dataset and allowing to immediately retargeting the features to different classification and search problems. Experimental results are conducted on two very different Cultural Heritage image archives, composed of illuminated manuscript miniatures, and architectural elements pictures collected from the web, on which the proposed approach outperforms the Bag of Words technique both in classification and retrieval.","Consumption of Profile Information from Heterogeneous Sources to Leverage Human-Computer InteractionUbiquitous computing brings new challenges to system and application designers. It is not enough to deliver information at any time, at any place and in any form; information must be relevant to the user. Ubiquitous user model interoperability allows enrichment of adaptive systems obtaining a better understanding of the user, but conflict resolution is necessary to deliver the best suited values despite the existence of international standards for different concepts. In this paper, we present the algorithm of conflict resolution to consume of profile information from the ubiquitous user model. We illustrate the enrichment of user models with one elemental concept for human-computer interaction: the language concept.","Stock Cloud Computing Platform:Architecture and Prototype SystemsThe Challenge of Big Data leads to a great interests in Cloud Computing in both research and industry. Many Cloud Platforms have been proposed and implemented in various applications, however, there are few works focusing on designing integrated platforms from a data driven perspective for stock market. In this paper, we propose a cloud platform for stock market with four-tier architectures that introduces Infrastructure as a Service(IaaS),Data as a Service(DaaS),Platform as a Service(PaaS) and Software as a Service(SaaS). The proposed cloud platform integrates big data processing, data mining, and cloud com- puting technologies, and can provide high-performance computing and s data service as well. Finally, a case study on market surveillance in stock market validates the effectiveness and efficiency of the proposed prototype systems.","Pattern Graphs: Combining Multivariate Time Series and Labelled Interval Sequences for ClassificationClassifying multivariate time series is often dealt with by transforming the numeric series into labelled intervals, because many pattern representations exist to deal with labelled intervals. Finding the right preprocessing is not only time consum- ing but also critical for the success of the learning algorithms. In this paper we show how pattern graphs, a powerful pattern language for temporal classification rules, can be extended in order to handle labelled intervals in combination with the raw time series. We thereby reduce dependence on the quality of the preprocessing and at the same time increase performance. These benefits are demonstrated experimentally on 10 different data sets.","Constant-Round Concurrent Zero Knowledge in the Bounded Player ModelIn [18] Goyal et al. introduced the bounded player model for secure computation. In the bounded player model, there are an a priori bounded number of players in the system, however, each player may execute any unbounded polynomial number of sessions. They showed that even though the model consists of a relatively mild relaxation of the standard model, it allows for round-efficient concurrent zero knowledge. Their protocol requires a super-constant number of rounds. In this work we show, constructively, that there exists a constant-round concurrent zero-knowledge argument in the bounded player model. Our result relies on a new technique where the simulator obtains a trapdoor corresponding to a player identity by putting together information obtained in multiple sessions. Our protocol is only based on the existence of a collision-resistance hash-function family and comes with a \"straight-line\" simulator.#R##N##R##N#We note that this constitutes the strongest result known on constant-round concurrent zero knowledge in the plain model under well accepted relaxations and subsumes Barak's constant-round bounded concurrent zero-knowledge result. We view this as a positive step towards getting constant round fully concurrent zero-knowledge in the plain model, without relaxations.","An internet of custom-made things: from 3d printing and personal fabrication to personal design of interactive devicesIn the homes of bleeding-edge tinkerers around the world, a revolution is happening that, as many predict, will overshadow the PC and internet revolutions that began with home computers in the 70's: Personal Fabrication. Sub-$1000 3D printers are a reality, and other computer-controlled digital fabrication tools such as lasercutters are close behind. Research labs are printing anything from molecules to entire houses, and Fab Labs around the world are introducing the public to the possibilities and dangers of this new era in production.","An Investigation of Classification Algorithms for Predicting HIV Drug Resistance without Genotype Resistance TestingThe development of drug resistance is a major factor impeding the efficacy of antiretroviral treatment of South Africa's HIV infected population. While genotype resistance testing is the standard method to determine resistance, access to these tests is limited in low-resource settings. In this paper we investigate machine learning techniques for drug resistance prediction from routine treatment and laboratory data to help clinicians select patients for confirmatory genotype testing. The techniques, including binary relevance, HOMER, MLkNN, predictive clustering trees PCT, RAkEL and ensemble of classifier chains were tested on a dataset of 252 medical records of patients enrolled in an HIV treatment failure clinic in rural KwaZulu-Natal in South Africa. The PCT method performed best with a discriminant power of 1.56 for two drugs, above 1.0 for three others and a mean true positive rate of 0.68. These methods show potential for application where access to genotyping is limited.","Bridging the Gap between Rich Supply Chain Problems and the Effective Application of Metaheuristics through Ontology-Based ModelingSupply chains (SC) are exposed to dynamic markets and enlarged network structures. This induces abundant decision complexity and the need to frequently adapt decisions. Metaheuristics are most suitable for rich SC optimization problems. However, effectiveness and adaptability of these approaches are impaired through extensive modeling efforts and intricate data representation issues. Therefore we propose using ontological modeling to mitigate these disadvantages.","An enhanced semantic tree kernel for sentiment polarity classificationSentiment analysis has gained a lot of attention in recent years, mainly due to the many practical applications it supports and a growing demand for such applications. This growing demand is supported by an increasing amount and availability of opinionated online information, mainly due to the proliferation and popularity of social media. The majority of work in sentiment analysis considers the polarity of word terms rather than the polarity of specific senses of the word in context. However there has been an increased effort in distinguishing between different senses of a word as well as their different opinion-related properties. Syntactic parse trees are a widely used natural language processing construct that has been effectively employed for text classification tasks. This paper proposes a novel methodology for extending syntactic parse trees, based on word sense disambiguation and context specific opinion-related features. We evaluate the methodology on three publicly available corpuses, by employing the sub-set tree kernel as a similarity function in a support vector machine. We also evaluate the effectiveness of several publicly available sense specific sentiment lexicons. Experimental results show that all our extended parse tree representations surpass the baseline performance for every measure and across all corpuses, and compared well to other state-of-the-art techniques.","Deep Natural Language Processing for Italian Sign Language TranslationThis paper presents the architecture of a translator from written Italian into Italian Sign Language. We describe the main features of the four modules of this architecture, i.e. a dependency parser for Italian, an ontology based semantic interpreter, a generator based on expert-systems and combinatory categorial grammars, a planner to position signs in space. The result of this translation chain is signed by a virtual character. Finally, we report the results of a first \"intrinsic\" experiment for the evaluation of translation quality.","Cohort-level brain mapping: learning cognitive atoms to single out specialized regionsFunctional Magnetic Resonance Imaging (fMRI) studies map the human brain by testing the response of groups of individuals to carefully-crafted and contrasted tasks in order to delineate specialized brain regions and networks. The number of functional networks extracted is limited by the number of subject-level contrasts and does not grow with the cohort. Here, we introduce a new group-level brain mapping strategy to differentiate many regions reflecting the variety of brain network configurations observed in the population. Based on the principle of functional segregation, our approach singles out functionally-specialized brain regions by learning group-level functional profiles on which the response of brain regions can be represented sparsely. We use a dictionary-learning formulation that can be solved efficiently with on-line algorithms, scaling to arbitrary large datasets. Importantly, we model inter-subject correspondence as structure imposed in the estimated functional profiles, integrating a structure-inducing regularization with no additional computational cost. On a large multi-subject study, our approach extracts a large number of brain networks with meaningful functional profiles.","Reception of Space: Inspiring Design without a Designer ","Bankruptcy Prediction for Banks: An Artificial Intelligence Approach to Improve Understandability ","A Framework for Privacy Protection and Usage Control of Personal Data in a Smart City ScenarioIn this paper we address trust and privacy protection issues related to identity and personal data provided by citizens in a smart city environment. Our proposed solution combines identity management, trust negotiation, and usage control. We demonstrate our solution in a case study of a smart city during a crisis situation.","Modeling and Simulation of Soft Tissue DeformationA stable and accurate deformable model to simulate the deformation of soft tissues is a challenging area of research. This paper describes a soft tissue simulation method that can deform multiple organs synchronously and interact with virtual surgical instruments accurately. The model we used in our method is a multi-organ system by point masses and springs. The organs that anatomically connect to each other are jointed together by high stiffness springs. Here we propose a volume preserved mass-spring model for simulation of soft organ deformation. It does not rely on any direct constraint on the volume of tetrahedrons, but rather two constraints on the length of springs and the third constraint on the direction of springs. To provide reliable interaction between the soft tissues and kinematic instruments we incorporate the position-based attachment to accurately move the soft tissue with the tools. Experiments have been designed for evaluation of our method on porcine organs. Using a pair of freshly harvested porcine liver and gallbladder, the real organ deformation is CT scanned as ground truth for evaluation. Compared to the porcine model, our model achieves a mean absolute error 1.5024 mm on landmarks with a overall surface error 1.2905 mm for a small deformation the deformation of the hanging point is 49.1091 mm and a mean absolute error 2.9317 mm on landmarks with a overall surface error 2.6400 mm for a large deformation the deformation of the hanging point is 83.1376 mm. The change of volume for the two deformations are limited to 0.22% and 0.59%, respectively. Finally, we show that the proposed model is able to simulate the large deformation of the liver and gallbladder system in real-time calculations.","Local and Global Search Based PSO Algorithm ","A Study on the Scalability of Artificial Neural Networks Training Algorithms Using Multiple-Criteria Decision-Making MethodsIn recent years, the unrestrainable growth of the volume of data has raised new challenges in machine learning regarding scalability. Scalability comprises not simply accuracy but several other measures regarding computational resources. In order to compare the scalability of algorithms it is necessary to establish a method allowing integrating all these measures into a single rank. These methods should be able to i) merge results of algorithms to be compared from different benchmark data sets, ii) quantitatively measure the difference between algorithms, and iii) weight some measures against others if necessary. In order to manage these issues, in this research we propose the use of TOPSIS as multiple-criteria decision-making method to rank algorithms. The use of this method will be illustrated to obtain a study on the scalability of five of the most well-known training algorithms for artificial neural networks (ANNs).","Linked Open Ontology Cloud KOKO\u2014Managing a System of Cross-Domain Lightweight Ontologies ","An Effective Ant Colony Approach for Scheduling Parallel Batch-Processing MachinesThis paper investigates the scheduling problem of parallel batch-processing machines which involves the constraints of non-identical job sizes, unequal release times, and batch dependent processing times for minimizing makespan. We proposed an Ant Colony Optimization ACO algorithm to solve the problem. of the ACO algorithm. In order to utilize the available information and obtain a tradeoff between exploitation and exploration, a novel construction policy and an efficient candidate list strategy were introduced during the process of solution construction of the ACO algorithm. Through extensive computational experiments, the effectiveness of the proposed algorithm was validated on different test problems. The results demonstrated that the proposed ACO algorithm had a superior performance compared to other benchmark algorithms.","Sharing Information in Parallel Search with Search Space PartitioningIn this paper we propose a new approach to share information among the computation units of an iterative search partitioning parallel SAT solver by approximating validity. Experimental results show the streh of the approach, against both existing sharing techniques and absence of sharing. With the improved clause sharing, out of 600 instances we could solve 13 more than previous sharing techniques.","Towards Usability Evaluation of Multimodal Assistive Technologies Using RGB-D SensorsTo date there are many solutions in the field of assistive technologies addressing different kinds of disabilities. Each solution has opted for very specific (and incompatible) hardware and software tech- nologies. Recently, new devices initially destined to electronic entertain- ment are appearing. They have joined in a single sensor various types of technologies typical for assistance. In this paper, we show and evaluate how RGB-D sensors are capable of replacing traditional heterogeneous technologies and a single device covers several products in the field of multimodal human-computer interaction and assistive technologies. Fur- thermore, a prototype of a software equivalent to a traditional assistive technology product is shown.","The application of kalman filter based human-computer learning model to chinese word segmentationThis paper presents a human-computer interaction learning model for segmenting Chinese texts depending upon neither lexicon nor any annotated corpus. It enables users to add language knowledge to the system by directly intervening the segmentation process. Within limited times of user intervention, a segmentation result that fully matches the use (or with an accurate rate of 100% by manual judgement) is returned. A Kalman filter based model is adopted to learn and estimate the intention of users quickly and precisely from their interventions to reduce system prediction error hereafter. Experiments show that it achieves an encouraging performance in saving human effort and the segmenter with knowledge learned from users outperforms the baseline model by about 10% in segmenting homogenous texts.","On the use of teamwork software for multi-robot formation control ","Understanding user spatial behaviors for location-based recommendationsIn this paper, we introduce a network-based method to study user spatial behaviors based on check-in histories. The results of this study have direct implications for location-based recommendation systems.","High-Level Rules for Integration and Analysis of Data: New Challenges ","Improved Adaptive Differential Evolution Algorithm with External Archive ","Learning agent models in SeSAmDesigning the agent model in a multiagent simulation is a challenging task due to the generative nature of such systems. In this contribution we present an extension to the multiagent simulation platform SeSAm, introducing a learning-based design strategy for building agent behavior models.","Vertex Unique Labelled Subgraph MiningThis thesis proposes the novel concept of Vertex Unique Labelled Subgraph (VULS)        mining with respect to the field of graph-based knowledge discovery (or graph mining). The objective of the research is to investigate the benefits that the concept of VULS can offer in the context of vertex classification. A VULS is a subgraph with a particular structure and edge labelling that has a unique vertex labelling associated with it within a given (set of) host graph(s). VULS can describe highly discriminative and significant local geometries each with a particular associated vertex label pattern. This knowledge can then be used to predict vertex labels in ``unseen\" graphs (graphs with edge labels,  but without vertex labels). Thus this research is directed at identifying (mining)   VULS, of various forms, that ``best\" serve to both capture effectively graph information,  while at the same time allowing for the generation of effective vertex label predictors (classifiers). To this end, four VULS classifiers are proposed,  directed at mining   four different kinds of VULS: (i)  complete, (ii)  minimal, (iii)  frequent and (iv)  minimal frequent. The thesis describes and discusses each of these in detail including, in each case, the theoretical definition and algorithms with respect to VULS identification and prediction. A full evaluation of each of the VULS categories is also presented. #R##N##R##N#VULS has wide applicability in areas where the domain of interest can be represented in the form of some sort of a graph. The evaluation was primarily directed at predicting a form of deformation, known as springback, that occurs in the Asymmetric Incremental Sheet Forming (AISF)  manufacturing process. For the evaluation two flat-topped, square-based, pyramid shapes were used. Each pyramid had been manufactured twice using Steel and twice using Titanium. #R##N##R##N#The utilisation of VULS was also explored by applying the VULS concept to the  field of satellite image interpretation. Satellite data describing two villages located in a rural part of the Ethiopian hinterland were used for this purpose. In each case the ground surface was represented  in a similar manner to the way that AISF sheet metal surfaces were represented, with the $z$ dimension describing the grey scale value. The idea here was to predict vertex labels describing ground type. #R##N##R##N#As will become apparent,  from the work presented in this thesis,  the VULS concept is well suited to the task of 3D surface    classification with respect to AISF and satellite imagery. The thesis demonstrates that the use of frequent VULS (rather than the other forms of VULS considered) produces more efficient results in the AISF sheet metal forming application domain, whilst the use of minimal VULS provided promising results in the context of the satellite image interpretation domain. The reported evaluation also indicates that a sound foundation has been established for future work on more general VULS based vertex classification.","A Dynamic Bayesian Network Framework for Learning from Observation ","Possibilities of Industrial Data Description Using Fractal Geometry ","Modelling the Pertubation of Traffic Based on Ateb-functionsTraffic's periodic processes in computer networks based on Ateb-functions without perturbation were simulated. The types of small perturbations that influence the traffic's vibration were considered. Ap- propriate software that outputs the results in graphical and tabular forms was developed.","Fermentation Condition Optimization for Endophytic Fungus BS002 Isolated from Sophora Flavescens by Response Surface Methodology ","User-Defined Body Gestures for an Interactive Storytelling ScenarioFor improving full body interaction in an interactive storytelling sce- nario, we conducted a study to get a user-defined gesture set. 22 users per- formed 251 gestures while running through the story script with real interaction disabled, but with hints of what set of actions was currently requested by the application. We describe our interaction design process, starting with the con- duction of the study, continuing with the analysis of the recorded data including the creation of gesture taxonomy and the selection of gesture candidates, and ending with the integration of the gestures in our application.","Multi Objective Optimization of HPC Kernels for Performance, Power, and Energy ","Verifying concurrent memory reclamation algorithms with graceMemory management is one of the most complex aspects of modern concurrent algorithms, and various techniques proposed for it--such as hazard pointers, read-copy-update and epoch-based reclamation--have proved very challenging for formal reasoning. In this paper, we show that different memory reclamation techniques actually rely on the same implicit synchronisation pattern, not clearly reflected in the code, but only in the form of assertions used to argue its correctness. The pattern is based on the key concept of a grace period, during which a thread can access certain shared memory cells without fear that they get deallocated. We propose a modular reasoning method, motivated by the pattern, that handles all three of the above memory reclamation techniques in a uniform way. By explicating their fundamental core, our method achieves clean and simple proofs, scaling even to realistic implementations of the algorithms without a significant increase in proof complexity. We formalise the method using a combination of separation logic and temporal logic and use it to verify example instantiations of the three approaches to memory reclamation.","Aplica\u00e7\u00e3o para drag-and-drop de conte\u00fado multim\u00eddia entre dispositivos de intera\u00e7\u00e3o e visualiza\u00e7\u00e3oAs the new modalities of computer interfaces evolute, the manner we visualize and interact with information earn new possibilities. By the Natural User Interfaces (NUI), interactive processes such as touch and gesture-based became more present in applications of several domains with an ever-increasing demand of varied resource sharing. With this potential in mind, the local or remote collaborative task accomplishment become imminent. The present work aims to present the development of an application for multimedia content sharing and visualization between physically detached and heterogeneous devices adopting the interaction technique named drag-and-drop.","Detecting Events in Molecular Dynamics SimulationsWe describe the application of a recently published general event detection framework, called  EVE  to the challenging task of molecular event detection, that is, the automatic detection of structural changes of a molecule over time. Different types of molecular events can be of interest which have, in the past, been addressed by specialized methods. The framework used here allows different types of molecular events to be systematically investigated. In this paper, we summarize existing molecular event detection methods and demonstrate how  EVE  can be configured for a number of molecular event types.","Learning epistemic actions in model-free memory-free reinforcement learning: experiments with a neuro-robotic modelPassive sensory processing is often insufficient to guide biological organisms in complex environments. Rather, behaviourally relevant information can be accessed by performing so-called epistemicactions that explicitly aim at unveiling hidden information. However, it is still unclear how an autonomous agent can learn epistemic actions and how it can use them adaptively. In this work, we propose a definition of epistemic actions for POMDPs that derive from their characterizations in cognitive science and classical planning literature. We give theoretical insights about how partial observability and epistemic actions can affect the learning process and performance in the extreme conditions of model-free and memory-free reinforcement learning where hidden information cannot be represented. We finally investigate these concepts using an integrated eye-arm neural architecture for robot control, which can use its effectors to execute epistemic actions and can exploit the actively gathered information to efficiently accomplish a seek-and-reach task.","Immersive Interactive Information Mining with Application to Earth Observation Data RetrievalThe exponentially increasing amount of Earth Observation (EO) data requires novel approaches for data mining and exploration. Visual analytic systems have made valuable contribution in understand- ing the structure of data by providing humans with visual perception of data. However, these systems have limitations in dealing with large-scale high-dimensional data. For instance, the limitation in dimension of the display screen prevents visualizing high-dimensional data points. In this paper, we propose a virtual reality based visual analytic system, so called Immersive Information Mining, to enable knowledge discovery from the EO archive. In this system, Dimension Reduction (DR) techniques are applied to high-dimensional data to map into a lower-dimensional space to be visualized in an immersive 3D virtual environment. In such a sys- tem, users are able to navigate within the data volume to get visual per- ception. Moreover, they can manipulate the data and provide feedback for other processing steps to improve the performance of data mining system.","Fully Distributed Secure Video Surveillance Via Portable Device with User Awareness ","Point-and-Click Interface Based on Parameter-Free Eye Tracking Technique Using a Single Camera ","The use of Volunteered Geographic Information (VGI) and Crowdsourcing in Disaster Management: a Systematic Literature Review.The number of crisis events around the world has been increasing in the last years and suggests there is a real need to make communities more resilient to them. In addition to providing conventional authoritative data, ordinary citizens and residents in the affected areas are also voluntarily supplying information about the affected areas, in what has been called Crowdsourced or Volunteered Geographic Information (VGI). This paper conducts a Systemic Literature Review aimed at assessing the current state of research in the use of VGI as a source of information to aid the management of disasters. The results suggest there is an increasing body of knowledge of VGI and the way it can improve disaster management. It also reveals gaps in the use of VGI in the research areas of \u2018preparedness\u2019 and \u2018recovery\u2019, as well as the need for more robust case studies and experimental research to support this promising field.","Understanding Temporal Intent of User Query Based on Time-Based Query ClassificationWeb queries are time sensitive which implies that user's in- tent for information changes over time. How to recognize temporal in- tents behind user queries is crucial towards improving the performance of search engines. However, to the best of our knowledge, this problem has not been studied in existing work. In this paper, we propose a time- based query classification approach to understand user's temporal intent automatically. We first analyzed the shared features of queries' tempo- ral intent distributions. Then, we present a query taxonomy which group queries according to their temporal intents. Finally, for a new given query, we propose a machine learning method to decide its class in terms of its search frequency over time recorded in Web query logs. Experiments demonstrate that our approach can understand users' temporal intents effectively.","Mining Cohesive Domain Topics from Source Code ","Success Measurement of Enterprise Social NetworksEspecially in the knowledge intensive service industry and times of virtual teams, there is a high need to support collaboration and information ex- change between employees with IT. Whereas many organizations have recog- nized the great potential of Enterprise Social Networks (ESN) in this context, there is still a lack of well-founded and applicable approaches to make this po- tential visible i.e. to measure the success of ESN. To alleviate this drawback we propose a novel approach to measure ESN success covering the dimensions us- age and business value. To illustrate the practical benefit and applicability of the novel approach, we provide an extensive real-world example from the ser- vice industry. In cooperation with a large financial services provider, the ap- proach was successfully applied and led to an improved decision support for different stakeholder groups including system administrators and executive management.","Improving Prediction in TAC SCM by Integrating Multivariate and Temporal Aspects via PLS Regression ","Correcting the Usage of the Hoeffding Inequality in Stream MiningMany stream classification algorithms use the Hoeffding Inequality to identify the best split attribute during tree induction.#R##N##R##N#We show that the prerequisites of the Inequality are violated by these algorithms, and we propose corrective steps. The new stream classification core,  correctedVFDT , satisfies the prerequisites of the Hoeffding Inequality and thus provides the expected performance guarantees.#R##N##R##N#The goal of our work is not to improve accuracy, but to guarantee a reliable and interpretable error bound. Nonetheless, we show that our solution achieves lower error rates regarding split attributes and sooner split decisions while maintaining a similar level of accuracy.","An Overview of Experimental Studies on Software Inspection Process ","A method for teaching affordance for user experience design in interactive media design educationToday we are living in a world where boundaries among spatial design, object design and interactive media design (IMD) or human-computer interaction field are disappearing. Technological advances widen the abilities of interactive technologies day by day. We are on the verge of leaving the desktop metaphor behind while more natural and real life like interaction with interactive technologies is already on its way. As mentioned above, this is more about spatially interacting with new interaction modes such as gestures/touch/bio-feedback and new modes of showing content such as seamless/screen-free interfaces projected onto the eye or on different types of surfaces. These facts are highly related with the \"user experience\" subject. As put forth by Norman (1995), user experience paradigm aims to shift the focus from a more engineering approach to the emotions, behaviors of the human within his surrounding while interacting with the information. Today's designers are to design the user's whole experience, which means that traditional interaction design education concentrating on the media and computer is not enough. With this point of view, one of the aspects that is getting even more important now is ergonomics, thus affordance. This paper is about a method we are using in our interactive media design curriculum to study affordance and trigger the creativity of interaction design students.","An Immunity Inspired Anomaly Detection System: A General Framework ","Improving the Performance of NEAT Related Algorithm via Complexity Reduction in Search SpaceIn this paper, we focus on the learning aspect of NEAT and its variants in an attempt to solve benchmark problems through fewer generations. In NEAT, genetic algorithm is the key technique that is used to complexify artificial neural network. Crossover value, being the parameter that dictates the evolution of NEAT is reduced. Reducing crossover rate aids in allowing the algorithm to learn. This is because lesser interchange among genes ensures that patterns of genes carrying valuable information is not split or strayed during mating of two chromosomes. By tweaking the crossover parameter and with some minor modification, it is shown that the performance of NEAT can be improved. This enables NEAT algorithm to evolve slowly and retain information even while undergoing complexification. Thus, the learning process in NEAT is greatly enhanced as compared to evolution","Semantic-based construction of content and structure XML indexContent And Structure (CAS) index for XML data is an important index type that has not been widely researched, even though its role is important especially in multi domain applications. Most existing researches in XML Queries Optimization focus on structure index alone. Few have utilized the rich semantic of XML data to support CAS index and querying. In this paper, we propose two indexes namely Structural index and Content index, whose construction utilizes XML data semantics and schema. These indexes contribute to a better CAS queries performance. The experiments prove that our method improves the performance of CAS queries by reducing the cost of CPU time and the total number of scanned elements compared to a standard method.","Governance in the Technology Era: Implications of Actor Network Theory for Social Empowerment in South AsiaInformation and communication technologies (ICT) have proven their value in delivering time-sensitive and relevant information to targeted communities. Information has been the key resource to social development. Social entrepreneurs have leveraged ICT to reach out to people who are marginalized from public discourse. Despite successes however, some ICT initiatives have failed due to underestimating the social requirements of technology and to relying more on information systems than on the information the system transports. How information is produced and applied to a social context to create meaning is more important than the means by which it is represented through portable monitors and mobile devices. The paper argues in order to take advantage of today's ICT, it is critical that we understand how technology and society mediate within a socio-technical framework. Using the Actor Network Theory, the paper explains the process of mediation to highlight that the journey to technology-based solutions is not smooth. The Village Knowledge Center (VKC) project in India and the Access to Information (A2I) project in Bangladesh provide sound evidence of how ICT-led social development can be effective in the short run but meaningful long term changes will depend on the collaboration of social entrepreneurs and public administrators.","The Design of a Tangible User Interface for a Real-Time Strategy Game ","A Two Stage Approach for High School TimetablingThere are different types of educational timetabling prob- lems which are computationally difficult to solve. In this study, we deal with the High School Timetabling Problem which requires assignment of events, such as courses, and resources, such as classrooms, to time-slots under a set of different types of constraints. We describe an approach that hybridises an Evolutionary Algorithm variant and Simulated An- nealing methods to solve this problem. This approach is tested over a set of real world instances obtained across different countries. The empirical results demonstrate the viability of the hybrid approach when compared to the previously proposed techniques.","Approximations of Gaussian Process Uncertainties for Visual Recognition Problems ","Modeling and Utilizing Quality Properties in the Development of Composite Web MashupsUbiquitous Web resources and their manifold combinability are causing app development with current Web mashup platforms to be a challenging task, especially for low-skilled Web users. Hence, mashup composition demands for expressing quality requirements to facilitate selection and customization processes. Existing quality metamodels only provide guidelines or abstract categories, but neglect mashup-specific measuring directives and machine-readable representations. Therefore, we present a tailored quality property metamodel for composite Web mashups. We show, how it supports different settings of mashup development and execution. Finally, we demonstrate the metamodel's deployment in a mashup infrastructure and its utilization in different use cases.","Private Cloud Cooperation Framework for Reducing the Earthquake Damage on e-Learning Environment ","A Framework of Constructions of Minimum Storage Regenerating Codes with the Optimal Update/Access Property for Distributed Storage Systems Based on Invariant Subspace TechniqueIn this paper, we present a generic framework for constructing systematic minimum storage regenerating codes with two parity nodes based on invariant subspace technique. Codes constructed in our framework not only contain some best known codes as special cases, but also include some new codes with good properties such as the optimal access property and the optimal update property. In addition, to the best of our knowledge, two of the new codes have the largest number of systematic nodes with the optimal update property for given store capacity of an individual node.","Design and Implementation of Conversational Agents for Harvesting Feedback in eLearning SystemsTraditionally conversational interfaces, such as chatbots, have been created in two distinct ways. Either by using natural language parsing methods or by creating conversational trees that utilise the natural Zipf curve distribution of conversations using a tool like AIML. This work describes a hybrid method where conversational trees are developed for specific types of conversations, and then through the use of a bespoke scripting language, called OwlLang, domain knowledge is extracted from semantic web ontologies. New knowledge obtained through the conversations can also be stored in the ontologies allowing an evolving knowledge base. The paper describes two case studies where this method has been used to evaluate TEL by surveying users, firstly about the experience of using a learning management system and secondly about students' experiences of an intelligent tutor system within the I-TUTOR project.","Congestion Games with Player-Specific Costs RevisitedWe study the existence of pure Nash equilibria in conges- tion games with player-specific costs. Specifically, we provide a thorough characterization of the maximal sets of cost functions that guarantee the existence of a pure Nash equilibrium. For the case that the players are unweighted, we show that it is nec- essary and sufficient that for every resource and for every pair of players the corresponding cost functions are affine transformations of each other. For weighted players, we show that in addition one needs to require that all cost functions are affine or all cost functions are exponential. Finally, we construct a four-player singleton weighted congestion game where the cost functions are identical among the resources and differ only by an additive constant among the players and show that it does not have a pure Nash equilibrium. This answers an open question by Mavronicolas et al. (15) who showed that such games with at most three players always have a pure Nash equilibrium.","SDRule-L: Managing Semantically Rich Business Decision ProcessesSemantic Decision Rule Language (SDRule-L) is an extension to Ob- ject-Role Modelling language (ORM), which is one of the most popular fact based, graphical modelling languages for designing information systems. In this paper, we want to discuss how SDRule-L models can be formalized, analysed and applied in a business context. An SDRule-L model may contain static (e.g., data constraints) and dynamic rules (e.g., sequence of events). A reasoning en- gine is created for detecting inconsistency. When an SDRule-L model is used to manage linked data, a feasible way is to align SDRule-L with Semantic Web languages, e.g. OWL. In order to achieve this, we propose to map dynamic rules into a combination of static rules and queries for detecting anomalies. In this paper, we will illustrate a model reification algorithm for automatically trans- forming SDRule-L models that contain dynamic rules into the ones containing static rules, which can be formalized in Description Logic.","Comparing Software Architecture Descriptions and Raw Source-Code: A Statistical Analysis of Maintainability Metrics ","Privacy-Preserving Data Mining Techniques: Survey and Challenges ","Slicing XML Documents Using Dependence GraphProgram Slicing is a popular technique that assists in various software maintenance activities like debugging, program comprehension and regression testing. It is a decomposition technique used for the ex- traction of program statements affecting the values computed at some point of interest. We propose a technique for computing slices of XML documents. Given a valid XML document, we produce a new XML doc- ument (a slice) containing the relevant information in the original XML document according to some criterion. We output a new DTD such that the computed slice is valid with respect to this DTD. Our technique first slices the associated DTD and the DTD slice is used as a slicing criterion in order to produce the associated XML slice.","A Semantic Web Information Integration System Based on Ontology-Mapping and Multilevel Query Interface ","Predicting Road Accidents Based on Current and Historical Spatio-temporal Traffic Flow Data ","An Effort Prediction Model Based on BPM Measures for Process Automation ","Real-Time Communication over Wireless Sensor Network \u2013 A Prototype for Disaster Areas ","Lean Software Development Measures and Indicators : A Systematic Mapping StudyBackground: Lean Software Development (LSD) aims for improvement, yet this improvement requires measures to identify whether a difference has been achieved, and provide decision support for further improvement. Objective: This study identifies measures and indicators proposed in literature on LSD, then structures them according to ISO/IEC 15939, allowing for comparability due to a use of a standard. Method: Systematic mapping is the research methodology. Result: The published literature on LSD measures has significantly increased since 2010. The two pre-dominant study types are evaluation research and experience reports. 22 base measures, 13 derived measures, and 14 indicators were identified. Conclusion: Gaps exist with respect to LSD principles. In particular: deferring commitment, respecting people and knowledge creation. The principle of delivering fast is well supported.","Giving Students Real-World Experience via Virtual-Reality Learning: How one MBA school created an immersive online experience for aspiring business leadersThe iMBA program at the Lake Forest Graduate School of Management (LFGSM) allows students to participate in a virtual internship program within a simulated manufacturing company. iMBA lets students work in a virtual corporation with real products, customers, competitors, opportunities, and challenges. This immersion-based, virtual reality learning is considered  stickier  than passive  sit back and observe  style lectures as students are more emotionally engaged. Because academic learning and virtual internship occur simultaneously students are able to immediately apply the scholastic concepts, enabling them to more rapidly develop and practice critical business skills.","Formal Analysis of Dynamic Domain Establishment Protocol in Cloud Logging Service ","Automatic 3D Motion Estimation of Left Ventricle from C-arm Rotational Angiocardiography Using a Prior Motion Model and Learning Based Boundary Detector ","Application Security in Mobile Devices Using Unified Communications ","Local feature coding for action recognition using RGB-D cameraIn this paper, we perform activity recognition using an inexpensive RGBD sensor (Microsoft Kinect). The main contribution of this paper is that the conventional STIPs feature are extracted from not only the RGB image, but also the depth image. To the best knowledge of the authors, there is no work on extracting STIPs feature from the depth image. In addition, the extracted feature are combined under the framework of locality-constrained linear coding framework and the resulting algorithm achieves better results than state-of-the-art on public dataset.","Do starting and ending effects in fixed-price group-buying differ?With the growing popularity of group-buying websites, a plethora of group-buying options is available to consumers. Given this range of choices, information diffusion in group-buying can greatly influence consumers' purchase decisions. Our study uses large-scale datasets from the top two group-buying websites in China, to explore the diffusion process and examine mass media communication (MMC) and interpersonal communication (IPC) during different periods of the buying process. The analysis results indicate that MMC and IPC at the start of the process can positively affect the sales, while it leads to fewer sales during the ending period in fixed-price group-buying, which contradicts the results of previous studies. To the best of our knowledge, this is the first study to explore information diffusion in group- buying. This study provides a number of theoretical insights into group-buying from a new perspective, as well as practical management implications.","A Data Fusion Perspective on Human Motion Analysis Including Multiple Camera ApplicationsHuman motion analysis methods have received increasing attention during the last two decades. In parallel, data fusion technolo- gies have emerged as a powerful tool for the estimation of properties of objects in the real world. This papers presents a view of human mo- tion analysis from the viewpoint of data fusion. JDL process model and Dasarathy's input-output hierarchy are employed to categorize the works in the area. A survey of the literature in human motion analysis from multiple cameras is included. Future research directions in the area are identified after this review.","Cascaded Random Forest for Fast Object Detection ","Causal explanation in the coordinating process: a critical realist case study of federated IT governance structuresLarge, multi-unit organizations are continually challenged to balance demands for centralization of information technology that lead to cost and service efficiencies through standardization while providing flexibility at the local unit level in order to meet unique business, customer, and service needs. This has led many organizations to adopt hybrid federated information technology governance (ITG) structures to find this balance. This approach to ITG establishes demand for various means to coordinate effectively across the organization to achieve the desired benefits. Past research has focused on the efficacy of various coordination mechanisms (e.g., steering committees, task forces) to coordinate activities related to information technology. However, we lack insights as to how and why these various coordination approaches help organizations achieve desired coordinated outcomes. This research specifically identifies coordinating as a process. Adopting the philosophy of critical realism, we conducted a longitudinal, comparative case study of two coordinating efforts in a federated ITG structure. Through a multifaceted approach to scientific logic employing deductive, inductive, and retroductive elements, we explicate two causal mechanisms, consensus making and unit aligning, which help to explain the coordinating process and the coordination outcomes observed in these efforts. We additionally elaborate the operation of the mechanisms through the typology of macro-micro-macro influences. Further, we demonstrate the value of the causal mechanisms to understanding the coordinating process by highlighting the complementarity in insights relative to the theories of power and politics and of rational choice. The study contributes to our understanding of coordinating as a process and of governance in federated IT organizations. Importantly, our study illustrates the value of applying critical realism to develop causal explanations and generate insights about a phenomenon.","Dynamic Modeling and Computer Simulation of 3D Objects GraspingAmong the essentials functionalities of several robotic systems are grasping and manipulating of objects by multi-fingered robot hands. Therefore many researchers have studied features of the two major closely related tasks. In this paper, we consider the problem of mathematical modeling of the robotic hand, the object and the physical interactions between the object and fingers under sliding constraints. Development of a numerical simulator for 3-D object grasping and manipulation by multi-fingered robot hands is an active area in robotic field. By integrating the derived Lagrange's equations of motion of the fingers and object under sliding constrains in the 3D simulator HandGrasp that is designed and developed at REGIM (Laboratory of REsearch Group on Intelligent Machine), numerical simulation results of 3-D object pinching and manipulation based on the impedance control law. This simulation results show the validity of mathematical modeling and the control method","Repeatable optimization algorithm based discrete PSO for virtual network embeddingAiming at reducing the link load and improving substrate network resource utilization ratio, we model the virtual network embedding (VNE) problem as an integer linear programming and present a discrete particle swarm optimization based algorithm to solve the problem. The approach allows multiple virtual nodes of the same VN can be embedded into the same physical node as long as there is enough resource capacity. It not only can cut down embedding processes of virtual link and reduce the embedding time, but also can save the physical link cost and make more virtual networks to be embedded at the same time. Simulation results demonstrate that comparing with the existing VNE algorithm, the proposed algorithm performs better for accessing more virtual networks and reducing embedding cost.","Applying wavelet packet decomposition and one-class support vector machine on vehicle acceleration traces for road anomaly detectionRoad condition monitoring through real-time intelligent systems has become more and more significant due to heavy road transportation. Road conditions can be roughly divided into normal and anomaly segments. The number of former should be much larger than the latter for a useable road. Based on the nature of road condition monitoring, anomaly detection is applied, especially for pothole detection in this study, using accelerometer data of a riding car. Accelerometer data were first labeled and segmented, after which features were extracted by wavelet packet decomposition. A classification model was built using one-class support vector machine. For the classifier, the data of some normal segments were used to train the classifier and the left normal segments and all potholes were for the testing stage. The results demonstrate that all 21 potholes were detected reliably in this study. With low computing cost, the proposed approach is promising for real-time application.","The role of specialized intelligent body-system networks in guiding general-purpose cognitionHuman cognition is portrayed as involving a highly flexible, self-organizing \"cognitive network\", closely coupled with a number of more specific intelligent \"body-system networks\" --- e.g. those associated with the perceptual and motor systems, the heart, the digestive system, the liver, and the immune and endocrine systems, all of which have been shown to have their own adaptive intelligence. These specialized intelligent networks provide the general-purpose cognitive network with critical structural and dynamical inductive biasing. It is argued that early-stage AGI systems must involve roughly comparable inductive biasing, though not necessarily achieved in the same way.","GoalSPEC: A Goal Specification Language Supporting Adaptivity and EvolutionThe characteristic of being autonomous and proactive makes the agents able to explore a wide solution space, that dynamically changes or contains uncertainty. We propose a language for describing system goals that may be injected at run-time into the system. The novelty of our approach consists in decoupling the business goals what is expected and their implementation how to address the desired behavior. Indeed relieving the tension between 'what' and 'how' provides more degrees of freedom to the system. On the occurrence, agents of our system may exploit their features mainly autonomy and proactivity, but also learning and planning for getting benefits from a wider solution space. The result is that the system behavior may adapt to the current operating conditions. Moreover, the injection mechanism contributes to reduce the effort in evolving the system. This paper focuses on the goal specification language that is the base for enabling both adaptivity and evolution.","Analysis of Brain Areas Activated while Using Strategies to Improve the Working Memory CapacityImprovement of the working memory capacity is expected to enhance the reasoning task and reading comprehension abilities. The aim of this study was to investigate effective methods for improving the working memory capacity. We used the reading span test (RST) as a task and examined the types of strategies that can be used to process tasks as well as strategies that may improve working memory capacity. In this experiment, we used functional magnetic resonance imaging to observe the brain areas activated in subjects during RST. We examined the high-span subjects (HSS) in the preliminary RST and found that the HSS used a scene imagery strategy when performing RST. The low-span subjects (LSS) were trained to learn the same strategy that was used by HSS. We observed that the similar brain areas as those in HSS were activated in LSS and their RST scores were improved.","A 2-chain can interlock with an open 10-chainIt is an open problem, posed in \\cite{SoCG}, to determine the minimal $k$ such that an open flexible $k$-chain can interlock with a flexible 2-chain. It was first established in \\cite{GLOSZ} that there is an open 16-chain in a trapezoid frame that achieves interlocking. This was subsequently improved in \\cite{GLOZ} to establish interlocking between a 2-chain and an open 11-chain. Here we improve that result once more, establishing interlocking between a 2-chain and a 10-chain. We present arguments that indicate that 10 is likely the minimum.","A Life-Cycle Model for Software Service Engineering ","Extending Application of Non-verbal Communication to Effective Requirement Elicitation ","Design Lessons from Deploying NFC Mobile PaymentsThis work was co-funded by \u201cAgencia de Inovacao\u201d and the national QREN pro- gram through the COMPETE program, under the project MOBIPAG - National Initia- tive for Mobile Payments (project 13847).","Linked services infrastructure: a single entry point for online media related to any linked data conceptIn this submission, we describe the Linked Services Infrastructure (LSI). It uses Semantic Web Service technology to map individual concepts (identified by Linked Data URIs) to sets of online media content aggegrated from heterogeneous Web APIs. It exposes this mapping service in a RESTful API and returns RDF based responses for further processing if desired. The LSI can be used as a general purpose tool for user agents to retrieve different online media resources to illustrate a concept to a user.","The Division Method in Visualization of High Frequency Electromagnetic Wave Propagation for Distributed Computing on CAVE System ","PhenoGP: combining programs to avoid code disruptionIn conventional Genetic Programming (GP), n programs are simultaneously evaluated and only the best programs will survive from one generation to the next. It is a pity as some programs might contain useful code that might be hidden or not evaluated due to the presence of introns. For example in regression, 0\u00d7 (perfect code) will unfortunately not be assigned a good fitness and this program might be discarded due to the evolutionary process. In this paper, we develop a new form of GP called PhenoGP (PGP). PGP individuals consist of ordered lists of programs to be executed in which the ultimate goal is to find the best order from simple building-blocks programs. If the fitness remains stalled during the run, new building-blocks programs are generated. PGP seems to compare fairly well with canonical GP.","Did We Miss Something? Correspondence Analysis of Usability DataIdeas are formed in a process of idea generation that includes creation, development, and communication of new ideas. Drawing has been used as a support for ideation for centuries. Today, computerized tools are commonly used for drawing. Such tools form a user interface between the human and the resulting drawing presented on the screen. The interface may come between the user and the drawing in a disruptive way also affecting the ideation process.Using controlled laboratory studies, this thesis investigates the consequences of drawing with different user interfaces in two types of tasks: creative drawing tasks (based on a standardized test of creativity) and non-creative drawing tasks (i.e. shape-tracing tasks where no new idea is created). The goal was to identify and evaluate the consequences of the several issues originating from the use of different input devices, the functionality of the graphical user interfaces, the formulation of the drawing task, and the user\u2019s previous experience.The results showed that drawing tasks are oriented toward quality of outcomes and that higher input accuracy led to higher quality of outcomes of both creative and non-creative drawing tasks. This came with a trade-off between the quantity and quality. In ideation, less accurate input devices facilitated significantly more ideas but these were of lower quality. In non-creative tracing, higher speeds caused lower quality of outcomes.The users subjectively preferred higher accuracy, also when an inaccurate user interface offered an eraser function. However, using the eraser allowed avoiding reinterpretations of ideas and led to ideation strategies characterized by laborious drawing that negatively affected the quality and quantity of the ideas produced. For non-creative drawing, the more difficult the shapes were, the lower the tracing accuracy.In the thesis a new framework for interaction analysis is introduced that improves the theoretical and practical understanding of computerized drawing tasks and the phenomena resulting from different aspects of the user interface design of computerized drawing tools.This thesis demonstrates that the inaccuracy of computerized tools cannot only make our drawings less aesthetically pleasing but also negatively affect ideas that are created in the process.","Multigrid convergent curvature estimatorWe propose in this paper an estimator of derivative and curvature of discrete curves. Based on adaptive convolution that preserves contour, we use local geometrical information as the heat kernel to convolve with a discrete curve and give estimation of its geometrical parameters. We recover on regular part of the curve the classical convolution based on gaussian kernel. We study the bounded error of our approach for first and second order derivative and we discuss about the multigrid convergence.","Redundant Nodes Elimination in Wireless Sensor Networks ","Interpretability Issues in Evolutionary Multi-Objective Fuzzy Knowledge Base Systems ","Interacting with a Context-Aware Personal Information Sharing SystemThe di.me userware is a decentralised personal information sharing system with a difference: extracted information and observed personal activi- ties are exploited to automatically recognise personal situations, provide privacy- related warnings, and recommend and/or automate user actions. To enable reasoning, personal information from multiple devices and online sources is inte- grated and transformed to a machine-interpretable format. Aside from distributed personal information monitoring, an intuitive user interface also enables the i) manual customisation of advanced context-driven services and ii) their semi- automatic adaptation across interactive notifications. In this paper we outline how average users interact with the current user interface, and our plans to improve it.","PAC optimal exploration in continuous space Markov decision processesCurrent exploration algorithms can be classified in two broad categories: Heuristic, and PAC optimal. While numerous researchers have used heuristic approaches such as e-greedy exploration successfully, such approaches lack formal, finite sample guarantees and may need a significant amount of finetuning to produce good results. PAC optimal exploration algorithms, on the other hand, offer strong theoretical guarantees but are inapplicable in domains of realistic size. The goal of this paper is to bridge the gap between theory and practice, by introducing C-PACE, an algorithm which offers strong theoretical guarantees and can be applied to interesting, continuous space problems.","SYNAT System Ontology: Design Patterns Applied to Modeling of Scientific Community, Preliminary Model Evaluation ","Dimensionality reduction for efficient single frame hand pose estimationModel based approaches for the recovery of the 3D position, orientation and full articulation of the human hand have a number of attractive properties. One bottleneck towards their practical exploitation is their computational cost. To a large extent, this is determined by the large dimensionality of the problem to be solved. In this work we exploit the fact that the parametric joints space representing hand configurations is highly redundant. Thus, we employ Principal Component Analysis (PCA) to learn a lower dimensional space that describes compactly and effectively the human hand articulation. The reduced dimensionality of the resulting space leads to a simpler optimization problem, so model-based approaches require less computational effort to solve it. Experiments demonstrate that the proposed approach achieves better accuracy in hand pose recovery compared to a state of the art baseline method using only 1/4 of the latter's computational budget.","Computing Semantic Similarity Using Large Static Corpora ","Utterance Discourse and Meaning: A Pragmatic Journey with the Bangla Discourse Particle /na/For some cases meaning only depends on the manner of utterances. Discourse particles as the discourse-marking expressions are such cases which are extremely valuable in a discourse and exceptionally ambiguous in terms of language processing. This paper provides a particular case study with the elaborated examples of typical context sensitivity of the utterances of Bangla discourse particle na. We also attempt to analyze syntactic distribution. Such as topicalization and tag question formation with na in Bangla. Each type of nais exemplified with a spectrum graph to indicate the variation of the utterances. This attempt follows a descriptive framework of pragmatic analysis of discourse.","Guarded Transformation for the Modal mu-CalculusGuarded normal form requires occurrences of fixpoint variables in a mu-calculus-formula to occur under the scope of a modal operator. The literature contains guarded transformations that effectively bring a mu-calculus-formula into guarded normal form. We show that the known guarded transformations can cause an exponential blowup in formula size, contrary to existing claims of polynomial behaviour. We also show that any polynomial guarded transformation for mu-calculus-formulas in the more relaxed vectorial form gives rise to a polynomial solution algorithm for parity games, the existence of which is an open problem.","On fuzzy topological structures of rough fuzzy setsA rough fuzzy set is the result of approximation of a fuzzy set with respect to a crisp approximation space. In this paper, we investigate topological structures of rough fuzzy sets. We first show that a reflexive crisp rough approximation space can induce a fuzzy Alexandrov space. We then prove that the lower and upper rough fuzzy approximation operators are, respectively, the fuzzy interior operator and fuzzy closure operator if and only if the binary relation in the crisp approximation space is reflexive and transitive. We also examine that a similarity crisp approximation space can produce a fuzzy clopen topological space. Finally, we present the sufficient and necessary conditions that a fuzzy interior (closure, respectively) operator derived from a fuzzy topological space can associate with a reflexive and transitive crisp relation such that the induced lower (upper, respectively) rough fuzzy approximation operator is exactly the fuzzy interior (closure, respectively) operator.","In-network RFID Data Filtering Scheme in RFID-WSN for RFID ApplicationsIn the integration of wireless sensor networks (WSN) and radio frequency identification (RFID), RFID data can use WSN protocols for multi-hop communication. Due to readers overlapped regions in dense areas and due to readers multiple read cycles, a lot of duplicate data is produced. Transmitting such duplicates towards base station waste node energies. In-network filtering of these duplicates can save transmission overhead, but on the other hand it increases computation cost. Delay is an important parameter in RFID applications that has not been considered yet by existing approaches. Both communication overhead and computation overhead can affect the delay performance in terms of queuing delay and processing delay respectively. Therefore, it is required to tune the filtering algorithm. In this paper, our in-network filtering scheme tend to find this trade-off between these two costs for better delay performance. In simulation part, we showed the effect of these costs on delay performance.","Multi-atlas propagation whole heart segmentation from MRI and CTA using a local normalised correlation coefficient criterionAccurate segmentation of the whole heart from 3D image sequences is an important step in the developement of clinical applications. As manual delineation is a tedious task that is prone to errors and dependant on the expertise of the observer, fully automated segmentation methods are highly desirable. In this work, we present a fully automated method for the segmentation of the whole heart and the great vessels from 3D images. The method is based on a muti-atlas propagation segmentation scheme, that has been proven to be succesful in brain segmentation. Based on a cross correlation metric, our method selects the best atlases for propagation allowing the refinement of the segmentation at each iteration of the propagation. We show that our method allows segmentation from multiple image modalities by validating it on computed tomography angiography (CTA) and magnetic resonance images (MRI). Our results are comparable to state-of-the-art methods on CTA and MRI with average Dice scores of 90.9% and 89.0% for the whole heart when evaluated on a 23 and 8 cases, respectively.","Memristor-Based Phase-Lead Controller Circuit DesignAbstract. Memristor predicted and described by L. O. Chua is a new electrical element. Memristor with variable resistance which changes automatically as its voltage changing can be used as a tunable parameter in control systems. Phase-lead controller is widely used in industrial process control applications. The conventional method for adjusting phase-lead controller parameters is based on the \u201ctrial and error\u201d procedure which leads to an inconvenient and approximated design. In the meantime, once the parameters are adjusted, they are fixed during the control system operation. In this paper, memristor-based phase-lead (M-phase-lead) controller is presented. Based on memristor constitutive relations of the memristance and memductance, the proposed M-phase-lead controller is more flexible during the design process. The theoretical description of design scheme is presented and simulation example is given to show the effectiveness of the advocated design methodology. Keywords: Frequency-domain, Memristor, phase-lead.","POSTER: Approximation Algorithm for Minimizing the Size of Coverage Hole in Wireless Sensor Networks ","Stripe Model: An Efficient Method to Detect Multi-form Stripe StructuresWe present a general mathematical model for multiple forms of stripes. Based on the model, we propose a method to detect stripes built on scale-space. This method generates difference of Gaussian (DoG) maps by subtracting neighbor Gaussian layers, and reserves extremal responses in each DoG map by comparing to its neighbors. Candidate stripe regions are then formed from connected extremal responses. After that, approximate centerlines of stripes are extracted from candidate stripe regions using non-maximum suppression, which eliminates undesired edge responses simultaneously. And stripe masks could be restored from those centerlines with the estimated stripe width. Owing to the ability of extracting candidate regions, our method avoids traversing to do costly directional calculation on all pixels, so it is very efficient. Experiments show the robustness and efficiency of the proposed method, and demonstrate its ability to be applied to different kinds of applications in the image processing stage.","Mitosis Detection in Breast Cancer Histology Images with Deep Neural NetworksWe use deep max-pooling convolutional neural networks to detect mi- tosis in breast histology images. The networks are trained to classify each pixel in the images, using as context a patch centered on the pixel. Simple postprocessing is then applied to the network output. Our approach won the ICPR 2012 mitosis detection competition, outperforming other contestants by a significant margin.","Type-Based complexity analysis for fork processesWe introduce a type system for concurrent programs described as a parallel imperative language using while-loops and fork/wait instructions, in which processes do not share a global memory, in order to analyze computational complexity. The type system provides an analysis of the data-flow based both on a data ramification principle related to tiering discipline and on secure typed languages. The main result states that well-typed processes characterize exactly the set of functions computable in polynomial space under termination, confluence and lock-freedom assumptions. More precisely, each process computes in polynomial time so that the evaluation of a process may be performed in polynomial time on a parallel model of computation. Type inference of the presented analysis is decidable in linear time provided that basic operator semantics is known.","An Integrated Biomedical Ontology Mapping Strategy Based on Multiple Mapping MethodsIn investigating relevant ontology mapping methods, this study focuses on the integration method of ontology mapping. Many resources such as PubMed and UMLS are used for designing the multi-dimensional calculation parameters of ontology mapping, with consideration for morphology, semantics, attributes, and background knowledge. Furthermore, we develop a study on biomedical ontology mapping methods based on multiple strategies, as well as experimentally validate the proposed ontology mapping framework. similar factors. These heterogeneous resources should be mapped and integrated because biomedicine is characterized by a knowledge hierarchy of close internal relations. Ontology mapping is the basis of semantic interoperability, and the mapping relation between ontologies facilitates across-dataset inquiry submission, data conversion, and knowledge inference for multiple heterogeneous resources. Focusing on the characteristics and status quo of ontological resources in the biomedical field, this paper consolidates ontology mapping concepts and methods, and puts forward an approach that is suitable for the biomedical field. The proposed method can support most biomedically related ontology mapping tasks and serves as basis for the integration of biochemical resources, the semantic interoperability of heterogeneous resources, and the sharing and application of distributed resources. The method also serves as technical support for large-scale biochemical knowledge sharing, integration, release, and semantic research on knowledge organization systems and other upper-level biomedical applications. These requirements reflect the considerable significance of studying biomedical ontology mapping.","ZigBee Device Verification for Securing Industrial Control and Building Automation Systems ","Detecting real-time burst topics in microblog streams: how sentiment can helpMicroblog has become an increasing valuable resource of up-to-date topics about what is happening in the world. In this paper, we propose a novel approach of detecting real-time events in microblog streams based on bursty sentiments detection. Instead of traditional sentiment orientation like positive, negative and neutral, we use sentiment vector as our sentiment model to abstract subjective messages which are then used to detect bursts and clustered into new events. Experimental evaluations show that our approach could perform effectively for online event detection. Although we worked with Chinese in our research, the technique can be used with any other language.","On Perfect Absorbants in De Bruijn DigraphsAn absorbant of a digraph D is a set S \u2286 V(D) such that, for every v \u2208 V(D)\\ S, there exists an arc (v, u) with u \u2208 S. We denote the cardinality of a minimum absorbant by \u03b3a(D). An absorbant S is called a perfect absorbant if no vertex of S has an out-neighbor in S and no two vertices in S have ac ommon in-neighbor. In this paper, we are concerned with the perfect absorbant problem in gener- alized De Bruijn digraphs. We prove that some classes of generalized De Bruijn graphs have perfect absorbants. We also answer some questions asked by Shan et al. in (10), i.e., we affirm that \u03b3a(GB(8k\ufffd4, 4k\ufffd3))= 3a nd\u03b3a(GB(6k ,2 k\ufffd 1)) = 4f ork 2.","Detection of Article Qualities in the Chinese Wikipedia Based on C4.5 Decision TreeThe number of articles in Wikipedia is growing rapidly. It is important for Wikipedia to provide users with high quality and reliable articles. However, the quality assessment metric provided by Wikipedia are inefficient, and other mainstream quality detection methods only fo- cus on the qualities of the English Wikipedia articles, and usually analyze the text contents of articles, which is also a time-consuming process. In this paper, we propose a method for detecting the article qualities of the Chinese Wikipedia based on C4.5 decision tree. The problem of quality detection is transformed to classification problem of high-quality and low-quality articles. By using the fields from the tables in the Chi- nese Wikipedia database, we built the decision trees to distinguish high- quality articles from low-quality ones.","An introduction to string re-writing kernelLearning for sentence re-writing is a fundamental task in natural language processing and information retrieval. In this paper, we propose a new class of kernel functions, referred to as string rewriting kernel, to address the problem. A string re-writing kernel measures the similarity between two pairs of strings. It can capture the lexical and structural similarity between sentence pairs without the need of constructing syntactic trees. We further propose an instance of string re-writing kernel which can be computed efficiently. Experimental results on benchmark datasets show that our method can achieve comparable results with state-of-the-art methods on two sentence rewriting learning tasks: paraphrase identification and recognizing textual entailment.","eGuided: Sharing Media in Academic and Social Networks Based on Peer-Assisted Learning e-Portfolios ","An algebraic characterization of testable boolean CSPsGiven an instance $\\mathcal{I}$ of a CSP, a tester for $\\mathcal{I}$ distinguishes assignments satisfying $\\mathcal{I}$ from those which are far from any assignment satisfying $\\mathcal{I}$. The efficiency of a tester is measured by its query complexity, the number of variable assignments queried by the algorithm. In this paper, we characterize the hardness of testing Boolean CSPs in terms of the algebra generated by the relations used to form constraints. In terms of computational complexity, we show that if a non-trivial Boolean CSP is sublinear-query testable (resp., not sublinear-query testable), then the CSP is in NL (resp., P-complete, \u2295L-complete or NL-complete) and that if a sublinear-query testable Boolean CSP is constant-query testable (resp., not constant-query testable), then counting the number of solutions of the CSP is in P (resp., $\\sharp$P-complete).#R##N##R##N#Also, we conjecture that a CSP instance is testable in sublinear time if its Gaifman graph has bounded treewidth. We confirm the conjecture when a near-unanimity operation is a polymorphism of the CSP.","Multilocal Programming and ApplicationsMultilocal programming aims to identify all local maximizers of uncon- strained or constrained nonlinear optimization problems. The multilocal program- ming theory relies on global optimization strategies combined with simple ideas that are inspired in deflection or stretching techniques to avoid convergence to the already detected local maximizers. The most used methods to solve this type of problems are based on stochastic procedures. In general, population-based methods are computationally expensive but rather reliable in identifying all local solutions. Stochastic methods based on point-to-point strategies are faster to identify the global solution, but sometimes are not able to identify all the optimal solutions of the prob- lem. To handle the constraints of the problem, some penalty strategies are proposed. A well-known set of test problems is used to assess the performance of the algo- rithms. In this chapter, a review on recent techniques for both unconstrained and constrained multilocal programming is presented. Some real-world multilocal pro- gramming problems based on chemical engineering process design applications are described.","An Innovative Approach to Assess the Quality of Major Parks in Environmentally Degraded Mega-City Dhaka ","Conflict-Based Program Rewriting for Solving Configuration ProblemsMany real-world design problems such as product configuration require a flexible number of components and thus rely on tuple generating dependencies in order to express relations between entities. Often, such problems are subject to optimization, preferring models which include a minimal number of constants substituted in existentially quantified formulas.#R##N##R##N#In this paper we propose an approach based on automated program rewriting which avoids such substitutions of existentially quantified variables that would lead to a contradiction. While preserving all solutions, the method significantly reduces runtime and solves instances of a class of real-world configuration problems which could not be efficiently solved by current techniques.","A Normalization Scheme for the Non-symmetric s-Step Lanczos AlgorithmThe Lanczos algorithm is among the most frequently used techniques for computing a few dominant eigenvalues of a large sparse non-symmetric matrix. When variants of this algorithm are implemented on distributed-memory computers, the synchronization time spent in computing dot products is increasingly limiting the parallel scalability. The goal of s-step algorithms is to reduce the harmful influence of dot products on the parallel performance by grouping several of these operations for joint execution; thus, plummeting synchronization time when using a large number of processes. This paper extends the non-symmetric s-step Lanczos method introduced by Kim and Chronopoulos (J. Comput. Appl. Math., 42(3), 357\u0097374, 1992) by a novel normalization scheme. Compared to the unnormalized algorithm, the normalized variant improves numerical stability and reduces the possibility of breakdowns.","Towards a Systematic Benchmarking of Ontology-Based Query Rewriting SystemsQuery rewriting is one of the fundamental steps in ontology-based data access (OBDA) approaches. It takes as inputs an ontology and a query written according to that ontology, and produces as an output a set of queries that should be evaluated to account for the inferences that should be considered for that query and ontology. Different query rewriting systems give support to different ontology languages with varying expressiveness, and the rewritten queries obtained as an output do also vary in expressiveness. This heterogeneity has traditionally made it difficult to compare different approaches, and the area lacks in general commonly agreed benchmarks that could be used not only for such comparisons but also for improving OBDA support. In this paper we compile data, dimensions and measurements that have been used to evaluate some of the most recent systems, we analyse and characterise these assets, and provide a unified set of them that could be used as a starting point towards a more systematic benchmarking process for such systems. Finally, we apply this initial benchmark with some of the most relevant OBDA approaches in the state of the art.","Controlling Data Flow with a Policy-Based Programming Language for the WebIt has become increasingly easy to write Web applications and other distributed programs by orchestrating invocations to remote third-party services. Increasingly, these third-party services themselves invoke other services and so on, making it difficult for the original application developer to anticipate where his/her data will end up. This may lead to privacy breaches or contractual violations. In this paper, we explore a simple distributed programming language that allows a web service provider to infer automatically where user data will travel to, and the developer to impose statically-checkable constraints on acceptable routes. For example, this may provide confidence that company data will not flow to a competitor, or that privacy-sensitive data goes through an anonymizer before being sent further out.","Computing Covers of Plane ForestsLet be a function that maps any non-empty subset A of R 2 to a non-empty subset (A) of R 2 . A -cover of a set T =fT1;T2;:::;Tmg of pairwise non-crossing trees in the plane is a set of pairwise disjoint connected regions such that 1. each treeTi is contained in some region of the cover, 2. each region of the cover is either (a) (Ti) for some i, or (b) (A[B), where A and B are constructed by either 2a or 2b, and A\\B6;. We present two properties for the function that make the -cover well-dened. Examples for such functions are the convex hull and the axis-aligned bounding box. For both of these functions , we show that the -cover can be computed in O(n log 2 n) time, where n is the total number of vertices of the trees in T .","Active sensing in complex multiagent environmentsIn this research, we focus on active sensing solutions to address challenging properties in complex environments, such as uncertainty, partial observability, non-stationarity, and limited resources. We describe our ongoing contributions, focusing on sensing for both individual agents and cooperating teams. We also outline how we are applying our research to two real-world applications: personal assistants and intelligent survey systems.","Segmentation of Heterochromatin Foci Using a 3D Spherical Harmonics Intensity Model ","Transformation of extended actigram star to BPMN2.0 and simulation model in the frame of model driven service engineering architectureCooperation between different enterprises to provide product and related services has become a must in order to set up win-win alliances and benefit better from market opportunities. This evolution has encountered several problems, like interoperability when trying to exchange data between heterogeneous systems. This paper shows how a model-driven approach can be an answer to service system implementation and interoperability problems. In particular it details the necessity to provide transformation mechanisms from conceptual description here Extended Actigram Star (EA*) models to more technical models such as BPMN 2.0 models. At the end the paper describes a last transformation to G-DEVS simulation models in order to validate, thanks to simulation, some behavioral properties of the BPMN model before going to implementation.","Randomized Algorithms for Removable Online Knapsack ProblemsIn this paper, we study removable online knapsack problem. The input is a sequence of items e1,e2,...,en, each of which has a weight and a value. Given the ith item ei, we either put ei into the knapsack or reject it. When ei is put into the knapsack, some items in the knapsack are removed with no cost if the sum of the weight of ei and the total weight in the current knapsack exceeds the capacity of the knapsack. Our goal is to maximize the profit, i.e., the sum of the values of items in the last knapsack. We show a randomized 2-competitive algorithm despite there is no constant competitive deterministic algorithm. We also give a lower bound 1 + 1/e \u2248 1.368. For the unweighted case, i.e., the value of each item is equal to the weight, we propose a 10/7-competitive algorithm and give a lower bound 1.25.","Interoperation in Complex Information Ecosystems (Dagstuhl Seminar 13252).This report documents the program and the outcomes of Dagstuhl Seminar 13252 \"Interoperation in Complex Information Ecosystems\".","A hybrid parallel algorithm for simulating seismic wave propagation in complex 3D models containing intrusionsThis paper presents an original algorithm for the simulation of seismic waves in models containing geological formations with complex properties such as anisotropy, attenuation, and small-scale inhomogeneities. Each of these structures requires special treatment: either small grid steps or computationally intense models and algorithms. These formations typically take as little as 25% of the model; thus computationally expensive approaches are only used locally, while more efficient algorithms are applied elsewhere. The designed hybrid algorithm is heterogeneous; the main focus of this research is the development of an efficient parallel implementation via domain decomposition.","Using dynamic multi-swarm particle swarm optimizer to improve the image sparse decomposition based on matching pursuitIn this paper, with projection value being considered as fitness value, the Dynamic Multi-Swarm Particle Swarm Optimizer (DMS-PSO) is applied to improve the best atom searching problem in the Sparse Decomposition of image based on the Matching Pursuit (MP) algorithm. Furthermore, Discrete Coefficient Mutation (DCM) strategy is introduced to enhance the local searching ability of DMS-PSO in the MP approach over the anisotropic atom dictionary. Experimental results indicate the superiority of DMS-PSO with DCM strategy in contrast with other popular versions of PSO.","Faster Query Execution for Partitioned RDF Data ","What is age's affect in collaborative learning environments?In educational environments, the learners' affective state is the subject of continuous research that seeks to create the most effective learning environment. This state has been shown to have a direct correlation on the learners' motivation and engagement, subsequently affecting their success or failure. This is consistent for both physical and virtual educational settings. In intelligent tutoring systems, embodied pedagogical agents have been used for the many benefits they provide including their affective influence. The agents are designed based on specific criterion including competency, gender, ethnicity or behavioural tendencies, to optimise their effect on a targeted audience. We developed a web-based collaborative learning application that supports simultaneous learner-to-virtual agent and learner-to-learner interactions. We conducted a study that investigated the influence of virtual agents' physical characteristics (attributes), specifically age, on learners' experience and its' influence on learning outcome. The results revealed that the age of virtual agents is an important factor that must be considered in virtual tutor design.","Dynamic model and sliding adaptive control of a chinese medicine sugar precipitation processA model dedicated to Chinese medicine sugar precipitation was designed, without consideration of crystal size distribution. Sliding mode adaptive control algorithm was proposed for the uncertain nonlinear systems based on Lyapunov's stability theory. The system was divided into nominal model and lumped disturbance term which embodies model mismatch, parameter uncertainties, and disturbances. Adaptive control was adopted to approach the uncertain input coefficients of system, robust control was introduced to reduce the lumped disturbance to a small bound in finite time, and sliding mode control was adopted to eliminate the tracking errors of the uncertain nonlinear system ultimately. The scheme is robust for the uncertainties and overcomes the chattering in the input of sliding mode control. It was applied to the precipitation control of sucrose-glucose mixed solution, and the validity of the proposed algorithm was supported by simulation results.","Towards verifying voter privacy through unlinkabilityThe increasing official use of security protocols for electronic voting deepens the need for their trustworthiness, hence for their formal verification. The impossibility of linking a voter to her vote, often called voter privacy or ballot secrecy, is the core property of many such protocols. Most existing work relies on equivalence statements in cryptographic extensions of process calculi. This paper provides the first theorem-proving based verification of voter privacy and overcomes some of the limitations inherent to process calculi-based analysis. Unlinkability between two pieces of information is specified as an extension to the Inductive Method for security protocol verification in Isabelle/HOL. New message operators for association extraction and synthesis are defined. Proving voter privacy demanded substantial effort and provided novel insights into both electronic voting protocols themselves and the analysed security goals. The central proof elements are described and shown to be reusable for different protocols with minimal interaction.","Video Quality Prediction over Wireless 4GIn this paper, we study the problem of video quality predic- tion over the wireless 4G network. Video transmission data is collected from a real 4G SCM testbed for investigating factors that affect video quality. After feature transformation and selection on video and network parameters, video quality is predicted by solving as regression problem. Experimental results show that the dominated factor on video quality is the channel attenuation and video quality can be well estimated by our models with small errors.","Creating GPU-Enabled Agent-Based Simulations Using a PDES Tool ","Human Action Search Based on Dynamic Shape VolumesIn this paper, an interactive system for human action video search is developed based on the dynamic shape volumes. The user is allowed to create a search query by freely and continuously posing any number of actions in front of the Kinect sensor. For the captured query video sequence and each data stream of the human action video database, we extracted useful shape properties on the basis of space-time volumes by exploiting the solution to the Poisson equation. Different from con- ventional learning-based human action recognition techniques, we apply approximate string matching (ASM) to achieve local alignment for the matching of two video sequences. The experiments demonstrate the ef- fectiveness of our system in support of the user's search task.","Personality and attitudes as predictors of risky driving behavior: evidence from beijing driversThe main aim of this study is to explore the relationships between personality traits, attitudes and risky driving behavior, in order to build a model of risky driving behavior that integrates the personality and social cognition approach. The study was based on a self-completion questionnaire survey carried out among 233 drivers in Beijing. The self-completion questionnaire consisted three sections: personality, attitudes towards traffic safety, and risky driving behavior. The results suggest that personality traits are valuable predictors of attitudes and risky driving behavior, and attitudes mediated the relation between the personality traits and risky driving behavior. Implications for road safety strategies are also discussed.","StdTrip+K: Design Rationale in the RDB-to-RDF ProcessThe design rationale behind the triplification of a relational database is a valuable information source, especially for the process of interlinking published triplesets. Indeed, studies show that the arbitrary use of the owl:sameAs property, without carrying context information regarding the triplesets to be linked, has jeopardized the reuse of the triplesets. This article therefore proposes the StdTrip+K process that integrates a design rationale approach with a triplification strategy. The process supports the reuse of standard RDF vocabularies recommended by W3C for publishing datasets and automatically collects the entire rationale behind the ontology design, using a specific vocabulary called Kuaba+W.","Guardian: Hypervisor as Security Foothold for Personal ComputersPersonal computers lack of a security foothold to allow the end-users to protect their systems or to mitigate the damage. Existing candidates either rely on a large Trusted Computing Base (TCB) or are too costly to widely deploy for commodity use. To fill this gap, we propose a hypervisor-based security foothold, named as Guardian, for commodity personal computers. We innovate a bootup and shutdown mechanism to achieve both integrity and availability of Guardian. We also propose two security utilities based on Guardian. One is a device mon- itor which detects malicious manipulation on camera and network adaptors. The other is hyper-firewall whereby Guardian expects incoming and outgoing network packets based on policies specified by the user. We have implemented Guardian (\u2248 25K SLOC) and the two utilities (\u2248 2.1K SLOC) on a PC with an Intel pro- cessor. Our experiments show that Guardian is practical and incurs insignificant overhead to the system.","The Role of Guanxi in Information Technology Enabled Organizations: A Structuration Theory Perspective ","BTW 2013 \u2013 Zwischen wissenschaftlicher Geschichte und moderner Herausforderung: 15. GI-Fachtagung Datenbanken: Business, Technology und Web 2013 ","Multi-level Autonomic Business Process ManagementThe final publication is available at Springer via  http://dx.doi.org/10.1007/978-3-642-38484-4_14","A Relative Feature Selection Algorithm for Graph Classification ","Hearing versus Seeing Identical TwinsIdentical twins pose a great challenge to face recognition systems due to their similar appearance. Nevertheless, even though twins may look alike, we believe they speak differently. Hence we propose to use their voice patterns to distinguish between twins. Voice is a natural signal to produce, and it is a combination of physiological and behavioral biometrics, therefore it is suitable for twin verification. In this paper, we collect an audio-visual database from 39 pairs of identical twins. Three types of typical voice features are investigated, including Pitch, Linear Prediction Coefficients LPC and Mel Frequency Cepstral Coefficients MFCC. For each type of voice feature, we use Gaussian Mixture Model to model the voice spectral distribution of each subject, and then employ the likelihood ratio of the probe belonging to different classes for verification. The experimental results on this database demonstrate a significant improvement by using voice over facial appearance to distinguish between identical twins. Furthermore, we show that by fusion both types of biometrics, recognition accuracy can be improved.","The design of SREE: a prototype potential ambiguity finder for requirements specifications and lessons learned[Context and Motivation] Many a tool for finding ambiguities in natural language (NL) requirements specifications (RSs) is based on a parser and a parts-of-speech identifier, which are inherently imperfect on real NL text. Therefore, any such tool inherently has less than 100% recall. Consequently, running such a tool on a NL RS for a highly critical system does not eliminate the need for a complete manual search for ambiguity in the RS. [Question/Problem] Can an ambiguity-finding tool (AFT) be built that has 100% recall on the types of ambiguities that are in the AFT's scope such that a manual search in an RS for ambiguities outside the AFT's scope is significantly easier than a manual search of the RS for all ambiguities? [Principal Ideas/Results] This paper presents the design of a prototype AFT, SREE (Systemized Requirements Engineering Environment), whose goal is achieving a 100% recall rate for the ambiguities in its scope, even at the cost of a precision rate of less than 100%. The ambiguities that SREE searches for by lexical analysis are the ones whose keyword indicators are found in SREE's ambiguity-indicator corpus that was constructed based on studies of several industrial strength RSs. SREE was run on two of these industrial strength RSs, and the time to do a completely manual search of these RSs is compared to the time to reject the false positives in SREE's output plus the time to do a manual search of these RSs for only ambiguities not in SREE's scope. [Contribution] SREE does not achieve its goals. However, the time comparison shows that the approach to divide ambiguity finding between an AFT with 100% recall for some types of ambiguity and a manual search for only the other types of ambiguity is promising enough to justify more work to improve the implementation of the approach. Some specific improvement suggestions are offered.","Collaboration Is Smart: Smart Learning CommunitiesTechnological advances in the last decades have significantly influenced education. Smart Learning Environments (SLEs) could be one solution to meet the needs of the 21 st century. In particular, we argue that smart collaboration is one fundamental need. This paper deals with the question what 'smart' is and why a SLE's design has to consider collaboration. Drawing on various theories, we argue that the community aspect plays a vital role in successful learning and problem solving. This paper outlines the benefits for the community and all parties involved (defined as a win-for-all or win n -solution), as well as drivers that might influence collaboration. Design principles for SLEs, Smart Learning Communities (SLCs) and finally the conclusion close the paper.","Comprehensive Uncertainty Management in MDPsMultistage decision-making in robots involved in real-world tasks is a process affected by uncertainty. The effects of the agent's ac- tions in a physical environment cannot be always predicted determin- istically and in a precise manner. Moreover, observing the environment can be a too onerous for a robot, hence not continuos. Markov Deci- sion Processes (MDPs) are a well-known solution inspired to the classic probabilistic approach for managing uncertainty. On the other hand, including fuzzy logics and possibility theory has widened uncertainty representation. Probability, possibility, fuzzy logics, and epistemic belief allow treating different and not always superimposable facets of uncer- tainty. This paper presents a new extended version of MDP, designed for managing all these kinds of uncertainty together to describe transi- tions between multi-valued fuzzy states. The motivation of this work is the design of robots that can be used to make decisions over time in an unpredictable environment. The model is described in detail along with its computational solution.","Methodology and Information System for Evaluating Environmental Protection Expenditure Efficiency at the Local LevelThe paper presents a methodology and information system for#N#evaluating the efficiency of current municipal environmental#N#protection expenditures. The methodology and information system#N#were approved by the Ministry of the Environment of the Czech#N#Republic as a voluntary tool for municipal officials. The#N#proposed methodological procedure for evaluating municipal#N#environmental protection expenditures is based on a weighted#N#assessment of multiple criteria. The procedure gives#N#municipalities an instrument for assessing expenditure#N#efficiency and addresses the three pillars of sustainable#N#development: economic development, social development, and#N#environmental protection. The methodology and information#N#system can be used by other countries and municipalities to#N#evaluate the efficiency of public spending at the local level.","'P.S.(Postscript)': Hearing of Your Heartstring\" 'P.S.': Hearing of your Heartstring \" is the interactive installation creating collaborative sound with users' voices. Through this artwork 'P.S.', we want to ease the people who have a huge wave of nostalgia because of remaining words in mind and sympathize with each other's nostalgia through hearing their voices carefully.","Quantized Local Edge Distribution: A Descriptor for B-mode Ultrasound Images ","GPS Estimation from Users\u2019 PhotosNowadays social media are very popular for people to share their photos with their friends. Many of the photos are geo-tagged (with GPS information) whether automatically or manually. Social media management websites such as Flickr allow users manually labeling their uploaded photos with GPS with the interface of dragging them into the map. However, manually dragging the photos to the map will bring more error and very boring for users to labeling their photos. Thus in this paper, a GPS location estimation approach is proposed. For an uploaded image, its GPS information is estimated by both hierarchical global feature classification and local feature refinement to guarantee the accuracy and computational cost. To guarantee the estimation performances, k-nearest neighbors are selected in global feature classification stage. Experiments show the effectiveness of our proposed approach.","Why Is It That the Different University Specialties in General and Engineering More Specifically Are Not Mentioned When Talking about Medical Work and HealthHow is it possible that when talking about technological de- velopments in surgery and specifically in endovascular surgery no one thinks that without the other sciences: engineers, physicists, ITs etc, we wouldnt have the evolution we have now? Why is medicine separated from the rest of the campus and the society, when its the only business that affects 100% of the people on this planet? And in addition considering that the economical aspect has more than ever a starring role? Remember: we are more than twice the population we were 50 years ago on the planet; therefore no one can be invisible in health.","Large-Scale Experiments for Mathematical Document Classification ","Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence (1993)This is the Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence, which was held in Washington, DC, July 9-11, 1993","Efficient Attack Detection Based on a Compressed Model ","A New Model for Product Adoption over Social NetworksBuilding upon the observation that individuals' decisions to purchase a product are influenced by recommendations from their friends as well as their own preferences, in our work, we propose a new model that factors in people's preferences for a product and the number of his/her neighbors that have adopted this product. In our model, as in related ones, beginning with an \"active\" seed set (adopters), an adoption action diffuses in a cascade fashion based on a stochastic rule. We demonstrate that under this model, maximizing individuals' adoption of a product, called the product adoption maximization (PAM) problem, is NP-hard, and the objective function for product adoption is sub-modular for time T (T = 1, 2) when the function for estimating the influence coming from neighbors is sub-linear. Hence, a natural greedy algorithm guarantees an approximation. Furthermore, we show that it is hard to approximate the PAM problem when the function for estimating the influence coming from neighbors is not sub-linear.","Equilibria of online scheduling algorithmsWe describe a model for competitive online scheduling algorithms. Two servers, each with a single observable queue, compete for customers. Upon arrival, each customer strategically chooses the queue with minimal expected wait time. Each scheduler wishes to maximize its number of customers, and can strategically select which scheduling algorithm, such as First-Come-First-Served (FCFS), to use for its queue. This induces a game played by the servers and the customers.#R##N##R##N#We consider a non-Bayesian setting, where servers and customers play to maximize worst-case payoffs. We show that there is a unique subgame perfect safety-level equilibrium and we describe the associated scheduling algorithm (which is not FCFS). The uniqueness result holds for both randomized and deterministic algorithms, with a different equilibrium algorithm in each case.#R##N##R##N#When the goal of the servers is to minimize competitive ratio, we prove that it is an equilibrium for each server to apply FCFS: each server obtains the optimal competitive ratio of 2.","Classification Systems, their Digitization and Consequences for Data-Driven Decision Making: Understanding Representational QualityClassification systems are foundational in many standardized software tools. This digitization of classification systems gives them a new 'materiality' that, jointly with the social practices of information producers/consumers, has significant consequences on the representational quality of such information systems. Based on a multi-site field study, we suggest that representational quality is achieved through four types of negotiations that human actors engage in when confronted with the materiality of a new IS. These negotiations are associated with three broad practices (instantiation, renarration and meta-narration), and three different information production / consumption situations. We contribute to the relational theorization of representational quality and extend classification systems research by drawing explicit attention to the importance of 'materialization' of classification systems and the foundational role of representational quality in understanding the success and consequences of data-driven decision-making. \u00a9 (2013) by the AIS/ICIS Administrative Office All rights reserved.","Modified Binary Pattern for Finger Vein Recognition ","Feature and Future of Visual Cryptography Based SchemesVisual cryptography (VC) is a useful technique that combines the notions of perfect ciphers and secret sharing in cryptography. VC takes a binary image (the secret) and divides it into two or more pieces known as shares. When the shares are printed on transparencies and then superimposed, the secret can be recovered. No computer participation is required. There are various measures on which performance of visual cryptography scheme depends, such as pixel expansion, contrast, security, accuracy, computational complexity, share generated is meaningful or meaningless, type of secret images (either binary or color) and number of secret images(either single or multiple) encrypted by the scheme. In this paper, we will summarize the developments of visual cryptography since its birth in 1994, introduce the main research topics in this area where researchers have been contributing and outline the application of these schemes.","Designing a Service Innovation Measurement of SMEs ","Knowledge Integration in Problem Solving Processes ","From multicultural agents to culture-aware robotsIn our work on developing multicultural agents we have primarily relied on the analysis of video recordings of multimodal face to face interactions between humans, where the videos have been collected in different cultures. This posed some questions concering the cultural biases of the analysis due to the cultural background of the annotators. For the development of culture-aware robots we have now adopted a strategy that takes this cultural bias into account as a feature of the development process by integrating the potential user groups from different cultures into this process. We exemplify this approach with a case study on affective body movements for a humanoid robot.","K-Centroids-Based Supervised Classification of Texture Images Using the SIRV Modeling ","Average Optimal String Matching in Packed Strings ","Flame Classification through the Use of an Artificial Neural Network Trained with a Genetic Algorithm ","Evaluation of Endoscopic Image Enhancement for Feature Tracking: A New Validation FrameworkFeature tracking for endoscopic images is a critical compo- nent for image guided applications in minimally invasive surgery. Recent work in this field has shown success in acquiring tissue deformation, but it still faces issues. In particular, it often requires expensive algorithms to filter outliers. In this paper, we firstly propose two real-time pre-processes based on image filtering, to improve feature tracking robustness and thus reduce outlier percentage. However the performance evaluation of detec- tion and tracking algorithms on endoscopic images is still difficult and not standardized, due to the difficulty of ground truth data acquisition. To overcome this drawback, we secondly propose a novel framework that allows to provide artificial ground truth data, and thus to evaluate detec- tion and feature tracking performances. Finally, we demonstrate, using our framework on 9 different in-vivo video sequences, that the proposed pre-processes significantly increase the tracking performance.","Embedded System Platform for Safety-Critical Road Traffic Signal ApplicationsRoad traffic signals are used to signal information to drivers (e.g., red signal to stop). A controller residing in a local cabinet is managing the traffic signal. Depending on the desired traffic situation, the corresponding traffic signal is switched on or off via the power line. For the time being, there is no programmable logic included in each traffic signal. As a result, there is a single type for each application available e.g., due to different power supply levels or light output. In addition, functionality of traffic signals is limited so that its status information cannot be retrieved.#R##N##R##N#This paper presents an approach to traffic signals for safety-critical applications based on an embedded system. It includes a presentation of safetyrelated hardware and a microcontroller with embedded safety-related firmware. The result is a platform to be used in various applications and meeting safety and performance requirements according to standard EN 50556 and VDE 0832.","Preventing Side-Channel Leaks in Web Traffic: A Formal Approach. ","Improved Sound Source Localization and Front-Back Disambiguation for Humanoid Robots with Two Ears ","Evaluating a web-based tool for crowdsourced navigation stress testsWe present a web-based tool for evaluating the information architecture of a website. The tool allows the use of crowdsourcing platforms like Amazon's MTurk as a means for recruiting test persons, and to conduct asynchronous remote navigation stress tests (cf. Instone 2000). We also report on an evaluation study which compares our tool-based crowdsourced approach to a more traditional laboratory test setting. Results of this comparison indicate that although there are interesting differences between the two testing approaches, both lead to similar test results.","Privacy-Preserving User Data Oriented Services for Groups with Dynamic Participation ","Enhanced Block Playfair CipherIn this paper we will enhance the traditional Blick Playfair Cipher by encrypting the plaintext in blocks. For each block the keyword would be the same but the matrix will shift by some random value. As a result of which the diagram analysis would be very difficult which is done in the traditional Playfair Cipher to obtain the plaintext from the cipher text. The shift value will be generated using random algorithm which is very secure. Playfair Cipher method, based on polyalphabetic cipher is relatively easy to break because it still leaves much of the structure and a few hundred of letters of cipher text are sufficient. To add to its security and to make it more usable we are using 6x6 matrix instead of 5x5 which will be able to cover 26 alphabets in English and ten numerals i.e. from 0 to 9. This 6x6 matrix eliminate the case of putting of 2 alphabets (I and J) together in the matrix as it was in the 5x5 matrix. In this approach plaintext as well as key can be numeral, alphabetic or combination of both and a random number will shift the matrix every time.","Web Spam Detection Using MapReduce Approach to Collective Classification ","Real time patient flow management using business process management, location tags, and complex events processingHospitals in North America are operating at near full or full capacity. Ageing populations are further increasing patients' inflows. These trends manifest themselves in continuously increasing patients wait time that can reach 20 hours at emergency departments [1]. Excessive wait time is both costly to patients and hospitals, increases risks to patients, and in many cases, is in conflict with medical guidelines standards.","Monitoring and Predicting Journalistic ProfilesThe paper develops a pilot study aiming at finding a methodology for identifying features of journalistic writing profiles. The study is based on capturing dominant discursive tonalities, knowing that journalistic discourse entails public legitimacy. We made use of a series of natural language processing tools as preliminary steps in revealing three egocentric journalistic identities. Based on quantitative analysis, such as syntactic and lexical-semantic, we put in evidence qualitative pragmatic aspects. The final goal of this study is to configure a tool for automatic analysis of journalistic profiles. We have concentrated on three top Romanian journalists, whose newspaper publications have been monitored over a period of three months and semi-automatically analyzed. As a result, a database with their profiles is collected and interpreted. Such a tool could be of interest to mass-media, but also to specialists in communication and public relations, to political parties and to the public opinion, in general.","Self-stabilizing consensus average algorithm in distributed sensor networksOne important issue in sensor networks that has received renewed interest recently is average consensus, i.e., computing the average of n sensor measurements, where nodes iteratively exchange data with their neighbors and update their own data accordingly until reaching convergence to the right parameters estimate. In this paper, we introduce an efficient self-stabilizing algorithm to achieve/ensure the convergence of node states to the average of the initial measurements of the network. We prove that the convergence of the fusion process is finite and express an upper bound of the actual number of moves/iterations required by the algorithm. This means that our algorithm is guaranteed to reach a stable situation where no load will be sent from one sensor node to another. We also prove that the load difference between any two sensor nodes in the network is within $\\frac{\\varepsilon}{D}\\times\\left\\lfloor\\frac{D+1}{2}\\right\\rfloor&lt;\\varepsilon,$ where e is the prescribed global equilibrium threshold (this threshold is given by the system) and D is the diameter of the network.","The Virtual Reality Applied in Construction Machinery Industry ","Obsolescence Management of Commercial-Off-The-Shelf (COTS) in Defence SystemsAbout 70% of a system life-cycle cost is during the operations phase. Support activities, including maintenance, upgrades and repairs, are high cost items. In the past decade, performance-based contracting has become a standard agreement between the OEM and the customer that defines a fixed price for a guaranteed level of system performance over a given period of time. This puts the risks associated with support cost with the supplier. A means of cost reduction in the support phase is the use of Commercial-Off-The-Shelf (COST) components. One of the issues with COTS however is obsolescence. The life of a COTS com-ponent is usually much shorter than the life of a defence system. This paper dis-cusses a number of issues associated with the incorporation of COTS components in defence systems, their support and obsolescence management.","Evaluation of Class Binarization and Feature Selection in Tear Film Classification using TOPSIS ","Die Kontrollpflicht nach \u00a7 11 Abs. 2 Satz 4 BDSG im Zeitalter des Cloud ComputingAlternativen zur Vor-Ort-Kontrolle des Auftragnehmers durch den Auftraggeber Nutzt ein Unternehmen etwa fur die Verwaltung von Kunden- bzw. Mitarbeiterdaten einen Cloud Computing Service, so handelt es sich in der Regel um eine Auftragsdatenverarbeitung nach \u00a7 11 BDSG. Das Unternehmen ist als Auftraggeber dazu verpflichtet den Auftragnehmer vor Beginn der Datenverarbeitung und sodann regelmasig im Hinblick auf die Einhaltung der beim Auftragnehmer getroffenen technischen und organisatorischen Masnahmen zu kontrollieren und das Ergebnis zu dokumentieren. Eine Vor-Ort-Kontrolle scheint im Zeitalter des Cloud Computing nicht realistisch umsetzbar. Dieser Aufsatz beschaftigt sich daher mit Alternativen zur Vor-Ort-Kontrolle.","JT2FISA Java Type-2 Fuzzy Inference Systems Class Library for Building Object-Oriented Intelligent Applications ","A Method for Estimating Patient Specific Parameters for Simulation of Tissue Deformation by Finite Element AnalysisThis paper proposes a method for estimating patient-specific material parameters used in the finite element analysis which simulates soft tissue deformation. The estimation of suitable material parameters for a patient is important for a navigation system for endoscopic surgery. At first, many data of soft tissue deformation are generated by chang- ing the material parameters. Next, using Principle Component Analy- sis, each data with high dimensional is converted into the lower vector. The relationship between the material parameter and the deformation is found in the lower potential space.","Experiences by using AFFINE for building collaborative applications for online communitiesContinuous problems and deficits in developing complex and ever-changing (software) systems led to agile methods, e.g. Scrum. Nevertheless, the problem of considering a plethora of different functional as well as nonfunctional requirements (N/FRs) remains unsolved and gains in importance when engineering state-of-the-art software. The current tide of approaches aims at handling every single NFR by an individual process integrated into Scrum, yielding a process complexity which can not be handled properly. Scrum-based AFFINE was designed explicitly to provide an alternative solution to over-complex design- and development-processes and still considering all kinds of NFRs early enough in the process. In this paper, we discuss collected findings by using AFFINE in various projects dealing with the development of software for user-centered online communities towards some evidence of its suitability.","Cherry: mobile application for children with cancer.The Cherry project seeks to address the information needs of young cancer patients, their parents, and health care providers. It aims at helping the patients to understand various aspects of their  ...","Impact of Variable Privatization on Extracting Synchronization-Free Slices for Multi-core Computers ","Weighting Component Models by Predicting from Data Streams Using Ensembles of Genetic Fuzzy SystemsOur recently proposed method to predict from a data stream of real estate sales transactions based on ensembles of genetic fuzzy systems was extended to include weighting component models. The method consists in incremental expanding an ensemble by models built over successive chunks of a data stream. The predicted prices of residential premises computed by aged component models for current data are updated according to a trend function reflecting the changes of the market. The impact of different techniques of weighting component models on the accuracy of an ensemble was compared in the paper. Three techniques of weighting component models were proposed: proportional to their estimated accuracy, time of ageing, and dependent on property market fluctuations.","An Exploration of Collaboration over Time in Collective Crisis Response during the Haiti 2010 Earthquake ","Community Detection in Protein-Protein Interaction Networks Using Spectral and Graph Approaches ","Quantitative Performance Measures for Dynamic Optimization ProblemsMeasuring the performance of algorithms over dynamic optimization problems (DOPs) presents some important differences when compared to static ones. One of the main problems is the loss of solution quality as the optimization process advances in time. The objective i nD OPs is in tracking the optima as the landscape changes; however, it is possible that the algorithm gets progressively fur- ther from the optimum after some changes happened. The main goal of this chapter is to present some difficulties that may appear while reporting the results on DOPs, and introduce two new performance tools to overcome these problems. We propose a measure based on linear regression to measure fitness performance degradation, and analyze our results on the moving peaks problem, using several measures existing in the literature as well as our performance performance degradation measure. We also propose a second measure based on the area below the curve defined by some population attribute at each generation (e.g., the best-of-generation fitness), which is analyzed in order to see how it can help in understanding the algorithmic search behavior.","Adjusting to increasing product management problems: challenges and improvement proposals in one software company[Context and motivation] This paper seeks to understand the essential product management challenges that one software product company has recently started to face. [Question/problem] The paper illustrates how the case company, Maestro, has been forced to adjust its management style due to the increasingly complex and turbulent business environment. The paper further illustrates how the evolving management style has affected the way product requirements are managed. [Principal ideas/results] The comparison of our results with existing product management literature suggests that traditional product management approaches are becoming increasingly inadequate to deal with growing amounts of interpretations, requirements interdependencies and market turbulence. [Contribution] The findings of this paper indicate a need for examining literature from management and organizational sciences in order to expand the traditional view of requirements models as static and purely design-time entities towards new kinds of approaches that are more effective in dealing with complexity and turbulence. The paper eventually results with an identification of research gaps and important topics for future research.","IT Governance in Higher Education Institutions in Abu Dhabi, UAEWith IT affecting all aspects of university's/school's academic and professional affairs, an efficient IT governance ITG is required to assure that all kinds of expensive and complex information technology is appropriately governed. Despite the importance of IT; there has been limited research looking at how ITG is implemented in higher education institution or how to harness its benefits. This research focuses on how ITG is adopted and implemented in higher education institutions in UAE by considering the case of two different universities. The research proposes a theoretical framework derived from COBIT and Six Sigma to help in governing IT in higher education institutions. The framework will help in directing different processes toward evaluating any decision concerning the alignment and compatibility of IT with the overall strategies and goals of higher education institutions. This is achieved to increase services quality over time, aligning and supporting business strategies, and controlling and minimizing IT risks in order to increase stakeholder's value and reducing cost.","Intrusion Detection with Hypergraph-Based Attack ModelsIn numerous security scenarios, given a sequence of logged activities, it is necessary to look for all subsequences that represent an intrusion, which can be meant as any \"improper\" use of a system, an attempt to damage parts of it, to gather protected information, to follow \"paths\" that do not comply with security rules, etc. In this paper we propose an hypergraph-based attack model for intrusion detection. The model allows the specification of various kinds of constraints on possible attacks and provides a high degree of flexibility in representing many different security scenarios. Besides discussing the main features of the model, we study the problems of checking the consistency of attack models and detecting attack instances in sequences of logged activities.","A Proposal of the New System Model for Nursing Skill Learning Based on Cognition and Technique ","Perceptual Comparison of Demosaicing Algorithms and In-camera Demosaicing with JPEG CompressionColor image acquisition in digital cameras is often performed by using CCD or CMOS sensor chips with a color filter array on the top of a single monochromatic sensor. In this paper, a perceptual comparison is per- formed among three well known demosaicing algorithms plus in-camera demosaicing with lossy compression JPEG, by means of subjective tests, that is with the help of human beings. The novelty of the approach is that chosen algorithms have been selected as representative of those used in commercial raw image converters used by professionals in graphics and that the test has been performed on a large number of people, achieving results only partially similar to the results got by means of computed metrics. The results show that in the greatest part of conditions and for non particularly expert users, the capability of the most advanced demosaic- ing algorithms of producing an almost perfect reconstruction on the full-color image is not strictly required. Only for selected categories of images it is possible to find a clear winner among the algorithms","Towards Engineering Trust-Aware Future Internet Systems ","Observing Linked Data DynamicsIn this paper, we present the design and first results of theDy- namic Linked Data Observatory: a long-term experiment to monitor the two-hop neighbourhood of a core set of eighty thousand diverse Linked Data documents on a weekly basis. We present the methodology used for sampling the URIs to monitor, retrieving the documents, and further crawling part of the two-hop neighbourhood. Having now run this exper- iment for six months, we analyse the dynamics of the monitored docu- ments over the data collected thus far. We look at the estimated lifespan of the core documents, how often they go on-line or off-line, how often they change; we further investigate domain-level trends. Next we look at changes within the RDF content of the core documents across the weekly snapshots, examining the elements (i.e., triples, subjects, predicates, ob- jects, classes) that are most frequently added or removed. Thereafter, we look at how the links between dereferenceable documents evolves over time in the two-hop neighbourhood.","A Hybrid Approach for Business Environment-Aware Management of Service-Based Business Processes ","The Influence of the Nature of Need for Touch, Handcraft Material and Material Color on the Motivation for TouchThe main purpose of this research is to investigate the effect of user characteristic - the need for touch (NFT), handcraft materials and material col- ors on motivation of touch and preference. A total of 70 subjects were recruited in the study. In addition to the NFT level (high score group and low score group) was evaluated, handcraft materials (wood, glass, pottery, plastic and metal) and material colors (red and yellow) were studied in the experiment. The dependent variables including the willingness of touch, preference and 16 pairs of opposite adjectives for sense of sight were measured by questionnaire inter- view. The study results showed that the effect of NFT affect significantly willingness of touch (p&lt;0.001), preference (p&lt;0.01) and the sense of warm-cold (p&lt;0.05). All measures were affected significantly by handcraft material effect (p&lt;0.05). On the other hand, 11 pairs of opposite adjectives are affected signifi- cantly by material color factor. The results of regression equations showed that the willingness of touch was mainly affected by subjective preference. Moreo- ver, the subjective preference was mainly affected by the rating of beauty for product. Therefore, the subjective preference increased for a product was fol- lowed the rating of beauty and then the willing of touch was increased. The findings of this study can give an insight into the motivation of touch, and further provide some guidelines and recommendations about the product design and selling method to increase the competitive advantage of product.","TOWARDS ACTIVE LINGUISTIC AUTHENTICATIONBiometric technologies offer a new and effective means for securing com- puters against unauthorized access. Linguistic technologies and, in par- ticular, authorship attribution technologies can assist in this effort. This paper reports on the results of analyzing a novel corpus that was devel- oped to test the possibility of active linguistic authentication. The study collected the one-week work product of nineteen temporary workers in a simulated office environment. The results demonstrate that techniques culled from the field of authorship attribution can identify workers with more than 90% accuracy.","Anomaly Detection Using Cooperative Fuzzy Logic Controller ","Semantic-based Anomalous Pattern Discovery in Moving Object TrajectoriesIn this work, we investigate a novel semantic approach for pattern discovery in trajectories that, relying on ontologies, enhances object movement information with event semantics. The approach can be applied to the detection of movement patterns and behaviors whenever the semantics of events occurring along the trajectory is, explicitly or implicitly, available. In particular, we tested it against an exacting case scenario in maritime surveillance, i.e., the discovery of suspicious container transportations. #R##N#The methodology we have developed entails the formalization of the application domain through a domain ontology, extending the Moving Object Ontology (MOO) described in this paper. Afterwards, movement patterns have to be formalized, either as Description Logic (DL) axioms or queries, enabling the retrieval of the trajectories that follow the patterns. #R##N#In our experimental evaluation, we have considered a real world dataset of 18 Million of container events describing the deed undertaken in a port to accomplish the shipping (e.g., loading on a vessel, export operation). Leveraging events, we have reconstructed almost 300 thousand container trajectories referring to 50 thousand containers travelling along three years. We have formalized the anomalous itinerary patterns as DL axioms, testing different ontology APIs and DL reasoners to retrieve the suspicious transportations. #R##N#Our experiments demonstrate that the approach is feasible and efficient. In particular, the joint use of Pellet and SPARQL-DL enables to detect the trajectories following a given pattern in a reasonable time with big size datasets.","Model-guided placement of cerebral ventricular cathetersPurpose: Freehand placement of external ventricular drainage is not sufficiently accurate and precise. In the absence of high quality pre-operative 3D images, we propose the use of an average model for guidance of ventricular catheters. Methods: The model was segmented to extract the ventricles and registered to five normal volunteers using a combination of landmark based and surface based registration. The proposed method was validated by comparing the use of the average model to the use of volunteer-specific images. Results: The position and orientation of the ventricles were compared and the distances between the target points at the left and right foramen of Monroe were computed (Mean\u00b1std: 5.65\u00b11.60mm and 6.05\u00b11.34mm for the left and right side respectively). Conclusions: Although an average model for guidance of a surgical procedure has a number of limitations, our initial experiments show that the use of a model might provide sufficient guidance for determination of the angle of insertion. Future work will include further clinical testing and possible refinement of the model.","Streaming Model Transformations: Scenarios, Challenges and Initial SolutionsSeveral styles of model transformations are well-known and widely used, such as batch, live, incremental and lazy transformations. While they permit tackling advanced scenarios, some applications deal with models that are only available as a possibly infinite stream of ele- ments. Hence, in streaming transformations, source model elements are continuously produced by some process, or very large models are frag- mented and fed into the transformation engine. This poses a series of issues that cannot be tackled using current transformation engines. In this paper we motivate the applicability of this kind of transformations, explore the elements involved, and review several strategies to deal with them. We also propose a concrete approach, built on top of the Eclectic transformation tool.","Representation and Querying of Valid Time of Triples in Linked Geospatial Data ","Contextual Sentiment Analysis in Social Media Using High-Coverage LexiconAutomatically generated sentiment lexicons offer sentiment information for a large number of terms and often at a more granular level than manually gen- erated ones. While such rich information has the potential of enhancing sentiment analysis,italsopresentsthechallengeoffindingthebestpossiblestrategytoutilising the information. In SentiWordNet, negation terms and lexical valence shifters (i.e. intensifier and diminisher terms) are associated with sentiment scores. Therefore, such terms could either be treated as sentiment-bearing using the scores offered by the lexicon, or as sentiment modifiers that influence the scores assigned to adjacent terms. In this paper, we investigate the suitability of both these approaches applied to sentiment classification. Further, we explore the role of non-lexical modifiers com- mon to social media and introduce a sentiment score aggregation strategy named SmartSA. Evaluation on three social media datasets show that the strategy is effec- tive and outperform the baseline of using aggregate-and-average approach.","Cloud Computing in Healthcare \u2013 a Literature Review on Current State of Research ","Data Warehouse Architecture and Quality: Impact and Open ChallengesThe CAiSE 98 paper \u201cArchitecture and Quality in Data Warehouses\u201d and its ex-panded journal version (Jarke et al. 1999) was the first to add a Zachman-like(Zachman 1987) explicit conceptual enterpri ...","Error Correction of Partially Exposed RSA Private Keys from MSB SideThe most popular public key cryptosystem to date has been RSA, whose security primarily relies on the unfeasibility of factoring the modulus, which is a product of two large primes, and on the secrecy of certain RSA parameters. In 2009, the cold-boot attack by Halderman et al presented an important cryptanalytic model where a portion of the secret parameters may be exposed. In this direction, Heninger and Shacham Crypto 2009 introduced the problem of reconstructing RSA private keys when few random bits from each are known. Later, Henecka, May and Meurer Crypto 2010 introduced the problem of error-correction in the RSA private keys when all the bits are known with some probability of error. Their approach attempted error-correction from the least significant side of the parameters. In this paper we provide a novel technique for error-correction that works from the most significant side of the parameters. Representative experimental results are provided to substantiate our claim.","Architectural slicing: towards automatic harvesting of architectural prototypesArchitectural prototyping is a widely used practice, concerned with taking architectural decisions through experiments with lightweight implementations. However, many architectural decisions are only taken when systems are already (partially) implemented. This is problematic in the context of architectural prototyping since experiments with full systems are complex and expensive and thus architectural learning is hindered. In this paper, we propose a novel technique for harvesting architectural prototypes from existing systems, \"architectural slicing\", based on dynamic program slicing. Given a system and a slicing criterion, architectural slicing produces an architectural prototype that contains the elements in the architecture that are dependent on the elements in the slicing criterion.","Stereo GrabCut: Interactive and Consistent Object Extraction for Stereo ImagesThis paper presents an interactive object extraction approach for stereo images. The extraction task on stereo images has two significant differences compared to that on monoscopic images. First, the segmentation for both images should be consistent. Second, stereo images have implicit depth information, which supplies an important cue for object extraction. In this paper, we generate consistent segmentation by putting the correspondence relationship in a graph cut framework. Besides, we leverage depth information, which is obtained by stereo matching, to give a pre-estimation of foreground and background. The pre-estimation is then used to generate accurate color models to perform a graph cut based segmentation. To simplify the user interaction, we supply an interface similar to GrabCut, which only needs the user to drag a compact rectangle in most cases. The experiments show our approach works fast and produces more satisfactory results than state-of-the-art.","Learner-Created Scenario for Investigative Learning with Web Resources ","Optimization algorithm based on biology life cycle theoryBio-inspired optimization algorithms have been widely used to solve various scientific and engineering problems. Inspired by biology life cycle, this paper presents a novel optimization algorithm called Lifecycle-based Swarm Optimization. LSO algorithm simulates biologic life cycle process through six optimization operators: chemotactic, assimilation, transposition, crossover, selection and mutation. Experiments were conducted on 7 unimodal functions. The results demonstrate remarkable performance of the LSO algorithm on those functions when compared to several successful optimization techniques.","Issues with designing dementia-friendly interfacesPeople with dementia are a rapidly growing demographic. In a world which is increasingly dependent on computing, this large group of people is be-coming technologically isolated, due to the ill-suited design of interfaces. This paper looks at the possible 'roadblocks' which need to be considered when de-signing interfaces in order to ensure they are dementia-friendly. By considering the unique needs of a person with dementia, designers can ensure that their software is accessible to this demographic, hence potentially reducing the feel-ings of technological exclusion.","Actors, Holonic Enterprises, Ontologies and Multi-agent TechnologyHolonic enterprises are considered as one of the new types of networking organizations used to increase business efficiency. But in practice it requires to introduce a new type of management stimulating the interpreneur approach, active interaction between actors within the project teams, coordinated and effective decisions on resource scheduling in case of unpredictable events new projects, breakdowns, delays, illnesses etc.. In the paper we propose the concept of holonic enterprise based on the principles of intersubjective management and describe Smart Enterprise system for supporting decision making for such types of enterprises. The system combines top-down project planning with real time on-line and bottom-up communication with employees. This provides more intelligent, flexible and efficient resource scheduling in case of unexpected events. The functionality and architecture of Smart Enterprise system based on the use of ontology and multi-agent technology is outlined. The first results of the system use and perspectives are analyzed.","Bayesian Extensions of Kernel Least Mean SquaresThe kernel least mean squares (KLMS) algorithm is a computationally efficient nonlinear adaptive filtering method that \"kernelizes\" the celebrated (linear) least mean squares algorithm. We demonstrate that the least mean squares algorithm is closely related to the Kalman filtering, and thus, the KLMS can be interpreted as an approximate Bayesian filtering method. This allows us to systematically develop extensions of the KLMS by modifying the underlying state-space and observation models. The resulting extensions introduce many desirable properties such as \"forgetting\", and the ability to learn from discrete data, while retaining the computational simplicity and time complexity of the original algorithm.","Robust and Secure Iris Recognition ","Evaluation of EPIC Model of Soil NO3-N in Irrigated and Wheat-Maize Rotation Field on the Loess Plateau of ChinaEPIC model has been evaluated and used world wide, however there is#N#                            still some disagreements on the simulation results of nitrogen cycle.#N#                            Based on field experimental data, simulation results of soil#N#                                NO3-N was evaluated and the parameter#N#                            sensitivity for simulated NO3-N was analyzed in#N#                            irrigated winter wheat / summer maize field on the Loess Plateau of#N#                            China. Results showed 1) EPIC model estimated soil#N#                                NO3-N content and its movement among#N#                            different soil layers well, with the mean RRMSE value of 0.46, for#N#                            irrigated winter wheat / summer maize cropping system in the semi-humid#N#                            region of the Loess Plateau. 2) Simulation results of soil#N#                                NO3-N was more sensitive to soil parameters,#N#                            compared with crop parameters and meteorological parameters. 3)To#N#                            improve the parameter value of BN2, HI, TB, WA, CNDS, BD and FC was#N#                            better to the EPIC model to simulate soil NO3-N#N#                            on the Loess Plateau of China.","A Depression Detection Model Based on Sentiment Analysis in Micro-blog Social NetworkDatasets originating from social networks are valuable to many fields such as sociology and psychology. But the supports from technical perspective are far from enough, and specific approaches are urgently in need. This paper applies data mining to psychology area for detecting depressed users in social network services. Firstly, a sentiment analysis method is proposed utilizing vocabulary and man-made rules to calculate the depression inclination of each micro-blog. Secondly, a depression detection model is constructed based on the proposed method and 10 features of depressed users derived from psychological research. Then 180 users and 3 kinds of classifiers are used to verify the model, whose precisions are all around 80%. Also, the significance of each feature is analyzed. Lastly, an application is developed within the proposed model for mental health monitoring online. This study is supported by some psychologists, and facilitates them in data-centric aspect in turn.","Human in the loop: a model to integrate interaction issues in complex simulationsSeveral activities of the product development process as for example ergonomic analyses, usability testing, and what is defined as User Experience - UX- design in general require humans to be involved as testers. In order to achieve a good effectiveness degree, these tests must be performed on prototypes as much as possible similar to the final product, and this is costly and sometimes difficult to obtain during the development process. This is especially true at the earliest stages of the process. Functional mock-up - FMU - methods and tools can be of great help, because they allow technological aspects of the products, as electronics, hydraulics, mechanics, etc. to be represented and managed in a simple and effective way. Mathematical equations allow product behavior to be determined, due to input values representing the application environment of the product. At the moment, an FMU model is great in simulating product behavior from the technological point of view, but concerns about user interaction issues are left apart. The research described in this paper aims at widening the coverage of FMU to user-product interaction issues. The goal aims at evaluating the possibility of substituting real users with a characterization of them, and to model and simulate interaction in a homogeneous way together with all the other product aspects. All of this makes the research activities very challenging, and the result is a sort of FMU-assisted interaction modeling. As an evolution of what is generally recognized as hardware and software-in-the-loop, this methodology will be referred as human-in-the-loop.","Performance Measurement of Parallel Vlasov Code for Space Plasma on Scalar-Type Supercomputer Systems with Large Number of Cores ","Linear Space Bootstrap Communication SchemesWe consider a system of n processes with ids not a priori known, that are drawn from a large space, potentially unbounded. How can these n processes communicate to solve a task? We show that n a priori allocated Multi-Writer Multi-Reader (MWMR) registers are both needed and sufficient to solve any read-write wait free solvable task. This contrasts with the existing possible solution borrowed from adaptive algorithms that require \u0398(n 2) MWMR registers. To obtain these results, the paper shows how the processes can non blocking emulate a system of n Single-Writer Multi-Reader (SWMR) registers on top of n MWMR registers. It is impossible to do such an emulation with n\u2009\u2212\u20091 MWMR registers. Furthermore, we want to solve a sequence of tasks (potentially infinite) that are sequentially dependent (processes need the previous task's outputs in order to proceed to the next task). A non blocking emulation might starve a process forever. By doubling the space complexity, using 2n\u2009\u2212\u20091 rather than just n registers, the computation is wait free rather than non blocking.","Rainfall forecasting based on ensemble empirical mode decomposition and neural networksIn this paper a methodology for rainfall forecasting is presented, using the principle of decomposition and ensemble. In the proposed framework, the employed decomposition technique is the Ensemble Empirical Mode Decomposition (EEMD), which divides the original data into a set of simple components. Each component is modeled with a Feed Forward Neural Network (FNN) as a forecasting tool. Finally, the individual forecasting results for all components are combined to obtain the prediction result of the input signal. Experiments were performed on a real-observed rainfall data, and the attained results were compared against a single FNN model for the raw data, showing an improvement on the system performance.","Optimal Joint Sensing Threshold and Sub-channel Power Allocation in Multi-channel Cognitive RadioAn optimal joint sensing threshold and sub-band power allocation is proposed for multi-channel cognitive radio (CR) system by formulating a mixed-variable optimization problem to maximize the total throughput of the CR while constraining the total interference to the PU, the total power of the CR, and the probabilities of false alarm and detection of each sub-channel. Based on the bi-level optimization method, the proposed optimization problem is divided into two single-variable convex optimization sub-problems: the upper level for threshold optimization and the lower level for power optimization. The simulation results show that the proposed joint optimization can achieve desira- ble improvement on the throughput with different sub-channel gains.","Localization for a system of colliding robotsWe study the localization problem in the ring: a collection of n anonymous mobile robots are deployed in a continuous ring of perimeter one. All robots start moving at the same time along the ring with arbitrary velocity, starting in clockwise or counterclockwise direction around the ring. The robots bounce against each other when they meet. The task of each robot is to find out, in finite time, the initial position and the initial velocity of every deployed robot. The only way that robots perceive the information about the environment is by colliding with their neighbors; any type of communication among robots is not possible.#R##N##R##N#We assume the principle of momentum conservation as well as the conservation of energy, so robots exchange velocities when they collide. The capabilities of each robot are limited to: observing the times of its collisions, being aware of its velocity at any time, and processing the collected information. Robots have no control of their walks or velocities. Robots' walks depend on their initial positions, velocities, and the sequence of collisions. They are not equipped with any visibility mechanism.#R##N##R##N#The localization problem for bouncing robots has been studied previously in [1,2] in which robots are assumed to move at the same velocity. The configuration of initial positions of robots and their speeds is considered feasible, if there is a finite time, after which every robot starting at this configuration knows initial positions and velocities of all other robots. Authors of [1] conjectured that if robots have arbitrary velocities, the problem might be solvable, if the momentum conservation and energy preservation principles are assumed.#R##N##R##N#In this paper we prove that the conjecture in [1] is false. We show that the feasibility of any configuration and the required time for solving it under such stronger constraints depend only on the collection of velocities of the robots. More specifically, if v0,v1,\u2026,vn\u22121 are the velocities of a given robot configuration $\\mathcal{S}$, we prove that $\\mathcal{S}$ is feasible if and only if $v_i\\neq \\bar{v}$ for all 0\u2264i\u2264n\u22121, where $\\bar{v} = \\frac{v_0+\\ldots+v_{n-1}}{n}$. To figure out the initial positions of all robots no more than $\\frac{2}{min_{0\\leq i\\leq n-1} |v_i-\\bar{v}|}$ time is required.","Towards an Empirically Grounded Conceptual Model for Business Process ComplianceWith the ever increasing number of legal requirements, ensuring business process compliance is a major challenge for today's organizations. Thus, compliance management gained momentum in academia and practice in recent years. Information systems IS researchers focus on methods providing automated support for managing diverse compliance requirements. Thereby, compliance is approached from a rather technical perspective. Little effort has been devoted to establish a comprehensive conceptualization of compliance. In particular, previous research neglected to rigorously consider stakeholders' perception based on empirical research. To close this gap, this paper presents an empirically grounded conceptual model for compliance in the context of business processes. Based on results of 17 expert interviews and an online survey, a conceptual model is constructed. The model takes into account the wide range of control means that are applied in organizations to assure compliance. Hence, the model contributes to reducing complexity and improving transparency of the compliance domain.","On palindromic sequence automata and applicationsIn this paper, we present a novel weighted finite automata called PSA (Palindromic Subsequence Automata) that is a compact representation of all the palindromic subsequences of a string. Then we use PSA to solve the LCPS (Longest Common Palindromic Subsequence) problem. Our automata based algorithms are efficient both in theory and in practice.","Tactile Vibration of Personal Digital Assistants for Conveying FeelingsAt present, there are very few methods to utilize the vibration func- tion in personal digital assistant (PDA) devices, which are simple, but poor in variation. These methods do not effectively use the vibration function's poten- tial. In our research, we aim to maximize the use of vibration function for communication using PDA devices with the objective of adding a new value to the PDA's vibration function. We evaluate the relationships between vibrations and images evoked by them. From the results, we found the vibration patterns corresponding to each eight main type of feeling words in Japanese.","Text and Data Mining to Detect Phishing Websites and Spam EmailsIn this paper, we performed phishing and spam detection using textand data mining. For phishing websites detection, we extracted 17 features from the source code and URL of the websites and for spam-email detection we ap-plied text and data mining in tandem. In both studies, we achieved high sensi-tivity compared to previous studies and also provided decision rules.","Practical Querying of Temporal Data via OWL 2 QL and SQL: 2011. ","Re-thinking bookmark management --- less choice is more efficientThis research investigates the role of a Controlled Vocabulary (CV) in next generation bookmark management systems. The search for a more efficient graphical user interface solution to deal with the massive information overload situation faced by most computer users today is a pressing problem. CVs allow categorization of title words and phrases into the appropriate location recognized by the user, so as to facilitate easier information storage and retrieval. The results of this user study involving 152 individuals indicated that there is potential for a well-defined two-tier controlled vocabulary system to assist user categorization, information storage and retrieval in personal information management systems.","Functional Near-Infrared Spectroscopy in Addiction Treatment: Preliminary Evidence as a Biomarker of Treatment ResponseThere is growing evidence that there are functional changes in the brains of individuals with substance use disorders. Numerous studies utilizing functional magnetic resonance imaging (fMRI) have shown that drug cues elicit increased regional blood flow in reward-related brain areas among addicted participants that is not found among normal controls. This finding has prompted leading investigators to suggest fMRI might be useful as a diagnostic or prognostic biomarker of addiction severity. However, fMRI is too costly for routine use in most treatment facilities. Functional near-infrared spectroscopy (fNIRs) offers an alternative neuroimaging modality that is safe, affordable, and patient-friendly. This manuscript reviews evidence that fNIRs can be used to differentiate prefrontal cortical responses of current alcohol dependent participants from alcohol dependent patients in treatment for 90-180 days. Differential responses to both alcohol and natural reward cues in both groups suggests fNIRs might serve as a clinic-friendly neuroimaging technology to inform clinical practice.","Commutative Matrix-based Diffie-Hellman-Like Key-Exchange ProtocolA matrix-based Diffie-Hellman-like key exchange protocol and utilizing it secure key-exchange protocol similar to HMQV are proposed. The proposed key exchange protocol uses matrix multiplication operation only; it does not rely on the complexityofthediscretelogarithmproblemcontrarytotheprototypeanditsknown variants. Two-way arrival at the common key, similar to that employed in the Diffie- Hellman protocol, is provided by specially constructed commutative matrices. The trap-door property ensuring the proposed protocol security is based on exploiting of a non-invertible public matrix in the key generating process.","Adaptive Second-Order Total Variation: An Approach Aware of Slope DiscontinuitiesTotal variation (TV) regularization, originally introduced by Rudin, Osher and Fatemi in the context of image denoising, has become widely used in the field of inverse problems. Two major directions of modifications of the original approach were proposed later on. The first concerns adaptive variants of TV regularization, the second focuses on higher-order TV models. In the present paper, we combine the ideas of both directions by proposing adaptive second-order TV models, includ- ing one anisotropic model. Experiments demonstrate that introducing adaptivity results in an improvement of the reconstruction error.","Developing a concept interface design of ATM systems based on human-centred design processesTo accomplish our mission smoothly, we need to have good cooperation between human partners and artefacts in complex systems. In particular, it is a critical factor to establish good relationships between human partners and artefact systems. This type of system is also the work of Air Traffic Management (ATM). This research aims to make an interface design concept of the future ATM systems based on a Human-Centred Design approach. First, we discuss the method of design process to develop user interfaces of human consciousness. And then, we attempt to suggest methods of good understanding of Air traffic controllers' knowledge and behaviour based on the perspective of users. After that, we examine to make a prototype interface design concept of the future ATM systems which derived from the results of the task analysis.","ERROR-RATE PERFORMANCE ANALYSIS OF WIRELESS SENSOR NETWORKS OVER FADING CHANNELSIn this paper, we analyze the bit-error-rate (BER) performance of wireless sensor networks. A wireless sensor node with a\u00a0single transmitter antenna and multiple receiver antennas is considered here. We consider M (M \u2265 1) receiver antennas to mitigate\u00a0channel fading effects. BER performance is analyzed in the presence of a co-channel interference source. Wireless channel is assumed to\u00a0follow independently Nakagami fading for the wireless sensor network and Rayleigh fading for the interference signal. Based on the\u00a0derived analytical expressions, the effects of different fading channel and co-channel interference parameters on the BER performance of\u00a0wireless sensor networks are assessed.","Interesting Linguistic Features in Coreference Annotation of an Inflectional LanguageThis paper reports on linguistic features and decisions that we find vital in the process of annotation and resolution of coreference for highly inflec- tional languages. The presented results have been collected during preparation of a corpus of general direct nominal coreference of Polish. Starting from the notion of a mention, its borders and potential vs. actual referentiality, we discuss the problem of complete and near-identity, zero subjects and dominant expressions. We also present interesting linguistic cases influencing the coreference resolution such as the difference between semantic and syntactic heads or the phenomenon of coreference chains made of indefinite pronouns.","Theory of Evolutionary Algorithms (Dagstuhl Seminar 13271)This report documents the talks and discussions at the Dagstuhl Seminar 15211 \"Theory of Evolutionary Algorithms\". This seminar, now in its 8th edition, is the main meeting point of the highly active theory of randomized search heuristics subcommunities in Australia, Asia, North America, and Europe. Topics intensively discussed include rigorous runtime analysis and computational complexity theory for randomised search heuristics, information geometry of randomised search, and synergies between the theory of evolutionary algorithms and theories of natural evolution.","Towards Evaluating Interactive Ontology Matching Tools\ufffd \ufffd \ufffd \ufffd \ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd \ufffd \ufffd\ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd !\ufffd\ufffd\"\ufffd\ufffd\ufffd\ufffd#\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd$\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd !\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \"\ufffd\ufffd#\ufffd\ufffd\ufffd\ufffd$\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd%\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd \ufffd\ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd!\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \"\ufffd\ufffd#\ufffd\ufffd\ufffd\ufffd!\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd$\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd","Selection by Recursively Enumerable SetsFor given sets A, B and Z of natural numbers where the members of Z are z0 ,z 1 ,... in ascending order, one says that A is selected from B by Z if A(i )= B(zi) for all i. Furthermore, say that A is selected from B if A is selected from B by some recursively enumerable set, and that A is selected from B in n steps iff there are sets E0 ,E 1 ,...,E n such that E0 = A, En = B ,a ndEi is selected from Ei+1 for each i&lt;n . The following results on selections are obtained in the present paper. As et is\u03c9-r.e. if and only if it can be selected from a recursive set in finitely many steps if and only if it can be selected from a recursive set in two steps. There is some Martin-Lof random set from which any \u03c9-r.e. set can be selected in at most two steps, whereas no recursive set can be selected from a Martin-Lof random set in one step. Moreover, all sets selected from Chaitin's \u03a9 in finitely many steps are Martin-Lof random.","Implementing Behavior Driven Development in an Open Source ERP ","Serious games as enablers for training and education on operations on ships and off-shore platformsThis paper is focused on design and development of an advanced serious game for the maritime domain. The authors propose an innovative approach to developing training and educational support for navy vessels and/or off-shore platforms. This serious game is a distributed and multi-user simulation framework that allows the reduction of time, costs, and risks of training, by introducing the crew to operating procedures before having to carry out real tests at sea. The research is based on development of educational programs and virtual frameworks supporting cooperative training for complex operations management.","Using Dominant Sets for k-NN Prototype Selection ","B-Human 2013: Ensuring Stable Game PerformanceThe aim of a soccer game is to score more goals than the opponent does. The chances of doing so increase when all the own players are continuously present on the field. In the RoboCup Standard Platform League (SPL), the only reasons for players not to participate in a game are that they either have been penalized or they have not been ready for the match in the first place. This paper presents some of the methods the 2013 SPL world champion team B-Human uses to ensure a stable and continuous game performance. These include overcoming the weak obstacle avoidance of our 2012 system, reacting to a rule change by an improved detection of the field boundary, better support for analyzing games by logging images in real time, and quality management through procedures the human team members follow when participating in a competition.","iCO2: multi-user eco-driving training environment based on distributed constraint optimizationMulti-agent systems have already been successfully applied to a variety of traffic control problems and demonstrated the potential to lower travel times and environmental impact. Sharing this goal, we have developed iCO2, an online tool for training eco-friendly driving in a multi-user three-dimensional environment. iCO2 supports eco-driving practice by instructing computer-controlled agents, such as traffic lights and other vehicles, to create traffic situations that make eco-driving more difficult. Hence the agents take the role of \"opponents\" that try to achieve the optimal challenge level for the skill level of each user. The research challenge is to find the optimal challenge level for all user drivers in a shared simulation space that (1) involves both controllable entities (\"opponents\") and non-controllable entities (users) and (2) is highly dynamic, with dependencies between entities being created and destroyed in real time. We try to solve this problem by modeling the scenario as a distributed constraint optimization problem (DCOP). The main contribution of our paper is the application of a DCOP algorithm to such a new type of application scenario. We evaluate our approach by running scenarios both in terms of speed and optimality of the solutions proposed by the DCOP algorithm.","Non-monotonic Reasoning in Conceptual Modeling and Ontology Design: A ProposalThe Object Role Modeling language (ORM2) is nowadays the most widespread fact-based conceptual modeling language in the business world. Recently, it has been proposed an encoding of the core fragment of ORM2 (called ORM2 zero ) into the description logic ALCQI, allowing the use of reasoning technologies in the analysis of the schemas. A number of services has been defined there based on the FO semantics of ORM2. On the other hand, in many application domains there is a need for the formalization and modeling of defeasible information and non-monotonic reasoning services. Here we formalize a possible way of introducing non-monotonic reasoning into ORM2 schemas, enriching the language with special set of new constraints.","Objective measures of IS usage behavior under conditions of experience and pressure using eye fixation dataThe core objective of this study is to understand individuals IS usage by going beyond the traditional subjective self-reported and objective system-log measures to unveil the delicate process through which users interact with IS. In this study, we conducted a laboratory experiment to capture users\u2019 eye movement and, more importantly, applied a novel methodology that uses the Gaussian mixture model (GMM) to analyze the gathered physiological data. We also examine how performance pressure and prior usage experience of the investigative system affect IS usage patterns. Our results suggest that experienced and pressured users demonstrate more efficient and focused usage patterns than inexperienced and non-pressured ones, respectively. Our findings constitute an important advancement in the IS use literature. The proposed statistical approach for analyzing eye-movement data is a critical methodological contribution to the emerging research that uses eye-tracking technology for investigation.","Activity Theory as a Tool for Identifying Design Patterns in Cross-modal Collaborative Interaction ","A new presence display system using physical interface running on IP-PhonesIn this paper, we describe our developed a new presence display system running on IP-phone. And we also describe the knowledge provided by construction and use of the before system. We thought that we run new presence display system on touch panel display of IP-phone, then we designed and constructed the new system. Our new system is operating since 2010. People's presence status can be viewed through the web browser such as running on iPad. Presence status on web browser is changed immediately when you change it on an IP-phone. These are used Ajax technology. The presence display is easily customizable in every section. We added the indication of the call state of the telephone to a presence display. Thus you can go to meet a person by the timing when a call was over.","Fast track article: GoDisco++: A gossip algorithm for information dissemination in multi-dimensional community networksIn this paper we propose GoDisco++, a gossip based approach for information dissemination in online social community networks. GoDiscoo++ uses local information available to nodes-that is information associated with a node and its neighbors. The algorithm exploits multiple relations which may exist between nodes, and applies social principles and behavior inspired decentralized mechanisms for targeted dissemination. The dissemination process works with the dual aims of (i) maximizing the spread among relevant nodes (high recall) and (ii) minimizing spamming among non-relevant nodes (high precision). Such a designed dissemination scheme can have interesting applications like probabilistic publish/subscribe, decentralized recommendation and contextual advertisement systems, to name a few. We validate the proposed approach with simulation experiments performed using real and synthetic datasets.","Robust BPSO and Scene Change Based Digital Video Watermarking Algorithm in DWT-DFT-SVD Domain ","Performance of LTE in High Speed Railway Scenarios ","Searching Frequent Itemsets by Clustering Data: Towards a Parallel Approach Using MapreduceWe propose a new algorithm for searching frequent itemsets in large data bases. The idea is to start searching from a set of repre- sentative examples instead of testing the 1-itemset,the k-itemset and so on. A clustering algorithm is firstly applied in order to cluster the trans- actions into k clusters. The set of the k representative examples will be used as the starting point for searching frequent itemsets. Each cluster is represented by the most representative example. We show some pre- liminary results and we then propose a parallel version of this algorithm based on the MapReduce Framework.","SSIM-Based End-to-End Distortion Model for Error Resilient Video Coding over Packet-Switched NetworksConventional end-to-end distortion models measure the overall distortion based on independent estimation of the source distortion and channel distortion. However, they are not correlating well with perceptual characteristics in which a strong dependency exists among the source distortion, channel distortion and video content. As most compressed videos are represented to human users, perception-based end-to-end distortion model should be developed for error resilient video coding. In this paper, we propose a SSIM-based end-to-end distortion model to optimally estimate the overall perceptual distortion due to quantization, error concealment and error propagation. Experiments show that the proposed end-to-end distortion model can bring significant visual quality improvement for H.264/AVC video coding over packet-switched networks.","Contributing to the Internet of ThingsThe fast development of networked smart devices equipped with sensors and radio-frequency identification, connected to the Internet, is enabling the emergence of many new applications and the redesign of traditional systems towards more effective operation. Raising awareness among engineering PhD students for the potential of this new wave in their research work is a crucial element in their education. With this aim, the doctoral conference DoCEIS\u201913 focused on technological innovation for the Internet of Things, challenging the contributors to analyze in which ways their technical and scientific work could contribute to or benefit from this paradigm. The results of this initiative, which was reasonably successful, are briefly analyzed.","A precursory look at potential interaction objectives affecting flexible robotic cell safetyWith increased competitive challenges in the manufacturing sector, the need for operational excellence has led to an increased presence of robotics in factory settings. Traditionally, robotics in manufacturing has been relegated to routine and monotonous tasks performed in isolation to ensure human safety. Now, the advancements in robotics are encouraging a paradigm shift --- human-robot collaboration. These new robotic systems are imbued with the ability to 1) perceive anomalies in work environments and to correct/workaround these deficiencies, 2) adapt to changes in workload by means of reconfiguring their layout in a facility, and 3) autonomously navigate factory floors. Although we would like to believe that these innate abilities of second-generation robotics allow for immediate implementation of human-robot collaboration on factory floors, the truth is that more research is required to ensure safety, analyze performance, and define standards. This paper explores potential interaction objectives for human-robot communication in flexible robotic cells.","Algorithms, networks, and social phenomenaWe consider the development of computational models for systems involving social networks and large human audiences. In particular, we focus on the spread of information and behavior through such systems, and the ways in which these processes are affected by the underlying network structure.","Constraint-Driven Approach to Support Input Data Decision-Making in Business Process Management Systems ","A new method for generating the chinese news summary based on fuzzy reasoning and domain ontologyThis paper presents a new method for automatically generating the Chinese weather news summary based on fuzzy reasoning and the domain ontology, where the weather ontology, the time ontology and the geography ontology are predefined by domain experts. The summary is composed of candidate sentences which have higher scores, where the experimental data are adopted from the Chinese weather news website of Taiwan. The experimental results show that the proposed method outperforms the methods presented in [9] and [10] for automatically generating the Chinese news summary.","On Isodual Cyclic Codes over Finite Fields and Finite Chain Rings: Monomial EquivalenceThis paper present the construction cyclic isodual codes over finite fields and finite chain rings. These codes are monomially equivalent to their dual. Conditions are given for the existence of cyclic isodual codes. In addition, the concept of duadic codes over finite fields is extended to finite chain rings. Several constructions of isodual cyclic codes and self-dual codes are given.","Management of multiple and imperfect sources in the context of a territorial community environmental systemThe work presented in this paper is a part of Observox, a community environmental information system for the monitoring of agricultural practices and their pressure on water resources in the Vesle basin, Champagne-Ardenne, France. The construction of Observox is the result of several research projects, and it is based on a methodology involving the actors concerned by the issue of water quality. Furthermore such a system requires the use of information provided by multiple sources which are usually imperfect. To provide the most honest indicators to the system's users, we integrate the notion of information quality by a degree of confidence. Thus we present the use of two main frameworks for imperfect knowledge management in the environmental information system, the fuzzy logic for propagating imprecision and belief functions for merging classifications.","The safe system approach: a road safety strategy based on human factors principlesIn most safety critical domains, safety has been improved through the application of contemporary human error models and management methods. But the common strategic approach to improve road safety has so far mainly been built on the view that individual road-users utterly are responsible when crashes occur and countermeasures have consequently been aimed at changing the behaviour of the road-user. This approach is however slowly shifting and there is a growing understanding that the strategies must be based on human factors principles. In this paper the human factors principles of the Safe System approach are outlined and important implications for the design and regulation of the road transport system will be presented. It is concluded that the Safe System approach share vital foundations with the human factors concept. But it is argued that the Safe System approach takes the human factors approach further by regarding the capability of the human body to withstand external influences with a potential to induce bodily harm.","E-government Benchmarking in European Union: A Multicriteria Extreme Ranking ApproachE-government benchmarking is being conducted by various organizations but its assessment is based on a limited number of indicators and does not highlight the multidimensional nature of the electronically provided services. This paper outlines a multicriteria evaluation system based on four points of view: (1) infrastructures, (2) investments, (3) e-processes, and (4) users' attitude in order to evaluate European Union countries. In this paper, twenty one European Union countries are evaluated and ranked over their e- government progress. Their ranking is obtained through an additive value model which is assessed by an ordinal regression method and the use of the decision support system MIIDAS. In order to obtain robust evaluations, given the incomplete determination of inter-criteria model parameters, the extreme ranking analysis method, based on powerful mathematical programming techniques, has been applied to estimate each country's best and worst possible ranking position.","Creating Awareness of Emergency Departments Healthcare Values Using a Serious GameThe world in which medicine and healthcare institutions are managed is rapidly changing in complex and unpredictable ways. In periods of rapid change, highly adaptive organizations have competitive advantage. Therefore, training a modern, adaptive and high performing team is one of the keys to success. There is a growing body of evidence that Game-Based Learning can be highly successful in driving business results, and a variety of drivers are making it harder and harder to ignore as a candidate medium where deep and immersive learning needs to be delivered as is the case of healthcare management. In this paper we describe the Serious Game ImPROVE for training medical workers on the impacts of patient care quality and costs of different configurations of Emergency Department ED business processes.","Dealing with Bilingualism in Automatic Transcription of Historical Archive of Czech RadioOne of the biggest challenges in the automatic transcription of the historical audio archive of Czech and Czechoslovak radio is bilingualism. Two closely related languages, Czech and Slovak, are mixed in many archive documents. Both were the official languages in former Czechoslovakia (1918-1992) and both were used in media. The two languages are considered similar, although they differ in more than 75a% of their lexical inventories, which complicates automatic speech-to-text conversion. In this paper, we present and objectively measure the difference between the two languages. After that we propose a method suitable for automatic identification of two acoustically and lexically similar languages. It is based on employing 2 size-optimized parallel lexicons and language models. On large test data, we show that the 2 languages can be distinguished with almost 99a% accuracy. Moreover, the language identification module can be easily incorporated into a 2-pass decoding scheme with almost negligible additional computation costs. The proposed method has been employed in the project aimed at the disclosure of Czech and Czechoslovak oral cultural heritage.","An Efficient Algorithm for Mining Frequent Itemsets with Single ConstraintAbstract. Towards the user, it is necessary to find the frequent itemsets which include a set C 0 , especially when C 0 is changed regularly. Our recent studies showed that the frequent itemset mining with often changed constraints should be based on closed itemsets lattice and generators instead of database directly. In this paper, we propose a unique representation of frequent itemsets restricted on constraint C 0 using closed frequent itemsets and their generators. Then, we develop the efficient algorithm to quickly and non-repeatedly generate all fre-quent itemsets contain C 0 . Extensive experiments on a broad range of many synthetic and real datasets showed the effectiveness of our approach. Keywords. Frequent itemset, closed frequent itemset, generator, constraints mining, closed itemsets lattice. 1 Introduction Mining frequent itemsets is one of the important tasks in data mining. Although the set of all frequent itemsets is quite huge, users only take care of a small number of them which satisfy some given constraints. As a remedy, the model of constraint-based mining has been developed [5, 17, 21]. Constraints help to focus on interesting knowledge and to reduce the number of patterns extracted to those of potential inter-est. In addition, they are used for decreasing the search space and enhancing the min-ing efficiency as well. The two important types of constraints which have been stu-died by many authors are the anti-monotone constraint [17] denoted as C","Optimization of a Decentralized Medium Access Control Scheme for Single Radio Cognitive Networks ","Modeling and Characterization of Leakage Inductances for Transformer Winding Fault StudiesThis paper presents an analytical method to compute the leakage inductances of power transformers with a turn-to-turn winding fault. A leakage inductance model to represent the transformer with faulty turns is also proposed. The results obtained from the application of the analytical method are validated by using data obtained from finite-element analysis and experimental tests.","Effective Chinese Relation Extraction by Sentence Rolling and Candidate Ranking ","The e-Participation in Tranquillity Areas Identification as a Key Factor for Sustainable Landscape Planning ","Policy Making Improvement through Social LearningThe world for which policies have to be developed is becoming increasingly complex, uncertain and unpredictable. Citizens are better informed, have rising expectations and are making growing demands for services tailored to their individual needs. The traditional policy-making process --- where identification of problems and solutions given are defined by a small group of politicians and experts --- is characterized by several inefficiencies: risk of false identification of problems, misled setting of goals, wasted resources, unsatisfactory evaluation and, above all, inefficiently addressed societal problems. The main goal of paper is to address the above mentioned challenges through the exploitation of social learning and supporting ICT techniques for a more efficient and open policy making process. These will enable better motivation to participate by taking each opinion into account for the final solution. The paper discusses our Centralab ICT solution as a supporting environment for policy modeling. The aim of our solution is not to change policy-making processes but rather to support them with innovative ICT tools to reach the overall goal when policy-making results in better quality of democracy and improved civic capacity.","MAGIC summoning: towards automatic suggesting and testing of gestures with low probability of false positives during useGestures for interfaces should be short, pleasing, intuitive, and easily recognized by a computer. However, it is a challenge for interface designers to create gestures easily distinguishable from users' normal movements. Our tool MAGIC Summoning addresses this problem. Given a specific platform and task, we gather a large database of unlabeled sensor data captured in the environments in which the system will be used (an \"Everyday Gesture Library\" or EGL). The EGL is quantized and indexed via multi-dimensional Symbolic Aggregate approXimation (SAX) to enable quick searching. MAGIC exploits the SAX representation of the EGL to suggest gestures with a low likelihood of false triggering. Suggested gestures are ordered according to brevity and simplicity, freeing the interface designer to focus on the user experience. Once a gesture is selected, MAGIC can output synthetic examples of the gesture to train a chosen classifier (for example, with a hidden Markov model). If the interface designer suggests his own gesture and provides several examples, MAGIC estimates how accurately that gesture can be recognized and estimates its false positive rate by comparing it against the natural movements in the EGL. We demonstrate MAGIC's effectiveness in gesture selection and helpfulness in creating accurate gesture recognizers.","The Use of Natural Interaction to Enrich the User Experience in Telemedicine SystemsHuman communication always used gestures, movements and ex- pressions as oral language support. Certain gestures are so commonly used around the world that are understood throughout different cultures and times, such as a wave or thumbs up. Natural Interaction is a way to apply this concept to user interfaces in computer systems. In this paper we discuss about the use of Natural Interaction features in a telemedicine system. More specifically, we demonstrate the use of natural interaction interfaces for control and manipula- tion of 3D objects inside Arthron tool. Arthron is a telemedicine tool used for surgery transmissions.","Automatic Performance Model Generation for Java Enterprise Edition (EE) Applications ","Cloud-based Software Crowdsourcing (Dagstuhl Seminar 13362)This report documents the program and the outcomes of Dagstuhl Seminar 13362 \"Cloud-based Software Crowdsourcing\".#R##N##R##N#In addition to providing enormous resources and utility-based computing, clouds also enable a new software development methodology by crowdsourcing, where participants either collaborate or compete with each other to develop software. Seminar topics included crowd platforms, modeling, social issues, development processes, and verification.","A graph algorithm for linearizing simulink modelsThis paper presents a new efficient approach for performing linearization of Simulink\u00ae models. It improves the efficiency of existing linearization algorithms using a Jacobian graph, a graph-based data structure that captures the linear relationship between input, output and state variables. The graph-based algorithm enables the use of graph transformations to reduce the size of the Jacobian data structure, thereby improving the efficiency of subsequent computations. This paper presents a heuristic implementation of the graph-based algorithm. Experimental results on a number of Simulink models of different sizes show how the approach is able to significantly improve computational efficiency and memory use especially in models with large numbers of blocks and states.","Improvement of a Chaotic Map Based Key Agreement Protocol That Preserves Anonymity ","Comparison of LTL to Deterministic Rabin Automata TranslatorsNar\u016fstajici zajem o syntezu a pravd\u011bpodobnostni model checking pohani pokrok v oblasti p\u0159ekladu LTL na deterministicke omega-automaty. Typick\u00fd p\u0159eklad, implementovan\u00fd v nastroji ltl2dstar, vyu\u017eiva Safrovu konstrukci ke zdeterminizovani Buchiho automatu, je\u017e vzniknul pomoci libovolneho p\u0159ekladace LTL na Buchiho automaty. Od roku 2012 byly uvedeny t\u0159i nove p\u0159ekladace LTL na deterministicke Rabinovy automaty. Jmenovit\u011b Rabinizer, LTL3DRA a Rabinizer 2. Vsechny pracuji pouze pro fragmenty LTL, na druhou stranu nepou\u017eivaji Safrovu konstrukci. V nasi praci porovnavame rychlost a v\u00fdsledne automaty uveden\u00fdch nastroj\u016f, p\u0159icem\u017e ltl2dstar je kombinovano s n\u011bkolika p\u0159ekladaci LTL na Buchiho automaty: krom\u011b tradicniho LTL2BA take LTL-&gt;NBA, LTL3BA a Spot.","Sublinear-Time maintenance of breadth-first spanning tree in partially dynamic networksWe study the problem of maintaining a breadth-first spanning tree (BFS tree) in partially dynamic distributed networks modeling a sequence of either failures or additions of communication links (but not both). We show (1+e)-approximation algorithms whose amortized time (over some number of link changes) is sublinear in D, the maximum diameter of the network. This breaks the \u0398(D) time bound of recomputing \"from scratch\".#R##N##R##N#Our technique also leads to a (1+e)-approximate incremental algorithm for single-source shortest paths (SSSP) in the sequential (usual RAM) model. Prior to our work, the state of the art was the classic exact algorithm of [9] that is optimal under some assumptions [27]. Our result is the first to show that, in the incremental setting, this bound can be beaten in certain cases if a small approximation is allowed.","SIMD-Based Implementations of Sieving in Integer-Factoring AlgorithmsThe best known integer-factoring algorithms consist of two stages: the sieving stage and the linear-algebra stage. Efficient parallel implementations of both these stages have been reported in the litera- ture. All these implementations are based on multi-core or distributed parallelization. In this paper, we experimentally demonstrate that SIMD instructions available in many modern processors can lead to additional speedup in the computation of each core. We handle the sieving stage of the two fastest known factoring algorithms (NFSM and MPQSM), and are able to achieve 15-40% speedup over non-SIMD implementa- tions. Although the sieving stage offers many tantalizing possibilities of data parallelism, exploiting these possibilities to get practical advantages is a challenging task. Indeed, to the best of our knowledge, no similar SIMD-based implementation of sieving seems to have been reported in the literature.","Effects of Negative Testing on TDD: An Industrial ExperimentIn our recent academic experiments, an existence of positive test bias, that is lack of negative test cases, was identified when a test driven development approach was used. At the same time, when  ...","On the Indicating Words of Idiom Annotation in CCD (6th ed.)Seven years after the publication of the fifth edition, the sixth edition of Contemporary Chinese Dictionary (CCD) comes out. It is a systematic revi- sion based on the former editions and allows the CCD to keep pace with time and advance to a new level. With the method of quantitative analysis, the paper examines the types and the amount of changes in the IWs of idioms in the 6 th edition, aiming to analyze the possible causes, demonstrate its accomplishment and points out some remaining problems.","Multi-agent team formation: diversity beats strength?Team formation is a critical step in deploying a multi-agent team. In some scenarios, agents coordinate by voting continuously. When forming such teams, should we focus on the diversity of the team or on the strength of each member? Can a team of diverse (and weak) agents outperform a uniform team of strong agents? We propose a new model to address these questions. Our key contributions include: (i) we show that a diverse team can overcome a uniform team and we give the necessary conditions for it to happen; (ii) we present optimal voting rules for a diverse team; (iii) we perform synthetic experiments that demonstrate that both diversity and strength contribute to the performance of a team; (iv) we show experiments that demonstrate the usefulness of our model in one of the most difficult challenges for Artificial Intelligence: Computer Go.","Ditto - Deterministic Execution Replayability-as-a-Service for Java VM on MultiprocessorsAlongside the rise of multi-processor machines, concurrent programming models have grown to near ubiquity. Programs built on these models are prone to bugs with rare pre-conditions, arising from unanticipated interactions between parallel tasks. Replayers can be ef- ficient on uni-processor machines, but struggle with unreasonable over- head on multi-processors, both concerning slowdown of the execution time and size of the replay log. We present Ditto, a deterministic replayer for concurrent JVM applications executed on multi-processor machines, using both state-of-the-art and novel techniques. The main contribu- tion of Ditto is a novel pair of recording and replaying algorithms that: (a) serialize memory accesses at the instance field level, (b) employ par- tial transitive reduction and program-order pruning on-the-fly, (c) take advantage of TLO static analysis, escape analysis and JVM compiler op- timizations to identify thread-local accesses, and (d) take advantage of a lightweight checkpoint mechanism to avoid large logs in long running ap- plications with fine granularity interactions, and for faster replay to any point in execution. The results show that Ditto out-performs previous deterministic replayers targeted at Java programs.","Joint fractional segmentation and multi-tensor estimation in diffusion MRIIn this paper we present a novel Bayesian approach for fractional segmentation of white matter tracts and simultaneous estimation of a multi-tensor diffusion model. Our model consists of several white matter tracts, each with a corresponding weight and tensor compartment in each voxel. By incorporating a prior that assumes the tensor fields inside each tract are spatially correlated, we are able to reliably estimate multiple tensor compartments in fiber crossing regions, even with low angular diffusion-weighted imaging (DWI). Our model distinguishes the diffusion compartment associated with each tract, which reduces the effects of partial voluming and achieves more reliable statistics of diffusion measurements. We test our method on synthetic data with known ground truth and show that we can recover the correct volume fractions and tensor compartments. We also demonstrate that the proposed method results in improved segmentation and diffusion measurement statistics on real data in the presence of crossing tracts and partial voluming.","Reverse \u2013 Green Virtual Enterprises and Their Breeding Environments: Closed-Loop Networks ","Analysis of Selected Aspects of \u201cIBM I\u201d Security ","Balance Control of a Variable Centroid Inverted Pendulum Robot ","Cross-Domain Collaborative Recommendation in a Cold-Start Context: The Impact of User Profile Size on the Quality of RecommendationMost of the research studies on recommender systems are focused on single-domain recommendations. With the growth of multi-domain internet stores such as iTunes, Google Play, and Amazon.com, an opportunity to offer recommendations across different domains become more and more attractive. But there are few research studies on cross-domain recommender systems. In this paper, we study both the cold-start problem and the hypothesis that cross-domain recommendations provide more accuracy using a large volume of user data from a true multi-domain recommender service. Our results indicate that cross-domain collaborative filtering could significantly improve the quality of recommendation in cold start context and the auxiliary profile size plays an important role in it.","Online Social Networks: Privacy Threats and Defenses ","Analysis of User Editing Patterns in Ontology Development ProjectsThe development of real-world ontologies is a complex un- dertaking, commonly involving a group of domain experts with different expertise that work together in a collaborative setting. These ontologies are usually large scale and have a complex structure. To assist in the authoring process, ontology tools are key at making the editing process as streamlined as possible. Being able to predict confidently what the users are likely to do next as they edit an ontology will enable us to focus and structure the user interface accordingly and to enable more ef- ficient interaction and information discovery. In this paper, we use data mining techniques to investigate whether we are able to predict the next editing operation that a user will make based on the change history. We have analyzed the change logs of two real-world biomedical ontologies, and used association rule mining to find editing patterns using different features. We evaluated the prediction accuracy on a test set of change logs for these two ontologies. Our results indicate that we can indeed predict the next editing operation a user is likely to make. We will use the discovered editing patterns to develop a recommendation module for our editing tools, and to design user interface components that are better fitted with the user editing behaviors.","Business Operation Improvement through Integrated Infrastructure ManagementThe constant emergence of new technologies that improve existing ones in one way or another, creates a permanent need to incorporate innovative tools and components into the existing business ecosystem of legacy components, which cannot be discarded and need to be maintained.#R##N##R##N#This paper presents an integration effort between heterogeneous architectures that goes beyond the traditional on-demand integration and creates an infrastructure management framework to give support to present and future integrations. This effort has allowed the interaction between legacy infrastructure, namely IBM Mainframes, and state-of-the-art applications, platforms, and configuration management technologies, also allowing a better management of the available resources.#R##N##R##N#The integration project, called S.G.I.I. (Sistema de Gestion Integrada de Infraestructura, Integrated Infrastructure Management System) is a solution developed for a real business environment: the Spanish bank NCG Banco. The framework is based on two complementary modules: a front-end, designed over a Microsoft Internet Information Server that provides a means of communication between external applications and the IBM Mainframe; and a back-end, developed over the IBM Mainframe to allow the management of its own resources.","Connectivity Subnetwork Learning for Pathology and Developmental VariationsNetwork representation of brain connectivity has provided a novel means of investigating brain changes arising from pathology, development or aging. The high dimensionality of these networks demands methods that are not only able to extract the patterns that highlight these sources of variation, but describe them individually. In this paper, we present a unified framework for learning subnetwork patterns of connectivity by their projective non-negative decomposition into a reconstructive basis set, as well as, additional basis sets representing development and group discrimination. In order to obtain these components, we exploit the geometrical distribution of the population in the connectivity space by using a graph-theoretical scheme that imposes locality-preserving properties. In addition, the projection of the subject networks into the basis set provides a low dimensional representation of it, that teases apart the different sources of variation in the sample, facilitating variation-specific statistical analysis. The proposed framework is applied to a study of diffusion-based connectivity in subjects with autism.","Galaxy + Hadoop: Toward a Collaborative and Scalable Image Processing Toolbox in Cloud ","Compressing Microcontroller Execution Traces to Assist System AnalysisRecent technological advances have made possible the retrieval of execution traces on microcontrollers. However, the huge amount of data in the collected trace makes the trace analysis extremely difficult and time-consuming. In this paper, by leveraging both cycles and repetitions present in an execution trace, we present an approach which offers a compact and accurate trace compression. This compression may be used during the trace analysis without decompression, notably for identifying repeated cycles or comparing different cycles. The evaluation demonstrates that our approach reaches high compression ratios on microcontroller execution traces.","Neural Networks for Digital Media Analysis and Description ","Mapping ASTI patient's therapeutic-data model to virtual Medical Record: can VMR represent therapeutic data elements used by ASTI in clinical guideline implementations?Lack of interoperability between health information systems is a major obstacle in implementing Clinical decision supports systems (CDSS) and their widespread disseminations. Virtual Medical Record (vMR) proposed by HL7 is a common data model for representing clinical information Inputs and outputs that can be used by CDSS and local clinical systems. A CDSS called ASTI used a similar model to represent clinical data and therapeutic history of patient. In order to evaluate the compatibility of ASTI with vMR, we started to map the ASTI model of representing patient\u2019s therapeutic data to vMR. We compared the data elements and associated terminologies used in ASTI and vMR and we evaluated the semantic fidelity between the models. Only one data element the qualitative description of drug dosage, did not match the vMR model. However, it can be calculated in the execution engine. The semantic fidelity was satisfactorily preserved in 12 of 17 elements mapped between the models. This model of ASTI seems compatible to vMR. Further work is necessary to evaluate the compatibility of clinical data model of ASTI to vMR and the use of vMR in implementing practice guidelines.","Identification de complexes prot\u00e9ine-prot\u00e9ine par combinaison de classifieurs. Application \u00e0 Escherichia Coli.Nous proposons une approche permettant de predire des complexes impliquant trois proteines (appeles trimeres) a partir de combinaison de classifieurs appris sur des complexes n'impliquant que deux proteines (dimeres). La prediction de ces trimeres repose sur deux hypotheses biologiques : (i) deux proteines orthologues presentent des caracteristiques fonctionnelles similaires; (ii) deux proteines interagissant sous la forme d'un complexe sous-tendent une fonction biologique essentielle a l'espece concernee. Ces deux hypotheses sont exploitees pour decrire chaque paire de proteines par l'ensemble des especes pour lesquelles elles possedent un orthologue. Un ensemble de mesures de qualite classiquement utilisees pour evaluer l'interet des regles d'association est utilise pour evaluer la force du lien entre les deux proteines. L'organisme modele Escherichia coli a ete utilise pour evaluer notre approche.","Trust Management Method for Vehicular Ad Hoc NetworksIn vehicular ad hoc networks, evaluating trustworthiness of data is utmost necessary for the receiver to make reliable decisions that are very crucial in safety and traffic-efficiency related applications. Ex- isting trust management schemes that have been proposed so far for the vehicular networks has suffered from various limitations. For example, some schemes build trust based on the history of interactions. However, vehicular networks are ephemeral in nature, which makes that approach infeasible. Furthermore, in most of the existing approaches, unique iden- tities of each vehicle must be known. This violates user privacy. In order to overcome these limitations, we have proposed a novel trust manage- ment scheme for the vehicular networks. The proposed method is simple and completely decentralized, which makes it easy to implement in the vehicular networks. We have analytically proved its robustness with re- spect to various security threats. Furthermore, it introduces linear time complexity, which makes it suitable to use in real-time.","New algorithm for solving nonlinear equations rootsTraditional optimization algorithm is widely used solving nonlinear equations numerical solution problem ,it is not only slow convergence speed but also easy to fall into local optimal solution and solution low precision. Adaptive membrane computing optimization algorithm is important achievement performance improvement, Firstly, the high-dimensional space split,each subspace is a basic membrane, evolutionary strategy algorithm based on basic membrane area is used to improve the local search ability and convergence speed. Basic membrane area will be local optimum timing is transmitted to the surface membrane. Particle swarm optimization (PSO) has global search ability is used surface membrane area. through simulation the paper can comparatively analyze the performance of different algorithms.","Cluster Detection and Field-of-View Quality Rating - Applied to Automated Pap-smear AnalysisAutomated cervical cancer screening systems require high resolution analysis of a large number of epithelial cells, involving complex algorithms, mainly analysing the shape and texture of cell nucl ...","Analysis, Control and Synchronization of Hyperchaotic Zhou System via Adaptive Control ","Open Innovation as a Route to Value in Cloud ComputingBoth the cloud computing and open innovation paradigms represent recent phenomenon and as such many unanswered questions still persist. Indeed cloud computing\u2019s full innovation potential may only be fully realised through an open innovation approach. In responding to this research gap we propose a new value creation framework which is based on a review of the literature on cloud computing, innovation, open innovation and value. Taking the framework layer by layer, this paper describes the innovation potential across components capable of offering value to organisations. The main contribution of this paper lies in proposing a framework that seeks to identify best route(s) to value, thus providing a visual mapping to enable organisations determine which cloud computing components, implementations, solutions and innovation approach is most suitable for value attainment.","Online Video Game Addiction: A Review and an Information Systems Research Agenda. ","Range Extension Attacks on Contactless Smart CardsThe security of many near-field RFID systems such as credit cards, access control, e-passports, and e-voting, relies on the assumption that the tag holder is in close proximity to the reader. This assumption should be reasonable due to the fact that the nominal operation range of the RFID tag is only few centimeters. In this work we demonstrate a range extension setup which breaks this proximity assumption. Our system allows full communications with a near-field RFID reader from a range of 115cm - two orders of magnitude greater than nominal range - and uses power that can be supplied by a car battery. The addedflexibil- ity offered to an attacker by this range extension significantly improves the effectiveness and practicality of relay attacks on real-world systems.","Information Systems in Automobiles - Past, Present, and Future UsesA technology crucial for the transformation towards a sustainable energy paradigm, electric mobility recently has also drawn interest within the IS community. Electric vehicles are used for energy storage in residential energy management systems as well as in business models that aggregate the storage capacity of thousands of them to enter energy markets. In either case, information systems within the automobile can provide information on trips, driving patterns, and battery conditions. This paper provides an overview of such automobile information systems and current industry trends. We summarize their evolution during the past decades and argue that this evolution is still continuing with new innovations that offer interesting perspectives for IS research. We also illustrate how automobile information systems within electric vehicles can improve prediction accuracy concerning driving patterns and battery conditions. Thereby, they increase the efficiency of energy management systems as well as the profitability of electric vehicle business models.","Future fashion: at the interfaceImagining the future, we create sci-fi predictions visualized through telematic imagery, involving stage sets and costumes. Looking back at sci-fi's imagination we find it depicts the ideologies of the period in history when it was created far more accurately than it manages to predict future materials or functions. This article focuses on the body, but goes beyond the traditional perspectives of fashion, to consider wearables as an interface between the body and the world. Two key concepts will be presented in order to interpret future fashion, they are: &amp;'fungibility' and &amp;'empathy', which will be discussed through examples of clothing as a means for expressing data. User interfaces of the future will acknowledge the relationship between people, places and things as emergent spaces that generate meaning through everyday activity and therefore ones in which users themselves act as co-designers.","Multi-person Identification and Localization for Ambient Assistive LivingIn this paper, we present a novel, non-intrusive system that uses RFID technology and the Kinect sensor in order to identify and track multiple people in an assistive apartment. RFID is used for both identification and location estimation while information from the Kinect sensor is used for accurate localization. Data from the various modalities is fused using two techniques. During the experiments conducted, our system exhibited high accuracy, thus proving the effectiveness of the proposed design.","Unlimited Decidability of Distributed Synthesis with Limited Missing Knowledge ","Evaluation of somatosensory evoked responses when multiple tactile information was given to the palm: a MEG studyIn this study, as a part of comprehensive approach to develop an interface for tactile information delivery, we aimed at capturing the relationship between neuronal and perceptual sensitivity characteristics of in human hand as indexed by neuromagnetic and psychometric responses.#R##N##R##N#Airpuff stimuli were presented to multiple locations on the ventral side of subjects' palm, which somatosensory evoked responses were observed.#R##N##R##N#As a result, it was observed that the latency and amplitude of the evoked responses in the primary somatosensory area (SI) was not related to the location on the palm. Although mechanoreceptors in the palm area distributed densely at both the center of the palm and the proximal part of the proximal phalanges, no effects on location were found by the amplitude of the evoked responses at SI area. These results suggested that amplitude of the evoked responses at SI did not depend on the distribution of the mechanoreceptors.","Virtual Reality Immersion: An Important Tool for Diagnostic Analysis and Rehabilitation of People with DisabilitiesThis paper sets out the case for the importance of using virtual reality immersion for diagnostic analysis and rehabilitating people with disabilities. To do so, a review of the literature was undertaken by examining articles published between 2000 and 2012. The results show that browsing in virtual immersion en- vironments simulates real-world situations, with the advantage that this enables there to be full control over the variables analyzed and consequently over the health aspects involved. Furthermore, when using multisensory channels, the hu- man-task-system interface tools enable there to be simultaneous treatment of mul- tiple morbidities, which characterizes there having been an important advance made in the functional independence of people with disabilities.","Development and Experiences of an Autonomous Vehicle for High-Speed Navigation and Obstacle Avoidance ","The Growing Radial Basis Function (RBF) Neural Network and Its ApplicationsThis paper proposes a framework based on the cross-validation methods for constructing and training radial basis function (RBF) neural networks. The proposed growing RBF (GRBF) neural network begins with initial number of hidden units. In the process of training, the GRBF network adjusts the hidden neurons by eliminating some \"small\" hidden units and splitting one \"large\" hidden unit at the same cycle. If the prediction error in the system is not less than the pre-given threshold, the proposed method increases hidden units to re-estimate the parameters in the next process of training, until the stop criterion is satisfied. In practice, the proposed GRBF network are evaluated and tested on two real 3D seismic data sets with very favorable self- adaptive ability and satisfactory results.","Recommendation for online social feeds by exploiting user response behaviorIn recent years, online social networks have been dramatically expanded. Active users spend hours communicating with each other via these networks such that an enormous amount of data is created every second. The tremendous amount of newly created information costs users much time to discover interesting messages from their online social feeds. The problem is even exacerbated if users access these networks via mobile devices. To assist users in discovering interesting messages efficiently, in this paper, we propose a new approach to recommend interesting messages for each user by exploiting the user's response behavior. We extract data from the most popular social network, and the experimental results show that the proposed approach is effective and efficient.","Cyclic Shift on Prefix-Free LanguagesWe prove that the cyclic shift of a prefix-free language rep- resented by a minimal complete n-state deterministic finite automaton is recognized by a deterministic automaton of at most (2n \ufffd 3) n\ufffd 2 states. We also show that this bound is tight in the quaternary case, and that it cannot be met by using any smaller alphabet. In the ternary and binary cases, we still get exponential lower bounds.","Enjoying of traditional chinese shadow play: a cross-culture studyPiying, the world's intangible culture heritage, is an old Chinese art form and one of the origins of modern movie, which encountering the risk of extinction. The spirit of traditional Piying is to express rich emotion and stories through action change by artists. A cross-culture study was conducted to investigate the effect of Piying-induced emotion on heart rate and heart rate variability during Piying perception and performance. The result confirmed that Piying performance was far more effective in emotion induction than Piying perception. The results suggested Chinese are more fond of traditional Piying elements and American prefer experiencing interaction of Piying while the result of Japanese is between those of Chinese and American, they hope that there is a rule to follow in Piying show. Our approach is the first explorative emotion study on Piying art, which could be used as design mechanism to re-create and inherit Piying culture.","Rapid Mode Estimation for 3D Brain MRI Tumor SegmentationThe efficient definition of the tumor area is crucial in brain tumor resection planning. But current methods embedded in computer aided diagnosis systems can be time consuming, while the initialization of the segmentation mask may be possible. In this work, we develop a method for rapid automated segmentation of brain tumors.#R##N##R##N#The main contribution of our work is an efficient method to initialize the segmentation by casting it as nonparametric density mode estimation, and developing a Branch and Bound-based method to efficiently find the mode maximum of the density function. Our technique is exact, has guaranteed convergence to the global optimum, and scales logarithmically in the volume dimensions by virtue of recursively subdividing the search space through Branch-and-Bound and Dual-Tress data structures.#R##N##R##N#This estimated mode provides our system with an initial tumor hypothesis which is then refined by graph-cuts to provide a sharper outline of the tumor area.#R##N##R##N#We demonstrate a 12-fold acceleration with respect to a standard mean-shift implementation, allowing us to accelerate tumor detection to a level that would facilitate a high-degree brain tumor resection planning.","Predicting Users\u2019 Age Range in Micro-blog Network ","Linguistic Descriptions: Their Structure and ApplicationsIn this paper, we provide a brief survey of the main theoretical and conceptual principles of methods that use the, so called, linguistic descriptions and thus, belong to the broad area of methods encapsulated under the term modeling with words. The theoretical frame is fuzzy natural logic -- an extension of mathematical fuzzy logic consisting of several constituents. In this paper, we will deal with formal logical theory of evaluative linguistic expressions and the related concepts of linguistic description and perception-based logical deduction. Furthermore, we mention some applications and highlight two of them: forecasting and linguistic analysis of time series and linguistic associations mining.","Ambient Assistive Healthcare and Wellness Management \u2013 Is \u201cThe Wisdom of the Body\u201d Transposable to One\u2019s Home? ","Trust and Coordination in Offshore Outsourcing: An Account of Intercultural Collaboration in a Danish and Indian IT ContextThis paper reports from an empirical study of one of the largest IT and BPO offshore outsourcing endeavors embarked upon by a Danish company. Based on observations of structured, video-mediated handover meetings and follow-up interviews with the involved stakeholders, it presents an account of how the implementation of handover meetings affected Danish employeesper- ception of their Indian counterparts in terms of work attitude, competence and reliability - and ultimately how these handover meetings increased the Danish employeeswillingness and ability to trust their Indian counterparts. Contempo- rary research on trust in virtual teams is used to provide a theoretical framing of the empirical findings. The paper furthermore draws on Sabherwal's (2003) ca- tegorizations of coordination as being either biased towards organic mutual ad- justments or towards a priori structures. Through this perspective the findings suggest that formal coordination can be seen as a catalyst for building trust in virtual teams.","Algebraic program semantics for supercomputingThe competition for higher performance/price ratio is pushing processor chip design into the manycore age. Existing multicore technologies such as caching no longer scale up to dozens of processor cores. Even moderate level of performance optimisation requires direct handling of data locality and distribution. Such architectural complexity inevitably introduces challenges to programming. A better approach for abstraction than completely relying on compiler optimization is to expose some performance-critical features of the system and expect the programmer to handle them explicitly. This paper studies an algebra-semantic programming theory for a performance-transparent level of parallel programming of array-based data layout, distribution, transfer and their affinity with threads. The programming model contributes to the simplification of system-level complexities and the answering of crucial engineering questions through rigorous reasoning.","Distance Measures for Prototype Based Classification ","Dual Averaging and Proximal Gradient Descent for Online Alternating Direction Multiplier MethodWe develop new stochastic optimization methods that are applicable to a wide range of structured regularizations. Basically our methods are combinations of basic stochastic optimization techniques and Alternating Direction Multiplier Method (ADMM). ADMM is a general framework for optimizing a composite function, and has a wide range of applications. We propose two types of online variants of ADMM, which correspond to online proximal gradient descent and regularized dual averaging respectively. The proposed algorithms are computationally efficient and easy to implement. Our methods yield O(1/\u221aT) convergence of the expected risk. Moreover, the online proximal gradient descent type method yields O(log(T)/T) convergence for a strongly convex loss. Numerical experiments show effectiveness of our methods in learning tasks with structured sparsity such as overlapped group lasso.","Determining The Optimal Level Of Information Granularity For Efficient Energy Consumption Decisions: Experimental Evidence ","Predictors of Users' Willingness to Personalize Web SearchPersonalized Web search offers a promising solution to the task of user-tailored information-seeking; however, one of the reasons why it is not widely adopted by users is due to privacy concerns. Over the past few years social networking services SNS have re-shaped the traditional paradigm of information-seeking. People now tend to simultaneously make use of both Web search engines and social networking services when faced with an information need. In this paper, using data gathered in a user survey, we present an analysis of the correlation between the users' willingness to personalize Web search and their social network usage patterns. The participants' responses to the survey questions enabled us to use a regression model for identifying the relationship between SNS variables and willingness to personalize Web search. We also performed a follow-up user survey for use in a support vector machine SVM based prediction framework. The prediction results lead to the observation that SNS features such as a user's demographic factors such as age, gender, location, a user's presence or absence on Twitter and Google+, amount of activity on Twitter and Google+ along with the user's tendency to ask questions on social networks are significant predictors in characterising users who would be willing to opt for personalized Web search results.","Partial Least Squares for Word Confidence Estimation in Machine TranslationThe final publication is available at Springer via http://dx.doi.org/10.1007/978-3-642-38628-2_59","An Efficient Handover Mechanism by Adopting Direction Prediction and Adaptive Time-to-Trigger in LTE NetworksIn this paper, we propose an efficient handover mechanism for Long Term Evolution (LTE) networks. Both moving direction predic- tion and Time-to-Trigger (TTT) adjustment are taken into consideration for processing to lower the unnecessary handover. By referencing previ- ous locations, user equipment's (UE) moving direction is estimated by the cosine function to determine a better destined E-UTRAN NodeB (eNB). With adaptive TTT, we categorize UEs into 3 levels according to the velocity. Initially, TTT value is given for each level, and the value is decremented when the handover failure rate gets higher. In addition, we also combine both approaches of moving direction prediction and adaptive TTT into handover procedure. Simulation results show that the proposed method can effectively improve the handover efficiency. As compared with the standard handover procedure, an average reduction of 31% handovers can be obtained by applying the moving direction pre- diction. And, as compared with fixed TTT, up to the 36.5% of handover trigger failure rate can be expected by using the adaptive TTT handover triggering approach. The performance can be further improved when both approaches are taken in dealing with the handover procedure.","An approach for designing neural cryptographyNeural cryptography is widely considered as a novel method of exchanging secret key between two neural networks through mutual learning. This paper puts forward a generalized architecture to provide an approach to designing novel neural cryptography. Meanwhile, by taking an in-depth investigation on the security of neural cryptography, a heuristic rule is proposed. These results can effectively guide us to designing secure neural cryptography. Finally, an example is given to demonstrate the effectiveness of the proposed structure and the heuristic rule.","Large-Scale Multi-agent-Based Modeling and Simulation of Microblogging-Based Online Social NetworkOnline Social Networks (OSN) are self-organized systems with emergent behavior from the individual interactions. Microblogging services in OSN, like Twitter and Facebook, became extremely popular and are being used to target marketing campaigns. Key known issues on this targeting is to be able to predict human behavior like posting, for- warding or replying a message with regard to topics and sentiments, and to analyze the emergent behavior of such actions. To tackle this prob- lem we present a method to model and simulate interactive behavior in microblogging OSN taking into account the users sentiment. We make use of a stochastic multi-agent based approach and we explore Barack Obama's Twitter network as an egocentric network to present the exper- imental simulation results. We demonstrate that with this engineering method it is possible to develop social media simulators using a bottom- up approach (micro level) to evaluate the emergent behavior (macro level) and our preliminary results show how to better tune the modeler and the sampling and text classification impact on the simulation model.","A Wearable Cognitive Vision System for Navigation Assistance in Indoor EnvironmentExisting mobile navigation techniques are not applicable for indoor navigation. Obviously, the best navigator is a human companion. In this paper, we explore to build a wearable virtual navigator for indoor navigation. A novel cognitive vision system is designed which consists of long-term memory and working memory for complicated vision tasks in dynamic environments. The long-term memory mimics the flexibility and scalability of human cognitive memory for domain knowledge rep- resentation, and the working memory emulates the routine process and attention selection in human cognitive model for online visual percep- tion. Efficient algorithms for image classification and object detection are organized and performed under cognitive perception framework to achieve real-time performance. Field tests demonstrate its effectiveness and efficiency by recognizing scenes, locations, and landmark objects in real-time, and subsequently providing context-aware assistant to guide the user in the navigation of a complex office environment.","Deterministic counter machines and parallel matching computationsFor the classical family of languages recognized by quasi-realtime deterministic multi-counter machines of the partially blind type, we propose a new implementation by means of matching finite-state computations, within the model of consensually regular languages (recently introduced by the authors), whose properties are summarized. A counter machine computation is mapped on multiple DFA computations that must match in a precise sense. Such implementation maps the original counters onto a multiset over the states of the DFA. By carefully synchronizing and mutually excluding counter operations, we prove that the union of such counter languages is also consensual. This approach leads to a new way of specifying counter languages by means of regular expressions that define matching computations.","Ray-Casting-Based Evaluation Framework for Needle Insertion Force Feedback Algorithms ","Pragmatic quotient types in coqIn intensional type theory, it is not always possible to form the quotient of a type by an equivalence relation. However, quotients are extremely useful when formalizing mathematics, especially in algebra. We provide a Coq library with a pragmatic approach in two complementary components. First, we provide a framework to work with quotient types in an axiomatic manner. Second, we program construction mechanisms for some specific cases where it is possible to build a quotient type. This library was helpful in implementing the types of rational fractions, multivariate polynomials, field extensions and real algebraic numbers.","Local Decision and Verification with Bounded-Size OutputsWe are dealing with the design of algorithms using few resources, enabling to decide whether or not any given n-node graph G belongs to some given graph class    $\\mathcal C$   . Our model borrows from property testing the way the decision is taken, by an unconstrained interpretation function applied to the set of outputs produced by individual queries (instead of an interpretation function limited to the conjunction operator as in local distributed decision). It borrows from local distributed decision the fact that all nodes are involved in the decision (instead of o(n) nodes as in property testing). The unique, but severe restriction we impose to the nodes is a limitation on the amount of information they are enabled to output: every node is bounded to output a constant number of bits. In this paper, we provide separation results between distributed decision and verification classes, and we analyze the size of the certificates enabling to verify distributed languages.","Hierarchical Clustering Routing Protocol Based on Optimal Load Balancing in Wireless Sensor NetworksNowadays, Wireless Sensor Networks WSNs are widely used in different aspects of human life such as agriculture, health care systems, traffic engineering and so on. By improving WSN's design and applicability, still due to energy limitation in the sensors, the main concern is about the lifetime of sensors. Beside hardware aspect, establishing some efficient techniques for data sensing, processing and transition in the sensors can increase WSN's lifetime. In this paper, a new optimized routing protocolcalled OLBHC Optimal Load Balancing Hierarchical Clustering is designed. In contrast to some traditional methods such as LEACH, OLBHC could decrease the energy consumption in the sensors by utilizing the equalization method. In OLBHC, a Flag matrix which stores cluster head nodes' connection status is used and then an optimization algorithm is applied for selecting the best clusters in the network based on the energy consumption. The simulation results prove this proposed approach's efficiency because by applying OLBHC the average lifetime of nodes is about 160% longer than LEACH and almost all of the nodes are dead in LEACH when the first node begins to die in OLBHC.","An improved evolutionary algorithm for extractive text summarizationThe main challenge of extractive-base text summarization is in selecting the top representative sentences from the input document. Several techniques were proposed to enhance the process of selection such as feature-base, cluster-base, and graph-base methods. Basically, this paper proposed to enhance a previous work, and provides some limitations in the similarity calculation of that previous work. This paper proposes an enhanced mixed feature-base and cluster-base approaches to produce a high qualified single-document summary. We used the Jaccard similarity measure to adjust the sentence clustering process instead of using the Normalized Google Distance (NGD) similarity measure. In addition, this paper proposes a new real-to-integer values modulator instead of using the genetic mutation operator which was adopted in the previous work. The Differential Evolution (DE) algorithm is used for train and test the proposed methods. The DUC2002 dataset was preprocessed and used as a test bed. The results show that our proposed differential mutant presented a satisfied performance while the Genetic mutant proved to be the better. In addition, our analysis of NGD similarity scores showed that NGD was an inappropriate selection in the previous study as it performs successfully in a very big database such as Google. Our selection of Jaccard measure was fortunate and obtained superior results surpassed the NGD using the new proposed modulator and the genetic operator. In addition, both algorithms outperformed the standard baseline Microsoft Word Summarizer and Copernic methods.","Automatically pairing measured findings across narrative abdomen CT reports.Radiological measurements are one of the key variables in widely adopted guidelines (WHO, RECIST) that standardize and objectivize response assessment in oncology care. Measurements are typically described in free-text, narrative radiology reports. We present a natural language processing pipeline that extracts measurements from radiology reports and pairs them with extracted measurements from prior reports of the same clinical finding, e.g., lymph node or mass. A ground truth was created by manually pairing measurements in the abdomen CT reports of 50 patients. A Random Forest classifier trained on 15 features achieved superior results in an end-to-end evaluation of the pipeline on the extraction and pairing task: precision 0.910, recall 0.878, F-measure 0.894, AUC 0.988. Representing the narrative content in terms of UMLS concepts did not improve results. Applications of the proposed technology include data mining, advanced search and workflow support for healthcare professionals managing radiological measurements.","Cluster-Based Prediction of Mathematical Learning PatternsThis paper introduces a method to predict and analyse stu- dents' mathematical performance by detecting distinguishable subgroups of children who share similar learning patterns. We employ pairwise clus- tering to analyse a comprehensive dataset of user interactions obtained from a computer-based training system. The available data consist of multiple learning trajectories measured from children with developmen- tal dyscalculia, as well as from control children. Our online classification algorithm allows accurate assignment of children to clusters early in the training, enabling prediction of learning characteristics. The included re- sults demonstrate the high predictive power of assignments of children to subgroups, and the significant improvement in prediction accuracy for short- and long-term performance, knowledge gaps, overall training achievements, and scores of further external assessments.","A Systematic Review of Software Requirements Selection and Prioritization Using SBSE ApproachesSelection and prioritization of software requirements represents an area of interest in Search-Based Software Engineering SBSE and its main focus is finding and selecting a set of requirements that may be part of a software release. This paper uses a systematic review to investigate which SBSE approaches have been proposed to address software requirement selection and prioritization problems. The search strategy identified 30 articles in this area and they were analyzed for 18 previously established quality criteria. The results of this systematic review show which aspects of the requirements selection and prioritization problems were addressed by researchers, the methods approaches and search techniques currently adopted to address these problems, and the strengths and weaknesses of each of these techniques. The review provides a map showing the gaps and trends in the field, which can be useful to guide further research.","Recall-Oriented Evaluation for Information Retrieval SystemsIn a recall context, the user is interested in retrieving all relevant documents rather than retrieving a few that are at the top of the results list. In this article we propose ROM (Recall Oriented Measure) which takes into account the main elements that should be considered in evaluating information retrieval systems while ordering them in a way explicitly adapted to a recall context.","Using Principal Component Analysis for Practical Biasing of Power Traces to Improve Power Analysis Attacks ","Comparing hierarchical mathematical document clustering against the Mathematics Subject Classification tree ","Story generation with crowdsourced plot graphsStory generation is the problem of automatically selecting a sequence of events that meet a set of criteria and can be told as a story. Story generation is knowledge-intensive; traditional story generators rely on a priori defined domain models about fictional worlds, including characters, places, and actions that can be performed. Manually authoring the domain models is costly and thus not scalable. We present a novel class of story generation system that can generate stories in an unknown domain. Our system (a) automatically learns a domain model by crowdsourcing a corpus of narrative examples and (b) generates stories by sampling from the space defined by the domain model. A large-scale evaluation shows that stories generated by our system for a previously unknown topic are comparable in quality to simple stories authored by untrained humans.","Observing Dynamic Urban Environment through Stereo-Vision Based Dynamic Occupancy Grid Mapping ","Expression Reduction from Programs in a Symbolic Binary Executor ","PRIDE: Practical Intrusion Detection in Resource Constrained Wireless Mesh NetworksAs interest in wireless mesh networks grows, security challenges, e.g., intrusion detection, become of paramount importance. Traditional solutions for intrusion detection assign full IDS responsibilities to a few selected nodes. Recent results, however, have shown that a mesh router cannot reliably perform full IDS functions because of limited resources (i.e., processing power and memory). Cooperative IDS solutions, targeting resource constrained wireless networks impose high communication overhead and detection latency. To address these challenges, we propose PRIDE (PRactical Intrusion DEtection in resource constrained wireless mesh networks), a non-cooperative real-time intrusion detection scheme that optimally distributes IDS functions to nodes along traffic paths, such that detection rate is maximized, while resource consumption is below a given threshold. We formulate the optimal IDS function distribution as an integer linear program and propose algorithms for solving it accurately and fast (i.e., practical). We evaluate the performance of our proposed solution in a real-world, department-wide, mesh network.","Value Systems Alignment in Product Servicing NetworksAbstract: The notion of service-enhanced product brings new perspectives for value creation and differentiation in manufacturing. The existence of complex and highly customized products, the inclusion of business services that add value to the product typically require the collaboration of multiple stakeholders. It is natural that each stakeholder has its own set of values and preferences and as a result, conflicts among them might emerge due to some values misalignment. Therefore, the Value System Alignment assessment should be included when selecting partner for the formation of long-term collaborative networks for the operation and management of the product life-cycle. This paper presents the implementation of a Value System alignment assessment model, as a component of the cloud-based collaborative environment designed to support a mix of collaborative enterprise networks involved in the solar energy sector. Keywords: Collaborative networks, value systems, service-enhanced products.","Decentralized Intelligent Real World Embedded Systems: A Tool to Tune Design and Deployment ","Multi-label Classification Using Rough SetsIn multi-label classification, each instance may be associated with multiple labels simultaneously which is different from the traditional single-label classification where an instance is only associated with a single label. In this paper, we propose two types of approaches to deal with multi-label classification problem based on rough sets. The first type of approach is to transform the multi-label problem into one or more single-label problems and then use the classical rough set model to make decisions. The second type of approach is to extend the classical rough set model in order to handle multi-label dataset directly, where the new model considers the correlations among labels. The effectiveness of multi-label rough set model is presented by a series of experiments completed for two multi-label datasets.","Generation of User Interest Ontology Using ID3 Algorithm in the Social Web ","Factoring-Based Proxy Re-Encryption SchemesProxy re-encryption (PRE) realizes delegation of decryption rights, enabling a proxy holding a re-encryption key to convert a ciphertext originally intended for Alice into an encryption of the same message for Bob, and cannot learn anything about the encrypted plaintext. To the best of our knowledge, all of the existing PRE schemes are based on the Diffie-Hellman assumption and its variants. In this paper, we present the first factoring-based PRE schemes. In particular, we first propose a bidirectional multi-hop PRE scheme which is secure against chosen-plaintext attack in the standard model (i.e., without the random oracle idealization). We then propose a bidirectional single-hop PRE scheme which is secure against chosen-ciphertext attack (CCA) in the random oracle model. Finally, we extend the bidirectional single-hop PRE scheme to obtain a CCA-secure unidirectional single-hop PRE scheme.","Finite Element Research on Cutting Force and Temperature in Milling 300M SteelCutting force and temperature are major concerns in the aircraft landing gear manufacture to implement milling for 300M steel. These two factors strongly influence the surface characteristics of a machined product that have close relation with functional performance of the product. This paper describes investigations realised to perform simulations of end milling operations on 300M steel via AdvantEdge FEM software. In the simulations, the geometry of cutting tool is measured by coordinate measuring machine and modeled in UG software. The material flow stress data are obtained from Split Hopkinson Bar experiment. The material behaviour is modelled with a classical Johnson\u0097Cook law to accomplish the thermo-mechanical analysis. Good agreements between the numerical results and experimental data at various cutting velocities prove that the proposed model is capable of predicting the cutting forces and temperatures during milling of 300M steel accurately.","On the Formulation of Conceptual Spaces for Land Cover Classification Systems ","Understanding and Exploiting User\u2019s Navigational Intent in Community Question Answering ","NF-Based Algorithms for Online Bin Packing with Buffer and Item Size Limitation ","Multi-layer deformation estimation for fluoroscopic imagingAccurate estimation of motion in fluoroscopic imaging sequences is critical for improved frame interpolation/extrapolation, tracking of surgical instruments, and Digital Subtraction Angiography (DSA). The projection of multiple transparent objects undergoing multiple complicated deformations in 3D onto a single 2D view makes this motion estimation problem quite challenging and ill-suited to existing techniques used in medical image analysis. We propose a novel method for jointly decomposing the observed image into a set of additive layers each associated with its corresponding smooth nonlinear deformation, which together model the non-smooth motion observed in the projection images across several frames. A total variation based regularization penalty is used to incorporate the known structure of the input frames for well posedness of the layer separation problem. We present the use of this model for frame interpolation and artifact reduction in DSA. Results are included from synthetic and real clinical datasets.","Global Decisions Taking on the Basis of Dispersed Medical DataThe main aim of the article is to present a decision-making system using dispersed knowledge. The article introduces the system with dynamically generated coalitions. The local knowledge bases, on the basis of which a similar classification for the test object is made, are combined into a coalition. In the proposed system, the classification process can be divided into several steps. In the first step we describe the classification of a test object made on the basis of local knowledge base, by probability vectors over decision classes. We cluster local knowledge bases with respect to similarities of probability vectors. For every cluster, we find a kind of combined information. Finally, we classify the test object using the method for the conflict analysis. The main aim of the paper is to present the results of experiments on medical data. In experiments the situation is considered in which medical data from one domain are collected in many medical centers. We want to use all of the collected data at the same time in order to make a global decisions.","Automated Functional Verification of Application Specific Instruction-set ProcessorsNowadays highly competitive market of consumer electronics is very sensitive to the time it takes to introduce a new product. However, the ever- growing complexity of application specific instruction-set processors (ASIPs) which are inseparable parts of nowadays complex embedded systems makes this task even more challenging. In ASIPs, it is necessary to test and verify signifi- cantly bigger portion of logic, tricky timing behaviour or specific corner cases in a defined time schedule. As a consequence, the gap between the proposed ver- ification plan and the quality of verification tasks is widening due to this time restriction. One way how to solve this issue is using faster, efficient and cost- effective methods of verification. The aim of this paper is to introduce an auto- mated generation of SystemVerilog verification environments (testbenches) for verification of ASIPs. Results show that our approach reduces the time and effort needed for implementation of testbenches significantly and is robust enough to detect also well-hidden bugs.","Anisotropic Diffusion and Curve Evolution for Segmentation of Color Images in Cultural Heritage ","A conceptual client-designer framework: inspiring the development of inclusive design interactive techniquesThe adoption of inclusive design approach into design practice is compatible to the needs of an ageing society. However, tools and methods that promote inclusivity during new product development are scarcely used in industry. This paper is part of a research project that investigates ways to accommodate inclusive design into the design process in industrial context.#R##N##R##N#The present paper is based on the finds from the observations and interviews with industrial designers and interviews with stakeholders. The outcomes from the study supported a better understanding of the client-designer dynamic as well as the stages in the design process where information related to inclusive design could be introduced. The findings were essential to inspire the development of an inclusive design interactive technique to be used by clients and designers.","Molecular modelling studies of synthesized pentacyclo-undecane peptides as potential HIV-1 wild type C-SA protease inhibitorsIncreasing numbers of HIV infected patients along with severe treatment-associated complications and related deaths make the AIDS pandemic [1]. These inhibitors reduced the virus proliferation and this success made the HIV aspartic protease the prime target for AIDS therapies [2]. In this study, we present the first account of pentacycloundecane (PCU) lactam-peptide based HIV protease inhibitors with nanomolar activity against the resistance-prone wild type C-South African HIV-protease (C-SA). NMR and molecular docking were employed to determine a logical correlation between the inhibitory concentration (IC50) results and the 3D structure of the corresponding inhibitors in solution. NMR investigations indicated that the activity is related to the chirality of the PCU moiety and its ability to induce conformations of the coupled peptide side chain. In addition, docking studies confirmed the observed EASY-ROESY results and the experimental IC50 activity profile of the considered inhibitors. Due to theoretical importance of nuclear quadrupole resonance data [3] for characterization of molecular dynamics, DFT calculations are carried out to obtain 17O and 14N- NQR parameters. The studies reported in this work were undertaken to establish whether the NQR method could be used to derive a rational structure-activity relationship for these inhibitors. These findings open up useful applications for this family of inhibitors, considering the vast number of alternative disease related proteases that may exist.","Selecting source behavior in information fusion on the basis of consistency and specificityCombining pieces of information provided by several sources without prior knowledge about the behavior of the sources is an old yet still important and rather open problem in belief function theory. In this paper, we propose a general approach to select the behavior of sources, based on two cornerstones of information fusion that are the notions of specificity and consistency. This approach is framed in a recently introduced and general fusion scheme that allows a wide range of assumptions on the sources. In the process, we are also led to generalize a recently introduced measure of conflict to all Boolean connectives. Eventually, we show that our approach generalizes some important existing information fusion strategies.","Analysis and Development of Techniques and Methods in Medical Practice in Cochlear Implant Systems ","Adaptive Model of Cardiovascular System: Realization and Signal Database ","Exploiting the Semantic Similarity of Contextual Situations for Pre-filtering RecommendationContext-aware recommender systems aim at outperforming tradition- al context-free recommenders by exploiting information about the context under which the users' ratings are acquired. In this paper we present a novel contextu- al pre-filtering approach that takes advantage of the semantic similarities be- tween contextual situations. For assessing context similarity we rely only on the available users' ratings and we deem as similar two contextual situations that are influencing in a similar way the user's rating behavior. We present an ex- tensive comparative evaluation of the proposed approach using several contex- tually-tagged ratings data sets. We show that it outperforms state-of-the-art con- text-aware recommendation techniques.","Proceedings of the 1st International Workshop on Engineering Semantic Enterprise (ESE) 2012 ","An Application of Defeasible Logic Programming for Firewall Verification and ReconfigurationFirewalls are the frontier defense in network security. Fire- walls provide a set of rules that identify how to handle individual data packets arriving at the network. Firewall configuration is increasingly be- coming difficult. Filter properties called anomalies hint at possible con- flicts between rules. An argumentation framework could provide ways of handling such conflicts. Verification of a firewall involve finding out whether anomalies exist or not. Reconfiguration involves removing crit- ical anomalies discovered in the verification phase. In this paper, we show how a Defeasible Logic Programming approach with an underly- ing argumentation based semantics could be applied for verification and reconfiguration of a firewall.","Adaptive H-Extrema for Automatic Immunogold Particle Detection ","Non-intrusive Haptic Interfaces: State-of-the Art SurveyHaptic rendering technologies are becoming a strategic component of the new Human-Machines Interfaces. However, many existing devices generally operate with intrusive mechanical structures that limit rendering and transparency of haptic interaction. Several studies have addressed these constraints with different stimulation technologies. According to the nature of contacts between the device and the user, three main strategies were identified. This paper proposes to detail them and to highlight their advantages and drawbacks.","Using computer games as programming assignments for university students and secondary school pupilsProgramming is an inherent part of informatics both at university and at primary, secondary and high schools in Slovakia. In our paper we describe programming oriented courses attended by our university students --- the pre-service teachers. Further we describe programming knowledge and skills of secondary school pupils. We present a certain type of a computer game that we use already for several years as a motivation when teaching programming both at university and with younger children. As an example we focus on one assignment which was first presented to our university students as a final test after a programming course in Imagine. The same assignment was rewritten for 10-15 years old children and used in a programming competition Imagine Logo Cup 2012. We also present two different approaches to the solution of this assignment --- one using object-oriented programming and one without objects.","Security Analysis of the RC4+ Stream CipherThe  RC4+  stream cipher was proposed by Maitra and Paul at Indocrypt 2008. The authors had claimed that  RC4+  ironed out most of the weaknesses of the alleged  RC4  stream cipher and was only marginally slower than  RC4  in software. In this paper we show that it is possible to mount a distinguishing attack on  RC4+  based on the bias of the first output byte. The distinguisher requires around 226 samples produced by different keys of  RC4+ . In the second part of the paper we study the possibility of mounting the differential fault attack on  RC4  proposed by Biham et. al. in FSE 2005, on  RC4+ . We will show that that the  RC4+  is vulnerable to differential fault attack and it is possible to recover the entire internal state of the cipher at the beginning of the PRGA by injecting around 217.2 faults.","Data Usability Processor for Optical Remote Sensing Imagery: Design and Implementation into an Automated Processing ChainA range of global environmental and social problems, such as climate change or social transformation processes, are aggravated by diverse anthropogenic impacts. To monitor, analyse and combating these processes, topical information on the status, development, spatial and temporal dynamics of them is an indispensable prerequisite. The growing, frequently rapid demand for global and regional data in relevant geographical, geometric, semantic and temporal resolution can only be met by remote sensing data the majority of which are available on an operational scale. Not only does the availability of data present a major obstacle for the above applications, but also rapid processing of the acquired remote sensing data is a severe bottleneck for the provision of the required data for, e.g. time-critical investigations. These problems can be addressed by developing an automated processing chain to derive value-added data producing from the remote sensing input data. Effective automated data processing necessitates a data quality assessment prior to actual processing. This paper deals with a processor for an automated data usability assessment that can be integrated into an automated processing chain for operative value adding.","A situation awareness assistant for human deep space explorationThis paper presents the development and testing of a Virtual Camera (VC) system to improve astronaut and mission operations situation awareness while exploring other planetary bodies. In this embodiment, the VC is implemented using a tablet-based computer system to navigate through interactive database application. It is claimed that the advanced interaction media capability of the VC can improve situation awareness as the distribution of human space exploration roles change in deep space exploration. The VC is being developed and tested for usability and capability to improve situation awareness. Work completed thus far as well as what is needed to complete the project will be described. Planned testing will also be described.","The SafeCap Project on Railway Safety Verification and Capacity Simulation ","Accurate dense stereo matching of slanted surfaces using 2D integral imagesThis paper presents an advanced algorithm providing accurate stereo correspondences of two frames through concise disparity gradient estimation at the per-pixel level and 2D integral images. The key contributions of this novel algorithm are twofold: First, combining an upright cross-based support region with disparity gradient estimation realizes the implicit construction of a 3D support region for each anchor pixel. This approach yields the disparity accuracy for slanted surfaces as well as fronto-parallel surfaces. Second, the 2D integral image technique leads to a speedup of matching cost aggregation in the implicit 3D support regions. The experimental results show that the proposed algorithm can successfully convey the correspondences of actual sequence of outdoor stereo images and Middlebury stereo images with high accuracy in near real time.","Modal Logic for Preference Based on Reasons ","Bio-inspired Sensory Data AggregationThe Ambient Intelligence (AmI) research field focuses on the design of systems capable of adapting the surrounding environmental conditions so that they can match the users needs, whether those are consciously expressed or not [4][1]. In order to achieve this goal, an AmI system has to be endowed with sensory capabilities in order to monitor environment conditions and users\u2019 behavior and with cognitive capabilities in order to obtain a full context awareness. Amy systems have to distinguish between ambiguous situations, to learn from the past experience by exploiting feedback from the users and from the environment, and to react to external stimuli by modifying both its internal state and the external state. This work describes a modular multi-tier cognitive architecture which relies on a set of pervasive sensory and actuator devices, that are low intrusive and almost invisible for the users [3]; these features are achieved by adopting the ubiquitous computing paradigm, stating that the sensory and actuator functionalities have to be distributed over many devices pervasively deployed in the environment [5]. The pervasive sensory subsystem is controlled by a centralized AmI engine that allows to guarantee a unitary and coherent reasoning, and that is responsible for further stimuli processing. A parallel can be drawn with the nervous system of complex biological beings, composed by a peripheral nervous system, responsible of collecting and transmitting external stimuli, and a central system, responsible of performing cognitive activities. Whenever the sensory subsystem performs a partial stimuli aggregation, it basically mirrors some components of the human peripheral nervous system which are responsible for filtering perceptual information by means of distributed processing among several neurons [9]. In most cases, the peripheral nervous system does not perform this aggregation; indeed this may not be appropriate when the observed phenomena are not characterized by any apparent regularity. The main contribution of this work is the transposition of this way of aggregating and processing sensory data, typical of biological entities, in an artificial Ambient Intelligence system. This approach is strengthened by several works in literature, belonging to diverse research fields [6][2], showing the usefulness of aggregating and processing data at different levels of abstraction. A large set of sensory devices deployed in the same environment, allows to observe the manifold facets of an irregular phenomenon [7][8]. The rough aggregation of gathered sensory data implies the loss of pieces of information; nevertheless, in order to efficiently deal with a large flow of distinct sensory measurements, it is necessary to choose a suitable architectural paradigm.","Herausforderungen an ein durchg\u00e4ngiges Variantenmanagement in Software-Produktlinien und die daraus resultierende EntwicklungsprozessadaptionIn der Automobilindustrie werden Kundenwunsche zunehmend mittels Elektrik/Elektronik-Komponenten und zugehoriger Software realisiert. Dies fuhrt in der fortlaufenden Entwicklung zu einer steigenden Komplexitat und Variabilitat der Software. Software-Produktlinien (SPL) beschreiben eine Methodik, um solch variantenreiche Softwaresysteme zu beherrschen. Ein durchgangiges Variantenmanagement betrifft samtliche Entwicklungsphasen und deren Abstraktionsebenen. So ermoglicht es ein verbessertes Tracing, zielgenaue Change-Impact-Analysen und durchgangige Fehlerbeseitigungen. Um die Anforderungen an ein durchgangiges Variantenmanagement besser zu verstehen, untersuchten wir eine existierende SPL und fanden voneinander isoliert erstellte Merkmalmodelle vor. Als Ursachen hierfur lassen sich u. a. differenzierte Sichtweisen auf Softwareproduktvarianten in der Entwicklung sowie die fehlende Prozessverankerung der Merkmalmodellierung ausmachen. Eine Harmonisierung der isoliert erstellten Merkmalmodelle gestaltet sich aufwandig und erschwert ein durchgangiges Variantenmanagement.In diesem Beitrag werden industrielle Herausforderungen zum Erreichen eines durchgangigen Variantenmanagement in der Praxis erlautert. Ziel ist es, bestehende Merkmalmodelle zu harmonisieren und Assoziationen zwischen Merkmalen uber die gesamten Entwicklungsphasen und den vorhandenen Abstraktionsebenen herzustellen. Fur eine standardisierte Merkmalmodellierung wird zudem eine Adaption des Entwicklungsprozesses beschrieben.","Distributed clock synchronization algorithm for wide-range TDMA ad hoc networksIn this paper a new distributed clock synchronization algorithm for wireless multihop ad hoc network is presented. The algorithm is based on TSF (Timing Synchronization Function) used in IEEE 802.11. We extended TSF with determination of propagation delay between neighbors. This is especially important for wide-range networks where propagation delays can be significant. The performance analysis of the protocol is carried out with a simulation model.","Scalable-Grain Pipeline Parallelization Method for Multi-core SystemsHow to parallelize the great amount of legacy sequential programs is the most difficult challenge faced by multi-core designers. The existing parallelization methods at the compile time due to the obscured data dependences in C are not suitable for exploring the parallelism of streaming applications. In this paper, a software pipeline for multi-layer loop method is proposed for streaming applications to exploit the coarse-grained pipeline parallelism hidden in multi-layer loops. The proposed method consists of three major steps: 1 transform the task dependence graph of a streaming application to resolve intricate dependence, 2 schedule tasks to multiprocessor system-on-chip with the objective of minimizing the maximal execution time of all pipeline stages, and 3 adjust the granularity of pipeline stages to balance the workload among all stages. The efficiency of the method is validated by case studies of typical streaming applications on multi-core embedded system.","Spatial Database Quality and the Potential Uncertainty SourcesOne of the most significant features of geo-information systems is the creation of geospatial analyses. The analyses are based on fundamental geospatial data which model the landscape in the certain territory of interest. The analyses themselves are often described by a mathematical apparatus which uses a wide range of branches of mathematics, especially vector analysis, differential geometry, statistics, probability, fuzzy logic, etc. The classical mathematical description of analysis is clear and precisely defined. Complex geospatial analyses, however, work above geospatial data that do not have to be homogeneous from the point of view of quality. With respect to the capacity and technological possibilities of the data supplier, the input data can have different level of geometric and thematic accuracy, their thematic attributes can remain unfulfilled or the data can be obsolete to a certain extent. Also the location of objects (e.g. forested areas, soil, water area, etc.) can be uncertain concerning the impossibility to define them accurately (e.g. areas of different soil kinds are blended together) or change with time (coast line of watercourse that changes depending on rainfall). The stated imprecision and uncertainty then influence the result of the complete geospatial analysis. This influence gets bigger with the number of input data objects. The aim of the presented paper is to find a relation between the quality of input data and the reliability of the geospatial analysis result. The authors approach is based on mathematical models of analyses, models of vagueness and uncertainty, as well as from models for quality evaluation. In the research were used real data from the territory of the Czech Republic - current as well as historical - and specific methods of space evaluation used in decision-making processes of commanders and staff of the army.","Cuban Theater Digital Archive: A Multimodal Platform for Theater Documentation and Research ","Probabilistic cue integration for real-time object pose trackingRobust real time object pose tracking is an essential component for robotic applications as well as for the growing field of augmented reality. Currently available systems are typically either optimized for textured objects or for uniformly colored objects. The proposed approach combines complementary interest points in a common tracking framework which allows to handle a broad variety of objects regardless of their appearance and shape. A thorough evaluation of state of the art interest points shows that a multi scale FAST detector in combination with our own image descriptor outperforms all other combinations. Additionally, we show that a combination of complementary features improves the tracking performance slightly further.","Investigating monte-carlo methods on the weak schur problemNested Monte-Carlo Search (NMC) and Nested Rollout Policy Adaptation (NRPA) are Monte-Carlo tree search algorithms that have proved their efficiency at solving one-player game problems, such as morpion solitaire or sudoku 16x16, showing that these heuristics could potentially be applied to constraint problems. In the field of Ramsey theory, the weak Schur numberWS(k) is the largest integer n for which their exists a partition into k subsets of the integers [1,n] such that there is no x&lt;y&lt;z all in the same subset with x+y=z. Several studies have tackled the search for better lower bounds for the Weak Schur numbers WS(k), k\u22654. In this paper we investigate this problem using NMC and NRPA, and obtain a new lower bound for WS(6), namely WS(6)\u2265582.","Component-Based Design and Software ReadymadesEnd-user developers need access to tools and techniques that allow them to create, modify, and extend software artifacts without programming. Previous research has shown that visual software components can provide the right level of abstraction. However, component-based design (CBD) will succeed only if there is a good balance of standardization and flexibility (software issues) and a good balance of usefulness and usability (HCI issues). We present a vision for CBD and two approaches toward achieving it: 1) design by composition and 2) design by redesign. We claim that the latter is more user friendly but lacks the flexibility of the former. We propose the notion of \"software readymade\" as a theoretical concept to integrate them, inspired by the role of the \"spectator\" in the work of the artist Marcel Duchamp. We propose stand-alone multiperspective tailorable software components to instantiate the concept, and we give two examples (application units and nuggets).","Research on Active Vibration Control of Thin-Walled Workpiece in Milling Based on Voice Coil MotorThin-walled workpieces are widely used in the industries of aerospace, national defense, petrochemistry and so on. Workpiece machining vibration induced by cutting tools greatly affects the milling efficiency and accuracy, and hence vibration alleviation has now become a bottleneck technique for the milling process of thin-walled workpieces. An active control method is developed here to attenuate the milling vibration by using voice coil motors and laser displacement detectors as actuators and sensors, respectively. The control algorithm is embedded in a FPGA module, and the closed-loop system is fulfilled by a FPGA card. Finally, this closed-loop control system is examined by vibration control experiments on a thin-walled aluminium alloy workpiece, where the vibration amplitudes have been decreased by 75% with cutting frequency bandwidth of 15Hz. The feasibility and superiority of the proposed active control method and the closed-loop system are thus verified.","Cyber Threats Monitoring: Experimental Analysis of Malware Behavior in Cyberspace ","10 Gbps Current Mode Logic I/O BufferA new architecture for a high speed CML buffer is presented. The buffer is designed for OC-192/STM-64 applications to be used in the limiting amplifier which is a critical block in optical communication systems. OC- 192/STM-64 works around 10Gbps. The proposed architecture is also more efficient in terms of area.","Evaluating the Deployment of a Collection of Images in the CULTURA Environment ","Practical Duplicate Bug Reports Detection in a Large Web-Based Development Community ","Better Lattice Constructions for Solving Multivariate Linear Equations Modulo Unknown Divisors ","A Graph-Based Hierarchical Image Segmentation Method Based on a Statistical Merging Predicate ","An Engineering Design Support Tool Based on TRIZTRIZ contradiction matrix was built after years of study on patent information. Designers using TRIZ contradiction matrix have to identify the improving and worsening features of their design problems and determine the inventive principles to solve their design problems. It is common to identify multiple improving and worsening features and with some features more important than the others. With the updated 2003 and 2010 TRIZ contradiction matrix introduced, more features have been added and hence, there is a need for a software tool based on these TRIZ matrices. This paper presents an engineering design support tool based on TRIZ that allows considerations for multiple improving and worsening features and allows designers to prioritise these features using weights to solve their design problems as well as the option to choose the version of TRIZ they prefer.","CarbonCulture at DECC: digital engagement for sustainability at workThis paper reports on CarbonCulture at DECC, an employee engagement platform for sustainable behaviour, which took place at the Department of Energy &amp; Climate Change in London. Through a participatory design process, we developed simple web apps enabling staff to log actions around late working, food choices and commuting, and see colleagues' actions, providing a digital interface linking physical and spatial behaviour. We achieved a high level of engagement (16% of staff used the apps) and identified patterns of user engagement to inform future development.","Automated Reasoning for Regulatory ComplianceRegulatory compliance is gaining attention from information systems engineers who must design systems that at the same time satisfy stakeholder requirements and comply with applicable laws. In our previous work, we have introduced a conceptual modelling language called Nomos 2 that aids requirements engineers analyze law to identify alternative ways for compliance. This paper presents an implemented reasoning tool that supports analysis of law models. The technical contributions of the paper include the formalization of reasoning mechanisms, their implementation in the NRTool, as well as an elaborated evaluation framework intended to determine whether the tool is scalable with respect to problem size, complexity as well as search space. The results of our experiments with the tool suggest that this conceptual modelling approach scales to real life regulatory compliance problems.","Semi-supervised structuring of complex dataThe objective of the thesis is to explore how complex data can be treated using unsupervised machine learning techniques, in which additional information is injected to guide the exploratory process. Starting from specific problems, our contributions take into account the different dimensions of the complex data: their nature (image, text), the additional information attached to the data (labels, structure, concept ontologies) and the temporal dimension. A special attention is given to data representation and how additional information can be leveraged to improve this representation.","Computational Hardness of Validity in Probability LogicWe consider the complexity of validity in e-logic, a probability logic introduced by Terwijn. We prove that the set of valid formulas is \u03a0 1 1-hard, improving a previous undecidability result by Terwijn.","Erratum: A Noise Removal Algorithm for Time Series Microarray Data ","Knowledge Discovery Methods for Bankruptcy Prediction ","Robots as Adjunct Therapy: Reflections and Suggestions in Rehabilitation for People with Cognitive ImpairmentsThe expanding function of robots in rehabilitation has allowed for new intervention methods that are accurate, motivating and repetitive. By analyzing current state-of-the-art evidences, this paper proposes considerable necessities for robots to take part in the rehabilitation environments. Suggestions focus specifically on intervention for people affected by autism, Cerebral Palsy (CP) and dementia. Overall, a robot in human shape present advantages over other types of robots in autism and CP therapy context as it is physically suitable in imitation-based therapy. However, for elderly people affected with dementia, so far only robots in animal shape have been utilized in therapy and succeed to improve their mental functions.","How to Design a Network of ComparatorsWe discuss the networks of comparators designed for the task of compound object identification. We show how to process input objects by means of their ontology-based attribute representations through the layers of hierarchical structure in order to assembly the degrees of their resemblance to objects in the reference set. We present some examples illustrating how to use the networks of comparators in the areas of image recognition and text processing. We also investigate the ability of the networks of comparators to scale with respect to various aspects of complexity of considered compound object identification problems.","Integration of sparse multi-modality representation and geometrical constraint for isointense infant brain segmentationSegmentation of infant brain MR images is challenging due to insuf- ficient image quality, severe partial volume effect, and ongoing maturation and myelination process. During the first year of life, the signal contrast between white matter (WM) and gray matter (GM) in MR images undergoes inverse changes. In particular, the inversion of WM/GM signal contrast appears around 6-8 months of age, where brain tissues appear isointense and hence exhibit ex- tremely low tissue contrast, posing significant challenges for automated seg- mentation. In this paper, we propose a novel segmentation method to address the above-mentioned challenge based on the sparse representation of the com- plementary tissue distribution information from T1, T2 and diffusion-weighted images. Specifically, we first derive an initial segmentation from a library of aligned multi-modality images with ground-truth segmentations by using sparse representation in a patch-based fashion. The segmentation is further refined by the integration of the geometrical constraint information. The proposed method was evaluated on 22 6-month-old training subjects using leave-one-out cross- validation, as well as 10 additional infant testing subjects, showing superior results in comparison to other state-of-the-art methods.","Flexible design of a modular simultaneous exponentiation core for embedded platformsIn this paper we present a flexible hardware design for performing Simultaneous Exponentiations on embedded platforms. Simultaneous Exponentiations are often used in anonymous credentials protocols. The hardware is designed with VHDL and fit for use in embedded systems. The kernel of the design is a pipelined Montgomery multiplier. The length of the operands and the number of stages can be chosen before synthesis. We show the effect of the operand length and number of stages on the maximum attainable frequency as well as on the FPGA resources being used. Next to scalability of the hardware, we support different operand lengths at run-time. The design uses generic VHDL without any device-specific primitives, ensuring portability to other platforms. As a test-case we effectively integrated the hardware in a MicroBlaze embedded platform. With this platform we show that simultaneous exponentiations with our hardware are performed 70 times faster than with an all-software implementation.","BLOCK: Efficient Execution of Spatial Range Queries in Main-MemoryThe execution of spatial range queries is at the core of many applications, particularly in the simulation sciences but also in many other domains. Although main memory in desktop and supercomputers alike has grown considerably in recent years, most spatial indexes supporting the efficient execution of range queries are still only optimized for disk access (minimizing disk page reads). Recent research has primarily focused on the optimization of known disk-based approaches for memory (through cache alignment etc.) but has not fundamentally revisited index structures for memory. In this paper we develop BLOCK, a novel approach to execute range queries on spatial data in main memory. Our approach is built on the key insight, that in-memory approaches need to be designed to reduce the number of intersection tests (between objects and query but also in the index structure). Our experimental results show that BLOCK outperforms known in-memory indexes as well as in-memory implementations of disk-based spatial indexes up to a factor of 3. The experiments show that it is more scalable than competing approaches as the data sets become denser.","User Interpretations of Virtual Prototypes: Physical place mattersTechnology is known to affect users' understanding of virtual products. We study whether also physical place in which the product images are presented affects our understanding. To study this, we conducted user tests with furniture prototypes that were presented in 3D virtual environments. We focused on user interpretations of virtual prototypes in two distinct physical places: in a fair and in a virtual environment laboratory. The results reveal that, in the laboratory, users broadly focus on techni- cal features, whereas, in a fair, the users' main focus is on product models. The implica- tion of our study highlights the influence of the place in virtual prototype presentations.","Establishing Efficient Routes between Personal CloudsWe address the problem of establishing efficient routes between nodes in disjoint peer-to-peer overlay networks, motivated by the case of personal overlays, each consisting of an ensemble of fixed, mobile, and virtual devices belonging to an individual user. We argue that the problem of route optimization between such systems is different from both routing between single hosts and inter-domain internet routing --- in particular, scale and heterogeneity play a significant role, and the peer networks may wish to hide their topology for privacy reasons. We show that there is a significant tradeoff between efficiency and the degree of network information exposed to one peer network by the other, and present an approach that allows users to flexibly advertise desired information about their networks to one another. In this paper, we focus on optimizing the routes for latency and infer the potential to do the same for various other metrics such as bandwidth, monetary cost and energy consumption.","Development of smart device-based thermostatic control system appling on cooling vestsThis paper presents a smart device-based thermostatic control system for cooling vest application. The whole system consists of three parts: a pump-based circulating cooling system, a temperature sensing module, and an Android-based application software. The smart device uses Bluetooth technology to receive temperature sensor datum from the vest. The thermostatic control App determines whether to turn the pump motor on or off in order to transmit the motor signal to the vest. One smart device can control and record multiple cooling or heating vests at the same time in order to easily manipulate and save resources. A simple experiment was designed and implemented to verify the effect of thermostatic control to the vests. The results showed that this system helps to enhance the duration of the cooling or heating system and provides high efficiency and flexibility. The future work will focus on biomedical signal monitoring and web-based remote control.","An App Approach Towards User Empowerment in Personalized Service EnvironmentsThe laws of identity and privacy protection goals are major require- ments of user-centric personalized service environments. The goal is that users can send master data, preferences, attributes and claims together with policies to relying parties such as Cloud Services Providers in order to control purpose, usage, and availability of personally identifiable information. In order to meet the requirements and to establish a trusted end point this paper introduces a vir- tual representation of a user called LifeApp that can be downloaded and installed by relying partners. On the one hand this approach aims at empowering the user to control access, enforce policies, minimize misusage and enjoy - nonetheless - personalized contextual services. On the other hand relying parties benefit from synchronizing data whenever it changes at the user's or the requester's side. The advantages are up-to-date and authentic user data, simplified customer relationship management, and if needed compliance to local data protection. The paper introduces the app approach to personalized service environments based on the Kantara-UMA protocol.","Prototyping Distributed Collision-Free MAC Protocols for WLANs in Real HardwareCarrier Sense Multiple Access with Enhanced Collision Avoidance (CSMA/ECA) is a totally distributed, collision-free MAC protocol for IEEE 802.11 WLANs. It is capable of achieving greater throughput than the MAC protocol used in the current standard, called Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA), by means of picking a deterministic backoff after successful transmissions. This work is the first implementation of the main concept behind CSMA/ECA on real hardware. Experimental results confirm the advantages of CSMA/ECA over CSMA/CA in terms of throughput and set the ground for its complete prototyping on real hardware using OpenFWWF.","Integration of DANUM-Based Carrier-Grade Mesh Networks and IMS Infrastructure ","Transformation of SBVR Business Rules to UML Class ModelMultiple attempts have been made these days to automate the creation of class diagrams by providing structured English statements as input. The resulting diagrams are of close proximity to what the user wants. This paper is one such attempt to transform business designs written in OMG's (Object Management Group) standard SBVR (Semantics of Business Vocabulary and Rules) framework, into a set of classes in UML (Unified Modeling Language) Class Model using a theoretical approach. SBVR provides a set of specific rules which are processed in order to get class diagram of close proximity. It involves the transformation of \"Structured English\" into a set of UML Class Model with SBVR as a mediator. Further, the results of the approach are validated using VeTIS tool.","Document Difficulty Framework for Semi-automatic Text ClassificationText Classification systems are able to deal with large datasets, spending less time and human cost compared with manual classification. This is achieved, however, in expense of loss in quality. Semi-Automatic Text Classification SATC aims to achieve high quality with minimum human effort by ranking the documents according to their estimated certainty of being correctly classified. This paper introduces the Document Difficulty Framework DDF, a unification of different strategies to estimate the document certainty, and its application to SATC. DDF exploits the scores and thresholds computed by any given classifier. Different metrics are obtained by changing the parameters of the three levels the framework is lied upon: how to measure the confidence for each document-class evidence, which classes to observe class and how to aggregate this knowledge aggregation. Experiments show that DDF metrics consistently achieve high error reduction with large portions of the collection being automatically classified. Furthermore, DDF outperforms all the reported SATC methods in the literature.","An Information Quality Evaluation Framework of Object Tracking SystemsObject tracking systems track moving objects between locations and provide object positioning information. Such systems rely on tracking technologies e.g. Radio Frequency Identification (RFID). The challenge is how to ensure an adequate quality of information at a moderate infrastructure cost. We propose a framework that evaluates information quality (IQ) of object tracking systems, with respect to information completeness and accuracy. The framework models all the alternative configurations of an object tracking system and proposes quantitative metrics of accuracy and completeness as functions of the system configuration. Ultimately, it calculates IQ per configuration and employs the Crisp/Set Qualitative Comparative Analysis (CS/QCA) method to pinpoint specific design solutions that achieve high IQ. The framework is technology/ and application environment/independent and may be employed for both ex/post and ex/ante IQ evaluation of object tracking systems. The framework is illustrated through the IQ assessment of a product tracking system in a retail supply chain.","Towards modularly comparing programs using automated theorem proversIn this paper, we present a general framework for modularly comparing two (imperative) programs that can leverage single-program verifiers based on automated theorem provers. We formalize (i) mutual summaries for comparing the summaries of two programs, and (ii) relative termination to describe conditions under which two programs relatively terminate. The two rules together allow for checking correctness of interprocedural transformations. We also provide a general framework for dealing with unstructured control flow (including loops) in this framework. We demonstrate the usefulness and limitations of the framework for verifying equivalence, compiler optimizations, and interprocedural transformations.","Towards Test Case Reuse: A Study of Redundancies in Android Platform Test Libraries ","LPQ Based Static and Dynamic Modeling of Facial Expressions in 3D Videos ","Interval Type-2 Fuzzy System for Image Edge Detection Quality Evaluation Applied to Synthetic and Real Images ","P4R: Privacy-Preserving Pre-Payments with Refunds for Transportation SystemsWe propose a new lightweight payment scheme for transit systems called P4R: Privacy-Preserving Pre-Payments with Refunds. In P4R a user deposits money to obtain a bundle of credentials, where each credential allows to make an arbitrary ride. The actual fare of a trip is determined on-the-fly when exiting. Overpayments are refunded where all trip refunds of a user are aggregated in a single token thereby saving memory and increasing privacy. We build on Brands' e-cash scheme to realize the pre-payment system and a new variant of blind Boneh-Lynn- Shacham signatures to implement the refund capabilities. Our construc- tion is secure against malicious users and guarantees user privacy. We also provide an efficient implementation that shows the suitability of our scheme as future transit payment system.","Local Logo Recognition System for Mobile DevicesIn this paper, we propose a novel logo recognition system which can process a very large number of logos locally on mobile devices. The system is not only robust against challenging conditions such as different image scale, rotation, and noisy input, but time efficient and low memory consuming as well. The total computation cost is minimized by using a cascade approach, in which the fast algorithm is kept in the first layer to filter most of the testing cases, while the more expensive but robust one is put on the second layer to investigate only the \"confusing\" logos. In this paper, we also propose a \"background subtraction\" method, which considerably improves the second layer in terms of speed, accuracy, and database size. The system has been tested on a dataset of 3000 logos with promising results. The average running-time is just about 1.7 seconds on an average single core mobile device, which is very potential for many mobile applications.","Moving Region Segmentation Using Sparse Motion Cue from a Moving CameraThis paper presents a method for pixel-wise segmentation of mov- ing regions using sparse motion cues on an image from a freely moving camera. The main idea is to utilize residual motion, i.e., motion relative to a background, on sparse grid points. Our algorithm consists of three parts: global motion es- timation, characterization of points based on sparse motion cue, and pixel-wise labeling of moving regions. Experimental results on real image sequences are presented, showing the effectiveness of the proposed method.","Alternating Product Ciphers: A Case for Provable Security Comparisons (extended abstract)We formally study iterated block ciphers that alternate between two sequences of independent and identically distributed (i.i.d.) rounds. It is demonstrated that, in some cases the effect of alternating increases security, while in other cases the effect may strictly decrease security relative to the corresponding product of one of its component sequences. As this would appear to contradict conventional wisdom based on the ideal cipher approximation, we introduce new machinery for provable security comparisons. The comparisons made here simultaneously establish a coherent ordering of security metrics ranging from key-recovery cost to computational indistinguishability.","Approaches to Assessing Public Concerns: Building Linked Data for Public Goals and Criteria Extracted from Textual Content ","The relationship between handlebar and saddle heights on cycling comfortThis study aims to clarify the relationship between handlebar and saddle heights on cycling comforts by assessing the kinematics, kinetics, physiological loading and subjective perceived exertion rating. Twenty young adults with mean age 24.6 years (SD=0.1) were recruited to participate in this study. A commercial city bike with the adjustable handlebar and saddle had been set on the indoor cycling stands. All subjects were asked to ride randomly with 9 different postures (3 handle \u00d73 saddle heights) for continuous one hour. A 3-D motion analysis system (Zebris Medical GmbH, Germany) was used to collect the kinematic data. The body pressure measurement system (Body Pressure Measurement System, Tekscan, U.S.A) was applied to measure the pressure distribution, force and displacement of centre of mass (COM). A heart rate monitor (Polar RS-800, Kempele, Finland) was used to record the heart rate as the physiological loading. Moreover, a subjective perceived exertion rating scale (Borg CR-10) was used to assess subjective comfort around the body regions. The results of this study indicated that the lower handlebar with higher saddle cause greater ROM in wrist-ulnar deviation, wrist extension, trunk flexion and hip abduction. It also reveals more force on hand region, more discomfort around hand, ankle and back, and higher physiological loading. While cycling with higher handlebar and lower saddle, it has more ROM in wrist flexion, more body displacement on buttock region, little trunk forward, and more discomfort rating in buttock region. For handlebar and saddle adjustment, the considerations of body dimensions and characteristics, the relationship between handlebar and saddle heights might improve the cycling comfort and diminish musculoskeletal injury.","Multimodal Sentiment Analysis of Social MediaThis paper describes the approach we take to the analysis of social media, combining opinion mining from text and multimedia (images, videos, etc), and centred on entity and event recognition. We examine a particular use case, which is to help archivists select mater- ial for inclusion in an archive of social media for preserving community memories, moving towards structured preservation around semantic cat- egories. The textual approach we take is rule-based and builds on a number of sub-components, taking into account issues inherent in social media such as noisy ungrammatical text, use of swear words, sarcasm etc. The analysis of multimedia content complements this work in order to help resolve ambiguity and to provide further contextual information. We provide two main innovations in this work: first, the novel combination of text and multimedia opinion mining tools; and second, the adaptation of NLP tools for opinion mining specific to the problems of social media.","An estimation framework of a user learning curve on web-based interface using eye tracking equipmentThis paper addresses an estimation framework of a user learning curve on Web-based interface. Recent Web-based interface has rich features such as \"dynamic menu\", \"animation\" and so forth. A user sometimes gets lost in menus and hyperlinks, but gradually improves the performance of his/her task that is to find target information during the session. This performance change is in a sense considered to be \"learning curve\" as to the Web-based interface. To estimate the \"learning curve\" is necessary to evaluate the Web-based interface from the viewpoint of a user's task achievement. Our proposed estimation framework consists of two steps; One is to identify the relationships among the processing time, eye tracking log, and Web structure. The other is to identify the estimated formula as a \"learning curve\". This paper reports the relationship from preliminary experiment using several Web pages and eye tracking log.","Singing Like a Tenor without a Real VoiceWe describe a multimedia installation that provides users with the experience to sing like a tenor from the early 20th century. The user defines vowels with her mouth but does not produce sound. The mouth shape is recognized and tracked by a depth-sensing camera and synthesized using a dedicated sound analysis using formants. Arm gestures are recognized and used to determine pitch and volume of an artificially generated voice. This synthesized voice is additionally modified by acoustic filters to sound like a singing voice from an old gramophone. The installation allows to scan the user's face and to create an individual 3D model of a tenor character that is used to visualize the user performance.","A flexible approach to multi-level agent-based simulation with the mesoscopic representationLarge-scale simulations often use multiple agent representations to permit the study of specific multi-agent phenomena, and to find a balance between run-time performance and level of detail of the simulation. Although these approaches are effective, they do not always offer the desired level of analysis, especially when this level is between the resolutions of the models available. In this paper, we aim at offering a finer resolution in exploring this trade-off by introducing an intermediate level between two given resolutions, which can apply to all agent models and allows a more progressive transition to offer the desired level of analysis. We introduce a framework for such a methodology and evaluate it through the extension of an existing approach, along two criteria: its impact on computational resources, and an estimate of the dissimilarity between a simulation using our methodology and one without. Initial experiments show that consistency is almost maintained while CPU gain varies from low to significant depending on the context.","Studying Distributed Collaborations Using the Resource Allocation Negotiation Task (RANT) ","Communities, roles, and informational organigrams in directed networks: the Twitter network of the UK riotsDirectionality is a crucial ingredient in many complex networks, in which information, energy or influence are transmitted. We showcase a framework for flow-based analysis for directed networks through the study of a network of influential Twitter users during the 2011 riots in England. Our analysis extracts nuanced descriptions of the network in terms of a multiresolution structure of interest communities within which flows of information are contained and reinforced. Such communities identify groups according to location, profession, employer, and topic, and are largely undetected if edge directionality is ignored. The flow structure also allows us to generate an interest distance, affording a personalised view of the network from any given user. A complementary flow-based analysis leads to a classification of users into five roles beyond the standard leader-follower dichotomy. Integrating both viewpoints, we find that interest communities fall into distinct informational organigrams, which reflect their mix of users and the quality of dialogue. Our generic framework provides insight into how flows are generated, distributed, preserved and consumed in directed networks.","Learning of motor sequences based on a computational model of the cerebellumIn classical conditioning, the repeated presentation of a Conditioning Stimulus (CS) followed by an Unconditioned Stimulus (US) establishes a basic form of associative memory. After several paired CS-US presentations, a Conditioned Response (CR) is elicited by the solely presence of the CS. It is widely agreed that this associative memory is stored in the cerebellum. However, no studies have link this basic form of cerebellar associative learning with the acquisition of sequences of motor actions. The present work suggests that through the Nucleo Pontine Projections (NPPs), a CR elicited by a first CS may be fed-back to the cerebellum, and that this CR can act as the CS for a subsequent CR. This process would allow a single CS to trigger a sequence of learned responses, having a total duration above the timespan of the cerebellar memory trace. We demonstrate this principle with a robotic experiment, where a computational model of the cerebellum that includes the NPPs controls a robot navigating a track with two turns. A predictive cue, the CS, precedes the first turn, but the second one can only be acquired if the previous turn is also used as a CS. After repeated training trials, the robot associates a sequence of two turns to the single CS. This result confirms that the positive feedback established via the NPPs allows the cerbellar model to control an action sequence, and that the duration of the whole sequence can exceed the timespan of a cerebellar memory trace.","Approximation of Fuzzy Measures Using Second Order Measures: Estimation of Andness Bounds ","Interval Logics and \u03c9B-Regular LanguagesIn the recent years, interval temporal logics are emerging as a workable alternative to more standard point-based ones. In this paper, we establish an original connection between these logics and \u03c9B-regular languages. First, we provide a logical characterization of regular (resp., \u03c9-regular) languages in the interval logic AB \u00af B of Allen's relations meets, begun by ,a ndbegins over finite linear orders (resp., N). Then, we lift such a correspondence to \u03c9B-regular languages by substituting AB \u00af B \u00af A for AB \u00af B (AB \u00af B \u00af A is obtained from AB \u00af B by adding a modality for Allen's relation met by). In addition, we show that new classes of extended (\u03c9-)regular languages can be naturally defined in AB \u00af B \u00af A.","Switchback Cursor: Mouse Cursor Operation for Overlapped WindowingWhen we perform a task that involves opening a number of windows, we cannot access the objects behind them. Thus, we are forced to switch the fo- reground window frequently or to move it temporarily. In this paper, we pro- pose a Switchback Cursor technique where the cursor can move underneath windows when the user presses both the left and right mouse buttons. We also discuss some of the advantages of our method and effective situations that may be suited to the Switchback Cursor.","Cloud Computing -- An Approach with Modern CryptographyIn this paper we are proposing an algorithm which uses AES technique of 128/192/256 bit cipher key in encryption and decryption of data. AES provides high security as compared to other encryption techniques along with RSA. Cloud computing provides the customer with the requested services. It refers to applications and services that run on distributed network using virtualized resources and accessed by common IP and network standard. While providing data services it is becoming important to provide security for data. In cloud computing keeping data secure is an important issue to be focused. Even though AES was designed for military purposes, now a days it is been commercially adopted worldwide as it can encrypt most confidential document, as well as it can work in most restricted areas, and offers good defense against various attack techniques, and security level to protect data for next 2-3 decades.","A component-based evaluation protocol for clinical decision support interfacesIn this paper we present our experience in designing and applying an evaluation protocol for assessing usability of a clinical decision support (CDS) system. The protocol is based on component-based usability testing, cognitive interviewing, and a rigorous coding scheme cross-referenced to a component library. We applied this protocol to evaluate alternate designs of a CDS interface for a nursing plan of care tool. The protocol allowed us to aggregate and analyze usability data at various granularity levels, supporting both validation of existing components and providing guidance for targeted redesign.","Virtual Prototype Design of Double Disc Mower Drive Bracket Based on ANSYS Workbench ","A Corpus-Based Approach for the Induction of Ontology LexicaWhile there are many large knowledge bases (e.g. Freebase, Yago, DBpedia) as well as linked data sets available on the web, they typically lack lexical information stating how the properties and classes are realized lexically. If at all, typically only one label is attached to these properties, thus lacking any deeper syntactic information, e.g. about syn- tactic arguments and how these map to the semantic arguments of the property as well as about possible lexical variants or paraphrases. While there are lexicon models such as lemon allowing to define a lexicon for a given ontology, the cost involved in creating and maintaining such lexica is substantial, requiring a high manual effort. Towards lowering this effort, in this paper we present a semi-automatic approach that exploits a corpus to find occurrences in which a given property is ex- pressed, and generalizing over these occurrences by extracting depen- dency paths that can be used as a basis to create lemon lexicon entries. We evaluate the resulting automatically generated lexica with respect to DBpedia as dataset and Wikipedia as corresponding corpus, both in an automatic mode, by comparing to a manually created lexicon, and in a semi-automatic mode in which a lexicon engineer inspected the re- sults of the corpus-based approach, adding them to the existing lexicon if appropriate.","Bayes Optimality of Human Perception, Action and Learning: Behavioural and Neural Evidence ","Pacc - a discriminative and accuracy correlated measure for assessment of classification resultsMeasuring the performance of a classifier properly is important to determine which classifier to use for an application domain. The comparison is not straightforward since different experiments may use different datasets, different class categories, and different data distribution, thus biasing the results. Many performance (correctness) measures have been described to facilitate the comparison of classification results. In this paper, we provide an overview of the performance measures for multiclass classification, and list the qualities expected in a good performance measure. We introduce a novel measure, probabilistic accuracy (Pacc), to compare multiclass classification results and make a comparative study of several measures and our proposed method based on different confusion matrices. Experimental results show that our proposed method is discriminative and highly correlated with accuracy compared to other measures. The web version of the software is available at http://sprite.cs.uah.edu/perf/.","Research and Application of Corrosion Prediction Based on GRA-SVRCorrosion prediction is a technology of finding the corrosion law based on material corrosion data. Due to corrosion data has the characteristics of high dimensional nonlinearity, randomness and limited sizes, many data modeling methods based on large samples are not applicable. In the process of corrosion prediction, we have to deal with missing data values, outlier detec- tion, feature selection and regression. However, feature selection and regression would be the focus of our research in this paper. This paper adopts a modeling method combining of Grey Relational Analysis and Support Vector Regression, referred to as GRA-SVR, the former is used to select feature and the latter is used for regression. The experimental results show that, GRA-SVR method achieves higher precision than other methods such as BP Neural Network.","On transitive parallelisms of PG(3,4)A parallelism in \\(PG(n,q)\\) is transitive if it has an automorphism group which is transitive on the spreads. A parallelism is regular if all its spreads are regular. In \\(PG(3,4)\\) no examples of transitive and no regular parallelisms are known. Transitive parallelisms in \\(PG(3,4)\\) must have automorphisms of order 7. That is why we construct all 482 parallelisms with automorphisms of order 7 and establish that there are neither transitive, nor regular ones among them. We conclude that there are no transitive parallelisms in \\(PG(3,4)\\). The investigation is computer-aided. We use GAP (Groups, Algorithms, Programming\u2014a System for Computational Discrete Algebra) to find a subgroup of order 7 and its normalizer in the automorphism group of \\(PG(3,4)\\). For all the other constructions and tests we use our own software written in C++.","Single and Multi-objective in Silico Evolution of Tunable Genetic OscillatorsWe compare the ability of single and multi-objective evo- lutionary algorithms to evolve tunable self-sustained genetic oscillators. Our research is focused on the influence of objective setup on the suc- cess rate of evolving self-sustained oscillations and the tunability of the evolved oscillators. We compare temporal and frequency domain fitness functions for single and multi-objective evolution of the parameters in a three-gene genetic regulatory network. We observe that multiobjec- tivization can hinder convergence when decomposing a period specific based single objective setup in to a multi-objective setup that includes a frequency specific objective. We also find that the objective decomposi- tion from a frequency specified single objective setup to a multi-objective setup, which also specifies period, enable the synthesis of oscillatory dy- namics. However this does not help to enhance tunability. We reveal that the use of a helper function in the frequency domain improves the tunability of the oscillators, compared to a time domain based single objective, even if no desired frequency is specified.","Cloud Audits and Privacy Risks ","Heuristic Approach to Automatic Wrapper Generation for Social Media Websites ","Qualitative Analysis of Volunteered Geographic Information in a Spatially Enabled Society ProjectThe increase of data sources on the Internet and Web 2.0 advances have contributed to significant changes in the way we produce spatial information. The citizen is using collaborative environments to produce their own data, whether in the area of public security, infrastructure or for simple fun. The voluntary contribution is essential to make a spatially enabled society and help in decision-making process at all levels of a society, whether governmental, private or by the citizen. Analyzing the information gain that is recorded in collaborative Web systems is essential to know what is not being recorded in official data sources. The aim of this study is to evaluate the information gain generated by the user on a project to transform a conventional computerized municipal management for a spatially enabled society.","Overview of the NTCIR-10 Cross-Lingual Link Discovery Task.This paper presents an overview of NTCIR-10 Cross-lingual Link Discovery (CrossLink-2) task. For the task, we continued using the evaluation framework developed for the NTCIR-9 CrossLink-1 task. Overall, recommended links were evaluated at two levels (file-to-file and anchor-to-file); and system performance was evaluated with metrics: LMAP, R-Prec and P@N.","Enhancing a Layout-Aware Synthesis Methodology for Analog ICs by Embedding Statistical Knowledge into the Evolutionary Optimization KernelThis paper applies to the scientific area of electronic design automation (EDA) and addresses the automatic sizing of analog integrated circuits (ICs). Particularly, this work presents an innovative approach to enhance a state-of-the-art layout-aware circuit-level optimizer (GENOM-POF), by embedding statistical knowledge from an automatically generated gradient model into the multi-objective multi-constraint optimization kernel based on the NSGA-II algorithm. The approach was validated with typical analog circuit structures, using the UMC 0.13 \u03bcm integration technology, showing that, by enhancing the circuit sizing optimization kernel with the gradient model, the optimal solutions are achieved, considerably, faster and with identical or superior accuracy. Finally, the results are Pareto Optimal Fronts (POFs), which consist of a set of fully compliant sizing solutions, allowing the designer to explore the different trade-offs of the solution space, both through the achieved device sizes, or the respective layout solutions.","Brain Computer Interface Enhancement by Independent Component Analysis ","Automatic Detection of Facial Landmarks in Images with Different Sources of VariationsAccurate and robust extraction of feature points in 2D facial images has multiple applications in biometric face recognition, facial expression classi- fication, facial animation or human-computer interaction, among others. This pa- per describes a methodology for the fully automatic identification of 20 relevant facial points on static gray level images containing different types of variations. To solve the problem considered, we mainly use the shape and texture informa- tion provided by the images. The main advantage of this approach is its precision at point location, even for images with pronounced expressions. The presented method is tolerant to moderate scale changes and pose variations, and also to different illumination conditions. Our approach was tested on two of the most common databases used for facial expression analysis: Cohn-Kanade and JAFFE datasets, achieving respective average correct point detection rates of 94.2% and 96.15% on them. Our results were also compared to other related results pre- sented in the literature on the same databases.","Parameter Learning and Convergent Inference for Dense Random Fields ","Implementing eHealth Services for Enhanced Pharmaceutical Care Provision: Opportunities and Challenges ","Model-Based Approach for Self-correcting Strategy Design for Manufacturing of Small Metal Parts ","Building a Large Scale Test Collection for Effective Benchmarking of Mobile Landmark SearchStudying and analyzing system performance is one of the fundamental factors for the related technological advancement in image retrieval. In this paper, we report the construction of a large scale test collection for facilitating robust performance evaluation of mobile land- mark image search. Totally, the test collection consists of (1) 355,141 images about 128 landmarks in five cities over 3 continents from Flickr; (2) different kinds of textual features for each image, including surround- ing text (e.g. tags), contextual data (e.g. geo-location and upload time), and metadata (e.g. uploader and EXIF); and (3) six types of low-level visual features. For the task of landmark image retrieval evaluation, we also conduct a series of baseline experimental studies on the search per- formance over different visual queries, which represent different views of a landmark.","The TKB Project: Creative Technologies for Performance Composition, Analysis and Documentation ","Semi-supervised Gaussian Process Ordinal RegressionOrdinal regression problem arises in situations where exam- ples are rated in an ordinal scale. In practice, labeled ordinal data are difficult to obtain while unlabeled ordinal data are available in abun- dance. Designing a probabilistic semi-supervised classifier to perform ordinal regression is challenging. In this work, we propose a novel ap- proach for semi-supervised ordinal regression using Gaussian Processes (GP). It uses the expectation-propagation approximation idea, widely used for GP ordinal regression problem. The proposed approach makes use of unlabeled data in addition to the labeled data to learn a model by matching ordinal label distributions approximately between labeled and unlabeled data. The resulting mixed integer programming problem, involving model parameters (real-valued) and ordinal labels (integers) as variables, is solved efficiently using a sequence of alternating optimization steps. Experimental results on synthetic, bench-mark and real-world data sets demonstrate that the proposed GP based approach makes effective use of the unlabeled data to give better generalization performance (on the absolute error metric, in particular) than the supervised approach. Thus, it is a useful approach for probabilistic semi-supervised ordinal regression problem.","Classification of design decisions: an expert survey in practiceSupport for capturing architectural knowledge has been identified as an important research challenge. As the basis for an approach for recovering design decisions and capturing their rationale we have performed an expert survey in practice to gain insights into the different kinds, influence factors, and sources for design decisions and also on how they are currently captured in practice. The survey has been performed with software architects, software team leads, and senior developers from six different companies in Austria with more than 10 years of experience in software development on average. The survey confirms earlier work by other authors on design decision classification and influence factors but also identifies additional kinds of decisions and influence factors not mentioned in this previous work. In addition, we gained insight into the practice of capturing, the relative importance of different decisions and influence factors, and on potential sources for recovering decisions.","Mechanical verification of SAT refutations with extended resolutionWe present a mechanically-verified proof checker developed with the ACL2 theorem-proving system that is general enough to support the growing variety of increasingly complex satisfiability (SAT) solver techniques, including those based on extended resolution. A common approach to assure the correctness of SAT solvers is to emit a proof of unsatisfiability when no solution is reported to exist. Contemporary proof checkers only check logical equivalence using resolution-style inference. However, some state-of-the-art, conflict-driven clause-learning SAT solvers use preprocessing, inprocessing, and learning techniques, that cannot be checked solely by resolution-style inference. We have developed a mechanically-verified proof checker that assures refutation clauses preserve satisfiability. We believe our approach is sufficiently expressive to validate all known SAT-solver techniques.","Multi-class Cosegmentation with Pairwise Active LearningJointly segmenting common objects from multiple images remains a challenging problem. In this paper, we propose a multi-class cosegmentation method based on correlation clustering, which requires no prior knowledge of the number of clusters. Our method can handle large number of images because of the flexible graph structure and scalable clustering method. Moreover, we use active learning to intelligently recommend pairs of regions to users, in order to get pairwise must-link and cannot-link constraints. Then a novel dimensionality reduction method is proposed to produce an affinity matrix which reflects both the intrinsic structure of data and the constraints. Finally, correlation clustering is applied on the newly generated affinity matrix to acquire refined results. Experimental results show that our system can correct errors of initial segmentation and personalize segmentation result according to user preferences.","WebMate: Generating Test Cases for Web 2.0Web applications are everywhere\u2014well tested web applica- tions however are in short supply. The mixture of JavaScript, HTML and CSS in a variety of different browsers makes it virtually impossible to ap- ply static analysis techniques. In this setting, systematic testing becomes a real challenge. We present a technique to automatically generate tests for Web 2.0 applications. Our approach systematically explores and tests all distinct functions of a web application. Our prototype implementation WEBMATE handles interfaces as complex as Facebook and is able to cover up to 7 times as much code as existing tools. The only requirements to use WEBMATE are the address of the application and, if necessary, user name and password.","Detection of Texture and Isolated Features Using Alternating Morphological Filters ","Modeling Operation of Web Service ","Image Classification by Iterative Semi-Supervised Sparse CodingIn this paper, we propose a novel algorithm, Iterative Semi-supervised Sparse Coding(ISSC), which combines sparse coding and graph-based semi-supervised learning into a unified framework, in order to learn the discriminative sparse codes as well as an effective classification function. The ISSC algorithm fully exploits initial labels and the subsequently predicted labels for sparse codes learning. At the same time, during the graph-based semi-supervised learning stage, the similarity matrix is firstly adjusted through the latest learned sparse codes, and then is utilized to obtain a better classification function. In particular, by solving quadratic optimization, the ISSC approach can give rise to closed-form solution for learned sparse codes. We have extensively evaluated the proposed ISSC method over the widely used datasets for image classification task. The experimental results in terms of classification accuracy demonstrate that the proposed ISSC method is robust and can also achieve significant performance improvements with respect to the state-of-the-arts.","Hierarchical geographical modeling of user locations from social media postsWith the availability of cheap location sensors, geotagging of messages in online social networks is proliferating. For instance, Twitter, Facebook, Foursquare, and Google+ provide these services both explicitly by letting users choose their location or implicitly via a sensor. This paper presents an integrated  generative  model of location and message content. That is, we provide a model for combining distributions over locations, topics, and over user characteristics, both in terms of location and in terms of their content preferences. Unlike previous work which modeled data in a flat pre-defined representation, our model automatically infers both the hierarchical structure over content and over the size and position of geographical locations. This affords significantly higher accuracy --- location uncertainty is reduced by 40% relative to the best previous results [21] achieved on location estimation from Tweets.   We achieve this goal by proposing a new statistical model, the nested Chinese Restaurant Franchise (nCRF), a hierarchical model of tree distributions. Much statistical structure is shared between users. That said, each user has his own distribution over interests and places. The use of the nCRF allows us to capture the following effects: (1) We provide a topic model for Tweets; (2) We obtain location specific topics; (3) We infer a latent distribution of locations; (4) We provide a joint hierarchical model of topics and locations; (5) We infer personalized preferences over topics and locations within the above model. In doing so, we are both able to obtain accurate estimates of the location of a user based on his tweets and to obtain a detailed estimate of a geographical language model.","Practical Implementation of the Nonlinear Control of the Liquid Level in the Tank of Irregular ShapeIn this paper, the control of the liquid level in the tank of irregular (partially conical) shape is considered. The process nonlinearities must be incorporated in the control law to ensure good tracking properties and disturbances rejection despite of the variations of the operating point defined by the desired liquid level. For this purpose, two control strategies are considered: PI+GS (gain scheduling) controller with scheduling function based on the preliminary process identification and B-BAController (Balance-Based Adaptive Controller), which is derived from the nonlinear but significantly simplified model of the process, without any preliminary identification. The control performance of both techniques is verified experimentally and the results show superiority of the latter.","Fuzzy Digital Topology and Geometry and Their Applications to Medical Imaging ","A Novel Template Protection Method Based on Palmprint FeatureIn recent years, there are many algorithms have been reported to tackle biometric template protection problem, which can be divided into two categories, biometric cryptosystem approach and transformed-based approach. Previous work reported a method that combined these two approaches and pro- posed a framework for face biometric. However, this framework just worked for verification mode. In this paper, we combined both transform-based ap- proach and biometric cryptosystem approach, and developed a novel template protection method for identification based on palmprint biometric. The experi- mental results show that the proposed method maintains high identification rate and high security level.","Inclusive Design-Theory: How to take advantage of diversity in Information Systems DesignThe theme of ICIS 2013 in Milan is \u201cReshaping Society through Information Systems \u201d (http://icis2013.aisnet.org/). One aspect of reshaping society that has been recently discussed in central Europe is that of social inclusion (http://ec.europa.eu/social/main.jsp?catId=750l for instance, if design principles can be formalized in order to reshape the information systems design into a different, more-inclusive direction. We contend that IS falls short in tackling this issue. In this panel, Shirley Gregor, Fred Niederman, Eileen Trauth, and Cathy Urquhart reflect on the multiple aspects of social inclusion in the design and the resulting shape of Information Systems. This panel intends to deliver more in-depth results than merely advocating a stance for more diversity in the IS workforce. Building on the principles of Design Science, we believe that our discipline can help reshape the digital economy. As a key takeaway, the panel provides guidance on the impact of gender in IS theorizing as a demonstration example, and reflect on the trend towards Social Design in the IS research community.","Increasing stability of result organization for session searchSearch result clustering (SRC) organizes search results into labeled hierarchical structures as an \"information lay-of-land\", providing users an overview and helping them quickly locate relevant information from piles of search results. Hierarchies built by this process are usually sensitive to query changes. For search sessions with multiple queries, this could be undesirable since it may leave users a seemly random overview and partly diminish the benefits that SRC intents to offer. We propose to integrate external knowledge from Wikipedia when building concept hierarchies to boost their stability for session queries. Our evaluations on both TREC 2010 and 2011 Session tracks demonstrate that the proposed approaches outperform the state-of-the-art hierarchy construction algorithms in stability of search results organization.","The effect of private IT use on work performance - Towards an IT consumerization theory ","Empirical Recovery of Input Nonlinearity in Distributed Element ModelsTwo algorithms recovering an input nonlinearity in a nonlinear distributed element modeled as a Hammerstein system are proposed. The first is based on the empirical distribution function while the other on the empirical Haar orthogonal series. Both algorithms self-adjust their accuracy to a local density of the input measurements.","Honest Compressions and Their Application to Compression SchemesThe existence of a compression scheme for every concept class with bounded VC-dimension is one of the oldest open problems in statistical learning theory. Here we demonstrate the existence of such compression schemes under stronger assumptions than nite VCdimension. Specically, for each concept class we associate a family of concept classes that we call the alternating concept classes. Under the assumption that these concept classes have bounded VC-dimension, we prove existence of a compression scheme. This result is motivated by recent progress in the eld of model theory with respect to an analogues problem. In fact, our proof can be considered as a constructive proof of these advancements. This means that we describe the reconstruction function explicitly. Not less important, the theorems and proofs we present are in purely combinatorial terms and are available to the reader who is unfamiliar with model theory. Also, using tools from model theory, we apply our results and prove existence of compression schemes in interesting cases such as concept classes dened by hyperplanes, polynomials, exponentials, restricted analytic functions and compositions, additions and multiplications of all of the above.","PATHSenrich: A Web Service Prototype for Automatic Cultural Heritage Item EnrichmentLarge amounts of cultural heritage material are nowadays available through online digital library portals. Most of these cultural items have short descriptions and lack rich contextual information. The PATHS project has developed experimental enrichment services. As a proof of concept, this paper presents a web service prototype which allows independent content providers to enrich cultural heritage items with a subset of the full functionality: links to related items in the collection and links to related Wikipedia articles. In the future we plan to provide more advanced functionality, as available offline for PATHS.","An Algorithmic Formulation for Extracting Learning Concepts and Their Relatedness in eBook TextsIn this paper, we present an algorithmic formulation to automatically extract learning concepts and their relationships from eBook texts and to generate an RDF data that can be used for a number of purposes. Our algorithmic approach first extracts various parts of an eBook (such as chapters and sections) and then through a sentence-level parsing scheme identifies learning concepts described in the eBook text. We have programmed for the identification and extraction of relationships between different learning concepts occurring in a section. We have also been able to extract some general data about the eBooks such as author, price, and reviews (through eBook content mining and web crawling). The learning concepts, their relationships and other useful information extracted from the eBooks; is then programmatically transformed into a machine readable RDF data. The automated process of concept and relation extraction and their subsequent storage into RDF data, makes our effort important and useful for tasks like Information Extraction, Concept-based Search and Machine Reading.","How Good is Weak-Stabilization?A weak-stabilizing system is one that guarantees only the possibility of convergence to a correct behavior; i.e., a recovery path may visit an execution cycle before reaching a good behavior. To our knowledge, there has been no work on analyzing the power and performance of weak-stabilizing algorithms. In this paper, we investigate a metric for characterizing the recovery time of weak-stabilizing algorithms. This metric is based on expected mean value of recovery steps for resuming a correct behavior. Our method to evaluate this metric is based on probabilistic state exploration. We show that different weak-stabilizing algorithms perform differently during recovery, because of their structure (e.g., the length and reachability of cycles). We also introduce an automated technique that can improve the performance of implementation of weak-stabilizing algorithms through state encoding.","Homeomorphic Geometrical Transform for Collision Response in Surgical SimulationA new technique for multi-point collision response among 3D objects is presented. The method is applied to the interpenetration be- tween deformable and non-deformable models. Accuracy in the response to collided points is a critical premise that determines the fidelity and the stability of the subsequent deformations. Previous approaches as- sume a set of simplifications in the collision models that usually derives in inadequate model behaviors. The method pursues a twofold objective: (1) to consider the 3D character of the surgical instruments (2) to cope with the complex nature, concavities and convexities, of the interpen- etrated volume. For that purpose, an overall approximation of a local deformation is performed. First, the fidelity of each local deformation is modeled as a combination of penetration and sliding forces inferred from a feedback fuzzy logic system, and, second, the stability of the global deformation is ensured by the definition of an homeomorphic transfor- mation which enforces the preservation of the topology of deformable objects. A linear combination of a set of Compact Supported Radial Ba- sis Functions (CS-RBF) provides a customary mathematical description for finding a smooth displacement field. The resulting deformation field is thus expressed as an optimization problem. Preliminary results show its suitability and benefits for surgical simulation. Minimally Invasive Surgery (MIS) is consolidating as an alternative to the treat- ment of surgical affections against conventional surgery, due to the advantages it shows both in terms of patient safety and of economical costs. However, from a surgeon perspective, it requires the acquisition of new capacities related to spa- tial perception and dexterity. Among the different methods currently considered for MIS training, Virtual Reality (VR) plays a key role and it is foreseeable it may take the lead in the early future. Two inherent advantages from this sort of training techniques are their traceability (for evaluating the correct course, position, and execution time of the surgeon's hands), and their reproducibility (for training the ability to perform different procedures without patient risks). J.M. Sanches, L. Mico, and J.S. Cardoso (Eds.): IbPRIA 2013, LNCS 7887, pp. 433-440, 2013. c","SocACL: An ASP-Based Access Control Language for Online Social Networks ","Matching Ads in a Collaborative Advertising SystemClassical contextual advertising systems suggest suitable ads to a given webpage, without relying on further information - i.e. just analyzing its content. Although we agree that the target webpage is im- portant for selecting ads, in this paper we concentrate on the importance of taking into account also information extracted from the webpages that link the target webpage (inlinks). According to this insight, contextual advertising can be viewed as a collaborative filtering process, in which selecting a suitable ad corresponds to estimate to which extent the ad matches the characteristics of the \"current user\" (the webpage), together with the characteristics of similar users (the inlinks). We claim that, in so doing, the envisioned collaborative approach is able to improve classi- cal contextual advertising. Experiments have been performed comparing a collaborative system implemented in accordance with the proposed approach against (i) a classical content-based system and (ii) a system that relies only on the content of similar pages (disregarding the target webpage). Experimental results confirm the validity of the approach.","Semantic Recommendation of Information Sources for Lifelong LearningLifelong learning LLL has been debated in educational environments for more than a decade, but with the proliferation of mobile and wireless communication technologies and pervasiveness of educational environments, it has penetrated into our everyday lives and changed our perception on formal education. If we accept that LLL will have a bigger role in traditional education, and remove barriers between formal and informal learning, then we may open a range of new possibilities for modern learners, who decide what, when, why and how they wish to learn. In this paper we address the problem of choosing suitable learning sources in various situations we may encounter in LLL. We propose a semantic recommendation of learning sources, based on OWL/SWRL enabled computations for the purpose of supporting learners in lifelong learning environments. We use the example of learners in the healthcare domain in order to demonstrate both: the availability of online information and learning sources which support lifelong learning in healthcare, and the way we can address the needs of individual learners who are in a situation to learn informally. We focus on OWL/SWRL enabled computations because they a secure semantic interpretation of environments where lifelong learning takes place and b guarantee reasoning which results in recommendations of suitable learning sources in a particular situation in LLL.","Measuring the Impact of Communication in Agile Development: A Research Model and Pilot Test ","Hydrodynamic design optimization of trawl-door shapes with local surrogate modelsTrawl-doors have a large influence on the fuel consumption of fishing vessels. Design and optimization of trawl-doors using computational models are a key factor in minimizing the fuel consumption. This paper presents an optimization algorithm for the shape design of trawl-door shapes using computational fluid dynamic (CFD) models. Accurate CFD models are computationally expensive. Therefore, the direct use of traditional optimization algorithms, which often require a large number of evaluations, may prohibitive. The proposed approach is iterative and uses low-order local response surface approximation models of the expensive CFD model, constructed in each iteration, to reduce the number of evaluations. The algorithm is applied to the design of a two-element trawl-door (slat and airfoil), involving four design variables controlling the angle of attack and the slat position and orientation. The results show that a satisfactory design can be obtained at the cost of a few iterations of the algorithm.","Electroencephalogram Dynamics during Social Communication among Multiple PersonsThe brain dynamics of social behavior are important for un- derstanding the group intelligence that occurs in humans. Coordinated behavior between two subjects has been used as an experimental model of social behavior, but the creativity occurring in a group of multiple persons has not yet been discussed. In this study, a rhythmic commu- nication task was proposed as a model of social communication, and simultaneous electroencephalogram (EEG) of three subjects were evalu- ated. Results showed that the decrease of theta-band power in the EEG was correlated with the rhythm delay in the ensemble pattern, and the decreases of upper and lower alpha-band power were associated with the rhythm tempo and the rareness of ensemble pattern. This suggests that the theta- and alpha-band powers in the EEG associate with so- cial communication and cross-frequency EEG dynamics is essential for understanding the creativity in the social behavior.","An Approach for a Mutual Integration of the Web of Things with Business Processes ","An Energy Efficient Layer for Event-Based Communications in Web-of-Things Frameworks ","Modeling of Autonomous Vehicle Operation in Intelligent Transportation Systems ","An Analytical Approach to Single Node Delay-Coupled Reservoir ComputingReservoir computing has been successfully applied in difficult time series prediction tasks by injecting an input signal into a spatially extended reservoir of nonlinear subunits to perform history-dependent nonlinear computation. Recently, the network was replaced by a single nonlinear node, delay-coupled to itself. Instead of a spatial topology, subunits are arrayed in time along one delay span of the system. As a result, the reservoir exists only implicitly in a single delay differential equation, numerical solving of which is costly. We derive here approximate analytical equations for the reservoir by solving the underlying system explicitly. The analytical approximation represents the system accurately and yields comparable performance in reservoir benchmark tasks, while reducing computational costs by several orders of magnitude. This has important implications with respect to electronic realizations of the reservoir and opens up new possibilities for optimization and theoretical investigation.","Na\u00efve Bayes Ant Colony Optimization for Experimental Design ","Pupil response to precision in surgical task execution. ","Security Aspects of Virtualization in Cloud Computing ","Compression of Propositional Resolution Proofs by Lowering SubproofsThis paper describes a generalization of the LowerUnits algorithm for the compression of propositional resolution proofs. The generalized algorithm, here called LowerUnivalents, is able to lower not only units but also subproofs of non-unit clauses, provided that they satisfy some additional conditions. This new algorithm is particularly suited to be combined with the RecyclePivotsWithIntersection algorithm. A formal proof that LowerUnivalents always compresses more than LowerUnits is shown, and both algorithms are empirically compared on thousands of proofs produced by the SMT-Solver veriT.","Benefits Quantification in IT ProjectsThe probability of IT project failures can be mitigated more success- fully when discovered early. To support an early detection, transparency regard- ing a project's cash flows shall be increased. Therefore, an appropriate analysis and calculation of a project's costs, benefits, risks and interdependencies is in- evitable. Until today, however, a method that appropriately considers these fac- tors when estimating the ex ante project business case does not yet exist. Using the Action Design Research approach, we designed, applied and tested a practi- cable and integrated method of determining the monetary value of IT projects to generate generalized insights to benefits management. This method was con- jointly developed by practice and academia, to ensure practical applicability while upholding scientific rigor. Furthermore, to support understandability of the method, we provide an application example.","Mirror Prox Algorithm for Multi-Term Composite Minimization and Alternating DirectionsIn the paper, we develop a composite version of Mirror Prox algorithm for solving convex-concave saddle point problems and monotone variational inequalities of special structure, allowing to cover saddle point/variational analogies of what is usually called \"composite minimization\" (minimizing a sum of an easy-to-handle nonsmooth and a general-type smooth convex functions \"as if\" there were no nonsmooth component at all). We demonstrate that the composite Mirror Prox inherits the favourable (and unimprovable already in the large-scale bilinear saddle point case) $O(1/\\epsilon)$ efficiency estimate of its prototype. We demonstrate that the proposed approach can be naturally applied to Lasso-type problems with several penalizing terms (e.g. acting together $\\ell_1$ and nuclear norm regularization) and to problems of the structure considered in the alternating directions methods, implying in both cases methods with the $O(\\epsilon^{-1})$ complexity bounds.","From Foursquare to my Square: Learning Check-in Behavior from Multiple SourcesLocation-based services often use only a single mobility data source, which typically will be scarce for any new user when the system starts out. We propose a transfer learning method to characterize the temporal distribution of places of individuals by using an external, additional, large-scale check-in data set such as Foursquare data. The method is applied to the next place prediction problem, and we show that the incorporation of additional data through the proposed method improves the prediction accuracy when there is a limited amount of prior data.","Extending the Dependency Taxonomy of Agile Software DevelopmentSystems and software development is a collaborative activity and agile software development epitomises collaboration by formalising how teams and their customers work together to develop a software product. Collaboration is achieved, in part, using mechanisms for coordinating interdependent work. Coordination is defined as the managing of dependencies and this study explores the nature of dependencies in software development projects. Firstly, this study extends an existing taxonomy of dependencies based on evidence from agile projects by showing that three agile and one non-agile project show the same pattern of dependencies. Secondly, this study finds that knowledge dependencies are the most frequently occurring dependencies in these small co-located software projects. The key contribution of this research is a better understanding of the dependencies in software development projects. Understanding dependencies can lead to more informed selection of coordination mechanisms, and ultimately more effective collaboration.","A Transfer-Learning Approach to Image Segmentation Across Scanners by Maximizing Distribution SimilarityMany successful methods for biomedical image segmentation are based on supervised learning, where a segmentation algorithm is trained based on manually labeled training data. For supervised-learning algorithms to perform well, this training data has to be representative for the target data. In practice however, due to differences between scanners such representative training data is often not available.#R##N##R##N#We therefore present a segmentation algorithm in which labeled training data does not necessarily need to be representative for the target data, which allows for the use of training data from different studies than the target data. The algorithm assigns an importance weight to all training images, in such a way that the Kullback-Leibler divergence between the resulting distribution of the training data and the distribution of the target data is minimized.#R##N##R##N#In a set of experiments on MRI brain-tissue segmentation with training and target data from four substantially different studies our method improved mean classification errors with up to 25% compared to common supervised-learning approaches.","Multi class learning with individual sparsityMulti class problems are everywhere. Given an input the goal is to predict one of a few possible classes. Most previous work reduced learning to minimizing the empirical loss over some training set and an additional regularization term, prompting simple models or some other prior knowledge. Many learning regularizations promote sparsity, that is, small models or small number of features, as performed in group LASSO. Yet, such models do not always represent the classes well. In some problems, for each class, there is a small set of features that represents it well, yet the union of these sets is not small. We propose to use other regularizations that promote this type of sparsity, analyze the generalization property of such formulations, and show empirically that indeed, these regularizations not only perform well, but also promote such sparsity structure.","Integration of MapReduce with an Interactive Boosting Mechanism for Image Background Subtraction in Cultural Sightseeing ","Structured representation for core elements of common clinical decision support interventions to facilitate knowledge sharing. ","Runtime Adaptation of Component Based SystemsThe need for continuously available software systems and their ability to support runtime adaptation is increasingly considered as one key issue in the software development. In particular, the software architecture of dynamically adaptive component based systems must continuously adapt to varying environmental conditions and user requirements. Therefore, they propose a wide range of possible adaptations that can not all be foreseen at design time. In this context, we propose to combine the Architecture Description Languages and the Aspect-Oriented Software Development which allow to make the adaptation process easier to design, understand and possible to validate.","Beats Down: Using Heart Rate for Game Interaction in Mobile Settings ","Path Planning with Compressed All-Pairs Shortest Paths DataAll-pairs shortest paths (APSP) can eliminate the need to search in a graph, providing optimal moves very fast. A major challenge is storing pre-computed APSP data efficiently. Recently, compression has successfully been employed to scale the use of APSP data to roadmaps and gridmaps of realistic sizes. We develop new techniques that improve the compression power of state-of-the-art methods by up to a factor of 5. We demonstrate our ideas on game gridmpaps and the roadmap of Australia. Part of our ideas have been integrated in the Copa CPD system, one of the two best optimal participants in the grid-based path planning competition GPPC.","FWLS: A Local Search for Graph Coloring ","Flow Specification Patterns of End-User Programmers: Lessons Learnt from a Health Mobile Application Authoring Environment Design ","A comparative study on evolutionary algorithms for many-objective optimization.Many-objective optimization has been gaining increasing at- tention in the evolutionary multiobjective optimization community, and various approaches have been developed to solve many-objective prob- lems in recent years. However, the existing empirically comparative studies are often restricted to only a few approaches on a handful of test problems. This paper provides a systematic comparison of eight represen- tative approaches from the six angles to solve many-objective problems. The compared approaches are tested on four groups of well-defined con- tinuous and combinatorial test functions, by three performance metrics as well as a visual observation in the decision space. We conclude that none of the approaches has a clear advantage over the others, although some of them are competitive on most of the problems. In addition, different search abilities of these approaches on the problems with dif- ferent characteristics suggest a careful choice of approaches for solving a many-objective problem in hand.","Semantically-Enabled Environmental Data Discovery and Integration: Demonstration Using the Iceland Volcano Use Case ","Stakeholder Salience Changes in an e-Government Implementation ProjectIn this article we discuss in what ways an e-government project can give both expected and unexpected effects for agency employees and their working tasks. The purpose of this article is to illustrate the fact that, besides the aim to increase agency efficiency and citizen benefit, e-government implementation might also change the salience of involved stakeholders. We do this by focusing on one stakeholder group which was reluctant and hesitating in the beginning of the studied project; marginalized, passive, easily convinced, and old-fashioned. After the e-government implementation, this group had turned to satisfied, proud, influential, active, powerful, and modern IT users. The case shows how stakeholder salience might change over time in an e-government project. Stakeholder influence aspects and IT driven change aspects are intertwined. This makes it necessary for any e-government project to address the notion of stakeholder involvement in decision-making during the development and implementation phases, but also to acknowledge e-services force to change how things and people are perceived during these phases.","Modeling body shape from surface landmark configurationsDetailed statistical models of body size and shape are valuable for wide range of statistical analyses. Most body shape models represent a single posture, usually standing. Previous efforts to model both posture and body shape have parameterized posture using joint angles. This paper presents a statistical model of body shape in supported seated postures using a posture measured derived from surface landmarks rather than internal joint locations and angles. This method is not limited by a particular kinematic linkage deformation and so is particularly well suited to model the effects on body shape of posture changes in complex linkages such as the spine or shoulder.","Software Component Replication for Improved Fault-Tolerance: Can Multicore Processors Make It Work?Programs increasingly rely on the use of complex component libraries, such as in-memory databases. As any other software, these li- braries have bugs that may lead to the application failure. In this work we revisit the idea of software component replication for masking software bugs in the context of multi-core systems. We propose a new abstraction: a Macro-Component .A Macro-Component is a software component that includes several internal replicas with diverse implementations to detect and mask bugs. By relying on modern multicores processing capacity it is possible to execute the same operation in multiple replicas concurrently, thus incurring in minimal overhead. Also, by exploring the multiple ex- istent implementations of well-known interfaces, it is possible to use the idea without incurring in additional development cost.","NetworkING: using character relationships for interactive narrative generationIn this work, we revisit the duality between character and plot in Interactive Storytelling, and demonstrate the important role of social relationships between virtual characters in the generation of narrative: an aspect that has hitherto been overlooked as a generation mechanism. We argue that the structure of social relationships between characters can be used as a powerful mechanism to determine a narrative, putting less emphasis on the details of plot structure. This enables character relationships in the network and the situations which naturally arise from character interactions to act as key drivers for narrative generation. The mechanism is fully implemented in a demonstration system which allows the exploration of the impact of changes in the social network on narrative diversity using a baseline set of narrative actions typical of the popular medical drama genre. Experimental results confirm our expectation that changes in the relationships between virtual agents in a social network can yield significant qualitative difference in system-generated narratives. This constitutes a new mechanism for narrative generation somehow closer to how modern dramas are shaped in specific genres, where situations and relationships are determinant.","Traffic Radar: A Holonic Traffic Coordination System Using PROSA++ and D-MASThis paper presents Traffic Radar, a holonic traffic coordination system focusing on the distributed and dynamic nature of traffic systems. Two main architectural assets enable distributed real-time coordination, the holonic PROSA++ architecture and the delegate multi-agent system D-MAS pattern. Well proven and accurate first-order traffic models are used to model local traffic behaviour. Link and node holons encapsulate local traffic models and offer services to other holons and D-MAS ants in the environment. Early experiments with the Traffic Radar platform show its ability to forecast traffic flows and densities based on individual user intentions. Moreover, they show the ability to explore different routing solutions incorporating traffic density forecasts.","Carrier Aggregation for Enhancement of Bandwidth in 4G SystemsSince ITU-R had officially completed the formal definition of Third Generation (3G) systems in 1997, focus has been shifted to the Fourth Generation (4G) wireless cellular systems. The paper provides an overview of the different aspects of the proposed carrier aggregation technique, which would enable LTE-A systems to fully utilize the wider bandwidths up to 100MHz and as well maintain the backward compatibility with LTE systems. The contiguous and non contiguous carrier aggregation techniques have been discussed and their deployment scenarios have been illustrated. The technique of carrier aggregation will not only provide a wide bandwidth of 100 MHz but shall also help in achieving higher peak data rates and better coverage for medium data rates.","Face verification across age progressing based on active appearance model and gradient orientation pyramidFace verification in the presence of age progression is an important problem that has not been widely addressed. In this paper, we propose to use the Active Appearance Model (AAM) and Gradient Orientation Pyramid (GOP) feature representation for this problem. We use the AAM on the dataset and then get the representation of Gradient Orientation on a hierarchical model, which the appearance of GOP. When combined with a support vector machine (SVM), the representation demonstrates excellent performance in our experiments.","Hardware acceleration of genetic sequence alignmentNext generation DNA sequencing machines have been improving at an exceptional rate; the subsequent analysis of the generated sequenced data has become a bottleneck in current systems. This paper explores the use of reconfigurable hardware to accelerate the short read mapping problem, where the positions of millions of short DNA sequences are located relative to a known reference sequence. The proposed design comprises of an alignment processor based on a backtracking variation of the FM-index algorithm. The design represents a full solution to the short read mapping problem, capable of efficient exact and approximate alignment. We use reconfigurable hardware to accelerate the design and find that an implementation targeting the MaxWorkstation performs considerably faster and more energy efficient than current CPU and GPU based software aligners.","Legibility of Letters in Reality, 2D and 3D ProjectionVirtual prototypes are essential for engineers to understand the complex structures and arrangements of mechatronic products like automobiles. Currently, Virtual Environments (VE) are used for visual analysis and interaction with virtual models. In the next years more supplementary information will be integrated in the VE, completing the 3D-model. This includes names of single parts, corresponding materials or masses. However, up till now there is little explicit research on the psychological effects of additional text visualization in VE's. For example it un- clear if it is possible to visualize the textual information like on paper prints or on 2D displays. The current study empirically compares these types of different output mediums to advise rules for visualization of text in 3D Virtual Environments. Re- sults show, that textual information has to be slightly enlarged for the 3D Virtual Environment. In addition, subjects performed better in conditions with projected textual information compared to real text.","An Evidential and Context-Aware Recommendation Strategy to Enhance Interactions with Smart Spaces ","A Human-Inspired Collision Avoidance Method for Multi-robot and Mobile Autonomous RobotsIn this paper a novel and dynamic rectangular roundabout ('rectabout') collision avoidance method based on human behaviour is presented for multiple, homogeneous, autonomous and mobile robots. The approach does not depend on priority schemes and instead involves only local views. There is therefore no need for inter-robot communica- tion. The decentralized collision avoidance maneuver employs a virtual rectabout that allows each robot to re-plan its path. This maneuver is calculated independently by each robot involved in the possible collision. The virtual rectabout lies in the intersecting and conflicting position of two robot routes. Experimental simulations involving multi-robot sys- tems indicate that virtual rectabouts ensure that all robots remain free of collision while attempting to follow their goal direction. Comparisons with a centralized collision detection and avoidance approach demon- strate no additional move costs. However, the advantages of rectabouts are that no inter-robot communication or centralized coordination is re- quired, thereby cutting down significantly on communication and coor- dination overheads.","Review of : Basset, Herv\u00e9, Stuart, David &amp; Silber, Denise From Science 2.0 to Pharma 3.0 : Semantic search and social media in the pharmaceutical industry and STM publishing. Oxford: Chandos Publishing, 2012.Review of : Basset, Herve, Stuart, David &amp; Silber, Denise From Science 2.0 to Pharma 3.0 : Semantic search and social media in the pharmaceutical industry and STM publishing. Oxford: Chandos Publishing, 2012.","Usability Evaluation of the Agile Software ProcessAgile development methods are most flexible approach for software development where the development team keeps on improving the software with ongoing involvement of user. Despite its flexibility approach in software development, agile methods are still lacking usability evaluation approaches in their development, and integration of usability evaluation into agile development methods is not adequately addressed. In Agile software development, emphasis on requirement gathering and development of comprehensive feasibility reports is not considered in detail. Traditional software development considered this documentation as a quality attribute for the success of the project. Rapid solutions provided by agile software methods leads to the deficiency of good design and architecture which renders the project as expensive. As a remedy, a proposed life cycle for agile software development has been designed. The proposed life cycle outlined in this paper integrates usability evaluation concepts and agile software methodologies for the development of interactive software. To achieve the results, a survey form was formulated and carried out. The results show a greater interest of usability at the initial stage of software development along with user participation and involvement at each stage. The experiment was conducted in the software company by developing an interactive desktop-based application to evaluate the proposed life cycle and IEEE Std. 12207-2008, ISO 9241:210 was used to validate the proposed software model.","Towards a Theoretical Framework for Organizational Innovation. ","Recognition of Agents Based on Observation of Their Sequential BehaviorWe study the use of inverse reinforcement learning (IRL) as a tool for recognition of agents on the basis of observation of their sequential decision behavior. We model the problem faced by the agents as a Markov decision process (MDP) and model the observed behavior of an agent in terms of forward planning for the MDP. The reality of the agent's decision problem and process may not be expressed by the MDP and its policy, but we interpret the observation as optimal actions in the MDP. We use IRL to learn reward functions for the MDP and then use these reward functions as the basis for clustering or classification models. Experimental studies with GridWorld, a navigation problem, and the secretary problem, an optimal stopping problem, show algorithms' performance in different learning scenarios for agent recognition where the agents' underlying decision strategy may be expressed by the MDP policy or not. Empirical comparisons of our method with several existing IRL algorithms and with direct methods that use feature statistics observed in state-action space suggest it may be superior for agent recognition problems, particularly when the state space is large but the length of the observed decision trajectory is small.","Using evolutionary computation to create vectorial Boolean functions with low differential uniformity and high nonlinearityThe two most important criteria for vectorial Boolean functions used as S-boxes in block ciphers are differential uniformity and nonlinearity. Previous work in this field has focused only on nonlinearity and a different criterion, autocorrelation. In this paper, we describe the results of experiments in using simulated annealing, memetic algorithms, and ant colony optimisation to create vectorial Boolean functions with low differential uniformity.","Coreference annotation schema for an inflectional languageCreating a coreference corpus for an inflectional and free-word-order language is a challenging task due to specific syntactic features largely ignored by existing annotation guidelines, such as the absence of definite/indefinite articles (making quasi-anaphoricity very common), frequent use of zero subjects or discrepancies between syntactic and semantic heads. This paper comments on the experience gained in preparation of such a resource for an ongoing project (CORE), aiming at creating tools for coreference resolution.#R##N##R##N#Starting with a clarification of the relation between noun groups and mentions, through definition of the annotation scope and strategies, up to actual decisions for borderline cases, we present the process of building the first, to our best knowledge, corpus of general coreference of Polish.","Object Recognition and Modeling Using SIFT FeaturesIn this paper we present a technique for object recognition and modelling based on local image features matching. Given a complete set of views of an object the goal of our technique is the recognition of the same object in an image of a cluttered environment containing the object and an estimate of its pose. The method is based on visual modeling of objects from a multi-view representation of the object to recognize. The first step consists of creating object model, selecting a subset of the available views using SIFT descriptors to evaluate image similarity and relevance. The selected views are then assumed as the model of the object and we show that they can effectively be used to visually represent the main aspects of the object.#R##N##R##N#Recognition is done making comparison between the image containing an object in generic position and the views selected as object models. Once an object has been recognized the pose can be estimated searching the complete set of views of the object. Experimental results are very encouraging using both a private dataset we acquired in our lab and a publicly available dataset.","Foot Detection in Czech Using Pitch Information and HMMIn the presented work we are dealing with modelling and detection of lexical stress-group (foot) for Czech language. Detection of foot as one type of supra-segmental (prosody) information nearly corresponds to detection of word boundaries. Every native speaker is able to distinguish the feet in continuous speech, but on the other hand there are still no obvious connections between the sound qualities (pitch, intensity, syllable length) and foot prominence realization in Czech. In the experiment we tried to train the Hidden Markov Models (HMM) for Czech feet representation using only pitch information in the syllable nu- clei. The most of Czech SPEECON database was used as an experiment source database. A necessary part of the presented system is a tool that transforms given Czech text into the foot units according to the known linguistic rules.","Deploying hardware locks to improve performance and energy efficiency of hardware transactional memoryIn the search for new paradigms to simplify multithreaded programming, Transactional Memory (TM) is currently being advocated as a promising alternative to lock-based synchronization. Among the two most important alternatives proposed for conflict detection and data versioning in today's Hardware Transactional Memory systems (HTMs), the Lazy-Lazy one allows increased concurrency, potentially bringing higher performance levels in most cases. Unfortunately, the implementation of the commit protocol in Lazy-Lazy systems results in increased complexity and has severe impact on performance and energy consumption. In this work, we propose GCommit, an efficient and low cost hardware implementation of the SEQ commit protocol based on the use of hardware locks. Specifically, GCommit deploys hardware locks to ensure exclusive access to shared data at commit time. Implementing this functionality using dedicated hardware brings important benefits in terms of execution time as well as energy consumption with respect to traditional commit protocols that use the general-purpose interconnection network . Additionally, our proposal has negligible requirements in terms of area. Results for a 16-core CMP show that the GCommit protocol obtains average reductions of 15.7% and 13.7% in terms of execution time and energy consumption, respectively, compared with a traditional implementation of Scalable TCC with SEQ, a high-performance commit protocol proposed in the literature.","Interdependencies and Collaborative Action for Platform Leadership: A Comparative Analysis of Two Leading Chinese Multi-Sided Digital Platforms. ","Stochastic Maximum Principle for Hilbert Space Valued Forward-Backward Doubly SDEs with Poisson Jumps ","A Balanced, Systems Approach to Business Process Management Aligned to Hospital Strategy ","Transforming Formal Specification Constructs into Diagrammatic NotationsSpecification plays a vital role in software engineering to facilitate the development of highly dependable software. Various techniques may be used for specification work. Z is a formal specification language that is based on a strongly-typed fragment of Zermelo-Fraenkel set theory and first-order logic to provide for precise and unambiguous specifications. While diagrammatic specification languages may lack precision, they may, owing to their visual characteristics be a lucrative option for advocates of semi-formal specification techniques. In this paper we investigate to what extent formal constructs, e.g. Z may be transformed into diagrammatic notations. Several diagrammatic notations are considered and combined for this purpose.","Risks of Profiling and the Limits of Data Protection Law1 Abstract. Profiling and automated decision-making may pose risks to individuals. Possible risks that flow forth from profiling and automated decision-making in- clude discrimination, de-individualisation and stereotyping. To mitigate these risks, the right to privacy is traditionally invoked. However, given the rapid tech- nological developments in the area of profiling, it is questionable whether the right to informational privacy and data protection law provide an adequate level of pro- tection and are effective in balancing different interests when it comes to profiling. To answer the question as to whether data protection law can adequately protect us against the risks of profiling, I will discuss the role of data protection law in the context of profiling and automated decision-making. First, the specific risks asso- ciated with profiling and automated decision-making are explored. From there I examine how data protection law addresses these risks. Next I discuss possible limitations and possible drawbacks of data protection law when it comes to the is- sue of profiling and automated decision-making. I conclude with several sugges- tions to for making current data protection law more effective in dealing with the risks of profiling. These include more focus on the actual goals of data processing and 'ethics by design'.","Kalman filter with augmented measurement model: an ECG imaging simulation studyECG imaging is a non-invasive technique of characterizing the electrical activity and the corresponding excitation conduction of the heart using body surface ECG. The method may provide great opportunities in the planning of cardiac interventions and in the diagnosis of cardiac diseases. This work introduces an algorithm for the imaging of transmembrane voltages that is based on a Kalman filter with an augmented measurement model. In the latter, a regularization term is integrated as additional \"measurement\". The filter is trained using a-priori-knowledge from a simulation model. Two effects are investigated: the influence of the training data on the reconstruction quality and the representation of a-priori knowledge in the trained covariance matrices. The proposed algorithm shows a promising quality of reconstruction and may be used in the future to introduce generic physiological knowledge in solutions of cardiac source imaging.","Role of protein aggregation and interactions between \u03b1 -synuclein and calbindin in parkinson's diseaseParkinson's disease is one of the neurodegenerative diseases caused by protein aggregation. It has been reported that the proteins, \u03b1-synuclein and calbindin are related with Parkinson's disease. However, the interactions between these proteins and their relationship with protein aggregation prone regions have not yet been explored. In this work, we have systematically analyzed the characteristic features of amino acid residues in \u03b1-synuclein and calbindin, and obtained a structural model for the complex using protein docking procedures. The structural model of calbindin:\u03b1-synuclein complex structure was used to identify the binding site residues based on distance and energy based criteria. The aggregation prone regions in these proteins were identified using different computer programs and compared with binding site residues. Specific residues, which participate in aggregation and preventing calbindin-\u03b1-synuclein complex formation were explored and these residues may be main causes for Parkinson's disease. Further, we have carried out mutational analysis and estimated the energetic contributions of the aggregation prone regions towards stability. The results obtained in the present work would provide insights to understand the integrative role of protein-protein interactions and protein aggregation in Parkinson's disease and lead to new directions for inhibiting this disease.","Kernel Spectral Clustering for Motion Tracking: A First Approach ","On the tradeoff between economic efficiency and strategy proofness in randomized social choiceTwo fundamental notions in microeconomic theory are efficiency---no agent can be made better off without making another one worse off---and strategyproofness---no agent can obtain a more preferred outcome by misrepresenting his preferences. When social outcomes are probability distributions (or lotteries) over alternatives, there are varying degrees of these notions depending on how preferences over alternatives are extended to preference over lotteries. We show that efficiency and strategyproofness are incompatible to some extent when preferences are defined using stochastic dominance (SD) and therefore introduce a natural weakening of SD based on Savage's sure-thing principle (ST). While random serial dictatorship is SD-strategyproof, it only satisfies ST-efficiency. Our main result is that strict maximal lotteries---an appealing class of social decision schemes due to Kreweras and Fishburn---satisfy SD-efficiency and ST-strategyproofness.","An Architecture for Dynamic Web Service Provisioning Using Peer-to-Peer Networks ","Blocking Artifact Reduction in DIBR Using an Overcomplete 3D DictionaryIt has been reported that the image quality and depth perception rates are undesirably decreased by compression in DIBR. This is because high- frequency components are filtered by compression, and thus several compression artifacts occur. Blocking artifacts are the most representative ones which seriously degrade the picture quality, and are annoying to viewers. The fundamental cause of the coding artifacts is that the 3D contents are delivered to users over the existing 2D broadcast infrastructures which employ BDCT coding as image compression techniques. In this paper, we propose a new deblocking method in 3D images, i.e., video-plus-depth, using an overcomplete 3D dictionary. We generate the 3D dictionary from natural and depth images using the k-singular value decomposition (K-SVD) algorithm, and estimate an error threshold to utilize the 3D dictionary using a compression factor of the compressed images. Experimental results demonstrate that the proposed method is very effective in reducing undesirable blocking artifacts in 3D images.","Improved Algorithms Based on the Simple Particle Swarm Optimization ","A GENERIC BAYESIAN BELIEF MODEL FOR SIMILAR CYBER CRIMESBayesian belief network models designed for specific cyber crimes can be used to quickly collect and identify suspicious data that warrants further investigation. While Bayesian belief models tailored to individual cases exist, there has been no consideration of generalized case modeling. This paper examines the generalizability of two case-specific Bayesian belief networks for use in similar cases. Although the results are not conclu- sive, the changes in the degrees of belief support the hypothesis that generic Bayesian network models can enhance investigations of similar cyber crimes.","Toward Community-Driven Interest Management for Distributed Virtual EnvironmentA fundamental requirement for the discovery and the re- trieval of the entities of a distributed virtual environment is the definition of a scalable Interest Management (IM) support. This paper presents a distributed protocol for IM that integrates two different gossip protocols. The first one based on a discrete tessellation of the Area of Interest of a peer in order to maximise its coverage by the peer neighbours. The second is based on a distributed algorithm enabling the peers to self-organise themselves in communities. The paper presents a set of experimental results showing the effectiveness of the proposed approach.","Moving frames for heart fiber geometryElongated cardiac muscle cells named cardiomyocytes are densely packed in an intercellular collagen matrix and are aligned to helical segments in a manner which facilitates pumping via alternate contraction and relaxation. Characterizing the geometrical variation of their groupings as cardiac fibers is central to our understanding of normal heart function. Motivated by a recent abstraction by Savadjiev et al. of heart wall fibers into generalized helicoid minimal surfaces, this paper develops an extension based on differential forms. The key idea is to use Maurer-Cartan's method of moving frames to study the rotations of a frame field attached to the local fiber direction. This approach provides a new set of parameters that are complimentary to those of Savadjiev et al. and offers a framework for developing new models of the cardiac fiber architecture. This framework is used to compute the generalized helicoid parameters directly, without the need to formulate an optimization problem. The framework admits a straightforward numerical implementation that provides statistical measurements consistent with those previously reported. Using Diffusion MRI we demonstrate that one such specialization, the homeoid, constrains fibers to lie locally within ellipsoidal shells and yields improved fits in the rat, the dog and the human to those obtained using generalized helicoids.","Crowdsourcing Software Requirements and Development: A Mechanism-based Exploration of 'Opensourcing'Many commercial software firms rely on open source software (OSS) communities as a source of innovation and skilled labor. One specific form of interaction with OSS communities, termed \u2018opensourcing\u2019, involves firms collaborating with an OSS community by \u2018crowdsourcing\u2019 software production. However, beyond the existence of the phenomenon, little is known about how opensourcing, as a model of software production, works. The objective of this study is to explore opensourcing arrangements in a vertical software domain with a view to delineating enabling mechanisms that explain how firms can collaborate with communities to crowdsource the production of software. Using an in-depth case study of the production of hospital software in Thailand, this study explores how opensourcing is used to determine requirements, identify bugs, and provide user-to-user support in addition to the more traditional approach of crowdsourcing software code. The analysis reveals the operation of six high-level mechanisms (motivation, coordination, effective communication, filtering, integration, and nurturing) and reveals how they operate in conjunction with each other to facilitate opensourcing.","Mining sub-trajectory cliques to find frequent routesKnowledge of the routes frequently used by the tracked objects is embedded in the massive trajectory databases. Such knowledge has various applications in optimizing ports' operations and route-recommendation systems but is difficult to extract especially when the underlying road network information is unavailable. We propose a novel approach, which discovers frequent routes without any prior knowledge of the underlying road network, by mining sub-trajectory cliques. Since mining all sub-trajectory cliques is NP-Complete, we proposed two approximate algorithms based on the Apriori algorithm. Empirical results showed that our algorithms can run fast and their results are intuitive.","Recognition of periodic behavioral patterns from streaming mobility dataUbiquitous location-aware sensing devices have facilitated collection of large volumes of mobility data streams from moving entities such as people and animals, among others. Extraction of various types of periodic behavioral patterns hidden in such large volume of mobility data helps in understanding the dynamics of activities, interactions, and life style of these moving entities. The ever-increasing growth in the volume and dimensionality of such Big Data on the one hand, and the resource constraints of the sensing devices on the other hand, have made not only high pattern recognition accuracy but also low complexity, low resource consumption, and real-timeness important requirements for recognition of patterns from mobility data. In this paper, we propose a method for extracting periodic behavioral patterns from streaming mobility data which fulfills all these requirements. Our experimental results on both synthetic and real data sets confirm superiority of our method compared with existing techniques.","Decentralized coordination via task decomposition and reward shapingIn this work, we introduce a method for decentralized coordination in cooperative multiagent multi-task problems where the subtasks and agents are homogeneous. Using the method proposed, the agents cooperate at the high level task selection using the knowledge they gather by learning subtasks. We introduce a subtask selection method for single agent multi-task MDPs and we extend the work to multiagent multi-task MDPs by using reward shaping at the subtask level to coordinate the agents. Our results on a multi-rover problem show that agents which use the combination of task decomposition and subtask based difference rewards result in significant improvement both in terms of learning speed, and converged policies.","Automatic requirement categorization of large natural language specifications at mercedes-benz for review improvementsContext and motivation: Today's industry specifications, in particular those of the automotive industry, are complex and voluminous. At Mercedes-Benz, a specification and its referenced documents often sums up to 3,000 pages. Question/problem: A common way to ensure the quality in such natural language specifications is technical review. Given such large specifications, reviewers have major problems in finding defects, especially consistency or completeness defects, between requirements with related information, spread over the various documents. Principal ideas/results: In this paper, we investigate two specifications from Mercedes-Benz, whether requirements with related information spread over many sections of many documents can be automatically classified and extracted using text classification algorithms to support reviewers with their work. We further research enhancements to improve these classifiers. The results of this work demonstrate that an automatic classification of requirements for multiple aspects is feasible with high accuracy. Contribution: In this paper, we show how an automatic classification of requirements can be used to improve the review process. We discuss the limitations and potentials of using this approach.","Dynamic Filtering of Useless Data in an Adaptive Multi-Agent System : Evaluation in the Ambient DomainAmadeus is an Adaptive Multi-Agent System whose goal is to observe and to learn users\u2019 behaviour in an ambient system in order to perform their recurrent actions on their behalf. Considering the large number of devices (data sources) that generally compose ambient systems, performing an efficient learning in such a domain requires filtering useless data. This paper focuses on an extended version of Amadeus taking account this requirement and proposes a solution based on cooperative interactions between the different agents composing Amadeus. An evaluation of the performances of our system as well as the encouraging obtained results are then shown.","The Use of Transfer Algorithm for Clustering Categorical DataWe propose a new method for clustering categorical data. Clustering algorithms need to be designed specifically for categorical data because it has a different nature from numerical data. Here our focus is on the partition paradigm of algorithms. One existing approach is to transform categorical data into binary data and then use k-means. However it's computationally inefficient. Another approach is k-modes, which extends k-means by replacing means with modes. In our work, we show that the center-based objective function of k-modes can not produce accurate clustering results. Instead, we propose an objective function that is generalized from the k-means objective, but not based on centers. We show that it's more effective than the center-based objective and demonstrate it with real-life datasets. We also find that by using a particular algorithm called transfer algorithm, the proposed objective function can be efficiently solved. Thus our method is both efficient and effective.","Splitting of Operads and Rota-Baxter Operators on OperadsThis paper establishes a procedure that splits the operations in any algebraic operad, generalizing previous notions of splitting algebraic structures, from the dendriform algebra of Loday splitting the associative operation to the successors splitting binary operads. The separately treated bisuccessor and trisuccessor for binary operads are unified for general operads through the notion of configuration. Applications are provided for various n-algebras, the \\(A_{\\infty }\\) and \\(L_{\\infty }\\) algebras. Further, the concept of a Rota-Baxter operator, first showing its importance in the associative and Lie algebra contexts and then generalized to binary operads, is defined for all operads. The well-known connection from Rota-Baxter operators to dendriform algebras and its numerous extensions are expanded as the link from (relative) Rota-Baxter operators on operads to splittings of the operads","Accurate probability calibration for multiple classifiersIn classification problems, isotonic regression has been commonly used to map the prediction scores to posterior class probabilities. However, isotonic regression may suffer from overfitting, and the learned mapping is often discontinuous. Besides, current efforts mainly focus on the calibration of a single classifier. As different classifiers have different strengths, a combination of them can lead to better performance. In this paper, we propose a novel probability calibration approach for such an ensemble of classifiers. We first construct isotonic constraints on the desired probabilities based on soft voting of the classifiers. Manifold information is also incorporated to combat overfitting and ensure function smoothness. Computationally, the extended isotonic regression model can be learned efficiently by a novel optimization algorithm based on the alternating direction method of multipliers (ADMM). Experiments on a number of real-world data sets demonstrate that the proposed approach consistently outperforms independent classifiers and other combinations of the classifiers' probabilities in terms of the Brier score and AUC.","Neutral Speech to Anger Speech Conversion Using Prosody ModificationIn this paper, the dynamics of prosodic features are exploited for speech emotion conversion. In particular, emotion conversion of neutral speech to anger speech is accomplished. The database used for analysis of prosody is the Indian Institute of Technology Kharagpur Simulated Emotion Speech Corpus (IITKGP-SESC). The prosodic features considered for the study are pitch contour, intensity contour, and duration contour. Objective test is performed in terms of average of pitch contour and intensity contour. Subjective listening test results show that the effectiveness of perception of emotion is better in the case of pitch contour modification at the beginning and ending of utterance than for the whole utterance. The results show that the synthesized anger speech is perceived very close to natural anger emotion.","Network Anomaly Classification by Support Vector Classifiers Ensemble and Non-linear Projection Techniques ","Aggregating information from the crowd and the networkIn social systems, information often exists in a dispersed manner, as individual opinions, local insights and preferences. In order to make a global decision however, we need to be able to aggregate such local pieces of information into a global description of the system. Such information aggregation problems are key in setting up crowdsourcing or human computation systems. How do we formally build and analyze such information aggregation systems? In this talk we will discuss three different vignettes based on the particular information aggregation problem and the \"social system\" that we are extracting the information from.   In our first result, we will analyze a crowdsourcing system consisting of a set of users and binary choice questions. Each user has a specific reliability that determines the user's error rate in answering the questions. We show how to give an unsupervised algorithm for aggregating the user answers in order to simultaneously derive the user expertise as well as the truth values of the questions.   Our second result will deal with the case when there is an interacting user community on a question answer forum. User preferences of quality are now expressed in terms of (\"best answer\" and \"thumbs up/down\") votes cast on each other's content. We will analyze a set of possible factors that indicate bias in user voting behavior - these factors encompass different gaming behavior, as well as other eccentricities. We address the problem of aggregating user preferences (votes) using a supervised machine learning framework to calibrate such votes. We will see that this supervised learning method of content-agnostic vote calibration can significantly improve the performance of answer ranking and expert ranking.   The last part of the talk will describe how it is possible to exploit local insights that users have about their friends in order to improve the efficiency of surveying in a (networked) population. We will describe the notion of \"social sampling\", where participants in a poll respond with a summary of their friends' putative responses to the poll. The analysis of social sampling leads to novel trade-off questions: the savings in the number of samples(roughly the average size of neighborhood of participants) vs. the systematic bias in the poll due to the network structure. We show bounds on the variances of few such estimators - experiments on real world networks show this to be a useful paradigm in obtaining accurate information with small number of samples.","Spectral Expansion Solution Methodology for QBD-M Processes and Applications in Future Internet Engineering ","Sparse signal analysis using ramanujan sumsIn this paper, we perform sparse signal analysis by using the Ramanujan Sums (RS). The RS are orthogonal in nature and therefore offer excellent energy conservation. Our analysis shows that the RS can compress the energy of a periodic impulse chain signal into fewer number of RS coefficients than the Fourier transform (FT). In addition, the RS are faster than the FT in computation time because we can calculate the RS basis functions only once and save them to a file. We can retrieve these RS basis functions for our calculation instead of computing them online. To process a signal of 128 samples, we spend 1.0 millisecond for the RS and 5.82 milliseconds for the FT by using our unoptimized Matlab code.","CROWD LABOR MARKETS AS PLATFORM FOR IS RESEARCH: FIRST EVIDENCE FROM ELECTRONIC MARKETSCrowd labor markets such as Amazon Mechanical Turk (MTurk) have emerged as popular platforms where researchers can inexpensively run web-based experiments. Recent work even suggests that MTurk can be used to run large-scale field experiments such as prediction markets in which participants interact synchronously in real-time. Besides technical issues, several methodological questions arise and lead to the question of how results from MTurk and laboratory experiments compare. In this work we provide first insights into running market experiments on MTurk and compare the key property of markets, information efficiency, to a laboratory setting. The results are mixed at best. On MTurk, information aggregation took place less frequently than in the lab. Our results suggest that MTurk participants cannot handle as much complexity as laboratory participants in time-pressured, synchronized experiments.","Explicit context-aware kernel map learning for image annotationIn kernel methods, such as support vector machines, many existing kernels consider similarity between data by taking into account only their content and without context. In this paper, we propose an alternative that upgrades and further enhances usual kernels by making them context-aware. The proposed method is based on the optimization of an objective function mixing content, regularization and also context. We will show that the underlying kernel solution converges to a positive semi-definite similarity, which can also be expressed as a dot product involving \"explicit\" kernel maps. When combining these context-aware kernels with support vector machines, performances substantially improve for the challenging task of image annotation.","Speech Signals Parameterization Based on Auditory Filter ModelingThis paper presents a parameterization technique of speech signal based on auditory filter modeling by the Gammachirp auditory filterbank (GcFB), which is designed to provide a spectrum reflecting the spectral proper- ties of the cochlea filter, which is responsible of frequency analysis in the hu- man auditory system. The center frequencies of the GcFB are based on the ERB-rate scale, with the bandwidth of the Gammachirp filter is measured in Equivalent Rectangular Bandwidth (ERB) of human auditory filters. Our pa- rameterization approach gives interesting results vs. other standard techniques such as LPC (Linear Prediction Coefficients), PLP (Perceptual Linear Predic- tion), for recognition of isolated words of speech from the TIMIT database. The recognition system is implemented on HTK platform (Hidden Toolkit) based on the Hidden Markov Models with Gaussian Mixture observation continuous densities (HMM-GM).","Designing Enhanced Daily Digital Artifacts Based on the Analysis of Product Promotions Using Fictional Animation StoriesThe virtual forms present dynamically generated visual images containing information that influences a users behavior and thinking. In a typical way, adding a display to show visual expressions or projecting some information on an artifact offers computational visual forms on the existing daily artifacts. Using virtual forms is a very promising way to enhance artifacts surrounding us, and to make our daily life and business richer and more enjoyable. We believe that incorporating fictional stories into virtual forms offers a new possibility for enriching user experiences. In particular, integrating fictional stories into our daily activities through transmedia storytelling is a promising approach. Transmedia storytelling enables virtual forms to be employed everywhere to immersively integrate fictional stories into our daily activities. If we can design attractive virtual forms in a structured way, it will become easy to enrich user experiences. Currently, the design framework for virtual forms is not well defined. The framework needs to take into account the semiotic aspect of a virtual form. One key factor, in particular, is how strongly we believe in the reality of a fictional story within the virtual form. In this paper, we show the extracted insights discussed in the workshops and present some design implications for designing virtual forms that integrate fictional stories into our daily activities.","Vision Based Page Segmentation Algorithm: Extended and Perceived SuccessWeb pages consist of different visual segments, serving different purposes. Typical structural segments are header, right or left columns and main content. Segments can also have nested structure which means some segments may include other segments. Understanding these segments is important in properly displaying web pages for small screen devices and in alternative forms such as audio for screen reader users. There exist different techniques in identifying visual segments in a web page. One successful approach is Vision Based Segmentation Algorithm (VIPS Algorithm) which uses both the underlying source code and also the visual rendering of a web page. However, there are some limitations of this approach and this paper explains how we have extended and improved VIPS and built it in Java. We have also conducted some online user evaluations to investigate how people perceive the success of the segmentation approach and in which granularity they prefer to see a web page segmented. This paper presents the preliminary results which show that, people perceive segmentation with higher granularity as better segmentation regardless of the web page complexity.","Argumentation Theory for Decision Support in Health-Care: A Comparison with Machine LearningThis study investigates role of defeasible reasoning and argumentation theory for decision-support in the health-care sector. The main objective is to support clinicians with a tool for taking plausible and rational medical decisions that can be better justified and explained. The basic principles of argumentation theory are described and demonstrated in a well known health scenario: the breast cancer recurrence problem. It is shown how to translate clinical evidence in the form of arguments, how to define defeat relations among them and how to create a formal argumentation framework. Acceptability semantics are then applied over this framework to compute arguments justification status. It is demonstrated how this process can enhance clinician decision-making. A well-known dataset has been used to evaluate our argument-based approach. An encouraging 74% predictive accuracy is compared against the accuracy of well-established machine-learning classifiers that performed equally or worse than our argument-based approach. This result is extremely promising because not only demonstrates how a knowledge-base paradigm can perform as well as state-of-the-art learning-based paradigms, but also because it appears to have a better explanatory capacity and a higher degree of intuitiveness that might be appealing to clinicians.","Automata on Directed Graphs for the Recognition of Assembly Lines ","Competence measurement and informatics standards in secondary educationAs a result of the OECD Program for International Student Assessment (PISA) the development and assessment of educational standards became a high level objective in the German educational system. Following this tendency the German Informatics Society (GI) in 2008 published educational standards of informatics for lower secondary education that describe minimal informatics requirements for high school students. Up until now, no coherent competence model for the standards exists, but it is essential as a basis for the development of measurement instruments to adequately assess learners' competences according to the standards.#R##N##R##N#This paper describes the process and a first specific step to develop such a competence measurement tool for the informatics standards. In order to figure out if it is possible to use already existing competence measurement tools for those purposes we compare the MoKoM competence model with the informatics standards categories. In this project an empirically proofed competence model of Informatics with the target group of senior class students and related measurement tools were developed.#R##N##R##N#As a result of this analytical comparison we identify concurrent competence components of both concepts. For those components already existing empirical items of the MoKoM model could be applied to measure students' respective competences of the informatics standards. On the other hand the analysis reveals competence structures according to the standards that still needs to be supplemented with operationalized empirical items.","Towards a Semantic-Aware Collaborative Working EnvironmentCollaborative Working Environments (CWEs) enable an efficient collaboration between professionals, specially those settled in different locations of a company or stakeholders from different companies. This can be of great help for small and medium enterprises (SMEs), as an effective way to share information. However, it can be difficult for SMEs to have access to a fully integrated CWE providing different tools (e.g., videoconferencing, instant messaging, etc.). Currently, they may define a CWE as a combination of heterogeneous and non-integrated tools which are not able to share information between them. An integrated CWE would provide SMEs with the necessary means to collaborate, making information exchange easier.","Physiological responses and kansei evaluation on awarenessFor tasks in which the steps to achieve a goal are not specified, a user adopts the trial and error method to achieve the goal. If the system is able to induce \"awareness\" to user, the goal can be achieved in an effective manner. We aim to elucidate the mechanism of \"awareness\" in order to develop a system that incorporates induction of \"awareness\".#R##N##R##N#In this study, we examined the changes in the physiological indices of autonomic nervous activity before and after the occurrence of \"awareness\". We selected three types of tasks, namely, a jigsaw puzzle, a slide puzzle, and target shooting for which \"awareness\" was represented by the following items: \"can see the end in sight\", \"I think I may do it\", and \"grasp the techniques\". Kansei evaluation was performed for each task.","Preservation of Utility through Hybrid k-AnonymizationAnonymization-based privacy protection ensures that published data cannot be linked back to an individual. The most common approach in this domain is to apply generalizations on the private data in order to maintain a privacy standard such as k-anonymity. While generalization-based techniques preserve truthfulness, relatively small output space of such techniques often results in unacceptable utility loss especially when privacy requirements are strict. In this paper, we introduce the hybrid generalizations which are formed by not only generalizations but also the data relocation mechanism. Data relocation involves changing certain data cells to further populate small groups of tuples that are indistinguishable with each other. This allows us to create anonymizations of finer granularity confirming to the underlying privacy standards. Data relocation serves as a tradeoff between utility and truthfulness and we provide an input parameter to control this tradeoff. Experiments on real data show that allowing a relatively small number of relocations increases utility with respect to heuristic metrics and query answering accuracy.","Social network path analysis based on HBaseOnline social network services have become indispensable in people's daily life. The analysis of data in social network services often in- volves data mining techniques. However, the quick increase of users in such services posts challenges to develop effective data mining algorithms to deal with large social network data. In this paper, we propose a data-mining algo- rithm to get the shortest path between nodes in a social network. Based on HBase(1), this algorithm analyzes the social network model, and uses the in- termediary degrees and degree central algorithm to optimize the output from cloud platform. With a simulated social network, we validate the efficiency of the algorithm.","A Representation of an Old Polish Dictionary Designed for Practical ApplicationsWe describe an efficient representation of an old Polish dic- tionary designed for practical applications. This representation consists of two components: a memory-efficient automaton and a binary version of the dictionary. We have developed a separate automata library and we show some practical applications of the library within the context of the old Polish dictionary.","Power Reduction in Embedded Systems Using a Design Methodology Based on Synchronous Finite State Machines ","Role of OBA Approach in Object-Oriented Process Modelling and Simulation ","On the Encoding Invariance of Polynomial Time Computable Distribution EnsemblesThe notion of polynomial time invertibly samplable distribu- tions (PISamp) was introduced by Vereshchagin in (9) as a tool to prove (NP,PSamp) completeness, which is more convenient than previously used polynomial time computable distributions (PComp). The notion of a PISamp distribution is encoding invariant, while PComp distributions are not, if one-way permutations exist. Here we prove that PComp dis- tributions are not encoding invariant under a weaker assumption that one-way functions exist. This implies that the class of PISamp distribu- tions is strictly larger than that of PComp distributions (under the same assumption).","From Landscape to Portrait: A New Approach for Load Curve Data Analysis and CleansingLoad curve data is critical in the demand-response management of smart grid. The quality of load curve data, however, is hard to guarantee since the data is subject to communication losses, meter malfunctions, and many other impacts. We present a new approach to organize the load curve data so that many tasks such as data visualization, outlier detection, and data cleansing become easy. Our method adopts a new view, termed portrait, on the load curve data by analyzing the periodical patterns in the data and re-organizing the data for ease of analysis. We introduce algorithms to build the virtual portrait of load curve data, and demonstrate its application on load curve data cleansing with real-world trace data. Compared to existing methods using regression-based time series analysis, our method is much faster and more accurate for both small-scale and large-scale datasets.","A Computational Approach to Detecting and Assessing Sustainability-related Communities in Social Media ","Comparing Input Modalities for Peripheral Interaction: A Case Study on Peripheral Music ControlAbstract. In graphical user interfaces, every application usually asks for the us-er\u2019s full attention during interaction with it. Even marginal side activities often force the user to switch windows, which results in attention shifts and increased cognitive load. Peripheral interaction addresses this problem by providing input facilities in the periphery of the user\u2019s attention by relying on divided attention and human capabilities such as proprioception and spatial memory. Recent work shows promising results by shifting tasks to the periphery for parallel task execution. Up to now, most of these interfaces rely on tag-based objects, tokens or wearable devices, which need to be grasped and manipulated, e.g., by turn-ing, moving or pressing the device. To explore this design space further, we implemented three modalities for peripheral interaction with a desktop audio player application \u2013 graspable inte-raction, touch and freehand gestures. In an eight-week in-situ deployment, we compared the three modalities to each other and to media keys (as the state-of-the-art approach). We found that all modalities can be successfully used in the (visual and attentional) periphery and reduce the amount of cognitive load when interacting with an audio player. With this work we intend to (1) illustrate the variety of possible modalities beyond graspable interfaces, (2) give insights on manual peripheral interaction in general and the respective modalities in particular and (3) elaborate on paper based prototypes for the evaluation of peripheral interaction.","Cluster Analysis of Collective Behavior for a Robotic SwarmSwarm robotics is a new research field of multi-robot sys- tems which generally consists of many homogeneous autonomous robots without a global controller. Since a robotic swarm is controlled by an emergent way of many interactions with the other robots or an environ- ment, such as a result of self-organization, robot learning or artificial evolution, no method has been known to grasp the macroscopic collec- tive behavior in a practical sense, according to the best of our knowledge. In this paper, based on this situation, a novel method for analyzing the macroscopic collective behavior inspired by a technique in the field of complex network is proposed. The effectiveness of the proposed method is demonstrated on a robotic swarm behavior for the cooperative transport problem by extracting the community structure based on the modularity optimization.","Independent Component Analysis for EEG Data Preprocessing - Algorithms Comparison ","Efficient Baseline-Free Sampling in Parameter Exploring Policy Gradients: Super Symmetric PGPEPolicy Gradient methods that explore directly in parameter space are among the most effective and robust direct policy search methods and have drawn a lot of attention lately. The basic method from this field, Policy Gradients with Parameter-based Exploration, uses two samples that are symmetric around the current hypothesis to circumvent misleading reward in asymmetrical reward distributed problems gathered with the usual baseline approach. The exploration parameters are still updated by a baseline approach - leaving the exploration prone to asymmetric reward distributions. In this paper we will show how the exploration parameters can be sampled quasi symmetric despite having limited instead of free parameters for exploration. We give a transformation approximation to get quasi symmetric samples with respect to the exploration without changing the overall sampling distribution. Finally we will demonstrate that sampling symmetrically also for the exploration parameters is superior in needs of samples and robustness than the original sampling approach.","Personalizing triggers for charity actionsIn this paper we investigate whether there is scope for personalizing triggers in the domain of charitable action. The first of our two studies focuses on actions promoting human rights (via Amnesty International). While participants in a previous exploratory study had indicated that victim attributes (such as gender, religion, and ethnicity) would not matter at all, we found when observing participants' actions that in fact these attributes mattered greatly. Participants tended to select victim attributes similar to their own, showing a clear potential for personalization. These findings were corroborated by a further study in the area of charitable giving (using the KIVA micro-financing website). The paper also discusses implications for digital behavior intervention.","A Novel Routing Algorithm for On-Chip Communication in NoC on Diametrical 2D Mesh Interconnection Architecture ","Traitor-Traceable Key Pre-distribution Based on Visual Secret SharingIn this paper, we study the problem of traitor-traceable key pre-distribution for general access structures. We propose a new scheme for key pre-distribution using visual secret sharing, where the keys are generated based on certain combinatorial block designs. Our scheme naturally extends for general access structures, and provides a flexible many-to-one function using visual secret sharing concepts to efficiently avoid the problem of pixel expansion. In addition, our proposal accommodates a simple traitor-tracing functionality for video broadcast applications; using efficient PBIBD based combinatorial constructs and visual secret sharing based on random grids. In effect, our scheme provides a novel technique for secure video and image broadcast, using general access structures to reduce collusions, trace forgery, and identify traitors in case there is a collusion. We duly analyze and discuss the efficiency of our scheme for varying number of users in the broadcast network.","Online Voltage Stability Assessment of Power System by Comparing Voltage Stability Indices and Extreme Learning Machine ","The Challenge of Detection and Diagnosis of Fugacious Hardware Faults in VLSI DesignsThe final publication is available at Springer via http://dx.doi.org/10.1007/978-3-642-38789-0_7","Web usage mining with semantic analysisWeb usage mining has traditionally focused on the individual queries or query words leading to a web site or web page visit, mining patterns in such data. In our work, we aim to characterize websites in terms of the semantics of the queries that lead to them by linking queries to large knowledge bases on the Web. We demonstrate how to exploit such links for more effective pattern mining on query log data. We also show how such patterns can be used to qualitatively describe the differences between competing websites in the same domain and to quantitatively predict website abandonment.","Detection and classification of defect patterns in optical inspection using support vector machinesOptical inspection techniques have been widely used in industry as they are non-destructive, efficient to achieve, easy to process, and can provide rich information on product quality. Defect patterns such as rings, semi-circles, scratches, clusters are the most common defects in the semiconductor industry. Most methods cannot identify two scale-variant or shift-variant or rotation-variant defect patterns, which in fact belong to the same failure causes. To address these problems, a new approach has been proposed in this paper to detect these defect patterns in noisy images obtained from printed circuit boards, wafers, and etc. A median filter, background removal, morphological operation, segmentation and labeling are employed in the detection stage of our method. Support vector machine (SVM) is used to identify the defect patterns which are resized. Classification results of both simulated data and real noisy raw data show the effectiveness of our method.","Clothing Extraction by Coarse Region Localization and Fine Foreground/Background EstimationOnline shopping is becoming more and more popular for billions of web users because of its convenience and efficiency. Customers can use content-based product image search engine to find their desired products. However, a frustrating fact is that the search results are significantly affected by the presence of natural backgrounds and fashion models. To minimize the influence of these noises, in this paper, an automatic clothing extraction algorithm is proposed, which consists of two phases: coarse clothing region localization with human proportion, and fine foreground/background modeling. Experiments on two datasets crawled from e-commerce websites demonstrate that the proposed approach achieves good performance, and has competitive performance with the interactive solution.","Process Mining Versus Intention MiningProcess mining aims to discover, enhance or check the conformance of activity-oriented process models from event logs. A new field of research, called intention mining, recently emerged. This field has the same objectives as process mining but specifically addresses intentional process models (processes focused on the reasoning behind the activities). This paper aims to highlight the differences between these two fields of research and illustrates the use of min- ing techniques on a dataset of event logs, to discover an activity process model as well as an intentional process model.","Using video prototyping as a means to involve crisis communication personnel in the design process: innovating crisis management by creating a social media awareness toolSocial media is increasingly used for all kinds of everyday communication, with vast amounts of user-generated content being continuously generated and published. The data provides a new form of information source that can be exploited for obtaining additional knowledge regarding a subset of the population. Although it might be difficult to organize and assess individual text fragments, valuable insights contributing to the overall situational awareness can also be gained through acquiring social media texts and analyzing statistical properties in the data in near real-time. One such avenue of approach which is currently being developed is to analyze the text content linguistically and extract measures regarding the overall feelings and attitudes that people express in relation to an ongoing crisis. To make use of this kind of new information requires the algorithms and the resulting statistics to be designed and presented according to operational crisis management needs. In this paper, we describe the involvement of crisis management stakeholders in a series of user-centered activities in order to understand the needs, and design a useful tool. In particular, video prototyping has been used as method for quickly capturing a first explicit design idea based on real life experience, that could later be used for further generalization and tool design.","A Fast Semi-blind Reverberation Time Estimation Using Non-linear Least Squares MethodReverberation Time (RT) estimation is of great importance in de-reverberation techniques and characterizing room acoustics. Esti- mating and updating the RT parameter of an enclosed environment could be carried out either continuously or discretely in the free-decaying re- gions of recorded reverberant signal. In this paper, we present a novel continuous sub-band-based RT estimation method which employs the general model for the Power Spectral Density (PSD) of the reverberant signal. The temporal envelope of the observed reverberant PSD in each sub-band is fitted to the temporal envelope of the proposed theoretical PSD of the reverberant signal to estimate the RT value. In Comparison to a well-known method for RT estimation, the proposed approach per- forms both more accurately and faster, so that it can be used in real-time applications for fast tracking of the RT value with high accuracy.","Inclusive Personalized e-Learning Based on Affective Adaptive SupportEmotions and learning are closely related. In the PhD research pre- sented in this paper, that relation has to be taken advantage of. With this aim, within the framework of affective computing, the main goal proposed is model- ing learner's affective state in order to support adaptive features and provide an inclusive personalized e-learning experience. At the first stage of this research, emotion detection is the principal issue to cope with. A multimodal approach has been proposed, so gathering data from diverse sources to feed data mining systems able to supply emotional information is being the current ongoing work. On the next stages, the results of these data mining systems will be used to enhance learner models and based on these, offer a better e-learning expe- rience to improve learner's results.","Speaker Recognition Using Sparse Representation via Superimposed FeaturesIn this paper, we demonstrate the effectiveness of superim- posed features for the purpose of template matching-based speaker recog- nition using sparse representations. The principle behind our hypothesis is, if the test template approximately lies in the linear span of the train- ing templates of the genuine class, then so does any linear combination of test templates. In this paper, we introduce the notion of superimposed features for the first time. Using our initial trials on the TIMIT database, we have shown that superimposed features can result in reducing the com- plexity cost by 80 % with a very minor decrease in identification rate by 0.67 % and a minor increase in EER by 0.85 %.","On revenue maximization for agents with costly information acquisition: extended abstractA prevalent assumption in traditional mechanism design is that buyers know their precise value for an item; however, this assumption is rarely true in practice. In most settings, buyers can \"deliberate\", i.e., spend money or time, in order improve their estimate of an item's value. It is known that the deliberative setting is fundamentally different than the classical one, and desirable properties of a mechanism such as equilibria, revenue maximization, or truthfulness, may no longer hold.#R##N##R##N#In this paper we introduce a new general deliberative model in which users have independent private values that are a-priori unknown, but can be learned. We consider the design of dominant-strategy revenue-optimal auctions in this setting. Surprisingly, for a wide class of environments, we show the optimal revenue is attained with a sequential posted price mechanism (SPP). While this result is not constructive, we show how to construct approximately optimal SPPs in polynomial time. We also consider the design of Bayes-Nash incentive compatible auctions for a simple deliberative model.","A method of optimizing multi-tenant database query access ","Evolving an Harmonic Number Generator with ReNCoDeEvolutionary Algorithms (EA) are loosely inspired in the ideas of natural selection and genetics. Over the years some researchers have advocated the need of incorporating more ideas from biology into EAs, in particular with respect to the individuals' representation and the mapping from the genotype to the phenotype. One of the first successful proposals in that direction was the Artificial Regulatory Network (ARN) model. Soon after some variants of the ARN with increased capabilities were proposed, namely the Regulatory Network Computational Device (ReNCoDe). In this paper we further study ReNCoDe, testing the impli- cations of some design choices of the underlying ARN model. A Genetic Programming community-approved symbolic regression benchmark (the harmonic number) is used to compare the performance of the different alternatives.","Leveraging geographical metadata to improve search over social mediaWe propose the methods for document, query and relevance model expansion that leverage geographical metadata provided by social media. In particular, we propose a geographically-aware extension of the LDA topic model and utilize the resulting topics and language models in our expansion methods. The proposed approach has been experimentally evaluated over a large sample of Twitter, demonstrating significant improvements in search accuracy over traditional (geographically-unaware) retrieval models.","Coalitional Responsibility in Strategic SettingsThis paper focuses on the concept of group responsibility and presents a formal analysis of it from a strategic point of view. A group of agents is considered to be responsible for an outcome if the group can avoid the outcome. Based on this interpretation of group responsibility, different notions of group responsibility are provided and their properties are studied. The formal analysis starts with the semantics of different notions of group responsibility followed by their logical characterizations. The presented work is compared and related to the existing work on responsibility.","Proof Theory of a Multi-Lane Spatial LogicWe extend the Multi-lane Spatial Logic MLSL, introduced in previous work for proving the safety (collision freedom) of traffic maneuvers on a multi-lane highway, by length measurement and dynamic modalities. We investigate the proof theory of this extension, called EMLSL. To this end, we prove the undecidability of EMLSL but nevertheless present a sound proof system which allows for reasoning about the safety of traffic situations. We illustrate the latter by giving a formal proof for the reservation lemma we could only prove informally before. Furthermore we prove a basic theorem showing that the length measurement is independent from the number of lanes on the highway.","A Combined Position Evaluation Function in Chinese Chess Computer Game ","Searching for Predictors of Learning Outcomes in Non Abstract Eye Movement LogsWe present a study that addressed if providing students with scaffold- ing about how to \"integrate\" science text and animations impacts content learning. Scaffolding was delivered by a pedagogical agent and driven by student's eye gaze movements (compared to controls). We hypothesized that students in the pe- dagogical agent condition would engage in richer learning as evidence by a more \"integrated\" pattern from text to animation and back, etc. In addition to eye gazes we collected pre- and post test knowledge about the domain, and open responses to explanation-type questions. We are currently analyzing these data.","The State of the Art of Voronoi Diagram ResearchThe notion of Voronoi diagrams refer to a conceptually simple geometric construct that is based on a finite set of points in a Euclidean space. Intuitively speaking, it is such a simple notion that it can be described to a non-specialist. Indeed even some social and cultural settings can be described that would convey the essence of the concept. Consider for instance a number of strangers who are standing still in a room at random locations. In what region of space can an individual freely move his/her arms without appearing to be impolite to the others? Without having a precise definition of this personal space, each individual would most likely have an intuitive notion of it. If each individual is reduced to a single point occupying a specific location in the room, the personal space of a particular point is its Voronoi cell, the set of all points that are closer to that point than to any of the other points. Each Voronoi cell is a polyhedral region. The Voronoi diagram of the set of points is the partitioning of the space into the collection of Voronoi cells, together with their boundaries. It is not surprising that such a simple geometric construct should find numerous practical or theoretical applications in many fields of science. Voronoi diagrams of sets of points in the Euclidean spaces are fundamental geometric constructs. They find natural connections to other fundamental constructs appearing in computational geometry, e.g. Delaunay Triangulation ,p resent in many applications of Computer Graphics. Over the past few decades the subject of Voronoi diagrams has been flourishing through numerous research articles, turning it into a well-regarded area of computational geometry, with numerous theoretical and practical applications in diverse scientific areas. The 9th International Symposium on Voronoi Diagrams in Science and Engineering (ISVD) 2012, took place during June 27-29 at Rutgers, The State University of New Jersey. It was the first time this international event was held in the U.S. ISVD 2012 addressed a wide range of research and applications related to Voronoi diagrams. Forty submissions were refereed by anonymous reviewers from among the program committee members. Out of thirteen full articles and seven short ones that were selected for presentation at ISVD 2012, the top 20 percent were invited to submit a revised and extended version of their article for further review and consideration for the present issue. These papers have been selected based on several criteria, including quality, reviewer\u2019s comments, and feedback from conference participants.","Large-scale crossmedia retrieval for playlist generation and song discoveryTo explore vast collections of audio content, users require automated tools capable of providing music search and recommendation even when faced with large-scale collections. Collaborative-filtering recommenders rely on user-generated information and may be hindered by the lack of users or a bias for certain popular genres, enclosing users in an information bubble. Audio content analysis, on the other hand, is a reliable source of audio similarity, used in tasks such as music classification. For highly interactive tasks, however, the performance of analysis algorithms becomes an issue.#R##N##R##N#In this work, we address the playlist generation and song discovery tasks on large-scale datasets. We generate playlists and explore the collections with example-based queries using audio features, lyrics and tags. Approximate indexing and cross-media reranking are used for efficiency. Audio content is mapped to textual representations that can be handled by information retrieval libraries.#R##N##R##N#We explored the feasibility of this content-based approach in the Million Song Dataset, a large-scale collection of audio features and associated text data comprising almost 300 GB of information. The proposed strategy can be used independently as a content-based music retrieval system and as a component for hybrid recommender systems.","Benchmarking GPU-Based Phase Correlation for Homography-Based Registration of Aerial ImageryMany multi-image fusion applications require fast registration methods in order to allow real-time processing. Although the most popular approaches, local-feature-based methods, have proven efficient enough for registering image pairs at real-time, some applications like multi-frame background subtraction, super-resolution or high-dynamic-range imaging benefit from even faster algorithms. A common trend to speed up registration is to implement the algorithms on graphic cards (GPUs). However not all algorithms are specially suited for massive parallelization via GPUs. In this paper we evaluate the speed of a well-known global registration method, i.e. phase correlation, for computing 8-DOF homographies. We propose a benchmark to compare a CPU- and GPU-based implementation using different systems and a dataset of aerial imagery. We demonstrate that phase correlation benefits from GPU-based implementations much more than local methods, significantly increasing the processing speed. \u00a9 2013 Springer-Verlag.","Small red lesions detection using a MAS approachMicroaneurysms are the diabetic retinopathy first sign and its early detection is crucial for blindness prevention. Several approaches can be found in literature for the automatic microaneurysm segmenta- tion, but none of them has shown the required performance. In this study, a new approach is proposed based on an organization of agents enabling microaneurysms segmentation. This multiagent model is preceded by a preprocessing phase to allow the environment construction where agents are situated and interact. Then, microaneurysms segmentation emerges from agent interaction. With this study, competitive results comparing to more traditional algorithms were achieved, specially in detecting mi- croaneurysms close to vessels. It seems that a very efficient system for the diabetic retinopathy diagnosis can be built using MAS mechanisms.","Trustworthy Software Development Based on Model Driven Architecture ","Top-k Color Queries on Tree PathsWe present a data structure for the following problem: Given a tree    $\\mathcal{T}$   , with each of its nodes assigned a color in a totally ordered set, preprocess    $\\mathcal{T}$    to efficiently answer queries for the top  k  distinct colors on the path between two nodes, reporting the colors sorted in descending order. Our data structure requires linear space of  O ( n ) words and answers queries in  O ( k ) time.","Effect of Demography on Mobile Commerce Frequency of Actual Use in Saudi ArabiaWhen developing and aiming to achieve success in the arena of mobile commerce, user behaviour is one of the main aspects for consideration. This research seeks to analysis whether individuals\u2019 (gender, age, education level) influences their mobile commerce usage within the context of Saudi Arabia. The individuals analysed are own smartphone. We further present three hypotheses that investigate whether demographic factors have a significant statistical impact on the perception of those factors for mobile commerce acceptance in the Kingdom of Saudi Arabia. Survey data were collected from 574 participants in several cities across Saudi Arabia. The results emphasise that age affect statically on the actual usage. However, gender and education level all considerably not affect on the mobile commerce actual usage.","Positive Technology as a Driver for Health EngagementAbstract. Despite the fact that older adults are healthier than in the past, the current trend of an ageing population implies an increased risk and severity of chronic diseases. Low-resource healthcare systems face increased organizational healthcare costs, which is likely to result in an allocation of limited health resources. Healthcare organizations themselves must deal with patients\u2019 increasing need for a more active role in all the steps of the care &amp; cure process. Technological advances may play a crucial role in sustaining people\u2019s health management in daily life, but only if it is \u201cecologically\u201d designed and well-attuned to people\u2019s health needs and expectations. Healthcare is more and more called to orient innovative research approaches that recognize the crucial role of a person\u2019s engagement in health and well-being. This will enable patients to reach a higher quality of life and achieve a general psychophysical well-being. Thus, positive technological innovation can sustain people's engagement in health and invoke community empowerment, as we shall discuss in this document.","Improvements on Non-quadratic Stabilization of Takagi-Sugeno Models via Line-Integral Lyapunov FunctionsThis paper introduces two different generalizations on non-quadratic stabilization of Takagi-Sugeno models via line-integral Lyapunov functions. Inspired in recent developments which have proved to relax the conservativeness in the quadratic framework via suitable matrix transformations using a more general class of Lyapunov functions, the results here provided outperform the existing ones for line-integral Lyapunov functions with a linear matrix inequalities (LMI) form instead of bilinear matrix inequalities (BMI) in second order systems. Examples are provided to illustrate the advantages of the proposed technique over the existing approach.","NN based adaptive dynamic surface control for fully actuated AUVIn this brief, we consider the problem of tracking a desired trajectory for fully actuated autonomous underwater vehicle (AUV), in the presence of external disturbance and model errors. Based on the backstepping method and Lypunov stability theorem, we introduce the dynamic surface control (DSC) technique to tackle the problem of \"explosion of complexity\" which existing in the traditional backstepping algorithm. Furthermore, the norm of the ideal weighting vector in neural network (NN) systems is considered as the estimation parameter, such that only one parameter is adjusted. The proposed controller guarantees uniform ultimate bounded (UUB) of all the signals in the closed-loop system, while the tracking error converges to a small neighborhood of the origin. Finally, simulation studies are given to illustrate the effectiveness of the proposed algorithm.","Globally Rigid Ball-Polyhedra in Euclidean 3-SpaceThe rigidity theorems of Alexandrov (1950) and Stoker (1968) are classical results in the theory of convex polyhedra. We prove analogues of them for ball-polyhedra, which are intersections of finitely many con- gruent balls in Euclidean 3-space.","Current Trends in Bio-Ontologies and Data IntegrationBiological data integration is currently one of the major challenges in the field of Bioinformatics. Several studies show that biological knowledge is growing at a continuous rate and is usually distributed among many databases. This paper presents an overview of data integration and the existing approaches that aim to solve this problem. The paper will also review the different ontology approaches that were introduced by researchers for representing biological data.","How to Estimate a Technical VaR Using Conditional Probability, Attack Trees and a Crime Function ","Inferring gene regulatory networks from time-series expressions using random forests ensembleReconstructing gene regulatory network (GRN) from time-series expression data has become increasingly popular since time course data contain temporal information about gene regulation. A typical microarray gene expression data contain expressions of thousands of genes but the number of time samples is usually very small. Therefore, inferring a GRN from such a high-dimensional expression data poses a major challenge. This paper proposes a tree based ensemble of random forests in a multivariate auto-regression framework to tackle this problem. The efficacy of the proposed approach is demonstrated on synthetic time-series datasets and Saccharomyces cerevisiae (Yeast) microarray gene expression data with 9-genes. The performance is comparable or better than GRN generated using dynamic Bayesian networks and ordinary differential equations (ODE) model.","Characterizing Actions with Local Descriptors Based on Kinematics and Flow RecurrencesA common approach to characterize and recognize human actions consists of detecting interest points within the video volume and describe them locally, followed by a bag-of-words representation. Many of the proposed descriptors are based on the local optic flow, but they may simply summarize the flow in terms of histograms of its orientations. However, potentially interesting and discriminative properties of the op- tic flow are arguably ignored this way. This work addresses this issue by exploring two new optic flow-based descriptors. One of them consists of kinematic features of spatial variations of the optic flow. The other one captures dynamic patterns of the optic flow in terms of its temporal recurrences. It is experimentally found that these descriptors perform competitively with respect to state-of-the art descriptors. Further elab- oration of the proposed descriptors and additional experimentation is required to better assess their potential.","Circulation of Knowledge in a Co-innovation Network: An Assessment Approach ","Experience Report: AORE in Slot MachinesIn the context of an industrial project in the domain of slot machines, we needed to perform Aspect-Oriented Requirements Engineering, with a special emphasis on dependencies and interactions among concerns. The critical importance of interactions in this domain demanded explicit and detailed documentation of all interactions. We evaluated two AORE approaches: Theme/Doc and MDSOCRE, to establish their applicability in our setting. In this work we report on our experience, showing successful uses of both approaches and also where they fall short. To address these limitations, we have proposed some enhancements for both approaches and we present them here as well.","What Recommenders Recommend \u2013 An Analysis of Accuracy, Popularity, and Sales Diversity EffectsIn academic studies, the evaluation of recommender system (RS) algorithms is often limited to offline experimental designs based on historical data sets and metrics from the fields of Machine Learning or Information Retrieval. In real-world settings, however, other business- oriented metrics such as click-through-rates, customer retention or effects on the sales spectrum might be the true evaluation criteria for RS effec- tiveness. In this paper, we compare different RS algorithms with respect to their tendency of focusing on certain parts of the product spectrum. Our first analysis on different data sets shows that some algorithms - while able to generate highly accurate predictions - concentrate their top 10 recommendations on a very small fraction of the product cata- log or have a strong bias to recommending only relatively popular items than others. We see our work as a further step toward multiple-metric offline evaluation and to help service providers make better-informed de- cisions when looking for a recommendation strategy that is in line with the overall goals of the recommendation service.","Advances in the Logical Representation of Lexical SemanticsThe integration of lexical semantics and pragmatics in the analysis of the meaning of natural lan- guage has prompted changes to the global framework derived from Montague. In those works, the original lexicon, in which words were assigned an atomic type of a single-sorted logic, has been re- placed by a set of many-facetted lexical items that can compose their meaning with salient contextual properties using a rich typing system as a guide. Having related our proposal for such an expanded framework \u039bTYn, we present some recent advances in the logical formalisms associated, including constraints on lexical transformations and polymorphic quantifiers, and ongoing discussions and research on the granularity of the type system and the limits of transitivity.","Black-Box proof of knowledge of plaintext and multiparty computation with low communication overheadWe present a 2-round protocol to prove knowledge of a plaintext corresponding to a given ciphertext. Our protocol is black-box in the underlying cryptographic primitives and it can be instantiated with almost any fully homomorphic encryption scheme.#R##N##R##N#Since our protocol is only 2 rounds it cannot be zero-knowledge [GO94]; instead, we prove that our protocol ensures the semantic security of the underlying ciphertext.#R##N##R##N#To illustrate the merit of this relaxed proof of knowledge property, we use our result to construct a secure multi-party computation protocol for evaluating a function f in the standard model using only black-box access to a threshold fully homomorphic encryption scheme. This protocol requires communication that is independent of |f|; while Gentry [Gen09a] has previously shown how to construct secure multi-party protocols with similar communication rates, the use of our novel primitive (along with other new techniques) avoids the use of complicated generic white-box techniques (cf. PCP encodings [Gen09a] and generic zero-knowledge proofs [AJLA+12, LATV11].)#R##N##R##N#In this sense, our work demonstrates in principle that practical TFHE can lead to reasonably practical secure computation.","Dynamic K: A Novel Satisfaction Mechanism for CAR-Based ClassifiersIn this paper, we propose a novel satisfaction mechanism, named \"Dynamic K\", which could be introduced in any Class Association Rules CAR based classifier, to determine the class of unseen transactions. Experiments over several datasets show that the new satisfaction mechanism has better performance than the main satisfaction mechanism reported \"Best Rule\", \"Best K Rules\" and \"All Rules\". Additionally, the experiments show that \"Dynamic K\" obtains the best results independent of the CAR-based classifier used.","Integration of R Statistical Environment into ICT Infrastructure of GMP and GENASISThe Global Monitoring Plan (GMP) was established as a tool for#N#providing a worldwide overview of Stockholm Convention (SC)#N#compliance by monitoring and evaluation of SC 22 persistent#N#organic pollutants (POPs) concentration levels and their#N#trends. In order to evaluate a dataset on POPs concentrations#N#from the initial GMP campaign, it was essential to use advanced#N#statistical methods which are not incorporated in commonly used#N#database languages. Instead of a complete realization of these#N#methods in the main programming language, in which the#N#application is developed, this language was used only as an#N#interface to the server version of the powerful statistical#N#software R. The involvement of the R language into the#N#environmental pollution data assessment infrastructure of the#N#Global Environmental Assessment Information System (GENASIS)#N#adopted for the GMP data makes easier to avoid disambiguities#N#in data analysis and brings a powerful tool for advanced#N#statistical analysis and visualization of GMP and GENASIS data.","History-Offset Implementation Scheme of XML Documents and Its Evaluations ","Towards Simulating the Impact of National Culture on Organizations ","Customer Unification in E-CommerceData mining applied to social media is gaining popularity. It is worth noticing that most e-commerce services also cause the formation of small communities not only services oriented toward socializing people. The results of their analysis are easier to implement. Besides, we can expect a better perception of the business by its own users, therefore the analysis of their behavior is justified. In the paper we introduce an algorithm which identifies particular customers among not logged or not registered users of a given e-commerce service. The identification of a customer is based on data that was given so as to accomplish selling procedure. Customers rarely use exactly the same identification data each time. In consequence, it is possible to check if customers create a group of unrelated individuals or if there are symptoms of social behavior.","Structure from Motion Using Rigidly Coupled Cameras without Overlapping Views ","Fixed-parameter tractability of error correction in graphical linear systemsIn an overdetermined and feasible system of linear equations Ax=b, let #R##N#vector b be corrupted, in the way that at most k entries are off their #R##N#true values. Assume that we can check in the restricted system given by any minimal dependent set of rows, the correctness of all corresponding values in #R##N#b. Furthermore, A has only coefficients 0 and 1, with at most two 1s in #R##N#each row. We wish to recover the correct values in b and x as much as #R##N#possible. The problem arises in a certain chemical mixture inference application in molecular biology, where every observable reaction product stems from at most two candidate substances. After formalization we prove that the problem is NP-hard but fixed-parameter tractable in k. The FPT result #R##N#relies on the small girth of certain graphs.","Techniques and Toolset for Conformance Testing against UML Sequence DiagramsNovel techniques and a toolset are presented for automatically testing the conformance of software implementations against partial behavioral models constituted by a set of parameterized UML sequence diagrams (SDs), describ- ing both external and internal interactions. Test code is automatically generated from the SDs and executed on the Java implementation under test, and test results and coverage information are presented back visually in the model. A runtime test library handles internal interaction checking, test stubs, and user in- teraction testing. Incremental conformance checking is achieved by first trans- lating SDs to non-deterministic acceptance automata with parallelism.","An Optimization Model for Advanced Biofuel Production Based on Bio-oil GasificationBiomass can be converted to transportation fuels through gasifica- tion. However, commercialization of biomass gasification has been hampered by its high capital and operating costs, in addition to the difficulties of trans- porting bulky solid biomass over a long distance. A novel approach is to con- vert biomass to bio-oil at widely distributed small-scale fast pyrolysis plants, transport the bio-oil to a centralized location, gasify the bio-oil to syngas, and upgrade the syngas to transportation fuels. In this paper, a two-stage stochastic programming is formulated. The first-stage makes the capital investment deci- sions including the locations and capacities of the bio-facilities (fast pyrolysis and refining facility) while the second-stage determines the biomass and biofu- els flows. This paper aims to find the optimal design of the supply chain for this certain path considering uncertainties in biomass yield, biofuel price and trans- portation costs.","Identifying Critical Transitions of Biological Processes by Dynamical Network Biomarkers ","Toward the Development of Cognitive Robots ","Prediction of Processor Utilization for Real-Time Multimedia Stream Processing Tasks *Utilization of MPUs in a computing cluster node for multimedia stream processing is considered. Non-linear increase of processor utilization is described and a related class of algorithms for multimedia real-time processing tasks is defined. For such conditions, experiments measuring the processor utilization and output data loss were proposed and their results presented. A new formula for prediction of utilization was proposed and its verification for a representative set of tasks was performed.","Spotting Graphical Symbols in Camera-Acquired Documents in Real Time ","A usability study on natural interaction devices with ASD childrenIntelligent agents such as social robots and avatars have been used with Children with Autism (CWA) to help them learn social skills. Social robots afford a natural interaction but are expensive. Interaction with avatars, on the other hand, is through point-and-click interfaces and touch-screens. In this paper, we explore the use of Microsoft KinectTMas an interaction modality with children with autism. We found that while CWA could understand the concept of interacting through gestures, though they needed explicit physical modeling from their teachers to perform those gestures. We discuss the implications of this to user-interface design.","Distributed Finite-State Runtime Monitoring with Aggregated Events ","Generation of Multi-Device Adaptive MultiModal Web ApplicationsThis paper presents a set of tools to support multimodal adaptive Web applications. The contributions include a novel solution for generating multimodal interactive applications, which can be executed in any browser-enabled device; and run-time support for obtaining multimodal adaptations at various granularity levels, which can be specified through a language for adaptation rules. The architecture is able to exploit model-based user interface descriptions and adaptation rules in order to achieve adaptive behaviour that can be triggered by dynamic changes in the context of use. We also report on an example application and a user test concerning adaptation rules changing dynamically its multimodality.","From Concrete Examples to Heap Manipulating ProgramsData-structure manipulation is not just a perplexing ordeal for newbies, but also a tedious errand for seasoned programmers. Even af- ter a programmer gets the \"hang of things\", programming complex pointer manipulations (like reversing a linked list) still makes one reach for a note- book to draw some box-and-arrow diagrams to work out the low-level pointer jugglery. These diagrams are, not surprisingly, used as a basic tool to introduce heap manipulations in introductory programming courses. We propose a synthesis technology to automatically create programs that manipulate heap data-structures from such diagrams. The program- mer is needed to provide a set of concrete examples of her high-level strategy for the low-level manipulations to be discharged automatically. We plan the synthesis task as a sequence of \"fast\" stages, making it us- able in an integrated development environment. We envisage that such a tool will be useful to programmers as a code-assist comfortably tucked away in their favorite integrated development environment.","Adoption of Online Videos in Organizations: A Multi-Case ComparisonThe importance of online videos is increasing constantly. However, research has so far failed to provide an in-depth analysis of what has been driving the adoption of online videos within organizations. Thus, this study analyzes the adoption of online videos through case study research. We collected data from semi-structured interviews in four different organizations. A cross-case analysis shows that top-management and environmental characteristics drive the use of online videos. However, innovation and organizational characteristics do not influence the adoption of online videos in this study.","Onset and Peak Pattern Recognition on Photoplethysmographic Signals Using Neural NetworksTraditional methodologies use electrocardiographic ECG signals to develop automatic methods for onset and peak detection on the arterial pulse wave. In the present work a Multilayer Perceptron MLP neural network is used for classifying fiducial points on photoplethysmographic PPG signals. System was trained with a dataset of temporal segments from signals located based on information about onset and peak points. Different segments sizes and units in the neural network were used for the classification, and optimal values were searched. Results of the classification reach 98.1% in worse of cases. This proposal takes advantages from MLP neural networks for pattern classification. Additionally, the use of ECG signal was avoided in the presented methodology, making the system robust, less expensive and portable in front of this problem.","On Sparser Random 3SAT Refutation Algorithms and Feasible InterpolationWe formalize a combinatorial principle, called the 3XOR principle, due to Feige, Kim and Ofek (2006), as a family of unsatisfiable propositional formulas for which refutations of small size in any propositional proof system that possesses the feasible interpolation property imply an efficient deterministic refutation algorithm for random 3SAT with n variables and \\Omega(n^{1.4}) clauses. Such small size refutations would improve the current best (with respect to the clause density) efficient refutation algorithm, which works only for \\Omega(n^{1.5}) many clauses (Feige and Ofek 2007). #R##N#We then study the proof complexity of the above formulas in weak extensions of cutting planes and resolution. Specifically, we show that there are polynomial-size refutations of the 3XOR principle in resolution operating with disjunctions of quadratic equations (with small integer coefficients), denoted R(quad). We show that R(quad) is weakly automatizable iff R(lin) is weakly automatizable, where R(lin) is similar to R(quad) but with linear instead of quadratic equations, introduced in (Raz and Tzameret 2008). This reduces the question of the existence of efficient deterministic refutation algorithms for random 3SAT with n variables and \\Omega(n^{1.4}) clauses to the question of feasible interpolation of R(quad) and to the weak automatizability of R(lin).","Finding Opinion Strength Using Rule-Based Parsing for Arabic Sentiment AnalysisWith increasing interest in sentiment analysis research and opinionated web content always on the rise, focus on analysis of text in various domains and different languages is a relevant and important task. This paper explores the problems of sentiment analysis and opinion strength measurement using a rule-based approach tailored to the Arabic language. The approach takes into account language-specific traits that are valuable to syntactically segment a text, and allow for closer analy- sis of opinion-bearing language queues. By using an adapted sentiment lexicon along with sets of opinion indicators, a rule-based methodology for opinion-phrase extraction is introduced, followed by a method to rate the parsed opinions and offer a measure of opinion strength for the text under analysis. The proposed method, even with a small set of rules, shows potential for a simple and scalable opinion-rating system, which is of particular interest for morphologically-rich languages such as Arabic.","Fragmented Validation: A Simple and Efficient Contribution to XSLT Checking (Extended Abstract) ","Uniform convergence, stability and learnability for ranking problemsMost studies were devoted to the design of efficient algorithms and the evaluation and application on diverse ranking problems, whereas few work has been paid to the theoretical studies on ranking learnability. In this paper, we study the relation between uniform convergence, stability and learnability of ranking. In contrast to supervised learning where the learnability is equivalent to uniform convergence, we show that the ranking uniform convergence is sufficient but not necessary for ranking learnability with AERM, and we further present a sufficient condition for ranking uniform convergence with respect to bipartite ranking loss. Considering the ranking uniform convergence being unnecessary for ranking learnability, we prove that the ranking average stability is a necessary and sufficient condition for ranking learnability.","Sentiment Classification Using Supervised Sub-SpacingAn important application domain for Machine learning is sentiment classification. Here, the traditional approach is to represent documents using a Bag- Of-Words (BOW) model, where individual terms are used as features. However, the BOWmodelisunabletosufficientlymodelthevariationinherentinnaturallanguage text. Term-relatedness metrics are commonly used to overcome this limitation by capturing latent semantic concepts or topics in documents. However, representations produced using standard term relatedness approaches do not take into account class membership of documents. In this work, we present a novel approach called Super- vised Sub-Spacing (S3) for introducing supervision to term-relatedness extraction. S3 works by creating a separate sub-space for each class within which term rela- tions are extracted such that documents belonging to the same class are made more similar to one another. Recent approaches in sentiment classification have proposed combining machine learning with background knowledge from sentiment lexicons for improved performance. Thus, we present a simple, yet effective approach for augmenting S3 with background knowledge from SentiWordNet. Evaluation shows S3 to significantly out perform the state-of-the-art SVM classifier. Results also show that using background knowledge from SentiWordNet significantly improves the performance of S3.","Implementation of the C-mantec neural network constructive algorithm in an arduino uno microcontrollerA recently proposed constructive neural network algorithm, named C-Mantec, is fully implemented in a Arduino board. The C-Mantec algorithm generates very compact size neural architectures with good prediction abilities, and thus the board can be potentially used to learn on-site sensed data without needing to transmit information to a central control unit. An analysis of the more difficult steps of the implementation is detailed, and a test is carried out on a set of benchmark functions normally used in circuit design to show the correct functioning of the implementation.","Superresolution MUSIC Based on Mar\u010denko-Pastur Limit Distribution Reduces Uncertainty and Improves DNA Gene Expression-Based Microarray Classification ","Can You See It? Two Novel Eye-Tracking-Based Measures for Assigning Tags to Image RegionsEye tracking information can be used to assign given tags to image regions in order to describe the depicted scene in more details. We introduce and compare two novel eye-tracking-based measures for con- ducting such assignments: The segmentation measure uses automatically computed image segments and selects the one segment the user fixates for the longest time. The heat map measure is based on traditional gaze heat maps and sums up the users' fixation durations per pixel. Both mea- sures are applied on gaze data obtained for a set of social media images, which have manually labeled objects as ground truth. We have deter- mined a maximum average precision of 65% at which the segmentation measure points to the correct region in the image. The best coverage of the segments is obtained for the segmentation measure with a F-measure of 35%. Overall, both newly introduced gaze-based measures deliver bet- ter results than baseline measures that selects a segment based on the golden ratio of photography or the center position in the image. The eye-tracking-based segmentation measure significantly outperforms the baselines for precision and F-measure.","Discovering frequent itemsets on uncertain data: a systematic reviewIn this paper, we describe the development of a systematic review about the topic \"Discovering Frequent Itemsets on Uncertain Data\". To the best of our knowledge, this work seems to be the first systematic review addressing the topic. We show the whole process executed and its findings. Initially we define a rigorous protocol to lead the process. In the first phase, we create a systematic mapping of the area. In addition, from the complete reading of each article, a panorama of this area is presented. We reveal the search engines that most publicize this topic and which publishing types, authors and research institutions are involved in these papers. Moreover we identify the algorithms and the classes of these algorithms most compared over the years, how are made these comparisons, as well as their availabilities. Therefore this systematic review becomes a rich material for understanding this knowledge area.","MVA-Based Probabilistic Model of Shared Memory with a Round Robin Arbiter for Predicting Performance with Heterogeneous WorkloadMemory access contention can be a cause of performance problems and should be assessed at early stages of development. We devised a probabilistic model of shared memory for performance estimation. The calculation time is polynomial in the number of processors. The model is applicable for the region of high and heterogeneous bandwidth utilization. A round-robin arbiter is modeled using Mean Value Analysis MVA based approximations and incorporating non-linear dependence to the bandwidth utilization. To evaluate our model, estimated execution time is compared with the measured execution time of benchmark programs with memory access contention. We find a maximum error of 4.2% for the round-robin arbitration when we compensate for the burstiness of accesses.","Towards a Categorical Theory of Creativity for Music, Discourse, and CognitionThis article presents a first attempt at establishing a category-theoretical model of creative processes. The model, which is applied to musical creativity, discourse theory, and cognition, suggests the relevance of the notion of \"colimit\" as a unifying construction in the three domains as well as the central role played by the Yoneda Lemma in the categorical formalization of creative processes.","Multi-objectivization of the Tool Selection Problem on a Budget of Evaluations ","Real-Time Motion Artifact Compensation for PMD-ToF ImagesTime-of-Flight (ToF) cameras gained a lot of scientific at- tention and became a vivid field of research in the last years. A still re- maining problem of ToF cameras are motion artifacts in dynamic scenes. This paper presents a new preprocessing method for a fast motion ar- tifact compensation. We introduce a flow like algorithm that supports motion estimation, search field reduction and motion field optimization. The main focus lies on real-time processing capabilities. The approach is extensively tested and compared against other motion compensation techniques. For the evaluation, we use quantitative (ground-truth data, statistic error comparison) and qualitative (real environments, visual comparison) test methods. We show, that our proposed algorithm runs in real-time within a GPU based processing hardware (using NVIDIA Cuda) and corrects motion artifacts in a reliable way.","A New Distributed Optimization Approach for Solving CFD Design Problems Using Nash Game Coalition and Evolutionary Algorithms ","Cross-tier application and data partitioning of web applications for hybrid cloud deploymentHybrid cloud deployment offers flexibility in trade-offs between the cost-savings/scalability of the public cloud and control over data resources provided at a private premise. However, this flexibility comes at the expense of complexity in distributing a system over these two locations. For multi-tier web applications, this challenge manifests itself primarily in the partitioning of application- and database-tiers. While there is existing research that focuses on either application-tier or data-tier partitioning, we show that optimized partitioning of web applications benefits from both tiers being considered simultaneously. We present our research on a new cross-tier partitioning approach to help developers make effective trade-offs between performance and cost in a hybrid cloud deployment. In two case studies the approach results in up to 54% reduction in monetary costs compared to a premise only deployment and 56% improvement in execution time compared to a naive partitioning where application-tier is deployed in the cloud and data-tier is on private infrastructure.","Designing Similarity Indexes with Parallel Genetic ProgrammingThe increasing diversity of unstructured databases leads to the development of advanced indexing techniques as the metric indexing model does not fit to the general similarity models. Once the most critical postulate, namely the triangle inequality, does not hold, the metric model produces notable errors during the query evaluation. To overcome this situation and to obtain more qualitative results, we want to discover better indexing models for databases using arbitrary similarity measures. However, each database is unique in a specific way, so we outline the automatic way of exploring the best indexing method. We introduce the exploration approach using parallel genetic programming principles in a multi-threaded environment built upon recently introduced SIMDEX Framework. Furthermore, we introduce smart pivot table which is an intelligent indexing method capable of incorporating obtained results. We supplement the theoretical background with experiments showing the achieved improvements in comparison to the single-threaded evaluations.","Errors in Device Localization in MRI Using Z-FramesThe use of a passive MRI-visible tracking frame is a common method of localizing devices in MRI space for MRI-guided procedures. One of the most common tracking frame designs found in the literature is the z-frame, as it allows six degree-of-freedom pose estimation using only a single image slice. Despite the popularity of this design, it is susceptible to errors in pose estimation due to vari- ous image distortion mechanisms in MRI. In this paper, the absolute error in using a z-frame to localize a tool in MRI is quantified over various positions of the z- frame relative to the MRI isocenter, and for various levels of static magnetic field inhomogeneity. It was found that the error increases rapidly with distance from the isocenter in both the horizontal and vertical directions, but the error is much less sensitive to position when multiple contiguous slices are used with slice- select gradient nonlinearity correction enabled, as opposed to the more common approach of only using a single image slice. In addition, the error is found to in- crease rapidly with an increasing level of static field inhomogeneity, even with the z-frame placed within 10 cm of the isocenter.","Analysis of an electronic boardroom voting systemWe study a simple electronic boardroom voting system. While most existing systems rely on opaque electronic devices, a scientific committee of a research institute (the CNRS Section 07) has recently proposed an alternative system. Despite its simplicity (in particular, no use of cryptography), each voter can check that the outcome of the election corresponds to the votes, without having to trust the devices.#R##N##R##N#In this paper, we present three versions of this system, exhibiting potential attacks. We then formally model the system in the applied pi-calculus, and prove that two versions ensure both vote correctness (even if the devices are corrupted) and ballot secrecy (assuming the devices are honest).","Tempo Adaptation within Interactive Music Instruments in Mobile Phone ","Evaluating computational creativity: a standardised procedure for evaluating creative systems and its applicationThis thesis proposes SPECS: a Standardised Procedure for Evaluating Creative Systems.#R##N##R##N#No methodology has been accepted as standard for evaluating the creativity of a system in the field of computational creativity and the multi-faceted and subjective nature of creativity generates substantial definitional issues. Evaluative practice has developed a general lack of rigour and systematicity, hindering research progress.#R##N##R##N#SPECS is a standardised and systematic methodology for evaluating computational creativity. It is flexible enough to be applied to a variety of different types of creative system and adaptable to specific demands in different types of creativity. In the three-stage process of evaluation, researchers are required to be specific about what creativity entails in the domain they work in and what standards they test a system\u2019s creativity by. To assist researchers, definitional issues are investigated and a set of components representing aspects of creativity is presented, which was empirically derived using computational linguistics analysis. These components are recommended for use within SPECS, being offered as a general definition of creativity that can be customised to account for any specific priorities for creativity in a given domain.#R##N##R##N#SPECS is applied in a case study for detailed comparisons of the creativity of three musical improvisation systems, identifying which systems are more creative than others and why. In a second case study, SPECS is used to capture initial impressions on the creativity of systems presented at a 2011 computational creativity research event. Five systems performing different creative tasks are compared and contrasted.#R##N##R##N#These case studies exemplify the valuable information that can be obtained on a system\u2019s strengths and weaknesses. SPECS gives researchers vital feedback for improving their systems\u2019 creativity, informing further progress in computational creativity research.","Describing and Assessing Image Descriptions for Visually Impaired Web Users with IDAT ","Institutionalization and the Effectiveness of Enterprise Architecture ManagementEnterprise Architecture Management (EAM) has become a prominent discipline for managing increasingly complex Business/IT relationships in organizations. The more tangible aspects of EAM like modeling, planning, principles or governance structures are widely discussed and understood. However, institutionalizing EAM in an organization remains a challenging issue. Therefore, actually realized EAM benefits can be observed to vary widely across organizations. To address these issues, we take an institutional theory perspective and propose nine hypotheses which are tested based on quantitative empirical data. Our findings confirm seven institutional factors as antecedents for institutionalizing EAM in terms of positive stakeholder response, EA consistency and a realization of EAM benefits for the organization. Our research supports the understanding of the relevant phenomenon of institutionalization of EAM as a rather practice-driven discipline, where theoretical foundations as well as research into non-technical issues are limited so far.","A Subgraph Isomorphism Based Approach to Enable Discovery and Composition of Smart Space ElementsNowadays, the variety of mobile services is growing together with the number of customers and the heterogeneity of their mobile de- vices, thus, monitoring the users of a mobile network has become a chal- lenge. Considering Smart Space Governing to address this issue, in which the mobile network is considered an Smart Space (due to its size and complexity) and their elements (mobile devices and network monitoring services), it is possible to create rules to monitor the output of these elements. We call those rules as Smart Space Compositions and can be created through the platform's Visual Editor, that during the graphical creation process, provides the user with a list of similar existing composi- tions that can be reused at any time to improve the composition process. This paper describes the implementation by a Telecommunications Op- erator of this composition module supported by subgraph isomorphism techniques","Static and Dynamic Texture Mixing Using Optimal Transport ","Using an IT Strategy to Improve Company Interaction with Their Supply Chain - A Case Study of a Fire Truck Bodybuilding Business in Thailand ","Aligning Domain-Related Models for Creating Context for Software Product DesignA typical software product is developed so that it can fulfill the specific needs (problem that needs to be solved) within a given business do- main, based on a proper product design context. Although, assuring an align- ment between the technological developments with the business domain is a demanding task. With the purpose of clarifying the relations between the mod- els that support the business and the software representations, we present in this paper a V-Model based approach to align the business domain requirements with the context for product design. This V-Model encompasses the models that support the initial definition of the project goals, expressed through organiza- tional configurations, and the analysis and design of models that result in a process-level perspective of the system's logical architecture. Our approach adopts a process-level perspective with the intent to create context for product- level requirement elicitation. We present a case study as a demonstration and assessment of the applicability of our approach. Since the case study is extreme- ly complex, we illustrate how to use the ARID method to evaluate the obtained process-level architecture.","Enhancing SOM Based Visualization Methods for Better Data NavigationExisting SOM based visualization methods have the limitation of not being able to show detailed local distance information and global similarity of data at the same time. In this paper, we propose two approaches to overcome this limitation for better data navigation. In our experiments, we used MPEG-7 shape image dataset and classic IRIS dataset to demonstrate our approaches are superior to previous approaches in providing sufficient local and global information for data visual navigation.","Orthonormal Diffusion Decompositions of Images for Optical Flow Estimation ","Roadside Infrastructure Placement for Information Dissemination in Urban ITS Based on a Probabilistic ModelInformation dissemination is an important application in VANETs for traffic safety and efficiency. In urban area, roadside infrastructure nodes can be deployed for information dissemination. However, it is inefficient and uneconomical to cover the whole urban area. How to find the optimal locations to place DPs is a research problem. Some works on this issue have to collect accurate trajectories of all the vehicles, which is not practical in the real environment. In this paper, we propose a novel approach for DPs placement in grid road networks without knowing trajectories. Based on the analysis of path number between two intersections, a probabilistic model is proposed to get the trajectories estimation of vehicles. The theoretical optimal algorithm OA and two heuristic algorithms called KP-G and GA are developed for the problem. Simulation results reveal that GA is scalable and has the highest coverage ratio on average.","Autonomous Mobile Robots: A Distributed Computing PerspectiveThe distributed coordination and control of a team of autonomous mobile robots is a problem widely studied in a variety of fields, such as engineering, artificial intelligence, artificial life, robotics. Generally, in these areas, the problem is studied mostly from an empiri- cal point of view. Recently, the study of what can be computed by such team of robots has become increasingly popular in theoretical computer science and especially in distributed computing, where it is now an integral part of the investigations on computability by mobile entities (28). In this paper we describe the current investigations on the algorithmic limitations of what autonomous mobile robots can do with respect to different coordi- nation problems, and overview the main research topics that are gaining attention in this area.","Social Dimension of Sustainable Development \u2013 Safety and Ergonomics in Maintenance ActivitiesAbstract. The paper considered the issue of the impact of maintenance services for the safety and health of workers. This is undoubtedly an important issue as statistics show that in Europe 10 to 15% of fatal industrial accidents can be traced to maintenance operations. The role of these services in the modern enterprise is increasing, as companies increasingly depend on the proper functioning of its technical systems. In addition, the maintenance process involves not only technical services company employees, but also the employees of other functional areas and external agencies. All this makes, that maintenance in terms of security is a complex issue. Activities of maintenance services are generally associated only with phase of the operation of machinery. In the paper authors consider the effects of enlargement of operations maintenance services for all phases of the life of a technical object, including not only operation but also design, manufacturing and disposal phases. Such approach is able to provide more effective, proactive and preventive health and safety system.","Evaluating the Digital Manuscript Functionality --- User Testing for Lecture Video Annotation FeaturesIn current tele-teaching platforms the main challenges for learners are searching and filtering through the content and staying focused on learning with the help of the e-lectures. Video annotation and video indexing features may provide support for learners in this situation. In this paper we will introduce one solution for a lecture video annotation feature called the digital manuscript. Digital notes can be written synchronously or asynchronously to the time of the actual lecture. Different features such as instant time markers and formatting options are available. In order to prove our hypothesis that the digital manuscript feature enables students to better concentrate on watching the video lecture and thus results in an improved learning effectiveness, we conducted a user study. The results include insights into the perceived usefulness of the annotation functionality as well as a quantitative comparison of assessment results with and without the manuscript feature and the indexing features as comparison. An outlook to group functionalities as well as a semantic extension of the video annotation feature is finally given.","Recent Developments in Collective Decision Making in Combinatorial DomainsCollective decision making is the process of mapping the individual views of several individual agents into a joint decision. The need for collective decision making mechanisms is abundant, not just in the realm of politics, but also for a wide range of scientific and technological applications. These include, for instance, logistics, grid computing, and recommender systems. The alternatives to be decided upon often have a combinatorial structure: an alternative is characterised by a tuple of variables, each ranging over a finite domain. Classical approaches to collective decision making, developed in social choice theory, do not take the computational limitations induced by the combinatorial nature of the problem into account. For instance, if we are asked to elect a committee consisting of k representatives, choosing from a pool of n candidates, then we are in fact faced with a social choice problem with n k alternatives. Asking each voter for their full preferences over these n alternatives may not be feasible in practice. Similarly, if we have to choose between accepting or rejecting each of n different propositions, then we are dealing with a social choice problem with 2 n possible outcomes. In this talk I will report on a number of recent developments in the area of collective decision making in combinatorial domains. This includes the study of languages for the compact representation of preferences [2,4], the design of voting rules for multi-issue elections [1], and the analysis of the computational complexity of decision problems arising in judgment aggregation [3].","Personalized accessibility maps (PAMs) for communities with special needsAccessibility data/information is necessary to support the everyday mobility of people with special needs. As a means to accommodate mobility of students with special needs, universities and colleges provide maps with accessibility data/information for their campus, where some are static and others are interactive. In this paper, we describe the concept of Personalized Accessibility Maps (PAMs) and discuss the development of a PAM for the University of Pittsburgh's main campus as a representative PAM. As a result of this development, there is a better understanding of the technologies and techniques needed for PAMs along with challenges and future research directions.","Integrating Online Social Network Analysis in Personalized Web Search ","Hybrid genetic algorithms for stress recognition in readingStressis a major problem facing our world today and affects everyday lives providing motivation to develop an objective understanding of stress during typicalactivities. Physiological and physical response signals showing symptoms for stress can be used to provide hundreds of features. This encounters the problem of selecting appropriate features for stress recognition from a set of features that may include irrelevant, redundant or corrupted features. In addition, there is also a problem for selecting an appropriate computational classification model with optimal parameters to capture general stress patterns. The aim of this paper is to determine whether stress can be detected from individual-independent computational classification models with a genetic algorithm (GA) optimization scheme from sensor sourced stress response signals induced by reading text. The GA was used to select stress features, select a type of classifier and optimize the classifier's parameters for stress recognition. The classification models used were artificial neural networks (ANNs) and support vector machines (SVMs). Stress recognition rates obtained from an ANN and a SVM without a GA were 68% and 67% respectively. With a GA hybrid, the stress recognition rate improved to 89%. The improvement shows that a GA has the capacity to select salient stress features and define an optimal classification model with optimized parameter settings for stress recognition.","Enhancement of the Time Management in Production Planning Processes ","ORCHID Reduction-Ratio-Optimal Computation of Geo-spatial Distances for Link DiscoveryThe discovery of links between resources within knowledge bases is of crucial importance to realize the vision of the Semantic Web. Addressing this task is especially challenging when dealing with geo-spatial datasets due to their sheer size and the potential complexity of single geo-spatial objects. Yet, so far, little attention has been paid to the characteristics of geo-spatial data within the context of link discovery. In this paper, we address this gap by presenting Orchid, a reduction-ratio-optimal link discovery approach designed especially for geo-spatial data. Orchid relies on a combination of the Hausdorff and orthodromic metrics to compute the distance between geo-spatial objects. We first present two novel approaches for the efficient computation of Hausdorff distances. Then, we present the space tiling approach implemented by Orchid and prove that it is optimal with respect to the reduction ratio that it can achieve. The evaluation of our approaches is carried out on three real datasets of different size and complexity. Our results suggest that our approaches to the computation of Hausdorff distances require two orders of magnitude less orthodromic distances computations to compare geographical data. Moreover, they require two orders of magnitude less time than a naive approach to achieve this goal. Finally, our results indicate that Orchid scales to large datasets while outperforming the state of the art significantly.","Integrity in very large information systems: dealing with information risk black swansMulti-national enterprises, like financial services companies, operate large and critical information systems around the globe on a 24/7 basis. In an information-based business, even a single inadequately designed, implemented, tested and operated business application can put the existence of the enterprise at risk.#R##N##R##N#For adequately securing the integrity of business critical information and hence ensuring that such information is meaningful, accurate and timely, we present our risk assessment and controls framework: First, we introduce our criticality rating scheme that is based on the recoverability from integrity failures. For dealing with dependencies among applications, we present our approach based on services given a Service-Oriented Architecture (SOA). Second, we provide an overview of our design-related controls including a data analytics approach to continuously audit the most critical information assets. Finally, we present our learnings from a first implementation of the presented framework.","Development of Multiview Image Generation Simulator for Depth Map Quantization ","Expressivity Hierarchy of Languages for Epistemic Awareness ModelsWe study the expressivity hierarchy of languages for epistemic awareness models based on the operators for implicit and explicit knowledge, implicit and explicit possibility and awareness, providing in each case an expressivity characterisation in terms of bisimulation.","Adaptive Surface Visualization of Vessels with Embedded Blood Flow Based on the Suggestive Contour Measure ","Crowdsourcing Linked Data Quality AssessmentIn this paper we look into the use of crowdsourcing as a means to handle Linked Data quality problems that are challenging to be solved automatically. We analyzed the most common errors encountered in Linked Data sources and classified them according to the extent to which they are likely to be amenable to a specific form of crowdsourcing. Based on this analysis, we implemented a quality assessment methodology for Linked Data that leverages the wisdom of the crowds in different ways: (i) a contest targeting an expert crowd of researchers and Linked Data enthusiasts; complemented by (ii) paid microtasks published on Amazon Mechanical Turk.We empirically evaluated how this methodology could efficiently spot quality issues in DBpedia. We also investigated how the contributions of the two types of crowds could be optimally integrated into Linked Data curation processes. The results show that the two styles of crowdsourcing are complementary and that crowdsourcing-enabled quality assessment is a promising and affordable way to enhance the quality of Linked Data.","A complex adaptive systems perspective of health information technology implementation. ","A New Approach for Improving Cross-Document Knowledge Discovery Using WikipediaIn this paper, we present a new model that incorporates the extensive knowledge derived from Wikipedia for cross-document knowledge discovery. The model proposed here is based on our previously introduced Concept Chain Queries (CCQ) which is a special case of text mining focusing on detecting se- mantic relationships between two concepts across multiple documents. We at- tempt to overcome the limitations of CCQ by building a semantic kernel for concept closeness computing to complement existing knowledge in text corpus. The experimental evaluation demonstrates that the kernel-based approach out- performs in ranking important chains retrieved in the search results.","Simplification and Correctness of UML Class Diagrams --- Focusing on Multiplicity and Aggregation/Composition ConstraintsModel-driven Engineering requires efficient powerful methods for verifying model correctness and quality. Class Diagram is the central language within UML. Its main problems involve correctness problems, which include the consistency and the finite satisfiability problems, and quality problems, which include the redundancy and incomplete design problems. Two central constraints in class diagrams are the multiplicity and the aggregation/composition constraints. They are essential in modeling configuration management, features, biology, computer-aided design and database systems.#R##N##R##N#The contribution of this paper involves efficient algorithms for tightening multiplicity constraints that cannot be realized, and for identification of correctness problems that are caused by aggregation/composition constraints. The algorithms are analyzed, and their soundness and completeness properties are proved. We show that these constraints are inter-related, and that the combination of these algorithms strengthens their results.","Bridging the gap between refinement and heuristics in abstractionThere are two major uses of abstraction in planning and search: refinement (where abstract solutions are extended into concrete solutions) and heuristics (where abstract solutions are used to compute heuristics for the original search space). These two approaches are usually viewed as unrelated in the literature. It is reasonable to believe, though, that they are related, since they are both intrinsically based on the structure of abstract search spaces. We take the first steps towards formally investigating their relationships, employing our recently introduced framework for analysing and comparing abstraction methods. By adding some mechanisms for expressing metric properties, we can capture concepts like admissibility and consistency of heuristics. We present an extensive study of how such metric properties relate to the properties in the original framework, revealing a number of connections between the refinement and heuristic approaches. This also provides new insights into, for example, Valtorta's theorem and spurious states.","On the Complexity of Shortest Path Problems on Discounted Cost Graphs ","A Generative Model for Resolution Enhancement of Diffusion MRI DataThe advent of diffusion magnetic resonance imaging (DMRI) presents unique opportunities for the exploration of white matter connec- tivity in vivo and non-invasively. However, DMRI suffers from insufficient spatial resolution, often limiting its utility to the studying of only ma- jor white matter structures. Many image enhancement techniques rely on expensive scanner upgrades and complex time-consuming sequences. We will instead take a post-processing approach in this paper for res- olution enhancement of DMRI data. This will allow the enhancement of existing data without re-acquisition. Our method uses a generative model that reflects the image generation process and, after the param- eters of the model have been estimated, we can effectively sample high- resolution images from this model. More specifically, we assume that the diffusion-weighted signal at each voxel is an agglomeration of signals from an ensemble of fiber segments that can be oriented and located freely within the voxel. Our model for each voxel therefore consists of an arbitrary number of signal generating fiber segments, and the model parameters that need to be determined are the locations and orienta- tions of these fiber segments. Solving for these parameters is an ill-posed problem. However, by borrowing information from neighboring voxels, we show that this can be solved by using Markov chain Monte Carlo (MCMC) methods such as the Metropolis-Hastings algorithm. Prelimi- nary results indicate that out method substantially increases structural visibility in both subcortical and cortical regions.","Verification and validation of hybrid systemsHybrid systems tightly integrate software-based discrete control systems and continuous physical phenomena. Better methods and tools for design, modeling, and analysis are necessary as these systems become more complex, powerful, and prevalent in our daily life. There are two main approaches to model hybrid systems. One is to discretize them into fully discrete systems. We focus on two discrete models: a network of communicating FSMs (NCFSM) and event-condition-action (ECA) rules. In this dissertation, we make several contributions to verifying discrete systems. First, for an NCFSM, we symbolically encode and verify the properties of livelocks, strong connectedness, and dead transitions. We also design a symbolic equivalence checker to automatically generate test cases for fault-based testing. Second, for ECA rules, we verify both termination and confluence properties and then provide the first practical experimental results for the confluence property. #R##N#The second modeling method is to keep the continuous dynamics by using hybrid automata or block diagrams. Most verification problems for hybrid automata are undecidable even under severe limitations. However, using block diagrams, such as Simulink, researchers model a hybrid system as an input-output signals mapping box. This approach has been widely adopted by industry due to its scalability. Combining simulation and temporal logic, the validation technique is able to check whether the temporal behavior of the system meets a set of requirements. One significant challenge to the formal validation is that system requirements are often imprecise, non-modular, evolving, or even simply unknown. In this dissertation, we make the following contributions to tackle the requirement defects. First, we compare the performance of the two existing falsification engines. Second, we design a requirement mining framework, an instance of counterexample-guided inductive synthesis, which is able to mine formal requirements from a closed-loop model. Third, we observe the importance of the monotonicity of formulas for synthesis and use a satisfiability modulo theories (SMT) solver to prove this property. Fourth, we propose weighted temporal logics to improve the performance of this mining framework. This framework has the following two applications: mined requirements can be used to validate future modifications of the model and enhance understanding of legacy models; the framework can also guide the process of bug-finding through simulations. We present two case studies for requirement mining: a simple automobile transmission controller and an industrial airpath control engine.","A fully homomorphic cryptosystem with approximate perfect secrecyWe propose a new fully homomorphic cryptosystem called Symmetric Polly Cracker (SymPC) and we prove its security in the information theoretical settings. Namely, we prove that SymPC approaches perfect secrecy in bounded CPA model as its security parameter grows (which we call approximate perfect secrecy).#R##N##R##N#In our construction, we use a Grobner basis to generate a polynomial factor ring of ciphertexts and use the underlying field as the plaintext space. The Grobner basis equips the ciphertext factor ring with a multiplicative structure that is easily algorithmized, thus providing an environment for a fully homomorphic cryptosystem.","Secondary Task Method for Workload Measurement in Alarm Monitoring and Identification Tasks ","Automatic Emotional Reactions Identification: A Software Tool for Offline User Experience ResearchCurrent affective response studies lack dedicated data analysis procedures and tools for automatically annotating and triangulating emotional reactions to game-related events. The development of such a tool would potentially allow for both a deeper and more objective analy- sis of the emotional impact of digital media stimuli on players, as well as towards the rapid implementation of this type of studies. In this paper we describe the development of such a tool that enables researchers to conduct objective a posteriori analyses, without disturbing the gameplay experience, while also automating the annotation and emotional response identifica- tion process. The tool was designed in a data-independent fashion and allows the identified responses to be exported for further analysis in third-party statistical software applications.","Big Data--Conceptual Modeling to the RescueBig data is characterized by volume, variety, velocity, and veracity. We should expect conceptual modeling to provide some answers since its historical perspective has always been about structuring information--making its volume searchable, harnessing its variety uniformly, mitigating its velocity with automation, and checking its veracity with application constraints. We provide perspectives about how conceptual modeling can \"come to the rescue\" for many big-data applications by handling volume and velocity with automation, by inter-conceptual-model transformations for mitigating variety, and by conceptualized constraint checking for increasing veracity.","Selection of wavelet decomposition level for electro-oculographic saccadic de-noisingAtaxia SCA2 is a neurological disorder among a group of inherited diseases of the central nervous system. In SCA2, genetic defects lead to impairment of specific nerve fibers, resulting in degeneration of the cerebellum and its afferent connections. As anomalies in the oculomotor system are well known symptoms in SCA2, electro-oculographic records become a useful technique for SCA2 diagnosis. This work presents a novel technique for determining how many decomposition levels are necessary to perform signal de-noising, based on the evaluation of the shape correspondence between the wavelet approximation coefficients and the EOG record, focusing in noise cancellation in order to obtain a clean velocity profile. Experimental results show the validity of the approach.","Adapting a speech into sign language translation system to a new domain.This paper presents a methodology for adapting an advanced communication system for deaf people in a new domain. This methodology is a user-centered design approach consisting of four main steps: requirement analysis, parallel corpus generation, technology adaptation to the new domain, and finally, system evaluation. In this paper, the new considered domain has been the dialogues in a hotel reception. With this methodology, it was possible to develop the system in a few months, obtaining very good performance: good speech recognition and translation rates (around 90%) with small processing times.","Word Occurrence Based Extraction of Work Contributors from Statements of Responsibility ","StoryJam: Supporting Collective Storytelling with Game MechanicsCollective storytelling is a narrative form that has cultural, cognitive, and organizational applications. Built on existing research in group collaboration, this short paper examines how certain game mechanics can be used to encourage and structure collaboration in StoryJam, a multi-player online game for collective storytelling.","Represent MOD function by low degree polynomial with unbounded one-sided errorIn this paper, we prove tight lower bounds on the smallest degree of a nonzero polynomial in the ideal generated by $MOD_q$ or $\\neg MOD_q$ in the polynomial ring $F_p[x_1, \\ldots, x_n]/(x_1^2 = x_1, \\ldots, x_n^2 = x_n)$, $p,q$ are coprime, which is called \\emph{immunity} over $F_p$. The immunity of $MOD_q$ is lower bounded by $\\lfloor (n+1)/2 \\rfloor$, which is achievable when $n$ is a multiple of $2q$; the immunity of $\\neg MOD_q$ is exactly $\\lfloor (n+q-1)/q \\rfloor$ for every $q$ and $n$. Our result improves the previous bound $\\lfloor \\frac{n}{2(q-1)} \\rfloor$ by Green. #R##N#We observe how immunity over $F_p$ is related to $\\acc$ circuit lower bound. For example, if the immunity of $f$ over $F_p$ is lower bounded by $n/2 - o(\\sqrt{n})$, and $|1_f| = \\Omega(2^n)$, then $f$ requires $\\acc$ circuit of exponential size to compute.","Transparency in Data Mining: From Theory to Practice ","Inferring Fitness in Finite, Variably-sized, and Dynamically-structured PopulationsBiological fitness is not an observable quantity and must be inferred from population dynamics. Bayesian inference applied to the Moran process and variants yields a robust inference method that can infer fitness in finite, variably-sized, and dynamically-structured populations. Information about fitness is derived solely from birth-events in birth-death and death-birth processes in which selection acts proportionally to fitness, which allows the method to be applied to populations on a network where the network itself may be changing in time. Populations may also be allowed to change size while still allowing estimates for fitness to be inferred.","Predicate Abstraction for Programmable Logic ControllersIn this paper, we present a predicate abstraction for programs for programmable logic controllers (PLCs) so as to allow for model checking safety related properties. Our contribution is twofold: First, we give a formalization of PLC programs in first order logic, which is then used to automatically derive a predicate abstraction using SMT solving. Second, we employ an abstraction called predicate scoping which reduces the evaluation of predicates to certain program locations and thus can be used to exploit the cyclic scanning mode of PLC programs. We show the effectiveness of this approach in a small case study using programs from industry and academia.","Emergency mobile access to personal health records stored on an untrusted cloudWhen storing files on an untrusted cloud, attribute based encryption is the cryptosystem usually chosen to securely encrypt the files while allowing fine grained access. When storing Personal Health Records (PHR), we find that allowing access to a user's emergency medical records (EMRs) during an emergency would be difficult to achieve while ensuring privacy preservation. Providing ECPs with unlimited and unrestricted access to EMRs is not an acceptable solution for a privacy view point. In this work our aim is to allow ECPs the ability to access a patient's EMRs, but only in the case of an emergency, preventing them from abusing their privileges. We propose a solution that solves this problem without requiring the participation of the patient in the process.","Bayesian Estimation of Probabilistic Atlas for Anatomically-Informed Functional MRI Group AnalysesTraditional analyses of Functional Magnetic Resonance Imaging (fMRI) use little anatomical information. The registration of the images to a template is based on the individual anatomy and ignores functional information; subsequently detected activations are not confined to gray matter (GM). In this paper, we propose a statistical model to estimate a probabilistic atlas from functional and T1 MRIs that summarizes both anatomical and functional information and the geometric variability of the population. Registration and Segmentation are performed jointly along the atlas estimation and the functional activity is constrained to the GM, increasing the accuracy of the atlas.","Being confident about the quality of the predictions in recommender systemsRecommender systems suggest new items to users to try or buy based on their previous preferences or behavior. Many times the information used to recommend these items is limited. An explanation such as\"I believe you will like this item, but I do not have enough information to be fully confident about it.\" may mitigate the issue, but can also damage user trust because it alerts users to the fact that the system might be wrong. The findings in this paper suggest that there is a way of modelling recommendation confidence that is related to accuracy (MAE, RMSE and NDCG) and user rating behaviour (rated vs unrated items). In particular, it was found that unrated items have lower confidence compared to the entire item set - highlighting the importance of explanations for novel but risky recommendations.","Strategisches Experience ManagementDer Markt fur Endkundenprodukte im 21. Jahrhundert zeigt, dass Kunden \u00bbbrauchbare\u00ab Produkte mit \u00bbeinfach, klar, rasch, intelligent und ansprechend\u00ab umschreiben. Das rein technische Funktionieren wird als Standard vorausgesetzt. Auch im professionellen Arbeitsumfeld erwarten Benutzer ahnliche Qualitaten. Die Beratungspraxis lasst jedoch erkennen, dass nur sehr wenige Unternehmen eine \u00bbradikale Kundenorientierung\u00ab in der Produkt- und Serviceentwicklung leben, auch unabhangig von der jeweiligen Branche bzw. Unternehmensgrose. Der Beitrag zeigt die Bedeutung einer ubergeordneten Experience-Strategie als entscheidenden Unternehmensfaktor in hochkompetitiven Markten und stellt ein entsprechendes Modell bzw. eine Vorgehensmethodik fur die Institutionalisierung vor.","A novel model for medical image similarity retrievalFinding the similar medical images from medical image database can help doctors diagnose based on the cases before. However the similarity retrieval for medical images requires much higher accuracy than the general images. In this paper, a new model of uncertain location graph is presented for medical image modeling and similarity retrieval. Then a scheme for uncertain location graph retrieval is introduced. Furthermore, an index structure is applied to reduce the searching time. Experimental results reveal that our method functions well on medical images similarity retrieval with higher accuracy and efficiency.","Weight Based Live Migration of Virtual MachinesDue to having many advantages, virtualization has been widely used and become a key technology of cloud computing. Live migration of virtual machines is the core technique of virtualization fields, but the existing pre-copy live migration approaches have problems of low copy efficiency and long total migration time, so we propose a weight based live migration algorithm of virtual machines in this paper, which adds weights to the dirty page information collected, preferentially selects and transfers the dirty pages that are not modified frequently, the dirty pages that are modified frequently are transferred after virtual machine is suspended. The algorithm effectively reduces the amount of memory pages transferred and the total migration time. Experiment results show that when virtual machine is under heavy load, the proposed algorithm considerably reduces the number of transferred memory pages and shortens the total migration time without significantly increment of the virtual machine downtime.","Analysis of the Use of Events and States as Brute Facts in Modelling of Institutional FactsAlthough the institutional dimension of a multi-agent system can be affected directly by the actions of the agents, it can be also affected by facts originating in the environment or even in the institution. In previous work, we proposed a model, language and its interpreter to specify the institutional consequences of both events and states from environment and institution. This paper analyses this twofold approach, looking for a better understanding about the performance of the interpreter and about the design differences between using event and states. The contributions of this work are (i) the evaluation of some aspects of a proposed and implemented language, (ii) guidelines to choose between events and states to model count-as rules, and (iii) an initial benchmark to evaluate further improvements to the interpreter and the performance of similar proposals.","Study on the Electromagnetic Performance of Hydroelectric Generator Based on Intelligent Control ","MultiSETTER - Multiple RNA Structure Similarity AlgorithmRecent advances in RNA research and a steady growth of available RNA structures call for bioinformatics methods for handling RNA structural data. Recently, we have introduced SETTER \u0096 a fast and accurate method for RNA pairwise structural alignment. In the present contribution we describe its extension for multiple RNA structure alignment called MultiSETTER. It combines SETTER's decomposition of RNA structures into disjoint fragments with a well known multiple sequence alignment algorithm ClustalW adapted for the structural alignment. We demonstrate the validity of our approach on the task of automatic classification of RNA structures.","\"The Four Most-Used Passwords Are Love, Sex, Secret, and God\": Password Security and Training in Different User GroupsPicking good passwords is a cornerstone of computer security. Yet already since the early days (e.g. The Stockings Were Hung by the Chimney with Care from 1973; we have also borrowed our title from the 1995 movie Hackers), insecure passwords have been a major liability. Ordinary users want simple and fast solutions - they either choose a trivial (to remember and to guess) password, or pick a good one, write it down and stick the paper under the mouse pad, inside the pocket book or to the monitor. They are also prone to reflecting their personal preferences in their password choices, providing telling hints online and giving them out on just a simple social engineering attack. Kevin Mitnick has said that security is not a product that can be purchased off the shelf, but consists of policies, people, processes, and technology. This applies fully to password security as well. We studied several different groups (students, educators, ICT specialists etc - more than 300 people in total) and their password usage. The methods included password practices survey, password training sessions, discussions and also simulated social engineering attacks (the victims were informed immediately about their mistakes). We suggest that password training should be adjusted for different focus groups. For example, we found that schoolchildren tend to grasp new concepts faster - often, a simple explanation is enough to improve the password remark- ably. Thus, we would stress the people and process aspects of the Mitnick for- mula mentioned above.At the same time, many officials and specialists tend to react to password training with dismissal and scorn (our study suggests that 'you cannot guess my password' is an alarmingly common mindset). Examples like 'admin', 'Password', '123456' etc have occurred even at qualified security professionals, more so at educators. Yet, as Estonia is increasingly relying on the E-School system, these passwords are becoming a prime target. Therefore, for most adult users we suggest putting the emphasis on policy and technology aspects (strict, software-enforced lower limits of acceptable password length, character variability checks, but also clearly written rulesets etc).","Closing a Long-Standing Complexity Gap for Selection: V 3(42) = 50 ","Effects of In-Car Navigation Systems on User Perception of the Spatial Environment ","Semantic Approach to Cluster Validity Notion ","Vibro-Tactile Enrichment Improves Blind User Interaction with Mobile Touchscreens ","Extraction of Agent Groups with Similar Behaviour Based on Agent Profiles ","A study on the evolution of cooperation in networksThis paper studies the phenomenon of the evolution of co- operation in networks, where each player in networks plays an iterated game against its neighbours. An iterated game in a network is a multi- ple round game, where, in each round, a player gains payoff by playing a game with its neighbours and updates its action by using the actions and/or payoffs of its neighbours. The interaction model between the play- ers is usually represented as a two-player, two-action (i.e., cooperation and defection) Prisoner's Dilemma game. Currently, many researchers developed strategies for the evolution of cooperation in structured net- works in order to enhance cooperation, i.e., to increase the proportion of cooperators. However, experimental results, reported in current lit- erature, demonstrated that each of these strategies has advantages and disadvantages. In this paper, a self-organisation based strategy is pro- posed for the evolution of cooperation in networks, which can utilise the strengths of current strategies and avoid the limitations of current strategies. The proposed strategy is empirically evaluated and its good performance is exhibited. Moreover, we also theoretically find that, in static networks, the final proportion of cooperators evolved by any pure (or deterministic) strategies fluctuates cyclically irrespective of the initial proportion of cooperators.","Selected Random Subspace Novelty Detection Filter ","Abstraction Multimodal Low-Dimensional Representation from High-Dimensional Posture Information and Visual Images ","Hybrid Petri Nets for Modelling the Eukaryotic Cell CycleBrandenburgUniversityofTechnologyatCottbus,ComputerScienceInstitute,DataStructuresandSoftwareDependability,Postbox101344,03044Cottbus,Germanyhttp://www-dssz.informatik.tu-cottbus.de/Abstract. System level understanding of the repetitive cycle of cellgrowth and division is crucial for disclosing many unknown principlesofbiologicalorganisms.Thedeterministicorstochasticapproach\u2013whendeployedseparately\u2013arenotsu\ufb03cienttostudysuchcellregulationduetothecomplexityofthereactionnetworkandtheexistenceofreactionsat di\ufb00erent time scales. Thus, an integration of both approaches is ad-visabletostudysuchbiochemicalnetworks.InthispaperweshowhowGeneralised HybridPetri Nets can be used to intuitivelyrepresent andsimulatetheeukaryoticcellcycle.Ourmodelcapturesintrinsicaswellasextrinsicnoiseanddeploysstochasticaswellasdeterministicreactions.Additionally,marking-dependentarc weights are biologically motivatedand introduced to Snoopy \u2013 a tool for animating and simulating Petrinetsinvariousparadigms.Keywords: GeneralisedhybridPetrinets,hybridmodelling,eukaryoticcellcycle,Snoopy,marking-dependentarcweight.","Trajectory Planning and Stabilization for Formations Acting in Dynamic Environments ","A Novel Preprocessing Method for Illumination-Variant Color Face Image ","Maximum independent set of links with a monotone and sublinear power assignmentThis paper studies the problem of selecting a maximum independent set of links with a fixed monotone and sublinear power assignment under the physical interference model. The best-known approximation bound for this problem is a very large constant. In this paper, we present an approximation algorithm for this problem, which not only has a much smaller approximation bound but also produces an independent set of links with a stronger property, i.e., strong independence.","Multiobjective Local Search Techniques for Evolutionary Polygonal Approximation ","Improving University Quality of Services through Mobile Devices: The Case of the Technological University of Panama ","On random quotas and proportional representation in weighted voting gamesWeighted voting games (WVGs) model decision making bodies such as parliaments and councils. In such settings, it is often important to provide a measure of the influence a player has on the vote. Two highly popular such measures are the Shapley-Shubik power index, and the Banzhaf power index. Given a power measure, proportional representation is the property of having players' voting power proportional to the number of parliament seats they receive. Approximate proportional representation (w.r.t. the Banzhaf power index) can be ensured by changing the number of parliament seats each party receives; this is known as Penrose's square root method. However, a discrepancy between player weights and parliament seats is often undesirable or unfeasible; a simpler way of achieving approximate proportional representation is by changing the quota, i.e. the number of votes required in order to pass a bill.#R##N##R##N#It is known that a player's Shapley-Shubik power index is proportional to his weight when one chooses a quota at random; that is, when taking a random quota, proportional representation holds in expectation. In our work, we show that not only does proportional representation hold in expectation, it also holds for many quotas. We do so by providing bounds on the variance of the Shapley value when the quota is chosen at random, assuming certain weight distributions. We further explore the case where weights are sampled from i.i.d. binomial distributions; for this case, we show good bounds on an important parameter governing the behavior of the variance, as well as substantiating our claims with empirical analysis.","Teleoperation of Domestic Service Robots: Effects of Global 3D Environment Maps in the User Interface on Operators' Cognitive and Performance MetricsThis paper investigates the suitability of visualizing global 3D environment maps generated from RGB-D sensor data in teleoperation user interfaces for service robots. We carried out a controlled experiment involving 27 participants, four teleoperation tasks, and two types of novel global 3D mapping techniques. Results show substantial advantages of global 3D mapping over a control condition for three of the four tasks. Global 3D mapping in the user interface lead to reduced search times for objects and to fewer collisions. In most situations it also resulted in less operator workload, higher situation awareness, and higher accuracy of operators' mental models of the remote environment.","A Probabilistic Graphical Model for Tuning Cochlear ImplantsSevere and profound hearing losses can be treated with coch- lear implants (CI). Given that a CI may have up to 150 tunable parame- ters, adjusting them is a highly complex task. For this reason, we decided to build a decision support system based on a new type of probabilistic graphical model (PGM) that we call tuning networks. Given the results of a set of audiological tests and the current status of the parameter set, the system looks for the set of changes in the parameters of the CI that will lead to the biggest improvement in the user's hearing ability. Because of the high number of variables involved in the problem we have used an object-oriented approach to build the network. The prototype has been informally evaluated comparing its advice with those of the expert and of a previous decision support system based on deterministic rules. Tuning networks can be used to adjust other electrical or mechanical devices, not only in medicine.","One-Handed gesture design for browsing on touch phoneThe goal of this research is to understand how dual-surface touch gesture helps user interact mobile phone with one hand from user experience perspective. Hence, we proposed a set of gestures and some design recommendations for enhancing the browsing usability. Finally we emulated the information seeking task on mobile phone. The results showed that, compare to traditional graphic user interface, browsing gestures eased the thumb fatigue, reduced the error rate and task completed time.","Participatory Approach versus Bureaucratic \u2018Pressure\u2019: The Case of Health Information Systems ProgrammeImplementation of Information Systems in Public Healthcare in India has been a very complex undertaking. Participation of the end-users during de- sign and implementation is important. Participation within bureaucratic settings poses unique challenges, due to hierarchical, centralized, authoritarian and for- malistic practices. Even where State agencies have experimented to bring in imaginative changes, participation have not been voluntary, but have been enforced. This short paper attempts to analyse less know and less understood aspect of participatory approach entangled within bureaucratic systems. This paper attempts to analyse the issues around participation in order to identify two key areas: (1) How to encourage public sector employees to participate during design, development and implementation of IS? (2) How can public sector insti- tutions encourage effective participation? Discourses on Participatory Approach is drawn upon to analyse the case of Health Information Systems Programme.","Mining Audio Data for Multiple Instrument Recognition in Classical Music ","Research on Resource Management in PaaS Based on IaaS Environment ","Decentralized Ciphertext-Policy Attribute-Based Encryption Scheme with Fast DecryptionIn this paper, we propose an efficient multi-authority decentralized ciphertext-policy attribute-based encryption scheme dCP-ABE-MAS for monotone access structures (MAS). Our setup is without any central authority (CA) where all authorities function entirely independently and need not even be aware of each other. The scheme makes use of the minimal authorized sets representation of MAS to encrypt messages, and hence the size of ciphertext is linear in the number of minimal authorized sets in MAS and the number of bilinear pairings is constant during decryption. We describe several networks that can use dCP-ABE-MAS to control data access from unauthorized nodes. The proposed scheme resists collusion attacks and is secure against chosen plaintext attacks in the generic bilinear group model over prime order bilinear groups.","A Toolkit for Ring-LWE CryptographyRecent advances in lattice cryptography, mainly stemming from the development of ring-based primitives such as ring-LWE, have made it possible to design cryptographic schemes whose efficiency is competitive with that of more traditional number-theoretic ones, along with entirely new applications like fully homomorphic encryption. Unfortunately, realizing the full potential of ring-based cryptography has so far been hindered by a lack of practical algorithms and analytical tools for working in this context. As a result, most previous works have focused on very special classes of rings such as power-of-two cyclotomics, which significantly restricts the possible applications. We bridge this gap by introducing a toolkit of fast, modular algorithms and analytical techniques that can be used in a wide variety of ring-based cryptographic applications, particularly those built around ring-LWE. Our techniques yield applications that work in arbitrary cyclotomic rings, with no loss in their underlying worst-case hardness guarantees, and very little loss in computational efficiency, relative to power-of-two cyclotomics. To demonstrate the toolkit's applicability, we develop two illustrative applications: a public-key cryptosystem and a \"somewhat homomorphic\" symmetric encryption scheme. Both apply to arbitrary cyclotomics, have tight parameters, and very efficient implementations.","Empirical Specification of Dialogue Games for an Interactive AgentThis article addresses the challenge of designing the com- municative behaviour of an agent interacting with humans. We present a data-driven methodology based on the production of a matrix repre- sentation of a corpus from which we extract dialogue patterns. These patterns reflect the minimal units of interaction which turn out to be very attractive for dialogue modelling. We present a framework to spec- ify dialogue games from these patterns based on the notion of social commitments. We exemplify the specification of dialogue games by im- plementing all the steps of our methodology on a task-oriented corpus. The produced games are validated by showing that they appropriately describe the patterns appearing in a reference corpus.","A Revenue-Maximizing Scheme for Radio Access Technology Selection in Heterogeneous Wireless Networks with User Profile Differentiation ","A Service Oriented Framework for Animating Big Spatiotemporal DatasetsWe propose a service oriented distributed system framework for animating big spatiotemporal vector datasets. The aim is exploiting the patterns in spatial data dynamically changing over time. Animation consists of succes- sively played and temporally related still map images. Each map image in the animation is a satellite map enriched with (or plotted over) spatiotemporal data- sets. The system components are designed as web services. We also extend open standards' GIS web services definitions with topic-based publish- subscribe paradigm, which best suits to the animation requirements. Vast amounts of data related to earth are time-series and spatial in nature. Spatial data are preferably represented and displayed as map layers. When you have the same layer in several different moments along the time, it is better to display them as part of a movie. This is called time-series animation, which is a visualization technique ideal- ly suited for the display and analysis of spatiotemporal and geographic data sets. Map animations enable scientific analysis and results to be understood not only by the scientist but also the public and policymakers from different domains and education level. Animated maps can be interpreted more easily than their static representations by the users. We propose a service oriented distributed system framework (1) for map anima- tions. Maps are created from spatiotemporal datasets. Services in the system are de- fined with standard bodies (Open Geospatial Consortium (OGC) (2) and ISO-TC211). Standardization offers advantages for data sharing, for combining software compo- nents and for overlaying graphical outputs from different sources. However, standar- dization comes with its costs. Costs mostly come from the fact that web services are based on XML based SOAP over HTTP protocol and data to be processed are en- coded in Geographic Markup language (GML) (3) which is an XML-based format. To overcome such problems in a distributed system framework requiring large scale XML-encoded geographic feature sets, we have investigated the possibilities of using topic-based publish-subscribe paradigms (which is mostly used in P2P systems) for","Learning a Sparse Representation for Robust Face Recognition ","Memory Efficient Self-Stabilizing k-Independent Dominating Set ConstructionIn this paper, we consider the problem of computing a k-independent dominating set in a self-stabilizing manner in case where k &gt; 1. A nodes set is a k-independent dominating set (also called maximal k-independent set) if and only if this set is a k-independent set and a k-dominating set. A set of nodes, I is k-independent if the distance between any pair of I's nodes is at least k + 1. A set of nodes D is k-dominating if every node is within distance k of a node of D.","Challenges and opportunities of mobile app developmentThe past few years have seen a remarkable transformation in how we communicate, interact with each other and conduct business. Look around you in the restaurant, or in the stadium at the ball game, or on the subway, and notice the modern tie that binds: the mobile device. Think about how you plan your next vacation, or buy movie tickets, or file an insurance claim, or pay your bills. There's no guarantee you're using it for activities like these, but chances are pretty high that you are: the mobile device. Smart phones, tablets and even so-called \"convertible\" lap tops are all around us, and woe be to the business that doesn't pander shamelessly to this new method of interaction because -- for the average consumer -- ads in the yellow pages, friendly store fronts, and even good old fashioned web pages don't cut it these days.","Multi-label Classification with Output KernelsAlthough multi-label classification has become an increasingly important problem in machine learning, current approaches remain restricted to learning in the original label space or in a simple linear projection of the original label space. Instead, we propose to use kernels on output label vectors to significantly expand the forms of label dependence that can be captured. The main challenge is to reformulate standard multi-label losses to handle kernels between output vectors. We first demonstrate how a state-of-the-art large margin loss for multi-label classification can be reformulated, exactly, to handle output kernels as well as input kernels. Importantly, the pre-image problem for multi-label classification can be easily solved at test time, while the training procedure can still be simply expressed as a quadratic program in a dual parameter space. We then develop a projected gradient descent training procedure for this new formulation. Our empirical results demonstrate the efficacy of the proposed approach on complex image labeling tasks.","Sequent Calculi for Multi-modal Logic with InteractionThis paper studies Gentzen-style sequent calculi for multi-modal logics with interaction between the modalities. We prove cut elimination and some of its usual corollaries for two such logics: Standard Deontic Logic with the Ought-implies-Can principle, and a non-normal deontic logic where obligation, permissions and abilities interact in a complex way. The key insight of these results is to make rules sensitive to the shape of the formulas on either sides of the sequents. This way one can devise rules in a much more modular fashion. This feature of Hilbert-style systems is notoriously lost when one moves to sequent calculi. By partly restoring modularity the method proposed here can potentially provide a unified approach to the proof theory of multi-modal systems.","The strong perron integral of fuzzy number valued functionsIn this paper, we study the strong Perron integral of fuzzy-number-valued function, and show that the strong fuzzy Perron integral is equivalent to the fuzzy McShane integral.","Shortest Path Computation over Disk-Resident Large Graphs Based on Extended Bulk Synchronous Parallel Methods ","Evaluating emergency physicians: data envelopment analysis approach.The purpose of this research is to develop an evaluation tool to assess performance of Emergency Physicians according to such criteria as resource utilization, patient throughput and the quality of care. Evaluation is conducted using a mathematical programming model known as Data Envelopment Analysis (DEA). Use of this model does not require the subjective assignment of weights associated with each criterion \u2013 a feature typical of methodologies that rely on composite scores. The DEA model presented in this paper was developed using a hypothetical data set describing a representative set of profiles of Emergency Physicians. The solution to the model relates the performance of each Emergency Physician in relation to the others and to a benchmark. We discuss how such an evaluation tool can be used in practice.","Governance of IT Service Procurement: Relationship vs Network based Approach ","First Hand Developer Experiences of Social Devices ","An Online Trend Analysis Method for Measuring Data Based on Historical Data Clustering ","On Skyline Queries and How to Choose from Pareto Sets* Abstract. Skyline queries are well known for their intuitive query formalization and easy to understand semantics when selecting the most interesting database objects in a personalized fashion. They naturally fill the gap between set-based SQL queries and rank-aware database retrieval and thus have emerged in the last few years as a popular tool for personalized retrieval in the database research community. Unfortunately, the Skyline paradigm also exhibits some significant drawbacks. Most prevalent among those problems is the so called \"curse of di- mensionality\" which often leads to unmanageable result set sizes. This flood of query results, usually containing a significant portion of the original database, in turn severely hampers the paradigm's applicability in real-life systems. In this chapter, we will provide a survey of techniques to remedy this problem by choos- ing the most interesting objects from the multitude of skyline objects in order to obtain truly manageable and personalized query results.","Complete Abstractions EverywhereWhile soundness captures an essential requirement of the intrinsic approximation of any static analysis, completeness encodes approximations that are as precise as possible. Although a static analysis of some undecidable program property cannot be complete relatively to its reference semantics, it may well happen that it is complete relatively to an approximated and decidable reference semantics. In this paper, we will argue on the ubiquity of completeness properties in static analysis and we will discuss the beneficial role that completeness can play as a tool for designing and fine-tuning static analyses by reasoning on the completeness properties of their underlying abstract domains.","Dynamic Torque Control Incorporating Tracking Differentiator for Motor-Driven Load Simulator ","Design and implementation of an office automation assistant utility using adobe AIR technologyComprehensive online office automation platform helps one process/exchange online documents, schedule meetings and complete information integration as well as other daily office work. However active reminding function of incoming documents/scheduled meetings still remains unavailable in most of the current office automation systems. Thus, traditionally, users have to repeatedly refresh related web pages to obtain latest information, which inevitably influences working efficiency. To tackle the problem, we design and implement an assistant utility, providing the needed reminding functions. The utility is built on Adobe AIR technology, a desktop-oriented browser-less runtime frame for developing Rich Internet Applications (RIAs). Through the provided web service, the utility gets the latest information from office automation server. Additionally, HTTP service is employed for providing auto update capability. Moreover, memory optimization is considered in the design and implementation.","A Neural Network Simulation of Spreading Depression ","Skyline Query for Location-Based Recommendation in Mobile ApplicationThe development of mobile computing and communication technology has become more and more important in recent years. In many mobile applications, users need to select \"good\" information in massive data and skyline query is an approach to achieve the goal in decision-marking situations. In our paper, we present skyline queries in mobile application to select the most qualified parking lots according to the current location and some other information of the parking lots. The information, such as the space number, is updating varying time and the user's location will change, too. Furthermore, we only need to consider the parking lots in local position to gain the optimization goal, rather than global optimization goal. So we need to improve the sky- line query and make it appropriate for local query and location-based dynamic query.","Towards a Framework for Structuring Theory in IS ResearchIn the past, IS research has been criticized for its inability to build a cumulative tradition of IS-specific theory. We suggest that the difficulty in structuring theoretical contributions in IS is one facet of that problem. This has led to a situation in which a lot of theory generation in IS is not made apparent as such. Based on a conceptual review on theory, we design a framework to structure theoretical contributions in IS. Applying our framework, we show that IS research does offer a broad basis of early, substantive theories and even some more comprehensive theoretical accounts specific to our discipline that IS scholars could build on in a cumulative tradition. We use the context of theory generation in and for IS based on the Grounded Theory approach. In doing so, we hope to enable a more structured discourse on the current state of theory generation in IS.","Publishing a Disease Ontologies as Linked DataPublishing open data as linked data is a significant trend in not only the Semantic Web community but also other domains such as life science, government, media, geographic research and publication. One feature of linked data is the instance-centric approach, which assumes that considerable linked instances can result in valuable knowledge. In the context of linked data, ontologies offer a common vocabulary and schema for RDF graphs. However, from an ontological engineering viewpoint, some ontologies offer systematized knowledge, developed under close cooperation between domain experts and ontology engineers. Such ontologies could be a valuable knowledge base for advanced information systems. Although ontologies in RDF formats using OWL or RDFS can be published as linked data, it is not always convenient to use other applications because of the complicated graph structures. Consequently, this paper discusses RDF data models for publishing ontologies as linked data. As a case study, we focus on a disease ontology in which diseases are defined as causal chains.","Using Interleaving to Avoid the Effects of Multiple Adjacent Faults in On-Chip Interconnection LinesAs technology shrinks, higher operating frequencies, reduced feature sizes and lower supply voltages allow greater performance, but the reliability has been affected negatively. Smaller devices and wire spacing lead to an in- crease in the occurrence of multiple adjacent faults. Thus, the system reliability is seriously affected. Error correction codes are a powerful technique that al- lows higher reliability using information redundancy. This paper focuses on the use of interleaved codes to tolerate faults in on-chip interconnection lines. Inter- leaving has been extensively used in memories, but not in system buses. To il- lustrate the features of this technique, an example has been included.","Soft Pattern Mining in NeuroscienceWhile the lower-level mechanisms of neural information process- ing (in biological neural networks) are fairly well understood, the principles of higher-level processing remain a topic of intense debate in the neuroscience community. With many theories competing to explain how stimuli are en- coded in nerve signal (spike) patterns, data analysis tools are desired by which proper tests can be carried out on recorded parallel spike trains. This paper surveys how pattern mining methods, especially soft methods that tackle the core problems of temporal imprecision and selective participation ,c an help to test the temporal coincidence coding hypothesis. Future challenges consist in extending these methods, in particular to the case of spatio-temporal coding.","Fuzzy Least Squares Estimation with New Fuzzy Operations ","Automated Test Case Generation in End-User Programming ","Improving ESA with document similarityExplicit semantic analysis (ESA) is a technique for computing semantic relatedness between natural language texts. It is a document-based distributional model similar to latent semantic analysis (LSA), which is often built on the Wikipedia database when it is required for general English usage. Unlike LSA, however, ESA does not use dimensionality reduction, and therefore it is sometimes unable to account for similarity between words that do not co-occur with same concepts, even if their concepts themselves cover similar subjects. In the Wikipedia implementation ESA concepts are Wikipedia articles, and the Wikilinks between the articles are used to overcome the concept-similarity problem. In this paper, we provide two general solutions for integration of concept-concept similarities into the ESA model, ones that do not rely on a particular corpus structure and do not alter the explicit concept-mapping properties that distinguish ESA from models like LSA and latent Dirichlet allocation (LDA).","Verifying Temporal Properties in Real ModelsBased on pioneering work of Lauchli and Leonard in the 1960s, a novel and expressive formal language, Model Expressions, for describing the compositional construction of general linear temporal structures has recently been proposed. A sub-language, Real Model Ex- pressions, is capable of specifying models over the real flow of time but its semantics are subtly different because of the specific properties of the real numbers. Model checking techniques have been developed for the general linear Model Expressions and it was shown that checking temporal formulas against structures described in the formal language is PSPACE-Complete and linear in the length of the model expression. In this paper we present a model checker for temporal formulas over real-flowed models. In fact the algorithm, and so its complexity, is the same as for the general linear case. To show that this is adequate we use a concept of temporal bisimula- tions and establish that it is respected by the compositional construction method. We can then check the correctness of using the general linear model checking algorithm when applied to real model expressions with their special semantics on real-flowed structures.","An Abrupt Signal Detection as Accident Detection by Hamiltonian Eigenvalue on Highway CCTV Traffic Signal ","Image Segmentation Based on Representative Colors Detection and Region Merging ","Spotz: a location-based approach to self-awarenessThis paper introduces the location-based mobile application Spotz that explores the persuasive qualities of sharing location information visually to promote behavior change. Spotz encourages users to become self-aware of the kinds of places they visit which can have motivational properties deriving from social feedback. The app displays a continually evolving graphic of relatively sized circles depicting the number and type of places at which the users check-in, including the option to upload this visual to social media.","Limits of Imitating Marketplace Design: The Case of an Automotive Service Marketplace. ","Entrepreneurship Competence Assessment Through a Game Based Learning MOOC ","Consumer Acceptance of Electronic Reading DevicesThis study investigates the acceptance of electronic reading devices among newspaper subscribers. The theoretical framework is based on the Technology Acceptance Model TAM, which was modified to suit the context. The empirical data was collected from 1084 newspaper subscribers. First, principal component analysis was used to examine the consumers' attitudes towards electronic reading devices. Based on the analysis, five distinct factors in relation to consumers' willingness to adopt electronic reading devices were found: 'Eco-consciousness', 'Social prestige', 'Ease of use', 'Enjoyment value' and 'Extra features'. Second, based on the results of the factor analysis, consumers were grouped into four groups using cluster analysis. These groups were: Enjoyment seeking consumers, Eco-consciousness consumers, Serious and practical consumers, and Social consumers. Finally, the authors examined how these consumer groups differ in their intention to use electronic reading devices, and found several interesting differences.","HN-Sim: A Structural Similarity Measure over Object-Behavior NetworksMeasurement of similarity is a critical work for many ap- plications such as text analysis, link prediction and recommendation. However, existing work stresses on content and rarely involves structural features. Even fewer methods are applicable for heterogeneous network, which is prevalent in the real world, such as bibliographic information network. To address this problem, we propose a new measurement of similarity from the perspective of the heterogeneous structure. Hetero- geneous neighborhood is utilized to instantiate the topological features and categorize the related nodes in graph model. We make a compari- son between our measurement and some traditional ones with the real data in DBLP 1 and Flickr 2 . Manual evaluation shows that our method outperforms the traditional ones.","A block cipher mode of operation with two keysIn this paper, we propose a novel block cipher mode of operation (BCMO for short), named Output Protection Chain (OPC for short), which as a symmetric encryption structure is different from other existing BCMOs in that it employs two keys, rather than one key, to protect the output of the mode. The security threats of chosen-plaintext attacks on three existing common BCMOs, including the Cipher Feedback mode (CFB), the Output Feedback mode (OFB), and the Counter mode (CTR), are also analyzed. After that, we explain why the OPC mode (or simply the OPC) can effectively avoid chosen-plaintext attacks, and why its security level is higher than those of CFB, OFB, and CTR.","Opening the Black Box of Ontology MatchingDue to the high heterogeneity of ontologies, a combination of many methods is necessary in order to discover correctly the semantic correspondences between their elements. An ontology matching tool can be seen as a collection of several matching components, each implementing a specific method dealing with a specific heterogeneity type (terminological, structural or semantic). In addition, a mapping selection module is introduced to filter out the most likely mapping candidates. This paper proposes an empirical study of the interaction between these components working together inside an ontology matching system. By the help of datasets from the Ontology Alignment Evaluation Initiative, we have carried out several experimental studies. In the first place, we have been interested in the impact of the mapping selection module on the performance of terminological and structural matchers revealing the advantage of using global methods vs. local ones. Further, we have carried an extensive study on the flaw of the performance of a structural matcher in the presence of noisy input coming from a terminological method. Finally, we have analyzed the behavior of a structural and a semantic component with respect to inputs taken from different terminological matchers.","Performance of planning support systems: what is it, and how do we report on it?Planning Support Systems (PSSs) are a family of computer based instruments specifically designed to support actors in their complex tasks in the field of planning. There is a gap between the high expectations that PSS developers have about the usefulness of their instruments and the instruments\u2019 application in daily planning practice. PSS academics have proposed several ways to close this so-called implementation gap through a range of software, hardware and orgware approaches. Several of these approaches have been applied in practical planning settings. There is however a lack of consistent and structured reporting on the effectiveness of these approaches in improving PSS performance. Therefore, it is hard to distinguish between successful and less successful strategies, and it is difficult to draw overall lessons. This paper (1) proposes a comprehensive multidimensional framework that operationalizes PSS performance, and (2) analyses how recent PSS implementation studies have reported on this performance. The developed framework, based on literature from Group Model Building and group psychology, is sensitive to a wide variety of performance dimensions and therefore forms a useful guideline for assessing PSS implementation strategies. Studying these in a common framework supports the potential transfer of lessons to other PSS implementations. Most of the analyzed studies only posed hypotheses about which dimensions are improved through a specific strategy, but did not report on measuring impacts. By structurally measuring the effectiveness of a range of strategies to improve PSS implementation, lessons can be exchanged and a consistent body of knowledge can be built.","Making the Right Connections: Challenges for the Educator and Learner ","Production Plan-Driven Flexible Assembly Automation ArchitectureManufacturing industries are currently under a strong pressure to easily adapt to changing market situations. In order to stay profitable production automation systems need to flexibly adapt to different products, product variants, and product volumes. In this work we investigate how a flexible recipe-based control approach can be transferred from batch automation systems to discrete manufacturing. We define a generic control architecture and a manufacturing recipe model that allows to execute recipe parts directly in the low-level control devices of the involved manufacturing cells. An evaluation of the developed system on a demonstration plant shows the aptness for discrete manufacturing. The developed system with its flexibility on the lowest control level can also serve as a foundation for highly flexible supervising control strategies like the HMS approach.","How to create a user experience storyNarratives are a tool used in many disciplines. In the area of User Experience Design (UXD), in particular, a storytelling approach can be applied during the whole design process to improve the quality of developed concepts regarding user experience (UX). Furthermore stories support designers in exploring and communicating their new concept ideas. However, the guidelines on how to create a story are either too abstract or do not focus on the experience elements of the interaction. This paper aims at systemizing the storytelling approach in the context of UXD in a ten-step-methodology for story creation. The proposed approach emphasizes on experience-related elements of interaction. The UX story is written by and aims at designers with the scope to communicate UX and reinforce it in product implementation. Further, the approach is systemized in a ten-steps-description with additional form sheets in order to support the application by designers from various backgrounds. In future projects a systematic evaluation of the tools introduced would validate the observed positive outcomes of applying storytelling in UX projects.","Utilizing Microblogs for Web Page Relevant Term Acquisition ","Adapting Recommendation Diversity to Openness to Experience : A Study of Human BehaviourThis paper uses a User-as-Wizard approach to evaluate how people apply diversity to a set of recommendations. In particular, it considers how diversity is applied for a recipient with high or low Openness to Experience, a personality trait from the Five Factor Model. While there was no effect of the personality trait on the degree of diversity applied, there seems to be a trend in the way in which it was applied. Maximal categorical diversity (across genres) was more likely to be applied to those with high Openness to Experience, at the expense of maximal thematic diversity (within genres). \u00a9 2013 Springer-Verlag.","Sentic Computing for Social Media Analysis, Representation, and Retrieval ","A Study of the Combination of Variation Operators in the NSGA-II AlgorithmMulti-objective evolutionary algorithms rely on the use of variation operators as their basic mechanism to carry out the evolution- ary process. These operators are usually fixed and applied in the same way during algorithm execution, e.g., the mutation probability in genetic algorithms. This paper analyses whether a more dynamic approach com- bining different operators with variable application rate along the search process allows to improve the static classical behavior. This way, we ex- plore the combined use of three different operators (simulated binary crossover, differential evolution's operator, and polynomial mutation) in the NSGA-II algorithm. We have considered two strategies for selecting the operators: random and adaptive. The resulting variants have been tested on a set of 19 complex problems, and our results indicate that both schemes significantly improve the performance of the original NSGA-II algorithm, achieving the random and adaptive variants the best overall results in the bi- and three-objective considered problems, respectively.","Non-linear feature fusion based on polynomial correlation filter for face recognitionConference Name:4th International Conference on Intelligence Science and Big Data Engineering, IScIDE 2013. Conference Address: Beijing, China. Time:July 31, 2013 - August 2, 2013.","Feature selection and classification of high dimensional mass spectrometry data: a genetic programming approachBiomarker discovery using mass spectrometry (MS) data is very useful in disease detection and drug discovery. The process of biomarker discovery in MS data must start with feature selection as the number of features in MS data is extremely large (e.g. thousands) while the number of samples is comparatively small. In this study, we propose the use of genetic programming (GP) for automatic feature selection and classification of MS data. This GP based approach works by using the features selected by two feature selection metrics, namely information gain (IG) and relief-f (REFS-F) in the terminal set. The feature selection performance of the proposed approach is examined and compared with IG and REFS-F alone on five MS data sets with different numbers of features and instances. Naive Bayes (NB), support vector machines (SVMs) and J48 decision trees (J48) are used in the experiments to evaluate the classification accuracy of the selected features. Meanwhile, GP is also used as a classification method in the experiments and its performance is compared with that of NB, SVMs and J48. The results show that GP as a feature selection method can select a smaller number of features with better classification performance than IG and REFS-F using NB, SVMs and J48. In addition, GP as a classification method also outperforms NB and J48 and achieves comparable or slightly better performance than SVMs on these data sets.","Security for Diversity: Studying the Effects of Verbal and Imagery Processes on User Authentication Mechanisms ","Fast Catheter Tracking in Echocardiographic Sequences for Cardiac Catheterization InterventionsFor most cardiac catheterization interventions, X-ray imaging is currently used as a standard imaging technique. However, lack of 3D soft tissue information and harmful radiation mean that X-ray imaging is not an ideal modality. In contrast, 3D echocardiography can overcome these disadvantages. In this paper, we propose a fast catheter tracking strategy for 3D ultrasound sequences. The main advantage of our strategy is low use of X-ray imaging, which significantly decreases the radiation exposure. In addition, 3D soft tissue imaging can be introduced by using ultrasound. To enable the tracking procedure, initialization is carried out on the first ultrasound frame. Given the location of the catheter in the previous frame, which is in the form of a set of ordered landmarks, 3D Speeded-Up Robust Feature SURF responses are calculated for candidate voxels in the surrounding region of each landmark on the next frame. One candidate is selected among all voxels for each landmark based on Fast Primal-Dual optimization Fast-PD. As a result, a new set of ordered landmarks is extracted, corresponding to the potential location of the catheter on the next frame. In order to adapt the tracking to the changing length of the catheter in the view, landmarks which may not be located on the catheter are ruled out. Then a catheter growing strategy is performed to extend the tracked part of the catheter to the untracked part. Based on 10 ultrasound phantom sequences and two clinical sequences, comprising more than 1300 frames, our experimental results show that the tracking system can track catheters with an error of less than 2.5mm and a speed of more than 3 fps.","Monitoring system-of-systems requirements in multi product lines[Context and motivation] Large-scale software-intensive systems are often considered as systems of systems comprising several interrelated product lines from which system variants are derived to meet the overall requirements. [Question/problem] If multiple teams and experts configure these individual systems, their individual configuration choices might conflict with the system-of-systems requirements. [Principal ideas/results] This research preview paper presents our ongoing work on a tool-supported approach for monitoring system-of-systems requirements formalized as constraints during distributed product derivation in multi product lines. [Contribution] The approach allows detecting violations of multi system requirements during the configuration of individual systems and provides immediate feedback to the involved configurers. Our approach is integrated in the product configuration tool DOPLER developed in cooperation with an industrial partner.","A Real-Time Fluid Rendering Method with Adaptive Surface Smoothing and Realistic SplashWe present an adaptive approach in particle-based fluid sim- ulation to smooth the surface rendered using splatting in screen space. A real-time effect of surface smoothing and edge preserving is achieved in both the situations that camera is close to or far away from the fluid. This method is based on Bilateral filtering and using an adaptive range coefficient according to the viewing distance, so that the filter offers more blurring effect while the camera is approaching the surface and more edge protection when the viewpoint is maintaining a long distance to the fluid. We also introduce a physics-based splash model in turbulent flow for real-time simulation with a corresponding rendering method. The local density of particles in SPH simulation and Weber number are used to determine the formation and breakup of splash particles. Based on the splash breakup regime in physics, a pattern is proposed to organize the shape formed by the newly generated breaking up particles.","Comparison of Reinforcement and Supervised Learning Methods in Farmer-Pest Problem with Delayed RewardsIn this paper we propose a method based on the time-window idea which allows agents to generate their strategy using supervised learning algorithms in environments with delayed rewards. It is universal and can be used in various environments. Learning speed of the proposed method and reinforcement learning algorithm are compared in a Farmer-Pest problem with delayed rewards. Farmer-Pest problem is chosen for the comparison because it is designed especially for learning algorithms benchmarking. It has several dimensions which change environment characteristics and allows to test algorithms in various conditions. This paper presents results for one reinforcement learning method (SARSA) and three supervised learning algorithms (Naive Bayes, C4.5 and Ripper). These algorithms are tested on configurations with various complexity.","An Application of Computational Collective Intelligence to Governance and Policy Modelling ","A Framework for User Interaction for Adaptive Web-Based Information Systems. ","Ambiguity preferences and gamesAmbiguity (Knightian uncertainty) describes the situations where individuals cannot or do not assign subjective probabilities to uncertain events, in contrast we shall use risk to refer to situations where the decision-maker is familiar with the relevant probabilities. Ellsberg's [1] classic experiments motivate the study of ambiguity. The Ellsberg paradox suggests the standard subjective expected utility theory (SEU) cannot explain such ambiguity preference. Various of preference models are proposed and they are rarely related to one another. This paper interprets the ambiguity aversion from the game theory point of view. We find that the widely used Multiple-Priors reference (MP) can be interpreted by a zero-sum game. We formulate another game to capture a more optimistic ambiguity aversion defined in this paper.","Time to change: deciding when to switch action plans during a social interactionBuilding on the extensive cognitive science literature on the subject, this paper introduces a model of the brain mechanisms underlying social interactions in humans and other primates. The fundamental components of the model are the \"Action Observation\" and \"Action Planning\" Systems, dedicated respectively to interpreting/recognizing the partner's movements and to plan actions suited to achieve certain goals. We have implemented a version of the model including reaching and grasping actions, and tuned on real experimental data coming from human psychophysical studies. The system is able to automatically detect the switching point in which the Action Planning System takes control over the Action Observation System, overriding the automatic imitation behaviour with a complementary social response. With such computational implementation we aim at validating the model and also at endowing an artificial agent with the ability of performing meaningful complementary responses to observed actions in social scenarios.","ArgTrust: decision making with information from sources of varying trustworthinessThis work aims to support decision making in situations where sources of information are of varying trustworthiness. Formal argumentation is used to capture the relationships between such information sources and conclusions drawn from them. A prototype implementation is demonstrated, applied to a problem from military decision making.","Barrel-Type Distortion Compensated Fourier Feature ExtractionFourier based feature extraction is a common and powerful technique used in texture classification. In case of endoscopic imaging, often significant barrel-type distortions affect the feature extraction. Although images can be rectified using distortion correction techniques, in previous work feature extraction proved to suffer not just from geometric distortions, but also from effects within distortion correction. Distortion correction in combination with Fourier features has not been investigated so far. We introduce and evaluate three strategies to partially or completely compensate the geometric distortion in combination with Fourier features. With two methods, the interpolation within distortion correction can be omitted which should lead to a benefit in classification. Instead of making a general statement, we distinguish between certain frequencies and identify the positive and the negative aspects of the strategies.","Classification of opinion questionsWith the increasing growth of opinions on news, services and so on, automatic opinion question answering aims at answering questions involving views of persons, and plays an important role in fields of sentiment analysis and information recommendation. One challenge is that opinion questions may contain different types of question focuses that affect answer extraction, such as holders, comparison and location. In this paper, we build a taxonomy of opinion questions, and propose a hierarchical classification technique to classify opinion questions according to our constructed taxonomy. This technique first uses Bayesian classifier and then employs an approach leveraging semantic similarities between questions. Experimental results show that our approach significantly improves performances over baseline and other related works.","Monitoring Learning Activities in PLE Using Semantic Modelling of Learner Behaviour ","A Method for Simulation Model Validation Based on Theil\u2019s Inequality Coefficient and Principal Component Analysis ","On Communication over Gaussian Sensor Networks with Adversaries: Further ResultsThis paper presents new results on the game theoretical analysis of optimal communications strategies over a sensor network model. Our model involves one single Gaussian source observed by many sensors, subject to additive independent Gaussian observation noise. Sensors communicate with the receiver over an additive Gaussian multiple access channel. The aim of the receiver is to reconstruct the underlying source with minimum mean squared error. The scenario of interest here is one where some of the sensors act as adversary (jammer): they aim to maximize distortion. While our recent prior work solved the case where either all or none of the sensors coordinate (use randomized strategies), the focus of this work is the setting where only a subset of the transmitter and/or jammer sensors can coordinate. We show that the solution crucially depends on the ratio of the number of transmitter sensors that can coordinate to the ones that cannot. If this ratio is larger than a fixed threshold determined by the network settings (transmit and jamming power, channel noise and sensor observation noise), then the problem is a zero-sum game and admits a saddle point solution where transmitters with coordination capabilities use randomized linear encoding while the rest of the transmitter sensors is not used at all. Adversarial sensors that can coordinate generate identical Gaussian noise while other adversaries generate independent Gaussian noise. Otherwise (if that ratio is smaller than the threshold), the problem becomes a Stackelberg game where the leader (all transmitter sensors) uses fixed (non-randomized) linear encoding while the follower (all adversarial sensors) uses fixed linear encoding with the opposite sign.","Efficient E-Cash in Practice: NFC-Based Payments for Public Transportation SystemsNear field communication (NFC) is a recent popular technology that will facilitate many aspects of payments with mobile tokens. In the domain of public transportation payment systems electronic payments have many benefits, including improved throughput, new capabilities (congestion-based pricing etc.) and user convenience. A common concern when using electronic payments is that a user's privacy is sacrificed. However, cryptographic e-cash schemes pro- vide provable guarantees for both security and user privacy. Even though e-cash protocols have been proposed three decades ago, there are relatively few ac- tual implementations, since their computation complexity makes an execution on lightweight devices rather difficult. This paper presents an efficient implemen- tation of Brands (11) and ACL (4) e-cash schemes on an NFC smartphone: the BlackBerry Bold 9900. Due to their efficiency during the spending phase, when compared to other schemes, and the fact that payments can be verified offline, these schemes are especially suited for, but not limited to, use in public trans- port. Additionally, the encoding of validated attributes (e.g. a user's age range, zip code etc.) is possible in the coins being withdrawn, which allows for addi- tional features such as variable pricing (e.g. reduced fare for senior customers) and privacy-preserving data collection. We present a subtle technique to make use of the ECDHKeyAgreement class that is available in the BlackBerry API (and in the API of other systems) and show how the schemes can be implemented efficiently to satisfy the tight timing imposed by the transportation setting.","Iterative routing algorithm of Inter-FPGA signals for Multi-FPGA prototyping platformOver the last few years, multi-FPGA-based prototyping becomes necessary to test System On Chip designs. However, the most important constraint of the prototyping platform is the interconnection resources limitation between FPGAs. When the number of inter-FPGA signals is greater than the number of physical connections available on the prototyping board, signals are time-multiplexed which decreases the system frequency. We propose in this paper an advanced method to route all the signals with an optimized multiplexing ratio. Signals are grouped then routed using the intra-FPGA routing algorithm: Pathfinder. This algorithm is adapted to deal with the inter-FPGA routing problem. Many scenarios are proposed to obtain the most optimized results in terms of prototyping system frequency. Using this technique, the system frequency is improved by an average of 12.8%.","An Empirical Study of the Factors Influencing Use of Social Network Service ","A Sustainability Lifecycle Assessment of Products and Services for the Extended Enterprise EvolutionRecently numerous companies are moving from products to services to create new business opportunities and increase the value perceived by the customers thanks to an extended value creation network. The research challenge is to support traditional manufacturing enterprises evaluating the shift from products to services as far as sustainability is concerned. While product sustai- nability can be assessed by several tools, the impacts of PSS (Product-Service Systems) are almost unexplored. This paper adopts a holistic approach to assess sustainability by estimating three main impacts: environmental, economical and social. The methodology is illustrated by means of an industrial case study fo- cusing on washing machines; it analyses the traditional scenario based on tangi- ble product selling with a vertical supply-chain, and an innovative PSS scenario proposing washing as a service within an extended network. Data comparison highlights the achievable benefits of PSS on sustainability.","How Newly Appointed CIOs Take Charge: The Critical First Two YearsThe transition for any executive into a new appointment is a challenge. This transition for the newly appointed Chief Information Officer (CIO) is especially so given the breadth of their responsibilities. The CIO not only manages the delivery of IT services and projects but must be viewed as a legitimate business leader in order to influence strategic decision-making. This study explores the experience of CIOs taking charge of a new appointment. It integrates concepts from leader socialization and role theory with CIO leadership challenges. The data is based on in depth interviews with twenty one CIOs representing nineteen industries. The findings suggest that CIOs experience three overlapping phases of taking charge: entry, stabilization and renewal. These phases result in confidence, credibility and legitimacy as a new leader in the organization. The data further reveals that the organizational situation encountered by the CIO is a significant influence on the taking charge process. In particular, transition type - start-up, turnaround, realignment or success-sustaining \u2013 impact the process as well as determining whether the appointment is an \u2018insider\u2019 or an \u2018outsider.\u2019 The study suggests that CIOs experience organizational socialization in two domains of leadership. These domains are supply-side and demand-side leadership with the data indicating that supply-side socialization occurs first.","Computing incoherence explanations for learned ontologiesRecent developments in ontology learning research have made it possible to generate significantly more expressive ontologies. Novel approaches can support human ontology engineers in rapidly creating logically complex and richly axiomatized schemas. Although the higher complexity increases the likelihood of modeling flaws, there is currently little tool support for diagnosing and repairing ontologies produced by automated approaches. Off-the-shelf debuggers based on logical reasoning struggle with the particular characteristics of learned ontologies. They are mostly inefficient when it comes to detecting modeling flaws, or highlighting all of the logical reasons for the discovered problems. In this paper, we propose a reasoning approach for discovering unsatisfiable classes and properties that is optimized for handling automatically generated, expressive ontologies. We describe our implementation of this approach, which we evaluated by comparing it with state-of-the-art reasoners.","Boolean Language Operations on Nondeterministic Automata with a Pushdown of Constant HeightWe study the size-cost of Boolean operations on constant height nondeterministic pushdown automata ,i .e. on pushdown automata with a constant limit on the size of the pushdown. For intersection ,w e show an exponential simulation and prove that the exponential blow- up is necessary. For union ,i nstead, we provide al inear trade-o! while, for complement ,w e show ad ouble-exponential simulation and prove a single-exponential lower bound.","Improvement of the Relaxation Procedure in Concurrent Q-LearningIn this paper, we point out problems in concurrent Q-learning CQL, which is one of the adaptation techniques to dynamic environment in reinforcement learning and propose the modification of the relaxation procedure in CQL. We apply the proposed algorithm to the problem of maze in reinforcement learning and validate what kind of behavior the original CQL and the proposed algorithm show for the changes of environment such as the change of goals and the emergence of obstacles.","PROMETHEE-GAIA Method as a Support of the Decision-Making Process in Evaluating Technical FacilitiesThis paper describes the application of PROMETHEE-GAIA metho- dology in a multiple criteria analysis to rank potential environmental invest- ments in mineral-processing companies. The intent of the paper is to identify best technical facilities on the basis of preferential relations between a set of va- riants. The method of Total Cost Analysis (TCA) was chosen to define the cri- teria. The economic and environmental costs, as well as the benefits of these technical facilities, were determined by means of this method. PROMETHEE is one of the methods in the Multi Criteria Analysis (MCA) category. The MCA, as the name implies, deals with the evaluation of a number of variants by sever- al criteria. The technical facility was selected by a comparative analysis involv- ing five influential parameters (Investment Costs, Annual Operating Costs, Operating Income, Administrative Costs and Disposal Fees, Economic and En- vironmental Benefits). As expected, the analysis resulted in a preferential rank- ing of these technical facilities.","Face Detection and Recognition under Heterogeneous Database Based on Fusion of Catadioptric and PTZ Vision SensorsLarge field of view with high resolution has always been sought-after for Mobile Robotic Authentication. So the vision system proposed here is composed of a catadioptric sensor for full range monitoring and a Pan Tilt Zoom (PTZ) camera together forming an innovative sensor, able to detect and track any moving objects at a higher zoom level. In our application, the catadioptric sensor is calibrated and used to detect and track Regions Of Interest (ROIs) within its 360 degree Field Of View (FOV), especially face regions. Using a joint calibration strategy, the PTZ camera parameters are automatically adjusted by the system in order to detect and track the face ROI within a higher resolution and project the same in facespace for recognition via Eigenface algorithm. The whole development has been partially validated by application for the Face recognition using our own database.","Research on formation control for hybrid multi-robot based on leader-followerFor the problem of formation control of multiple robot system, a kind of formation control for hybrid Multi-robot based on Leader-Follower is proposed in this paper. The main leader searches an optimal path fast by using GPSO-PF algorithm, which is starting point to the target point, at the same time, using KLSPI algorithm avoids obstacle independently; The movement of the second leader in accordance with the key points, which are planned by the main leader, and combined with their own sensor information and formation width adjust formation shape, which make the followers and its matched the second leader keep expected distance and angle relation, then control formation shape. Simulation results are given to demonstrate the effectiveness of the proposed formation control method.","The Conceptual Model Is The Code. Why NotThe selection of the paper entitled \"OO-METHOD: An OO Software Production Environment Combining Conventional and Formal Methods\" for this book on Advanced Information Systems Engineering allows us to reflect on the research context where the work was developed and presented (in \"CAiSE 1997\") and to introduce its main contributions, how they have evolved with time and what influence the approach could have in the emergence of the Model-Driven Engineering domain. As the main goal was to provide a Software Process that should be fully Conceptual Model-based, the central message of this chapter is still the same 16 years later: the Conceptual Model must be the key software artefact of a sound, correct and complete Software Production Process. Novel approaches were required to generate a sound software production process, and they should use conceptual models as the key software artefact. The model should be the code of the application, and a conceptual modelling programming style should become a reality. While historically Software Engineering is in practice focused on programs, we have always tried to provide methods and tools to achieve the objective of make modelling the essential activity of programming. Why not making true the statement that \"the model is the code?\". This was our point when we published our referred CAiSE paper, and it is still our position now, with many more results and experiences to support it, that we introduce throughout this work.","On the verification of timed discrete-event modelsTimed discrete-event (DE) is an actor-oriented formalism for modeling timed systems. A DE model is a network of actors consuming/producing timed events from/to a set of input/output channels. In this paper we study a basic DE model, called deterministic DE (DDE), where actors are simple constant-delay components, and two extensions of DDE: NDE, where actors are non-deterministic delays, and DETA, where actors are either deterministic delays or timed automata. We investigate verification questions on DE models and examine expressiveness relationships between the DE models and timed automata.","Predictive Taint Analysis for Extended Testing of Parallel Executions ","Using google n-grams to expand word-emotion association lexiconWe present an approach to automatically generate a word-emotion lexicon based on a smaller human-annotated lexicon. To identify associated feelings of a target word (a word being considered for inclusion in the lexicon), our proposed approach uses the frequencies, counts or unique words around it within the trigrams from the Google n-gram corpus. The approach was tuned using as training lexicon, a subset of the National Research Council of Canada (NRC) word-emotion association lexicon, and applied to generate new lexicons of 18,000 words. We present six different lexicons generated by different ways using the frequencies, counts, or unique words extracted from the n-gram corpus. Finally, we evaluate our approach by testing each generated lexicon against a human-annotated lexicon to classify feelings from affective text, and demonstrate that the larger generated lexicons perform better than the human-annotated one.","How fit is OWL to represent realist ontologies? The semantics of representational units in realist ontologies and the Web Ontology Language ","A Logic for Extensive Games with Short SightTo characterize the structures and reason about strategies of extensivegames,much work has been done to provide the logical systems for such games. These logic systems focus on various perspectives of extensive games: Harrenstein et al., 2003 concentrated on describing equilibrium concepts and strategic reasoning. van Benthem, 2002 used dynamic logic to describe games as well as strategies.","High Quality Image Deblurring Scheme Using the Pyramid Hyper-Laplacian L2 Norm Priors AlgorithmIn this paper, a very effective image deblurring algorithm is proposed. It combines the techniques of the pyramid structure, the Hyper-Laplacian model, the hybrid norm priors for gradients, and the half-quadratic penalty method. In image deblurring, it is always a tradeoff between the goals of making the edge part sharp and reducing the ringing and the noise effects in the non-edge part. However, using the proposed algorithm, the two goals can be achieved at the same time. Many state-of-art image deblurring algorithms take the gradient of the reconstructed image into account to reduce the effect of noise. In the proposed algorithm, since the pyramid structure and the hybrid norm are applied, the image deblurring performance can be further improved. Simulations show that the proposed algorithm can successfully reconstruct the original image and outperforms the state-of-art methods for image deblurring.","The Estimation of aNobii Users' Reading Diversity Using Book Co-ownership Data: A Social Analytical ApproachUsage data available through social media provides a great many opportunities to capture users' preference. Using books saved in users' online bookshelves, the study set out to explore social network analytical methods to capture the diversity of a reader's reading interests. \"Reading diversity\" denotes how widely scattered one's reading interests are. Drawing data from aNobii, a social networking site for booklovers, users' reading diversity was defined by the number of components created by the book co-ownership network of the books in their bookshelves. Five book-book similarity measures were proposed and their clustering results were tested against users' self-assessed reading diversity in order to identify the best suited similarity measure and threshold for such a task. One of the proposed similar measures produce a clustering results that is significantly correlated with users' self-assessed diversity. Furthermore, a multiple regression analysis showed that the proposed measure was able to provide explanatory power for reading diversity over and above mere counting the number of books in the bookshelf.","Extraction of Cardiac and Respiratory Motion Information from Cardiac X-Ray Fluoroscopy Images Using Hierarchical Manifold LearningWe present a novel and clinically useful method to automatically determine the regions that carry cardiac and respiratory motion information directly from standard mono-plane X-ray fluoroscopy images. We demonstrate the application of our method for the purposes of retrospective cardiac and respiratory gating of X-ray images. Validation is performed on five mono-plane imaging sequences comprising a total of 284 frames from five patients undergoing radiofrequency ablation for the treatment of atrial fibrillation. We established end-inspiration, end-expiration and systolic gating with success rates of 100%, 100% and 95.3%, respectively. This technique is useful for retrospective gating of X-ray images and, unlike many previously proposed techniques, does not require specific catheters to be visible and works without any knowledge of catheter geometry.","Distributed Architecture for a Peer-to-Peer-Based Virtual Microscope ","Anytime Pack Heuristic SearchHeuristic search is a fundamental problem solving technique in artificial intelligence. In this paper, we propose an anytime heuristic search algorithm called Anytime Pack Search (APS) which helps in solv- ing hard combinatorial search problems efficiently. It expands nodes of a search graph in a localized best-first manner so as to converge towards good quality solutions at regular intervals. APS is complete on bounded graphs and guarantees termination with an optimal solution. Experi- mental results on the sliding-tile puzzle problem, the traveling salesman problem, and the single-machine scheduling problem show that APS sig- nificantly outperforms some of the state-of-the-art anytime algorithms.","Using Social Information for Flow Allocation in MANETsAdhoc networks enable communication between distributed, mobile wireless nodes without any supporting infrastructure. In the absence of centralized control, such networks require node interaction, and are inherently based on cooperation between nodes. In this paper, we use social and behavioral trust of nodes to form a flow allocation optimization problem. We initialize trust using information gained from users' social relationships (from social networks) and update the trusts metric over time based on observed node behaviors. We conduct analysis of social trust using real data sets and used it as a parameter for performance evaluation of our frame work in ns-3. Based on our approach we obtain a significant improvement in both detection rate and packet delivery ratio using social trust information when compared to behavioral trust alone. Further, we observe that social trust is critical in the event of mobility and plays a crucial role in bootstrapping the computation of trust.","A Fuzzy Scheme for Gait Cycle Phase Detection Oriented to Medical Diagnosis ","The Classification of Pavement Crack Image Based on Beamlet AlgorithmPavement distress, the various defects such as holes and cracks,#N#                            represent a significant engineering and economic concern. This paper#N#                            based on Beamlet algorithm using MATLAB software to process the pavement#N#                            crack images and classify the different cracks into four types:#N#                            horizontal, vertical, alligator, and block types. Experiment results#N#                            show that the proposed method can effectively detect and classify of the#N#                            pavement cracks with a high success rate, in which transverse crack and#N#                            longitudinal crack detection rate reach to 100%, and alligator crack and#N#                            block crack reach more than 85%.","General and Efficient Cognitive Model Discovery Using a Simulated Student ","Fostering PLM implementation in SMEs: modelling and managing verification processes.Abstract   PLM is largely recognized as the most effective business strategy by all those companies committed to deliver complex and continuously-evolving products, particularly if these operate at a multinational level. However, only a small number of these companies, the larger ones, has reached the level of maturity necessary to implement it in an effective manner. SMEs are not usually amongst these. This paper proposes a user-friendly Visualization Model (VM), that can guide the implementation of PLM philosophy in whatever scale company, provided its processes have been standardized. The model has been tested with major and smaller companies operating in the field of precision manufacturing showing encouraging results. However, as SMEs would get the greatest benefits, it is presented, in this paper, by means of a case study involving a small metrology company. A further content of novelty here, is represented by the fact that the case study's company is using this method to start operating according to the new ISO Geometrical Product Specification and Verification (GPS) standards.","Designing an artifact for the integration of ubiquitous information systems in an enterprise contextIn the past most IT innovations were initially introduced inside organizations and it was there where individuals first came in contact with new technologies. Nowadays, also the private life has gained importance for the adoption of technologies. Not often, individuals acquire new IT innovations privately, before they realize their value for professional activities and start using them for work. Their employers, however, struggle to integrate those innovations into their already heterogeneous organizational landscapes. The result is often an overly insufficient and ineffective use of private IT in organizations. In fact, previous integration research has provided various concepts to abate such negative effects, integrating the data and functionality of a few more private systems seems not a big deal. However, if one looks closer, it becomes apparent that private IT is autonomous from organizational control, rendering many common approaches inapplicable. Our research addresses this problem. Using the scenario of self-employed insurance brokers, we identify several characteristics of private IT ecosystems, here conceptualized as ubiquitous information systems (UIS), which prevent its productive use for professional activities. Based on these findings we suggest and instantiate a solution design which solves many issues of heterogeneity, but also accounts for the autonomy and distribution of the private UIS and its sub-systems. We conclude our research with a discussion of six propositions about the expected impact of our solution on individual performance.","Some Aspects of Neural Network State Variable Estimator Improvement in Induction Motor DriveSome aspects of state variable estimator improvement is pro- posed in the paper. The estimator approximates stator current compo- nents in the rotor flux reference frame with the help of neural networks. Some modification of the training procedure is considered that leads to the estimator accuracy improvement. Provided tests confirmed this fea- ture but further steps are necessary to increase state variables estimation in the low supplying frequency range. In many vector controlled induction motor drives applications rotor speed mea- surement or estimation is not necessary for adjustment of its operating point effectively. Such a case relates to traction drives where torque value is rather used than a vehicle speed. Moreover the absence of the rotor speed measurement increases robustness and reliability of the drive. Therefore control strategies that use other than rotor speed state variables are especially welcome. For the vector control strategy, the most needed state variable of the motor is the rotor flux in terms of its phase angle and amplitude as it allows any of advanced control schemes to be implemented. Among various techniques to estimate rotor flux, the Model Reference Adap- tive System approach looks to be the most promising as it offers higher accuracy due to closed-loop operation (4). However considered scheme suffers from variety of drawbacks like: integration drift, sensibility to noise present in the measured signals or parameters variation of the motor. On the other hand, in a control circuit, much useful are stator current components in the rotor flux reference frame which can be easily calculated knowing rotor flux position and amplitude. Such a scheme, presented in (5), simplifies and improves estimation part of the control circuit, but requires rotor flux position detection which involves all the above mentioned drawbacks related to this task. Although there are other effec- tive methods applicable in this case using fuzzy modeling (1)(2)(3), proposed NN estimator of stator current components in the rotor flux reference frame seems to be an interesting solution as it employs completely different approach to the problem. The intention of the paper is to find out how artificial intelligence tools are useful in the stator current components estimation in the rotor reference frame and how accurate is the estimator in the whole frequency and load range","Towards certifying network calculusNetwork Calculus (NC) [5] is an established theory for determining bounds on message delays and for dimensioning buffers in the design of networks for embedded systems. It is supported by academic and industrial tool sets and has been widely used, including for the design and certification of the Airbus A380 AFDX backbone [1,3,4]. However, while the theory of NC is generally well understood, results produced by existing tools have to be trusted: some algorithms require subtle reasoning in order to ensure their applicability, and implementation errors could result in faulty network design, with unpredictable consequences.","Precise Slicing in Imperative Programs via Term-Rewriting and Abstract InterpretationWe propose a new approach for producing precise constrained slices of programs in a language such as C. We build upon a previous approach for this problem, which is based on term-rewriting, which pri- marily targets loop-free fragments and is fully precise in this setting. We incorporate abstract interpretation into term-rewriting, using a given ar- bitrary abstract lattice, resulting in a novel technique for slicing loops whose precision is linked to the power of the given abstract lattice. We address pointers in a first-class manner, including when they are used within loops to traverse and update recursive data structures. Finally, we illustrate the comparative precision of our slices over those of previous approaches using representative examples.","A Security Engineering Process Approach for the Future Development of Complex Aircraft Cabin SystemsDue to increasing functionality associated with rising complexity of aircraft cabin systems which are used by cabin crew, passengers, maintenance staff and other stakeholders, security engineering has to become an integral part of the system engineering process in aviation industry. This paper deals with a security engineering process approach for the development of complex aircraft systems, which is fully integrated into the development process. As an appropriate process model we introduce the so called three-V-model, which represents the governing system engineering process (SEP) associated with the safety engineering process (SafEP) and the security engineering process (SecEP). All three processes are pursued concurrently and are interacting reci- procally on each development level with the predominant SEP. We describe in detail involved security engineering activities and finally demonstrate how the interaction between the SEP and the SecEP is improved and optimized by the use of so called security context parameters (SCPs).","Emotion Sharing with the Emotional Digital Picture FrameThis paper presents the design and implementation of emotional digital picture frame system, which is designed for a group of users to share their emotions via photographs with their own emotional expressions. This system detects user emotions using physiological sensor signals in real-time and changes audio-visual elements of photographs dynamically in response to the user's emotional state. This system allows user emotions to be shared with other users in remote locations. Also, it provides the emotional rule authoring tool to enable users to create their own expression for audio-visual element to fit their emotion. In particular, the rendering elements of a photograph can appear differently when another user's emotion is received.","Experimental Study on Display of Energy-Related Information in Smart Homes Using Virtual RealityEnvironmental pollution and electrical power shortages are serious issues, especially in Japan recently. Since private households are clearly constitute one of the main energy consumers today, positive effects on the environment can be expected if home energy consumption is reduced. Accordingly, our research purpose is to develop a prototype smart home that can offer \"smart\" quality of life, QOL, to its residents and reduce both CO2 emissions and energy consumption. An important issue toward achieving this aim is how to show energy-related information to the home's residents.#R##N##R##N#As a first step, we perform a preliminary experiment on reducing the numbers of candidates of locations and contents of energy-related information. Next, we perform another experiment to clarify the locations and contents of energy-related information expected to be in demand for display in actual smart homes.","Cumulus4j: A Provably Secure Database Abstraction Layer ","An Influence of Self-evaluated Gender Role on the Privacy Management Behavior in Online Social NetworksThe primary goal of this paper is testing a causal model of privacy management indicating the influence of gender on the user behavior of privacy management in OSNs. We adopted communication privacy management theory and the theory of planned behavior, developed a causal model showing the in- fluence of self-evaluated gender role on the behavior of privacy management in online social networks, and tested a set of hypotheses using structural equation modeling (SEM). The results of SEM indicate that self-evaluation of masculini- ty and femininity did not have significant relationship with user's behavior of privacy management in OSN.","An Empirical Study of Oversampling and Undersampling for Instance Selection Methods on Imbalance DatasetsInstance selection methods get low accuracy in problems with imbalanced databases. In the literature, the problem of imbalanced databases has been tackled applying oversampling or undersampling methods. Therefore, in this paper, we present an empirical study about the use of oversampling and undersampling methods to improve the accuracy of instance selection methods on imbalanced databases. We apply different oversampling and undersampling methods jointly with instance selectors over several public imbalanced databases. Our experimental results show that using oversampling and undersampling methods significantly improves the accuracy for the minority class.","Prebiotic Evolution of Molecular Assemblies: From Molecules to EcologyPresent life portrays a two-tier phenomenology: molecules compose supramolecular structures, such as cells or organisms, which in turn portray population behaviors, including selection, evolution and ecological dynamics. Prebiotic models have often focused on evolution in populations of self-replicating supramolecules, without explicitly invoking the intermediate molecular-to-supramolecular stage. We explore a prebiotic model that allows one to relate parameters of chemical interaction networks within molecular assemblies to emergent ecological and evolutionary properties in populations of such assemblies. We use the graded autocatalysis replication domain (GARD) model, which simulates the network dynamics of amphipile-containing molecular assemblies, and exhibits quasistationary compositional states termed compotypes. These grow by catalyzed accretion, divide and propagate their compositional information to progeny in a replication-like manner. The model allows us to ask how molecular network parameters influence assembly evolution and population ecology, analyzable by a multi species logistic (r-K) model for population ecology (Lotka-Volterra competition model). We found that compotypes with a larger intrinsic molecular repertoire show a higher intrinsic growth (r) and lower carrying capacity (K), as well as lower replication fidelity. This supports a prebiotic scenario initiated by fast-replicating assemblies with a high molecular diversity, evolving into more faithful replicators with narrower molecular repertoires. A main difference from classical ecology is that in GARD species inter convert into each other rather than consume each other or compete on resources, thus representing \u2018fast forward\u2019 of speciation.","Random Rates for 0-Extension and Low-Diameter DecompositionsConsider the problem of partitioning an arbitrary metric space into pieces of diameter at most \\Delta, such every pair of points is separated with relatively low probability. We propose a rate-based algorithm inspired by multiplicatively-weighted Voronoi diagrams, and prove it has optimal trade-offs. This also gives us another logarithmic approximation algorithm for the 0-extension problem.","Tree Interpolation in VampireWe describe new extensions of the Vampire theorem prover for computing tree interpolants. These extensions generalize Craig interpolation in Vampire, and can also be used to derive sequence interpolants. We evaluated our implementation on a large number of examples over the theory of linear integer arithmetic and integer-indexed arrays, with and without quantifiers. When compared to other methods, our experiments show that some examples could only be solved by our implementation.","Congestion Control for Vehicular Environments by Adjusting IEEE 802.11 Contention Window SizeMedium access control protocols should manage the highly dynamic nature of Vehicular Ad Hoc Networks (VANETs) and the variety of application requirements. Therefore, achieving a well-designed MAC protocol in VANETs is a challenging issue. The contention window is a critical element for handling medium access collisions in IEEE 802.11, and it highly affects the communications performance. This paper proposes a new contention window control scheme, called DBM-ACW, for VANET environments. Analysis and simulation results using OMNeT++ in urban scenarios show that DBM-ACW provides better overall performance compared with previous proposals, even with high network densities.","Statistical Characteristics of Portal Images and Their Influence in Noise ReductionPortal imaging is used in radiotherapy to asses the correct positioning of the patient before applying the treatment. Given the high energy particles used in portal image formation, portal image is intrin- sically bound by low contrast and poor spatial resolution. The relevance of portal imaging in radiotherapy treatments and its common use justify efforts to improve its inherent low quality. The knowledge of the statistical properties of both image and noise is essential in order to develop suitable processing algorithms to clean the image. The aim of this paper is to show how the statistical characteristics of the portal images and noise images generated in one of the portal imaging systems most widely deployed, can be exploited to improve the quality of noisy portal images through efficient denoising methods. An ensemble of portal images is used to investigate their statistical characteristics. In the case of noise, a process of averaging and subtrac- tion of the mean is used to extract noise images. The distribution found for the noise is clearly Gaussian, in both the spatial and the wavelet domain. The curves for the noise show a parabolic shape in the semi-log graphs across the different scales, which translates into Gaussian character in the transformed domain. On the other hand, the probability density functions (pdf's) for portal images show large tails. Wavelet thresholding takes advantage of the different statistical fea- tures found for noise and signal. In the present work wavelet thresholding is compared to Wiener filtering, and the assesment of the denoised image is carried out by means of the peak signal to noise ratio PSNR and the structural similarity index SSMI. Thresholding the wavelet coefficients of the noisy image gives better denoising results for both figures of merit (PSNR and SSIM) than the Wiener filter in all the analysed cases. Furthermore, the differences be- tween the methods increase as the noise increases. abstract environment.","Evolutionary Ordinal Extreme Learning MachineRecently the ordinal extreme learning machine (ELMOR) algorithm has been proposed to adapt the extreme learning machine (ELM) algorithm to ordinal regression problems (problems where there is an order arrangement between categories). In addition, the ELM stan- dard model has the drawback of needing many hidden layer nodes in order to achieve suitable performance. For this reason, several alterna- tives have been proposed, such as the evolutionary extreme learning ma- chine (EELM). In this article we present an evolutionary ELMOR that improves the performance of ELMOR and EELM for ordinal regression. The model is integrated in the differential evolution algorithm of EELM, and it is extended to allow the use of a continuous weighted RMSE fitness function which is proposed to guide the optimization process. This favors classifiers which predict labels as close as possible (in the ordinal scale) to the real one. The experiments include eight datasets, five methods and three specific performance metrics. The results show the performance improvement of this type of neural networks for specific metrics which consider both the magnitude of errors and class imbalance.","Comparing and Visualizing the Social Spreading of Products on a Large Social Network ","Human factors and the human domain: exploring aspects of human geography and human terrain in a military contextThis paper introduces the concept of the Human Domain within military operations and considers how it has evolved from Cultural Geography into more specific sub-components of Human Geography and Human Terrain. At a high level, Human Geography and Human Terrain map across to strategic and tactical decision-making respectively. However, there is a confusing array of terminology and definitions surrounding these factors. Given this complexity, what might have originally been considered a Human Domain continuum from a strategic level down to a tactical level may be better represented as overlapping constructs on a spectrum of understanding, each with their own approaches to data capture and analysis.","DEVELOPING A PROCEDURE MODEL FOR BUSINESS PROCESS STANDARDIZATIONFirms are focusing more closely on standardizing or homogenizing instances of a particular business process across different business units or locations. Our paper introduces research in progress on a business process standardization (BPS) procedure model that guides firms in conducting effective BPS firm-wide. This model is currently being developed and tested by applying it to a business process at Lufthansa Technik, following a design science cycle and taking an action research approach. This paper shows how we are following the good-practice guidelines of design science and how we intend to evaluate the applicability and effectiveness of the model. Eventually, we expect this model to contribute significantly to extant research on BPS, which has to date focused on the outcomes of BPS and on the contingencies of BPS effectiveness rather than making prescriptive suggestions for reaping substantial process efficiency gains in large and decentralized firms.","Net-based analysis of event processing networks: the fast flower delivery caseEvent processing networks emerged as a paradigm to implement applications that interact with distributed, loosely coupled components. Such a network consists of event producers, event consumers, and event processing agents that implement the application logic. Event processing networks are typically intended to process an extensive amount of events. Hence, there is a need for performance and scalability evaluation at design time. In this paper, we take up the challenge of modelling event processing networks using coloured Petri nets. We outline how this type of system is modelled and illustrate the formalisation with the widely used showcase of the Fast Flower Delivery Application (FFDA). Further, we report on the validation of the obtained coloured Petri net with an implementation of the FFDA in the ETALIS framework. Finally, we show how the net of the FFDA is employed for analysis with CPN-Tools.","Performance Evaluation of Edge-Directed Interpolation Methods for ImagesMany interpolation methods have been developed for high visual quality, but fail for inability to preserve image structures. Edges carry heavy structural information for detection, determination and classification. Edge-adaptive interpolation approaches become a center of focus. In this paper, performance of four edge-directed interpolation methods comparing with two traditional methods is evaluated on two groups of images. These methods include new edge-directed interpolation (NEDI), edge-guided image interpolation (EGII), iterative curvature-based interpolation (ICBI), directional cubic convolution interpolation (DCCI) and two traditional approaches, bi-linear and bi-cubic. Meanwhile, no parameters are mentioned to measure edge-preserving ability of edge-adaptive interpolation approaches and we proposed two. One evaluates accuracy and the other measures robustness of edge-preservation ability. Performance evaluation is based on six parameters. Objective assessment and visual analysis are illustrated and conclusions are drawn from theoretical backgrounds and practical results.","A Data Mining-Based Wind Power Forecasting Method: Results for Wind Power Plants in TurkeyWith the huge technological and industrial developments in recent years, the electricity demand of all countries has been increasing day by day. In order to supply the electricity needs, countries have been looking for ways of benefitting from their renewable energy sources efficiently and wind energy is an important and ubiquitous renewable energy source. However, due to wind's discontinuity and unstable characteristics, a reliable wind forecasting system is crucial not only for transmission system operators but also wind power plant WPP owners. This paper presents a reliable forecasting method based on data mining approaches. The method uses numerical weather predictions and past power measurements of the WPPs as input and it produces hourly short-term wind power forecasts for the WPPs for a time period of 48 hours. The method has been tested in the Wind Power Monitoring and Forecast Center R\u0103i\u00be?TM project of Turkey for a duration of six months for 14 WPPs. The proposed model achieves better accuracy performance rates than those of the other well-known forecasting models for seven of WPPs selected for the testing procedure by the General Directorate of Renewable Energy in Turkey.","Studies on a Hybrid Way of Rules and Statistics for Chinese Conjunction Usages Recognition ","An introduction to yoyo blind man algorithm (YOYO-BMA)In this paper, a new algorithm is proposed which is inspired by human intelligence named YOYO Blind Man Algorithms (YOYO-BMA). The main idea of YOYO-BMA is the combination of human intelligence with features of yoyo. In the proposed algorithm, it is supposed that there are some men in a dark room, which are named blind men. They look for the optimum. Each man has at least a yoyo to use as assistant. Men search problem space using their yoyos. This new algorithm is compared with 5 other different algorithms and the results show the better performance of YOYO-BMA compared with the other ones.","DVFS Aware CPU Credit Enforcement in a Virtualized SystemNowadays, virtualization is present in almost all computing infrastructures. Thanks to VM migration and server consolidation, virtualization helps reducing power consumption in distributed environments. On another side, Dynamic Voltage and Frequency Scaling (DVFS) allows servers to dynamically modify the processor frequency (according to the CPU load) in order to achieve less energy consumption. We observed that these two techniques have several incompatibilities. For instance, if two virtual machines VM1 and VM2 are running on the same physical host (with their respective allocated credits), VM1 being overloaded and VM2 being underloaded, the host may be globally underloaded leading to a reduction of the processor frequency, which would penalize VM1 even if VM1's owner booked a given CPU capacity. In this paper, we analyze the compatibility of available VM schedulers with DVFS management in virtualized environments, we identify key issues and finally propose a DVFS aware VM scheduler which addresses these issues. We implemented and evaluated our prototype in the Xen virtualized environment.","Computation of Helicopter Phenomena Using a Higher Order Method ","Flexibility and Improved Resource Utilization Through Cloud Based ERP Systems: Critical Success Factors of SaaS Solutions in SME ","A Weighted Majority Vote Strategy Using Bayesian NetworksMost of the methods for combining classifiers rely on the assumption that the experts to be combined make uncorrelated errors. Unfortunately, this theoretical assumption is not easy to satisfy in prac- tical cases, thus effecting the performance obtainable by applying any combination strategy. We tried to solve this problem by explicitly mod- eling the dependencies among the experts through the estimation of the joint probability distributions among the outputs of the classifiers and the true class. In this paper we propose an ew weighted majority vote rule, that uses the joint probabilities of each class as weights for com- bining classifier outputs. A Bayesian Network automatically infers the joint probability distribution for each class. The final decision is made by taking into account both the votes received by each class and the statistical behavior of the classifiers. The experimental results confirmed the effectiveness of the proposed method.","Influence of Scaffold Stability and Electrostatics on Top7-Based Engineered Helical HIV-1 EpitopesWe have recently engineered HIV-1 epitopes into the Top7 protein as scaffold using molecular dynamics simulations. The immunogenicity of the computer-engineered chimeric proteins was verified using human patient sera. The level and quality of the immune response was correlated to the structural stability of the chimeras as determined by molecular dynamics simulations. This work offers support for this correlation by a comparison between the calculated and experimental circular dichroism spectra for a selection of the Top7-HIV-1 chimeric proteins. In addition, analyzes of surface charge distribution suggest that the maintenance of an electrostatic surface potential signature is crucial for the immunogenicity of the de novo designed proteins.","Applying Contextual Design to Multiple Teams in Emergency Management ","Towards a Secure Certificateless Proxy Re-Encryption SchemeProxy re-encryption (PRE) is an attractive paradigm, which gives good solutions to the problem of delegation of decryption rights. In proxy re-encryption, a semi-trusted proxy translates a ciphertext for Alice into a ciphertext of the same plaintext for Bob, without learning any information of the underlying message. As far as we know, previous PRE schemes are mainly in traditional public key infrastructure or identity-based cryptography, thus they suffer from certificate management problem or key escrow problem in practice. In order to solve these practical problems, we aim at constructing certificateless proxy re-encryption (CL-PRE) schemes.#R##N##R##N#In this paper, we first introduce a security definition against (replayable) chosen ciphertext attack (CCA) for certificateless proxy re-encryption. In our security model, the adversary is allowed to adaptively corrupt users (in a specific pattern). Then, we give some evidence that it is not easy to construct a secure CL-PRE. Actually, we present an attack to the chosen plaintext secure CL-PRE scheme proposed by Xu et al. [1]. We also show a novel generic construction for certificateless public key encryption (CL-PKE) can not be trivially adapted to CL-PRE by giving an attack to this generic construction. Finally, we present an efficient CL-PRE scheme and prove its security in the random oracle model based on well-known assumptions.","Design Principles for Spatio-Temporally Enabled PIM Tools: A Qualitative Analysis of Trip Planning ","Real-time simulations to support operational decision making in healthcareLong wait times lead to many important issues in the Canadian healthcare system. Emerging technologies now enable real-time measurement of wait times, leading to new opportunities for operational decision making in healthcare. This paper investigates a real-time simulation approach that exploits this information, combined with patient care process models, in order to support short-term predictions targeting the allocation of resources having an impact on wait times. A special style of modeling is used to enable real-time simulations with the Arena tool. The approach's feasibility is assessed on a realistic clinical process for cardiac patients of an Ontario hospital, with encouraging results.","An Iterative Algorithm for the Generalized Center Symmetric Solutions of a Class of Linear Matrix Equation and Its Optimal Approximation ","Research on Efficient Non-slotted Tree Structures for Advance Reservation ","Integration of Automated Neural Processing into an Army-Relevant Multitasking Simulation Environment ","Reconstruction of quantitative properties from x-raysIn some applications, the tomographic reconstruction is not an end in itself. When the goal is rather to gather information about the object being studied, the question is if it is more interesting to directly extract these information from the projections without the reconstructing step. We would then know if less projections are needed to directly get the information than to reconstruct the object. In this paper, we address the problem of extracting quantitative information about an object namely an estimation of its area, an upper and a lower bound to the perimeter given its projections from point sources.","Research Approach in Enterprise Engineering: A Matter of EngineeringEnterprises encounter serious problems in keeping pace with ever faster changing markets. Enterprise Engineering (EE) is an emerging field that is promising in providing solutions. Doing research in this field, requires choosing an appropriate research method for different parts of the research. This is the composition of the research method from known research methods, we call this engineering of the research approach. We structure available methods, approaches and techniques for qualitative research in information systems. We describe three epistemologies and discuss the different qualitative research methods and differences and similarities between them. For our research on EE that applies trans- action cost economics in designing enterprises using the notions of En- terprise Ontology and Enterprise Architecture we combine a positivist approach during literature study with an interpretivist approach during Action Research.","Success Factors in New Service Development - Digia Flowd AnalysisToday, the importance of digital services with social aspects is increasing all the time. Many companies have been strong in new product development, but today they are moving to new service development. Customer value has become the strategic factor for contemporary companies when developing products and services for consumers; even so that companies are selling customer value instead of products or services. Customer orientation and customer involvement play important roles in service industries. This study describes how the case company entered to B-to-C digital service market and developed a new social network cloud service for music lovers. This theory testing case study discusses and reflects the success factors of new service development and the organization against the literature. Mostly the theory is confirmed, but also improvement of the theory is suggested. Finally, future research ideas are proposed.","Enhanced Security for Cloud Storage using File EncryptionCloud computing is a term coined to a network that offers incredible processing power, a wide array of storage space and unbelievable speed of computation. Social media channels, corporate structures and individual consumers are all switching to the magnificent world of cloud computing. The flip side to this coin is that with cloud storage emerges the security issues of confidentiality, data integrity and data availability. Since the cloud is a mere collection of tangible super computers spread across the world, authentication and authorization for data access is more than a necessity. Our work attempts to overcome these security threats. The proposed methodology suggests the encryption of the files to be uploaded on the cloud. The integrity and confidentiality of the data uploaded by the user is ensured doubly by not only encrypting it but also providing access to the data only on successful authentication.","On the Complexity of Submap IsomorphismGeneralized maps describe the subdivision of objects in cells, and incidence and adjacency relations between cells, and they are widely used to model 2D and 3D images. Recently, we have defined submap isomorphism, which involves deciding if a copy of a pattern map may be found in a target map, and we have described a polynomial time algorithm for solving this problem when the pattern map is connected. In this paper, we show that submap isomorphism becomes NP-complete when the pattern map is not connected, by reducing the NP-complete problem Planar-4 3-SAT to it.","Hierarchical Directed Acyclic Graph (HDAG) Based Preprocessing Technique for Session Construction ","Statistics on Encrypted Cloud DataAs an increasing number of data is to be processed, out- sourcing data to the cloud environment becomes an appealing proposal to heighten the computation/storage efficiency, while avoiding costly and complicated system construction. However, it is necessary to encrypt the outsourced data to prevent the breaches of both data confidentiality and privacy. Most of the statistical procedures deal with the data in the cleartext form, making it hard to directly apply them to the data in the encrypted form. In this paper, we present a statistical framework to securely and efficiently obtain the statistics on encrypted cloud data through real-time processing. We build our framework on top of the searchable public-key encryption and provide detailed transformation of the statistical procedures for the plain data to those for the encrypted data. We provide detailed descriptions and examples of these transformed statistical procedures. Finally, we provide security analysis and perfor- mance evaluation of these transformed procedures and demonstrate the effectiveness and efficiency of the proposed framework.","The ACE theorem for querying the web of dataInspired by the CAP theorem, we identify three desirable properties when querying the Web of Data: Alignment (results up-to-date with sources), Coverage (results covering available remote sources), and Efficiency (bounded resources). In this short paper, we show that no system querying the Web can meet all three ACE properties, but instead must make practical trade-offs that we outline.","User Perceptions of Relevance and Its Effect on Retrieval in a Smart Textile ArchiveAHRC - Digital Transformations Research Development award for this project#R##N#(AH/J013218/1)","Changing Price Elasticity of Digital Goods: Empirical Study from the E-book Industry ","Towards a predictive model architecture for current or emergent pandemic situationsThis paper presents ideas towards building predictive models of the socio-economic interactions of autonomous population units (APUs). APU interaction models (AIM) can then be used to predict current or emergent pandemic situations. Our envisaged AIM system will comprise two fundamental components: (i) an existing generic discrete event simulator (DES) which will be adapted to socio-economic interactions of an APU, and (ii) a new data mining toolset (DMT) which will be integrated to the simulation toolset. In a part of our early work, we will identify and filter the data that flows into the AIM system. The DMT will consolidate digitized data (e.g., satellite imagery) with data from public and private news sources including human observation. The DES together with historical data generated from the DMT will form an initial model of the socio-economic interactions of an APU relative to a pandemic, which is used to get a prediction of the existing conditions. The DMT is then employed to explore the data and discover previously unknown, valid patterns and relationships pertaining to the spread of infectious disease. The model will iteratively compare the predicted data to the real-world DMT data until an accurate predictive model of the pandemic is obtained.","A study of monodromy in the computation of multidimensional persistenceThe computation of multidimensional persistent Betti numbers for a sublevel filtration on a suitable topological space equipped with a \u211dn-valued continuous filtering function can be reduced to the problem of computing persistent Betti numbers for a parameterized family of one-dimensional filtering functions. A notion of continuity for points in persistence diagrams exists over this parameter space excluding a discrete number of so-called singular parameter values. We have identified instances of nontrivial monodromy over loops in nonsingular parameter space. In other words, following cornerpoints of the persistence diagrams along nontrivial loops can result in them switching places. This has an important incidence, e.g., in computer-assisted shape recognition, as we believe that new, improved distances between shape signatures can be defined by considering continuous families of matchings between cornerpoints along paths in nonsingular parameter space. Considering that nonhomotopic paths may yield different matchings will therefore be necessary. In this contribution we will discuss theoretical properties of the monodromy in question and give an example of a filtration in which it can be shown to be nontrivial.","Estimation from Relative Measurements in Mobile Networks with Markovian Switching Topology: Clock Skew and Offset Estimation for Time SynchronizationWe analyze a distributed algorithm for estimation of scalar parameters belonging to nodes in a mobile network from noisy relative measurements. The motivation comes from the problem of clock skew and offset estimation for the purpose of time synchronization. The time variation of the network was modeled as a Markov chain. The estimates are shown to be mean square convergent under fairly weak assumptions on the Markov chain, as long as the union of the graphs is connected. Expressions for the asymptotic mean and correlation are also provided. The Markovian switching topology model of mobile networks is justified for certain node mobility models through empirically estimated conditional entropy measures.","Timing and Carrier Synchronization with Channel Estimation in AF Two-Way Relaying NetworksTwo-way relaying networks (TWRNs) allow for more bandwidth efficient use of the available spectrum since they allow for simultaneous information exchange between two users with the assistance of an intermediate relay node. However, due to superposition of signals at the relay node, the received signal at the user terminals is affected by multiple impairments, i.e., channel gains, timing offsets, and carrier frequency offsets, that need to be jointly estimated and compensated. This paper presents the system model for amplify-and-forward (AF) TWRNs in the presence of multiple impairments and proposes least squares and differential evolution based algorithms for joint estimation of these impairments. The Cramer-Rao lower bounds (CRLBs) for the joint estimation of multiple impairments are derived. A minimum mean-square error based receiver is then proposed to compensate the effect of multiple impairments and decode each user's signal. Simulation results show that the performance of the proposed estimators is very close to the derived CRLBs at moderate-to-high signal-to-noise-ratios. It is also shown that the bit-error rate performance of the overall AF TWRN is close to a TWRN that is based on assumption of perfect knowledge of the synchronization parameters.","Shifting the focus: an objective look at design fixationDesign fixation is a robust phenomenon that has been shown to affect amateurs, experts, and groups of designers across a variety of design domains. An area of confusion concerning the concept of design fixation is whether it is a conscious decision made by a designer or an unconscious action that occurs without awareness. The current research addresses this issue by utilizing eye tracking as an objective measure, in conjunction with subjective feedback, and design performance data to gain insight into the underlying processes of design fixation. It was found that there are major discrepancies in what people remember looking at, what people actually looked at, and what features designers fixated on. These findings inspire a fount of new research questions, as well as a possible rethinking of current design processes.","Learning Outcomes for Blog-Based Courses: A Case Study ","A note on totally regular variables and appell sequences in hypercomplex function theoryThe aim of our contribution is to call attention to the relationship between totally regular variables, introduced by R. Delanghe in 1970, and Appell sequences with respect to the hypercomplex derivative. Under some natural normalization condition the set of all paravector valued totally regular variables defined in the three dimensional Euclidean space will be completely characterized. Together with their integer powers they constitute automatically Appell sequences, since they are isomorphic to the complex variables.","Negotiated learning for smart grid agents: entity selection based on dynamic partially observable featuresAn attractive approach to managing electricity demand in the Smart Grid relies on real-time pricing (RTP) tariffs, where customers are incentivized to quickly adapt to changes in the cost of supply. However, choosing amongst competitive RTP tariffs is difficult when tariff prices change rapidly. The problem is further complicated when we assume that the price changes for a tariff are published in real-time only to those customers who are currently subscribed to that tariff, thus making the prices partially observable. We present models and learning algorithms for autonomous agents that can address the tariff selection problem on behalf of customers. We introduce Negotiated Learning, a general algorithm that enables a self-interested sequential decision-making agent to periodically select amongst a variable set of entities (e.g., tariffs) by negotiating with other agents in the environment to gather information about dynamic partially observable entity features (e.g., tariff prices) that affect the entity selection decision. We also contribute a formulation of the tariff selection problem as a Negotiable Entity Selection Process, a novel representation. We support our contributions with intuitive justification and simulation experiments based on real data on an open Smart Grid simulation platform.","Optimal Cross-Coupled Synchronization Control of a Precision Motion Stage Driven by Dual Linear MotorsIn this paper, the optimal cross-coupled synchronization control of a precision motion stage driven by dual linear motors is investigated. The single axis controller of linear motor is composed of a cascade PID/PI controller and a hybrid velocity and acceleration controller (VFC/AFC). The cross-coupled synchronization control scheme is incorporated with the hybrid trajectory tracking PID/PI+VFC/AFC controller to improve the tracking performance of single axis and reduce the synchronization error of dual linear motors simultaneously. The design of cross-coupled synchronization controller is formulated as an optimal control problem in which the performance index to be minimized weights the synchronization error explicitly. Experimental results show that the optimal cross-coupled synchronization control scheme has superior synchronization performance than the independent axis control scheme in synchronization error reduction.","Encoding local binary descriptors by bag-of-features with hamming distance for visual object categorizationThis paper presents a novel method for encoding local binary descriptors for Visual Object Categorization (VOC). Nowadays, local binary descriptors, e.g. LBP and BRIEF, have become very popular in image matching tasks because of their fast computation and matching using binary bitstrings. However, the bottleneck of applying them in the domain of VOC lies in the high dimensional histograms produced by encoding these binary bitstrings into decimal codes. To solve this problem, we propose to encode local binary bitstrings directly by the Bag-of-Features (BoF) model with Hamming distance. The advantages of this approach are two-fold: (1) It solves the high dimensionality issue of the traditional binary bitstring encoding methods, making local binary descriptors more feasible for the task of VOC, especially when more bits are considered; (2) It is computationally efficient because the Hamming distance, which is very suitable for comparing bitstrings, is based on bitwise XOR operations that can be fast computed on modern CPUs. The proposed method is validated by applying on LBP feature for the purpose of VOC. The experimental results on the PASCAL VOC 2007 benchmark show that our approach effectively improves the recognition accuracy compared to the traditional LBP feature.","Dynamic sampling schemes for optimal noise learning under multiple nonsmooth constraintsWe consider the bilevel optimisation approach proposed by De Los Reyes, Sch\\\"onlieb (2013) for learning the optimal parameters in a Total Variation (TV) denoising model featuring for multiple noise distributions. In applications, the use of databases (dictionaries) allows an accurate estimation of the parameters, but reflects in high computational costs due to the size of the databases and to the nonsmooth nature of the PDE constraints. To overcome this computational barrier we propose an optimisation algorithm that by sampling dynamically from the set of constraints and using a quasi-Newton method, solves the problem accurately and in an efficient way.","Introduction to the Proceedings of the 5th International Workshop on Personalization in Cloud and Service Computing (PCS) 2011 ","Sense Disambiguation Technique for Information Retrieval in Web Search ","Design and Deployment of Everyday UbiComp Solutions at the Hotel: An Empirical Study of Intrinsic Practice TransformationUnderstanding how people employ digital artifacts in their everyday settings to create more advanced interactive habitats is becoming a key issue in HCI research. This paper aims to contribute to this research by reporting an empirical study of artifact ecologies and their dynamics in day-to-day activities at a hotel. We describe two technological solutions, designed and implemented by people in the settings: (a) converting a paper-based cleaning staff roster into a Google Doc, and (b) switching from a traditional fax machine to email as a technology for handling communication with suppliers. We discuss a range of factors affecting such user-driven innovations, as well as the impact of the technologies on larger-scale interactive habitats.","Pit Stop for an Audio Steganography AlgorithmSteganography plays an important role in the field of secret communication. The security of such communication lies in the impossi- bility of proving that secret communication is taking place. We evaluate the implementation of a previously published spread spec- trum technique for steganography in auditive media. We have unveiled and solved several weaknesses that compromise undetectability. The spread-spectrum approach of the technique under evaluation is rather unusual for steganography and makes the secret message fit to sur- vive A/D and D/A conversions of analogue audio telephony, re-encoded speech channels of GSM/UMTS, or VoIP. Its impact to signal statis- tics, which is at least concealed by the lossy channel, is reduced. There is little published on robust audio steganography, its steganalysis, and evaluation, with the possible exception of audio watermarking, where undetectability is not as important.","New Concepts for Structuring 3D City Models - an Extended Level of Detail Concept for CityGML BuildingsWe propose a new Level of Detail (LoD) concept for CityGML buildings that differentiates a Geometrical Level of Detail (GLoD) and a Semantical Level of Detail (SLoD). These two LoD concepts are separately defined for the interior characteristics and the outer shell of a building, respectively. The City Geography Markup Language (CityGML) is an open and application independent information model for the representation, storage, and exchange of virtual 3D city models. It covers geometric representations of 3D objects as well as their semantics and their interrelation. The CityGML Level of Detail concept in general offers the possibility to generalize CityGML features from very detailed to a less detailed description. The current LoD concept suffers from strictly coupling geometry and semantics. In addition it provides only one LoD (LoD4) for the description of the interior of a building. The benefits of our new LoD concept are first, a substantially higher informative value for the Level of Detail, second, a better description of the interior Level of Detail, third, a broadening of the opportunities for indoor modelling, and last, a better assignability to all other modules represented in CityGML. Due to more combinations of GLoD and SLoD, the Level of Detail definition for every module in CityGML can be defined according to the nature of modelled real world phenomenon.","NFC provided user friendliness for technologically advanced servicesThis paper will discuss how an NFC enabled university campus can provide a wide range of user-friendly advanced services for its students and staff. These services combine information sources related to teaching, room reservation, social networking, proximity sensing, information collection and exchange, calendar services, event notifications, ticketing, loyalty cards, payment and more. In the ongoing NFC City Campus trial the usage of NFC enabled mobile phones, SIM cards as secure elements, and an adaptive infrastructure supporting information integration, demonstrates how NFC can contribute to the development of user friendly advanced services.","A Survey on Time-of-Flight Stereo FusionDue to the demand for depth maps of higher quality than possible with a single depth imaging technique today, there has been an increasing interest in the combination of different depth sensors to produce a \"super-camera\" that is more than the sum of the individual parts. In this survey paper, we give an overview over methods for the fusion of Time-of-Flight (ToF) and passive stereo data as well as applica- tions of the resulting high quality depth maps. Additionally, we provide a tutorial-based introduction to the principles behind ToF stereo fusion and the evaluation criteria used to benchmark these methods.","Take this personally: pollution attacks on personalized servicesModern Web services routinely personalize content to appeal to the specific interests, viewpoints, and contexts of individual users. Ideally, personalization allows sites to highlight information uniquely relevant to each of their users, thereby increasing user satisfaction--and, eventually, the service's bottom line. Unfortunately, as we demonstrate in this paper, the personalization mechanisms currently employed by popular services have not been hardened against attack. We show that third parties can manipulate them to increase the visibility of arbitrary content--whether it be a new YouTube video, an unpopular product on Amazon, or a low-ranking website in Google search returns. In particular, we demonstrate that attackers can inject information into users' profiles on these services, thereby perturbing the results of the services' personalization algorithms. While the details of our exploits are tailored to each service, the general approach is likely to apply quite broadly. By demonstrating the attack against three popular Web services, we highlight a new class of vulnerability that allows an attacker to affect a user's experience with a service, unbeknownst to the user or the service provider.","Nonparametric Mixture of Gaussian Processes with ConstraintsMotivated by the need to identify new and clinically relevant categories of lung disease, we propose a novel clustering with constraints method using a Dirichlet process mixture of Gaussian processes in a variational Bayesian nonparametric framework. We claim that individuals should be grouped according to biological and/or genetic similarity regardless of their level of disease severity; therefore, we introduce a new way of looking at subtyping/clustering by recasting it in terms of discovering associations of individuals to disease trajectories (i.e., grouping individuals based on their similarity in response to environmental and/or disease causing variables). The nonparametric nature of our algorithm allows for learning the unknown number of meaningful trajectories. Additionally, we acknowledge the usefulness of expert guidance by providing for their input using must-link and cannot-link constraints. These constraints are encoded with Markov random fields. We also provide an efficient variational approach for performing inference on our model.","Soft Computing Models in Online Real EstateIn this paper we present a decision support system that uses soft computing models for evaluation, selection and pricing of homes. The system (called LSPhome) is based on the Logic Scoring of Preference (LSP) evaluation method and implemented in the context of online real estate. The goal of this system is to use weighted compensative logic models that can precisely express user needs, and help both buyers and sellers of homes. The design of such a sys- tem creates specific logic and computational challenges. Soft computing logic problems include the use of verbalized importance scales for derivation of and- ness, penalty-controlled missingness-tolerant logic aggregation, detailed and verbalized presentation of evaluation results, and development of optimum pric- ing models. Computational problems include fast and parallel collection of he- terogeneous information from the Internet, and development of user interface for fast and simple creation of customized soft computing decision criteria by nonprofessional decision makers. Real estate is an area that includes a spectrum of soft computing decision problems. In this paper we present a survey of the most important soft computing models that are used in online real estate (ORE). The first such a problem is the development of crite- ria for evaluation and selection of homes. The home evaluation criteria are based on weighted compensative logic functions that can model adjustable degrees of simul- taneity and replaceability, mandatory, sufficient, and optional requirements, as well as adjustable degrees of importance of various home attributes. The aggregation of home quality and home affordability is also a soft computing logic problem. Similarly, the problem of optimum home pricing can also be solved using soft computing models. In ORE we frequently encounter problems of decision making with incomplete (miss- ing) inputs, and the need to expand aggregation models with missingness-tolerant aggregators. Finally, the users of ORE decision models are not decision experts, but nonprofessionals who need simple verbalized approach to specifying soft computing decision models. These seemingly heterogeneous problems are closely related in the","Detecting and Categorizing Indices in Lecture Video Using Supervised Machine LearningThis work reports on the evaluation of detecting scene transi- tions in lecture video through supervised machine learning. It expands on previous work by gathering training data from multiple human raters. We include a robust evaluation that compares predictions against the entire set of expert classifications in disagreement. Finally, we explore some of the issues around constructing training data from multiple hu- man experts, specifically emphasizing that evaluation strategies should be carefully considered when using aggregated training data. cluding projector content such as PowerPoint slides or other desktop activity. Our interest in these technologies is to enable fast, accurate navigation through content by way of thumbnails that represent the start of new segments in a lecture. These segments can be thought of as roughly corresponding to new slides in a PowerPoint presentation, though our intent is to work with broader forms of presentation and not rely on any particular technology or lecture paradigm. Unlike previous work which has used static algorithms (1) or learning algorithms trained on data from a single human rater (2) for determining these kinds of indices, we provide a method to compare algorithms based on multiple raters that are in disagreement. The re- sult is an increase in the quality of indexing compared to non-trained algorithms, and a method that considers training data from multiple raters. One contribution of this work is an exploration of the effects of considering multiple raters when annotating data for supervised machine learning. In pre- vious work (2), algorithms trained with data from a single rater were shown to produce better results than static algorithms. We go further and demonstrate a) the challenges in achieving agreement between multiple raters in this domain, and b) how aggregates for training can be formed on these conflicting ratings, and how these aggregates compare with the current state-of-the-practice. 1","Robust H\u221e filtering for sampled-data fuzzy systemsAbstract   This paper is concerned with robust     H    \u221e     filtering for Takagi\u2013Sugeno sampled-data fuzzy systems with uncertain parameters. Takagi\u2013Sugeno fuzzy system can describe a wide class of nonlinear systems, and is widely used in many engineering fields. Recently, system analysis and control design for nonlinear systems based fuzzy system approach have been active. The system is usually modelled as a continuous-time system, while in practical situations the observation is taken at discrete instants. Such an observation can be represented as a delayed signal. First it is shown that the error system which stems from an original fuzzy system and a sampled-data filter becomes a system with time-varying delay. Sufficient conditions for the error system to achieve the robust stability with     H    \u221e     disturbance attenuation are given in terms of linear matrix inequalities(LMIs). We derive such conditions via output delay system approach under the assumption that sampling-time is not greater than some prescribed number. Based on such conditions, we propose a robust     H    \u221e     sampled-data filter design for a fuzzy system. We consider two different cases for the premise variables in our filter design. Numerical examples are given to illustrate our robust     H    \u221e     sampled-data filtering.","An integrated 4D vision and visualisation systemThis paper reports on a pilot system for reconstruction and visualisation of complex spatio-temporal scenes by integrating two different types of data: outdoor 4D data measured by a rotating multi-beam LIDAR sensor, and 4D models of moving actors obtained in a 4D studio. A typical scenario is an outdoor scene with multiple walking pedestrians. The LIDAR monitors the scene from a fixed position and provides a dynamic point cloud. This information is processed to build a 3D model of the environment and detect and track the pedestrians. Each of them is represented by a point cluster and a trajectory. A moving cluster is then substituted by a detailed 4D model created in the studio. The output is a geometrically reconstructed and textured scene with avatars that follow in real time the trajectories of the pedestrians.","Deployment of Sensors in Regular Terrain in Form of Interconnected WSN Units ","Data Protection, Social Networks and Online Mass Media ","User Statistics and Traffic Analysis of Public Internet Access in Buses ","Brain-Computer interfacing for users with cerebral palsy, challenges and opportunitiesIt has been proposed that hybrid Brain-computer interfaces (hBCIs) could benefit individuals with Cerebral palsy (CP). To this end we review the results of two BCI studies undertaken with a total of 20 individuals with CP to determine if individuals in this user group can achieve BCI control.#R##N##R##N#Large performance differences are found between individuals. These are investigated to determine their possible causes. Differences in subject characteristics are observed to significantly relate to BCI performance accuracy. Additionally, significant relationships are also found between some subject characteristics and EEG components that are important for BCI control. Therefore, it is suggested that knowledge of individual users may guide development towards overcoming the challenges involved in providing BCIs that work well for individuals with CP.","Towards Thought Control of Next-Generation Wearable Computing DevicesA new wearable computing era featuring devices such as Google Glass, smartwatches, and digital contact lenses is almost upon us, bringing with it usability issues that conventional human computer interaction (HCI) modalities cannot resolve. Brain computer interface (BCI) technology is also rapidly advancing and is now at a point where noninvasive BCIs are being used in games and in healthcare. Thought control of wearable devices is an intriguing vision and would facilitate more intuitive HCI; however, to achieve even a modicum of control BCI currently requires massive processing power that is not available on mobile devices. Cloud computing is a maturing paradigm in which elastic computing power is provided on demand over networks. In this paper, we review the three technologies and take a look at possible ways cloud computing can be harnessed to provide the computational power needed to facilitate practical thought control of next-generation wearable computing devices.","PrefLib: A Library for Preferences http://www.preflib.orgWe introduce PrefLib: A Library for Preferences; an online resource located at      http://www.preflib.org       . With the emergence of computational social choice and an increased awareness of the applicability of preference reasoning techniques to areas ranging from recommendation systems to kidney exchanges, the interest in preferences has never been higher. We hope to encourage the growth of all facets of preference reasoning by establishing a centralized repository of high quality data based around simple, delimited data formats. We detail the challenges of constructing such a repository, provide a survey of the initial release of the library, and invite the community to use and help expand PrefLib.","Multi-verifier: A Novel Method for Fact Statement Verification ","How can persuasive technology help people choose for themselvesPersuasive technology is used when it is known in advance what the person in question should be persuaded to do. The job of helping people to choose for themselves what they want to do, in accordance with their own values, tastes, past experience, and capabilities, has been left to other types of interactive system, such as those for decision support or recommendation. But there are reasons why persuasive technology researchers might consider applying their skills to the challenge of helping users choose for themselves:#R##N##R##N#1 A lot of the innovative techniques developed in persuasive technology can be adapted to yield new ways of supporting choosing. Examples are techniques for monitoring behavior, for simulating the consequences of possible actions, for enforcing commitment strategies, for mediating social influence, and for communicating with users at opportune times and places.#R##N##R##N#2 While users of persuasive technology are doing what they have been persuaded to do, they often need to make nontrivial personal choices about exactly how to do it; their overall success and satisfaction will be affected by how well they make these choices.#R##N##R##N#This talk argues for these claims with reference to concepts and results from the psychology of everyday decision making, and it illustrates them with examples from past and ongoing research and practice.","Towards Automatic Generation of Hardware ClassifiersNowadays, in a broad range of application areas, the daily data production has reached unprecedented levels. This data origins from multiple sources, such as sensors, social media posts, digital pictures and videos and so on. The technical and scientific issues related to the data booming have been designated as the \"Big Data\" challenges. To deal with big data analysis, innovative algorithms and data mining tools are needed in order to extract information and discover knowledge from the continuous and increasing data growing. In most of data mining methods the data volume and variety directly impact on computational load. In this paper we illustrate a hardware architecture of the decision tree predictor, a widely adopted machine learning algorithm. In particular we show how it is possible to automatically generate a hardware implementation of the predictor module that provides a better throughput that available software solutions.","On Optimization Problems for Differential Inclusions with Random Initial Data ","Scalable and Fully Consistent Transactions in the Cloud through Hierarchical Validation ","Usability in RFP\u2019s: The Current Practice and Outline for the Future ","AMM-PF: Additional Mobility Management Scheme Based on Pointer Forwarding in PMIPv6 Networks ","SCSat: a soft constraint guided SAT solverSCSat is a SAT solver aimed at quickly finding a model for hard satisfiable instances using soft constraints. Soft constraints themselves are not necessarily maximally satisfied and may be relaxed if they are too strong to obtain a model. Appropriately given soft constraints can reduce search space drastically without losing many models, thus help find a model faster. In this way, we have succeeded to obtain several rare Ramsey graphs which contribute to raise the known best lower bound for the Ramsey number R(4,8) from 56 to 58.","On the development of mobile agent systems for wireless sensor networks : issues and solutions ","PRALINE: a tool for computing nash equilibria in concurrent gamesWe present PRALINE, which is the first tool to compute Nash equilibria in games played over graphs. We consider concurrent games: at each step, players choose their actions independently. There can be an arbitrary number of players. The preferences of the players are given by payoff functions that map states to integers, the goal for a player is then to maximize the limit superior of her payoff; this can be seen as a generalization of Buchi objectives. PRALINE looks for pure Nash equilibria in these games. It can construct the strategies of the equilibrium and users can play against it to test the equilibrium. We give the idea behind its implementation and present examples of its practical use.","A multiobjective approach based on the law of gravity and mass interactions for optimizing networksIn this work, we tackle a real-world telecommunication problem by using Evolutionary Computation and Multiobjective Optimization jointly. This problem is known in the literature as the Traffic Grooming problem and consists on multiplexing or grooming a set of low-speed traffic requests (Mbps) onto high-speed channels (Gbps) over an optical network with wavelength division multiplexing facility. We propose a multiobjective version of an algorithm based on the laws of motions and mass interactions (Gravitational Search Algorithm, GSA) for solving this NP-hard optimization problem. After carrying out several comparisons with other approaches published in the literature for this optical problem, we can conclude that the multiobjective GSA (MO-GSA) is able to obtain very promising results.","Incorporating Rough Data in Database Design for Imprecise Information Representation ","Prediction of Coal Calorific Value Based on a Hybrid Linear Regression and Support Vector Machine Model ","Affect detection from semantic and metaphorical interpretation of virtual dramaWe have developed an intelligent agent to engage with users in virtual drama improvisation previously. The agent was able to perform sentence-level affect detection especially from inputs with strong emotional indicators. In this research, we employ latent semantic analysis to interpret emotional expressions with vague affect indicators and ambiguous audiences. Latent semantic analysis is thus used to perform topic theme detection and target audience identification for such inputs. Then we also discuss how affect is detected for such inputs without strong emotional indicators with the consideration of emotions expressed by the intended audiences and relationships between speakers and audiences. This work also proves to be effective in recognizing metaphorical phenomena. Moreover, uncertainty-based active learning is also employed to deal with more open-ended and imbalanced affect detection tasks. Overall, this work enables the AI agent to deal with challenging issues in affect detection tasks.","Estimation of the collection parameter of information models for IRIn this paper we explore various methods to estimate the collection parameter of the information based models for ad hoc information retrieval. In previous studies, this parameter was set to the average number of documents where the word under consideration appears. We introduce here a fully formalized estimation method for both the log-logistic and the smoothed power law models that leads to improved versions of these models in IR. Furthermore, we show that the previous setting of the collection parameter of the log-logistic model is a special case of the estimated value proposed here.","Expressive Reasoning on Tree Structures: Recursion, Inverse Programs, Presburger Constraints and Nominals ","Scheduling a Cascade with Opposing InfluencesAdoption or rejection of ideas, products, and technologies in a soci- ety is often governed by simultaneous propagation of positive and negative in- fluences. Consider a planner trying to introduce an idea in different parts of a society at different times. How should the planner design a schedule considering this fact that positive reaction to the idea in early areas has a positive impact on probability of success in later areas, whereas a flopped reaction has exactly the opposite impact? We generalize a well-known economic model which has been recently used by Chierichetti, Kleinberg, and Panconesi (ACM EC'12). In this model the reaction of each area is determined by its initial preference and the reaction of early areas. We model the society by a graph where each node repre- sents a group of people with the same preferences. We consider a full propagation setting where news and influences propagate between every two areas. We gen- eralize previous works by studying the problem when people in different areas have various behaviors. We first prove, independent of the planner's schedule, influences help (resp., hurt) the planner to propagate her idea if it is an appealing (resp., unappealing) idea. We also study the problem of designing the optimal non-adaptive spreading strategy. In the non-adaptive spreading strategy, the schedule is fixed at the begin- ning and is never changed. Whereas, in adaptive spreading strategy the planner decides about the next move based on the current state of the cascade. We demon- strate that it is hard to propose a non-adaptive spreading strategy in general. Nev- ertheless, we propose an algorithm to find the best non-adaptive spreading strat- egy when probabilities of different behaviors of people in various areas drawn i.i.d from an unknown distribution. Then, we consider the influence propagation phenomenon when the underlying influence network can be any arbitrary graph. We show it is #P -complete to compute the expected number of adopters for a given spreading strategy. However, we design a polynomial-time algorithm for the problem of computing the expected number of adopters for a given schedule in the full propagation setting. Last but not least, we give a polynomial-time algo- rithm for designing an optimal adaptive spreading strategy in the full propagation setting.","P2P grid technology for virtual classrooms and laboratoriesComputing technologies can play important role in Virtual Classrooms and Laboratories (VCL) and e-learning settings. In these systems, the underlying computing platforms enable large number of students across the globe to collaborate and interact with each other as well as with the learning components. A typical VCL can be setup based on a traditional or Peer-to-Pear (P2P) Grid Computing. While several VCLs are currently using the traditional Grid, few have been reported utilizing P2P Grid. The latter provides with an alternative computing system, which mainly targets the scalability of the system and often with improved flexibility and interactions. We studied whether P2P Grid could provide an improved platform over its counterpart. We inspected large number of systems, examples of which are presented in this paper. We scrutinized their features, capabilities, and performance. Our investigation indicates that P2P Grid exhibits a superior behavior over its traditional counterpart for VCL setting. This is especially true for courses such as Parallel Computing, Simulation, and Networking since P2P Grid offers accessing to larger scale computational and data resources as well as much improved collaborative environment in heterogeneous and distributed communities.","Finding Errors in Python Programs Using Dynamic Symbolic ExecutionFor statically typed languages, dynamic symbolic execution (also called concolic testing) is a mature approach to automated test generation. However, extending it to dynamic languages presents sev- eral challenges. Complex semantics, fragmented and incomplete type in- formation, and calls to foreign functions lacking precise models make symbolic execution difficult. We propose a symbolic execution approach that mixes concrete and symbolic values and incrementally solves path constraints in search for alternate executions by lazily instantiating ax- iomatizations for called functions as needed. We present the symbolic execution model underlying this approach and illustrate the workings of our prototype concolic testing tool on an actual Python software package.","RepRank: reputation in a peer-to-peer online systemPeer-to-peer e-commerce networks exemplify online lemon markets. Trust is key to sustaining these networks. We present a reputation system named RepRank that approaches trust with an intuition that in the peer-to-peer e-commerce world consisting of buyers and sellers, good buyers are those who buy from good sellers, and good sellers are those from whom good buyers buy. We propagate trust and distrust in a network using this mutually recursive definition. We discuss the algorithms and present the evaluation results.","Abstract Interpretation of Recursive QueriesIn this paper, we extend recent works on concrete and ab- stract semantics of structured query languages by considering recursive queries too. We show that combining abstraction of data and widen- ing operators that guarantee the convergence of the computation may be useful not only for static analysis purposes, but also as a sound and effective tool for query language transformations.","Temporality in Planning: The Case of the Allocation of Parking Areas for Aircrafts ","Meta-ensembles of Classifiers for Alzheimer\u2019s Disease Detection Using Independent ROI Features ","A comparison of two dual methods for discrete optimal transportThe goal of this expository article is to present and compare two dual methods that have been proposed independently for computing solutions of the discrete or semi-discrete instances of optimal transport.","Web Searching for Health Information: An Observational Study to Explore Users' EmotionsTo-date, most of the research concerning online health information search has focused on how users search the Web and how they evaluate health websites. Despite the concerns raised on the impact of online health information on users, there is little research specifically exploring the problems users en- counter and emotions they exhibit during the search process. In this paper, we address this gap by conducting an observational study to understand how users search the Web for health information, the problems they encounter and the emotions they express during the search process. Through eye-tracking, think- aloud and interviews, we examined users' search process holistically. Results showed that users exhibited various negative emotions during the search process especially when there are perceived health risks. Highlighting the theo- retical and practical implications of this study, this paper makes recommenda- tions for future research to delve deeper into understanding users' emotions during Web searching for health information.","Scalable and High Performing Learning and Mining in Large-Scale Networked Environments: A State-of-the-art Survey ","Unsupervised Internet-Based Category Learning for Object RecognitionThis paper describes a new method for acquiring object categories by searching images on the Internet. An unsupervised method is proposed that, starting from a set of objects extracted from the Internet images automatically fetched for a given category name, selects a subset of objects suitable for build- ing a model of the category. The method is based on repeated k-means cluster- ing. Object relevance scoring is based on properties of the clusters in which they are placed. The approach is evaluated on generic categories (i.e. those usually referenced through common nouns). We demonstrate that the proposed approach significantly improves the quality of the training object collections.","A Knowledge Based Collaborative Platform for the Design and Deployment of Manufacturing Systems ","Incremental Principal Component Analysis-Based Sparse Representation for Face Pose ClassificationThis paper proposes an Adaptive Sparse Representation pose Classification (ASRC) algorithm to deal with face pose estimation in occlusion, bad illumination and low-resolution cases. The proposed approach classifies different poses, the appearance of face images from the same pose being modelled by an online eigenspace which is built via Incremental Principal Component Analysis. Then the combination of the eigenspaces of all pose classes are used as an over-complete dictionary for sparse representation and classification. However, the big amount of training images may lead to build an extremely large dictionary which will decelerate the classification procedure. To avoid this situation, we devise a conditional update method that updates the training eigenspace only with the misclassified face images. Experimental results show that the proposed method is very robust when the illumination condition changes very dynamically and image resolutions are quite poor.","An argumentative approach of conceptual modelling and model validation through theory buildingConceptual modelling and theory building are tightly bundled together, since conceptual models are one way to express one's thoughts, assumptions, beliefs and convictions, respectively his theory referencing a domain. However, while theory building does account for a process of knowledge creation and the evolution of a theory, which is characterised by falsification and rebuttals, a conceptual model remains a vessel of expressing a current state of knowledge. A theory held in a person's mind might develop during gaining experiences and through discussions with others, usually held in natural language. A conceptual model, however, disregards these aspects of theory building. Therefore in this paper, we will introduce an approach of purposefully constructing and validating conceptual models by means of arguments. This approach will not just enable a validation of a conceptual model against the theory of the creator, but against all theories the respective stakeholders might have.","Role of the Prefrontal Cortex (PFC) on Processing the Social Statistical Information: An fMRI StudyThe prefrontal cortex is crucial for memory encoding and processing, in which the lateral prefrontal cortex (LPFC) is more involved in semantic and episodic memory, whereas the medial prefrontal cortex (MPFC) is more related to the associative information processing and social cognition. Social statistical information is a kind of typical associative information with sociality. However, the role of the prefrontal cortex in comprehending the social statistical information remains unknown yet.This study focused on the brain activities of 36 normal subjects in the prefrontal cortex using fMRI while they viewed the social statistical information presented in either visual form as a graph or textual form as a verbal description of the information in the graph. The results showed that the graph and textual tasks consistently activated the anterior and posterior portions of ventrolateral prefrontal cortex (VLPFC), the dorsal and ventral MPFC. The results suggest that the VLPFC and the MPFC commonly contribute to the social statistical information processing.","Beyond Gambling Temptations: An Experimental Design Project to Detoxify Players from Irresistible Illusions of Gambling ","Investigating Perceptual Features for a Natural Human - Humanoid Robot Interaction Inside a Spontaneous SettingThe present paper aims to validate our research on human- humanoid interaction (HHI) using the minimalistic humanoid robot Te- lenoid. We have conducted human-robot interactions test with 100 young people with no prior interaction experience with this robot. The main goal is the analysis of the two social dimension (perception and believability) useful for increasing the natural behavior between users and Telenoid. We administrated our custom questionnaire to these subjects after a well de- fined experimental setting (ordinary and goal-guided task). After the analysis of the questionnaires, we obtained the proof that perceptual and believability conditions are necessary social dimensions for a successfully and efficiency HHI interaction in every daylife activities.","PQMPMS: a preference-enabled querying mechanism for personalized mobile searchA key challenge for personalized mobile search is to tailor the answers to the specific user by considering her contextual situation. To adapt the retrieved items to user's context, this paper presents a preference-enabled querying mechanism for personalized mobile search. By exploiting the user's dialogue history, we infer the weighted user preferences and interests. To further compute personalized answers, we aim to continuously collect the ratings given by the user's friends regarding relevant topics from stream-based data sources such as Twitter. An experiment shows that our approach allows to compute the most relevant answers, providing an increased quality of search experience for the user.","An Improvement of Process Reference Model Design and Validation Using Business Process Management ","Time based feedback and query expansion for twitter searchTwitter is an accepted platform among users for expressing views in a short text called a \"Tweet\" Application of search models to platforms like Twitter is still an open-ended question, though the creation of the TREC Microblog track in 2011 aims to help resolve it. In this paper, we propose a modified language search model by extending a traditional query-likelihood language model with time based feedback and query expansion. The proposed method makes use of two types of feedback, time feedback by evaluating the time distribution of top retrieved tweets, and query expansion by using highly frequent terms in top tweets as expanded terms. Our results suggest that using both types of feedback, we get better results than using a standard language model, and the time-based feedback uniformly improves results whether query expansion is used or not.","Story guided virtual environments in educational applicationsOver the last few years we have witnessed a rapid development and popularisation of serious gaming. This field is becoming approved in not only education, science, medicine, religion or engineering, but also in the area of cultural heritage through serious heritage games. This can be utilised for virtual reconstructions and virtual museums and possibly used for education in the form of edutainment, comprising various techniques, such as storytelling, visual expression of information, interactivity and entertainment [19]. This paper demonstrates a new concept of using story guided virtual environments for cultural heritage virtual reconstruction, with live virtual guides in an interactive Flash format. First we compare the implementations of the same environments in x3D and Flash and then we extend the project with digital storytelling, where a user is guided through the whole application using both narrative, non-interactive, movie-like elements and interactive exploration of the virtual environment. The introduced results can be easily adopted for serious games development.","Bi-Abduction with Pure Properties for Specification InferenceSeparation logic is a state-of-the-art logic for dealing with the program heap. Using its frame rule, initial works have strived towards automated modular verification for heap-manipulating programs against user-supplied specifications. Since manually writing specifications is a tedious and error-prone engineering process, the so-called bi-abduction (a combination of the frame rule and abductive inference) is proposed to automatically infer pre/post specifications on data structure shapes. However, it has omitted the inference of pure properties of data structures such as their size, sum, height, content and minimum/maximum value, which are needed to express a higher level of program correctness.#R##N##R##N#In this paper, we propose a novel approach, called pure bi-abduction, for inferring pure information for pre/post specifications, using the result from a prior shape analysis step. The power of our new bi-abductive entailment procedure is significantly enhanced by its collection of proof obligations over uninterpreted relations (functions). Additionally, we design a predicate extension mechanism to systematically extend shape predicates with pure properties. We have implemented our inference mechanism and evaluated its utility on a benchmark of programs. We show that pure properties are prerequisite to allow the correctness of about 20% of analyzed procedures to be captured and verified.","Performance Analysis of IEEE 802.11 EDCA for a Different Number of Access Categories and Comparison with DCF ","Creating a Repository of Community Memory in a 3D Virtual World: Experiences and Challenges ","Learning-Based Adaptation for Personalized Mobility AssistanceMobility assistance is of key importance for people with dis- abilities to remain autonomous in their preferred environments. In severe cases, assistance can be provided by robotized wheelchairs that can per- form complex maneuvers and/or correct the user's commands. User's ac- ceptance is of key importance, as some users do not like their commands to be modified. This work presents a solution to improve acceptance. It consists of making the robot learn how the user drives so corrections will not be so noticeable to the user. Case Based Reasoning (CBR) is used to acquire a user's driving model reactive level. Experiments with volunteers at Fondazione Santa Lucia (FSL) have proven that, indeed, this customized approach at assistance increases acceptance by the user.","Detecting Overlapping Communities in Complex Networks Using Swarm Intelligence for Multi-threaded Label Propagation ","The Dichotomous Intensional Expressive Power of the Nested Relational Calculus with PowersetMost existing studies on the expressive power of query lan- guages have focused on what queries can be expressed and what queries cannot be expressed in a query language. They do not tell us much about whether a query can be implemented efficiently in a query language. Yet, paradoxically, efficiency is a key concern in computer science. In this paper, the efficiency of queries in NR C(powerset ), a nested relational calculus with a powerset operation, is discussed. A dichotomy in the ef- ficiency of these queries on a large general class of structures\u2014which include long chains, deep trees, etc.\u2014is proved. In particular, it is shown that these queries are either already expressible in the usual nested re- lational calculus or require at least exponential space. This Dichotomy Theorem, when coupled with the bounded degree and locality proper- ties of the usual nested relational calculus becomes a powerful general tool in studying the intensional expressive power of query languages. The bounded degree and locality properties make it easy to prove that a query is inexpressible in the usual nested relational calculus. Then, if the query is expressible in NR C(powerset ), subject to the conditions of the Dichotomy Theorem, the query must take at least exponential space.","Efficient Evaluation of Ad-Hoc Range Aggregatesi\u00be?-MDA is a flexible and efficient operator for complex ad-hoc multi-dimensional aggregation queries. It separates the specification of aggregation groups for which aggregate values are computed base table b and the specification of aggregation tuples from which aggregate values are computed. Aggregation tuples are subsets of the detail table r and are defined by a general i\u00be?-condition. The i\u00be?-MDA requires one scan of r, during which the aggregates are incrementally updated.#R##N##R##N#In this paper, we propose a two-step evaluation strategy for i\u00be?-MDA to optimize the computation of ad-hoc range aggregates by reducing them to point aggregates. The first step scans r and computes point aggregates as a partial intermediate result xi\u00be?, which can be done efficiently. The second step combines the point aggregates to the final aggregates. This transformation significantly reduces the number of incremental updates to aggregates and reduces the runtime from    $\\mathcal{O}|{\\bf r}|\\cdot|{\\bf b}|$    to    $\\mathcal{O}|{\\bf r}|$   , provided that    $|{\\bf b}|     and |xi\u00be?| i\u00be? |b|, which is common for OLAP. An empirical evaluation confirms the analytical results and shows the effectiveness of our optimization: range queries are evaluated with almost the same efficiency as point queries.","A Simple Data Compression Algorithm for Wireless Sensor Networks ","Spiking Neural Network for On-line Cognitive Activity Classification Based on EEG DataThe paper presents a method for the classification of EEG data recorded in two cognitive scenarios, a relaxing and memory task. The method uses a reservoir of spiking neurons that are activated by the spatio-temporal EEG data. The states of the reservoir are periodically read out and classified producing in a continuous classification result over time. After suitable optimization of the model parameters, we achieve a test accuracy of 82% on a small data set. Future applications of the proposed model are discussed including its use for an early detection of a cognitive impairment such as in Alzheimers disease. Intellectual functioning including memory testing is a commonly used diagnosis tool to characterize the state of cognitive impairments such as Alzheimer's dis- ease. In this paper, we investigate the idea to use the classification ability of a machine learning algorithm as an indicator for the detection of memory related cognitive diseases. We have collected EEG recordings from a single healthy sub- ject performing a relaxing and a memory task; the latter represents the cognitive scenario. If the subject is healthy, a distinct difference between the EEG record- ings of the two scenarios is expected and a classification algorithm should be able to tell the memory and relax scenarios reliably apart. Therefore, if a high classification accuracy is observed, the subject is expected to be healthy. On the other hand, if the classification performance is poor, it may be an indicator for memory related cognitive disease. In this paper, we investigate a brief proof of concept only. We are especially interested in establishing the suitability of a reservoir computing approach for the described learning scenario. Reservoir com- puting has reported promising results on the detection of epileptic seizures (1) and the classification of motor imagery based on EEG data streams (6). While the above studies have investigated the suitability of Echo State Networks (4), we explore Liquid State Machines (LSM) (7) for classifying spatio-temporal EEG signals in this paper. Corresponding author.","Systematic management of simulation state for multi-branch simulations in simulinkSystematic simulation is a technique related and motivated by the formal analysis of hybrid dynamic systems. It combines the exhaustive and conservative nature of traditional model checking with numerical simulation for providing efficient algorithms to manage simulations. Multi-branch simulation is the concept advancing simulation efficiency by reducing the number of state transitions. This paper introduces an approach to implement multi-branch simulation into a popular industrial modeling and simulation tool, Simulink\u00ae. The notion of simulation state which is distinctly different from the dynamic system state, is introduced for Simulink models. From this, a novel semantics based on transition systems is then developed. In a prototype implementation, these semantics are encoded in the current architecture of the Simulink engine and enable demonstrating the benefit of such type of a simulation by three case studies.","Automatic Extraction of Forests from Historical Maps Based on Unsupervised Classification in the CIELab Color SpaceIn this chapter, we describe an automatic procedure to capture features on old maps. Early maps contain specific informations which allow us to reconstruct trajectories over time and space for land use/cover studies or urban area development. The most commonly used approach to extract these elements requires a user intervention for digitizing which widely limits its utilization. Therefore, it is essential to propose automatic methods in order to establish reproducible procedures. Capturing features automatically on scanned paper maps is a major challenge in GIS for many reasons: (1) many planimetric elements can be overlapped, (2) scanning procedure may conduct to a poor image quality, (3) lack of colors complicates the distinction of the elements. Based on a state of art, we propose a method based on color image segmentation and unsupervised classification (K-means algorithm) to extract forest features on the historical 'Map of France'. The first part of the procedure conducts to clean maps and eliminate elevation contour lines with filtering techniques. Then, we perform a color space conversion from RGB to L*a*b color space to improve uniformity of the image. To finish, a post processing step based on morphological operators and contextual rules is applied to clean-up features. Results show a high global accuracy of the proposed scheme for different excerpt of this historical map.","In Praise of Abundance: Why Individuals Matter in Design Science ","Globally optimal cortical surface matching with exact landmark correspondenceWe present a method for establishing correspondences between human cortical surfaces that exactly matches the positions of given point landmarks, while attaining the global minimum of an objective function that quantifies how far the mapping deviates from conformality. On each surface, a conformal transformation is applied to the Euclidean distance metric, resulting in a hyperbolic metric with isolated cone point singularities at the landmarks. Equivalently, each surface is mapped to a hyperbolic orbifold: a pillow-like surface with each point landmark corresponding to a pillow corner. An initial surface-to-surface mapping exactly aligns the landmarks, and gradient descent is used to find the single, global minimum of the Dirichlet energy of the remainder of the mapping. Using a population of real MRI-based cortical surfaces with manually labeled sulcus endpoints as landmarks, we evaluate the approach by how much it distorts surfaces and by its biological plausibility: how well it aligns previously-unseen anatomical landmarks and by how well it promotes expected associations between cortical thickness and age. We show that, compared to a painstakingly-tuned approach that balances a tradeoff between minimizing landmark mismatch and Dirichlet energy, our method has similar biological plausibility, superior surface distortion, a better theoretical foundation, and fewer arbitrary parameters to tune. We also compare to conformal mapper in the spherical domain to show that sacrificing exact conformality of the mapping does not cause noticeable reductions in biological plausibility.","The Energetic Reasoning Checker RevisitedEnergetic Reasoning (ER) is a powerful filtering algorithm for the Cumulative constraint. Unfortunately, ER is generally too costly to be used in practice. One reason of its bad behavior is that many intervals are considered as relevant by the checker of ER, although most of them should be ignored. In this paper, we provide a sharp characterization that allows to reduce the number of intervals by a factor seven. Our experiments show that associating this checker with a Time-Table filtering algorithm leads to promising results.","Explicit Exploration in Estimation of Distribution Algorithms ","Research and Application of DBSCAN Algorithm Based on Hadoop PlatformAlong with the rapid development of information age, more and more data can be obtained from the Internet, it is very difficult to get useful information and knowledge from these huge amounts of data. On the foundation of the existing algorithm based on DBSCAN, a new improved incremental DBSCAN clustering algorithm is proposed. Combining with cloud computing open source framework Hadoop, the improved algorithm use the programming model of MapReduce which can easy write distributed applications and simplify distributed programme to divide a huge amounts of data elements into chunks and distribute the chunks across the cluster and run the algorithm as a MapReduce job, in this way, this improved algorithm of data mining is integrated with framework Hadoop by the DBSCAN clustering algorithm. When data manipulation (add or delete) has occurred in the database, what we need to do is to mine the mutative data and merge the similar clusters, and ultimately form the final knowledge mining.Compared with single node server serial arithmetic and the overall mining, the time delay of data processing will be reduced. In the last part,the paper verified the effectiveness by experiments and data analysis.","Data-driven reduction of a cardiac myofilament modelThis manuscript presents a novel, data-driven approach to reduce a detailed cellular model of cardiac myofilament (MF) for efficient and accurate cellular simulations towards cell-to-organ computation. Based on 700 different sarcomere dynamics calculated using Rice model, we show through manifold learning that sarcomere force (SF) dynamics lays surprisingly in a linear manifold despite the non-linear equations of the MF model. Then, we learn a multivariate adaptive regression spline (MARS) model to predict SF from the Rice model parameters and sarcomere length dynamics. Evaluation on 300 testing data showed a prediction error of less than 0.4 nN/mm2 in terms of maximum force amplitude and 0.87 ms in terms of time to force peak, which is comparable to the differences observed with experimental data. Moreover, MARS provided insights on the driving parameters of the model, mainly MF geometry and cell mechanical passive properties. Thus, our approach may not only constitute a fast and accurate alternative to the original Rice model but also provide insights on parameter sensitivity.","Compiling Cooperative Task Management to ContinuationsAlthough preemptive concurrency models are dominant for multi-threaded concurrency, they may be criticized for the complexity of reasoning because of the implicit context switches. The actor model and cooperative concurrency models have regained attention as they encapsulate the thread of control. In this paper, we formalize a continuation-based compilation of cooperative multitasking for a simple language and prove its correctness.","Implicit learning leads to familiarity effects for intonation but not for voicePrevious studies have shown that speech processing is accelerated for familiar voices in contrast to unfamiliar ones (e.g. [1]), and for familiar intonation in contrast to unfamiliar intonation [2]. The present experiments probed these effects in a single experiment and tested whether they also occur with short, implicit familiarization. Results of two auditory lexical decision tasks (Experiment 1 with a task-based familiarization phase and Experiment 2 with a passive listening familiarization phase), showed that familiarity with the intonation (rise vs. fall) affected reaction times but that familiarity with the voice (speaker A vs. B) did not. Our results suggest that intonation (which contributes to utterance interpretation) is stored in the mental lexicon, but voice information is not.","A Simple Approach towards SKOSification of Digital Repositories ","Assessing the Differential Effect of Web Usability Dimensions on Perceived Usefulness of a B2C E-Commerce Website ","Neuron Threshold Variability in an Olfactory Model Improves Odorant DiscriminationWe used a model based on the olfactory system of insects to analyze the impact of neuron threshold variability in the mushroom body (MB) for odorant discrimination purposes. This model is a single- hidden-layer neural network (SLN) where the input layer represents the antennal lobe (AL), which contains a binary code for each odorant; the hidden layer that represents the Kenyon cells (KC) and the output layer named the output neurons. The KC and output layers are responsible for learning odor discrimination. The binary code obtained for each odorant in the output layer has been used to measure the discrimination error and to know what kind of thresholds (heterogeneous or homogeneous) provide better results when they are used in KC and output neurons. We show that discrimination error is lower for heterogeneous thresholds than for homogeneous thresholds.","Segmentation of Blood Cell Images Using Evolutionary MethodsAcute lymphoblastic leukemia is a blood cancer that can be cured if it is detected at early stages; however, the analysis of smear blood by a human expert is tired and subject to errors. In such a sense, diagnostic of the disease is costly and time consuming. Considering that situation, several automatic segmentation meth- ods have been proposed, some of them containing combinations of classic image analysis tools, as thresholding, morphology, color segmentation and active contours, only to mention some. In this paper is proposed the use of Hellinger distance as an alternative to Euclidean distance in order to estimate a Gaussian functions mixture that better fits a gray-level histogram of blood cell images. Two evolutionary meth- ods (Differential Evolution and Artificial Bee Colony) are used to perform segmen- tation based on histogram information and an estimator of minimum distance. The mentioned techniques are compared with classic Otsu's method by using a qualita- tive measure of the resulting segmentation and ground-truth images. Experimental results show that the three methods performed almost in a similar fashion, but the evolutionary ones evaluate almost 75 % less the objective function compared with Otsu's. Also, was found that the use of a minimum distance estimator constructed with Hellinger distance and evolutionary techniques is robust and does not need a penalization factor as the needed when an Euclidean distance is used.","A stock selective system by using hybrid models of classificationStock trade is a popular investing activity and during this activity, investors expect to gain higher profit with lower risk. Therefore, the problem of predicting stock returns has been an important issue for many years. This study is aimed on the discover relationship between financial data of public companies and return on investment by using data mining technology. The study propose a stock selective system by using hybrid models of classification. Use the hybrid models of association rules, cluster, and decision tree, it can provide meaningful decision rules for stock selection for intermediate- or long-term investors. Further, these rules are use to select some profitable stocks of the following years. The outcome evidences the higher return on investment in proposed model than general market average.","Combining supervised and unsupervised polarity classification for non-english reviewsTwo main approaches are used in order to detect the sentiment polarity from reviews. The supervised methods apply machine learning algorithms when training data are provided and the unsupervised methods are usually applied when linguistic resources are available and training data are not provided. Each one of them has its own advantages and disadvantages and for this reason we propose the use of meta-classifiers that combine both of them in order to classify the polarity of reviews. Firstly, the non-English corpus is translated to English with the aim of taking advantage of English linguistic resources. Then, it is generated two machine learning models over the two corpora (original and translated), and an unsupervised technique is only applied to the translated version. Finally, the three models are combined with a voting algorithm. Several experiments have been carried out using Spanish and Arabic corpora showing that the proposed combination approach achieves better results than those obtained by using the methods separately.","SafetyMet: A Metamodel for Safety StandardsIn domains such as automotive, avionics, and railway, critical systems must comply with safety standards to allow their operation in a given context. Safety compliance can be an extremely demanding activity as practitioners have to show fulfilment of the safety criteria specified in the standards and thus that a system can be deemed safe. This is usually both costly and time consuming, and becomes even more challenging when, for instance, a system changes or aims to be reused in another project or domain. This paper presents SafetyMet, a metamodel for safety standards targeted at facilitating safety compliance. The metamodel consists of entities and relationships that abstract concepts common to different safety standards from different domains. Its use can help practitioners to show how they have followed the recommendations of a standard, and particularly in evolutionary or cross-domain scenarios. We discuss the benefits of the use of the metamodel, its limitations, and open issues in order to clearly present the aspects of safety compliance that are facilitated and those that are not addressed.","GMAC: A Seed-Insensitive Approach to Local Community DetectionLocal community detection aims at finding a community structure starting from a seed i.e., a given vertex in a network without global information, such as online social networks that are too large and dynamic to ever be known fully. Nonetheless, the existing approaches to local community detection are usually sensitive to seeds, i.e., some seeds may lead to missing of some true communities. In this paper, we present a seed-insensitive method called GMAC for local community detection. It estimates the similarity between vertices via the investigation on vertices' neighborhoods, and reveals a local community by maximizing its internal similarity and minimizing its external similarity simultaneously. Extensive experimental results on both synthetic and real-world data sets verify the effectiveness of our GMAC algorithm.","Surjective cellular automata far from the Garden of EdenOne of the first and most famous results of cellular automata theory, Moore's Garden-of-Eden theorem has been proven to hold if and only if the underlying group possesses the measure-theoretic properties suggested by von Neumann to be the obstacle to the Banach-Tarski paradox. We show that several other results from the literature, already known to characterize surjective cellular automata in dimension d, hold precisely when the Garden-of-Eden theorem does. We focus in particular on the balancedness theorem, which has been proven by Bartholdi to fail on amenable groups, and we measure the amount of such failure.","Parallel Discrepancy-Based SearchBacktracking strategies based on the computation of discrepancies have proved themselves successful at solving large problems. They show really good performance when provided with a high-quality domain-specific branching heuristic variable and value ordering heuristic, which is the case for many industrial problems. We propose a novel approach PDS that allows parallelizing a strategy based on the computation of discrepancies LDS. The pool of processors visits the leaves in exactly the same order as the centralized algorithm would do. The implementation allows for a natural/intrinsic load balancing to occur filtering induced by constraint propagation would affect each processor pretty much in the same way, although there is no communication between processors. These properties make PDS a scalable algorithm that was used on a massively parallel supercomputer with thousands of cores. PDS improved the best known performance on an industrial problem.","2nd International Workshop on Load Testing of Large Software Systems (LT 2013)Nowadays, many software systems are offered in the cloud to millions of users. Field problems of these systems are often due to their inability to scale to field workloads, rather than feature bugs. To assure the quality of these systems, load testing is a required procedure in addition to the conventional functional testing. Problems in a load test could be caused by the system under test, the load generator or the test environment. This one-day workshop intended to bring together researchers and practitioners to discuss the challenges and opportunities of conducting load testing research on large scale software systems.","Talking about technology: the emergence of a new actor category through new mediaThis paper examines how a new actor category may emerge in a field of discourse through the new media of the Internet. Existing literatures on professional and organizational identity have shown the importance of identity claims and of the tensions surrounding \"optimal distinctiveness\" for new actors in a field, but have not examined the roles of new media in these processes. The literature on information technology (IT) and identity has highlighted the identity-challenging and identity-enhancing aspects of new IT use for existing actor categories but has not examined the dynamics associated with the emergence of new actor categories. Here, we investigate how a new actor category may emerge through the use of new media as a dynamic interaction of discursive practices, identity claims, and new media use. Drawing on findings from a case study of technology bloggers, we identified discursive practices through which a group of technology bloggers enacted claims of a distinctive identity in the joint construction of their discourse and in response to continuous developments in new media. Emergence of this new category was characterized by ongoing, opposing yet coexisting tendencies toward coalescence, fragmentation, and dispersion. Socio-technical dynamics underlying bloggers' use of new media and the actions of prominent (\"A-list\") bloggers contributed to these tendencies. We untangle theoretically the identity-enabling and identity-unsettling effects of new media and conceptualize the emergence of a new actor category through new media as an ongoing process in which the category identity may remain fluid, rather than progress to an endpoint.","Motivational Effects of Badge Systems on Participation in Stack Exchange Social Q&amp;A Online Community ","An Expressive Framework for Verifying Deadlock FreedomThis paper presents an expressive specification and verifica- tion framework for ensuring deadlock freedom of shared-memory con- current programs that manipulate locks. We introduce a novel delayed lockset checking technique to guarantee deadlock freedom of programs with interactions between thread and lock operations. With disjunctive formulae, we highlight how an abstraction based on precise lockset can be supported in our framework. By combining our technique with locklevels, we form a unified formalism for ensuring deadlock freedom from (1) dou- ble lock acquisition, (2) interactions between thread and lock operations, and (3) unordered locking. The proposed framework is general, and can be integrated with existing specification logics such as separation logic. Specifically, we have implemented this framework into a prototype tool, called ParaHIP, to automatically verify deadlock freedom and correct- ness of concurrent programs against user-supplied specifications.","Exploration of a Rich Feature Set for Automatic Term ExtractionDespite the importance of the term extraction methods and that several efforts have been devoted to improve them, they still have 4 main problems: (i) noise and silence generation; (ii) difficulty dealing with high number of terms; (iii) human effort and time to evaluate the terms; and (iv) still limited extraction results. In this paper, we deal with these four major problems in automatic term extraction by exploring a rich feature set in a machine learning approach. We minimized these problems and achieved state of the art results for unigrams in Brazilian Portuguese.","Die \u201eFrankfurter Schule\u201c in der Statistik und ihre Folgen\u201cFrankfurt School\u201d (FSS) here denotes a group of statisticians (three generations of professors at the University of Frankfurt/Germany). The period in which FSS was fairly active and influential covered about six decades beginning in the 1920ies. The school focused \u201cunderstanding\u201d and verbal interpretation of statistics rather than developing mathematically advanced methods in statistics. It deliberately emphasized problems of descriptive and official statistics at the expense of a more \u201cformal\u201d approach. Hence one of the consequences of the temporary sway of the FSS in German statistics was Germany\u2019s lagging behind in the respective fields of Statistics after the Second World War. Copyright Springer-Verlag Berlin Heidelberg 2013","Intertwined forward-backward reachability analysis using interpolantsIn this work we develop a novel SAT-based verification approach which is based on interpolation. The novelty of our approach is in extracting interpolants in both forward and backward manner and exploiting them for an intertwined approximated forward and backward reachability analysis. Our approach is also mostly local and avoids unrolling of the checked model as much as possible. This results in an efficient and complete SAT-based verification algorithm.#R##N##R##N#We implemented our algorithm and compared it with both McMillan's interpolation-based algorithm and with IC3, on real-life industrial designs as well as on examples from the HWMCC'11 benchmark. In many cases, our algorithm outperformed both methods.","Kernel-based Data Fusion for Machine Learning: Methods and Applications in Bioinformatics and Text MiningData fusion problems arise frequently in many different fields. This book provides a specific introduction to data fusion problems using support vector machines. In the first part, this book begins with a brief survey of additive models and Rayleigh quotient objectives in machine learning, and then introduces kernel fusion as the additive expansion of support vector machines in the dual problem. The second part presents several novel kernel fusion algorithms and some real applications in supervised and unsupervised learning. The last part of the book substantiates the value of the proposed theories and algorithms in MerKator, an open software to identify disease relevant genes based on the integration of heterogeneous genomic data sources in multiple species. The topics presented in this book are meant for researchers or students who use support vector machines. Several topics addressed in the book may also be interesting to computational biologists who want to tackle data fusion challenges in real applications. The background required of the reader is a good knowledge of data mining, machine learning and linear algebra.","A Web Service-Based Platform for Distributed Web Applications Integration ","Taxation and stability in cooperative gamesCooperative games are a useful framework for modeling multi-agent behavior in environments where agents must collaborate in order to complete tasks. Having jointly completed a task and generated revenue, agents need to agree on some reasonable method of sharing their profits. One particularly appealing family of payoff divisions is the {\\em core}, which consists of all coalitionally rational (or, stable) payoff divisions. Unfortunately, it is often the case that the core of a game is empty, i.e. there is no payoff scheme guaranteeing each group of agents a total payoff higher than what they can get on their own.#R##N##R##N#As stability is a highly attractive property, there have been various methods of achieving it proposed in the literature. One natural way of stabilizing a game is via taxation, i.e. reducing the value of some coalitions in order to decrease their bargaining power. Existing taxation methods include the e-core, the least-core and several others.#R##N##R##N#However, taxing coalitions is in general undesirable: one would not wish to overly tamper with a given coalitional game, or overly tax the agents. Thus, in this work we study minimal taxation policies, i.e. those minimizing the amount of tax required in order to stabilize a given game. We show that games that minimize the total tax are to some extent a linear approximation of the original games, and explore their properties. We demonstrate connections between the minimal tax and the cost of stability, and characterize the types of games for which it is possible to obtain a tax-minimizing policy using variants of notion of the eps-core, as well as those for which it is possible to do so using reliability extensions.","Exploring Margin for Dynamic Ensemble SelectionHow to effectively combine the outputs of base classifiers is one of the key issues in ensemble learning. A new dynamic ensemble selection algorithm is proposed in this paper. In order to predict a sample, the base classifiers whose classification confidences on this sample are greater than or equal to specified threshold value are selected. Since margin is an important factor to the generalization performance of voting classifiers, thus the threshold value is estimated via the minimization of margin loss. We analyze the proposed algorithm in detail and compare it with some other multiple classifiers fusion algorithms. The experimental results validate the effectiveness of our algorithm.","Message Passing or Shared Memory: Evaluating the Delegation Abstraction for MulticoresEven for small multi-core systems, it has become harder and harder to support a simple shared memory abstraction: processors access some memory regions more quickly than others, a phenomenon called non-uniform memory access (NUMA). These trends have prompted researchers to investigate alternative programming abstractions based on message passing rather than cache-coherent shared memory. To advance a pragmatic understanding of these models' strengths and weaknesses, we have explored a range of different message passing and shared memory designs, for a variety of concurrent data structures, running on different multicore architectures. Our goal was to evaluate which combinations perform best, and where simple software or hardware optimizations might have the most impact. We observe that different approaches perform best in different circumstances, and that the communication overhead of message passing can often outweigh its benefits. Nonetheless, we discuss ways in which this balance may shift in the future. Overall, we conclude that, by emphasizing high-level shared data abstractions, software should be designed to be largely independent of the choice of low-level communication mechanism.","The Building as the Interface: Architectural Design for Education in Virtual Worlds ","Hybrid Distributed ConsensusInspired by the proliferation of cloud-based services, this paper studies consensus, one of the most fundamental distributed computing problems, in a hybrid model of computation. In this model, processes (or nodes) exchange information by passing messages or by accessing a reliable and highly-available register hosted in the cloud. The paper presents a formal definition of the model and problem, and studies performance tradeoffs related to using such a register. Specifically, it proves a lower bound on the number of register accesses in deterministic protocols, and gives a simple deterministic protocol that meets this bound when the register is compare-and-swap (CAS). In addition, two efficient protocols are presented; the first one is probabilistic and solves consensus with a single CAS register access in expectation, while the second one is deterministic and requires a single CAS register access when some favorable network conditions occur. A benefit of those protocols is that they can ensure both liveness and safety, and only their efficiency is affected by the probabilistic and timing assumptions.","Analyzing hemagglutinin genes of human H5N1 virus by linear neighborhood embeddingThis work proposes using linear neighborhood embedding to visualize the distribution of viral genes in a two-dimensional space. The gradient descent algorithm for the embedding is described and the behavior of the algorithm is analyzed.","A convolutional neural network for pedestrian gender recognitionWe propose a discriminatively-trained convolutional neural network for gender classification of pedestrians. Convolutional neural networks are hierarchical, multilayered neural networks which integrate feature extraction and classification in a single framework. Using a relatively straightforward architecture and minimal preprocessing of the images, we achieved 80.4% accuracy on a dataset containing full body images of pedestrians in both front and rear views. The performance is comparable to the state-of-the-art obtained by previous methods without relying on using hand-engineered feature extractors.","A Polynomial Time Approximation Algorithm for the Two-Commodity Splittable Flow ProblemWe consider a generalization of the unsplittable maximum two-commodity flow problem on undirected graphs where each commodity $${i \\in \\{1, 2\\}}$$ can be split into a bounded number k i of equally-sized chunks that can be routed on different paths. We show that in contrast to the single-commodity case this problem is NP-hard, and hard to approximate to within a factor of \u03b1 &gt; 1/2. We present a polynomial time 1/2-approximation algorithm for the case of uniform chunk size over both commodities and show that for even k i and a mild cut condition it can be modified to yield an exact method. The uniform case can be used to derive a 1/4-approximation for the maximum concurrent (k 1 , k 2 )-splittable flow without chunk size restrictions for fixed demand ratios. Copyright Springer-Verlag 2013","Retrial Queueing System with Correlated Input, Finite Buffer, and Impatient Customers ","Prior Linguistic Knowledge Influences Implicit Language Learning. ","A Linear Regression Model for Interval-Valued Response Based on Set Arithmetic ","My dream theatreBeing able to resolve conflicts effectively is a skill of primary importance in our society. In this paper, we describe a serious game that aims to teach 9- to 11-year-old children conflict resolution by making them aware of the deep elements of conflict. The player is invited to manage a theatre club and mediate the conflicts that may suddenly arise between the synthetic characters as autonomous agents.","A Collaborative Enterprise Framework to Support Engineering Changes in Manufacturing Planning and ControlThe main challenges for the enterprises are complexity of the products and uncertainty of the processes. This challenge involves engineering change that frequently requires redesign or altering the products which may call for enterprise agility and flexibility. To meet such a requirement, enterprises require better tools for resilient manufacturing planning and control, and execution. Due to the limitations of the enterprise resource planning (ERP), there is a question how would the future enterprise systems will look like. To approach an answer to this question, this research paper provides an analysis of engineering changes, its characteristics, problems and their implications. Against the background, a conception of future collaborative enterprise model (CoPIDSS: Collaborative planning, information and decision support system) is proposed. In this paper, we discuss the importance of collaborative planning for enterprise resilient manufacturing planning and control. We have analysed user stories provided by industry as scenarios, to understand the collaborative processes in their workplaces and their needs for collaborative platform support. This paper aims to address the following research questions: How does engineering changes and error handling affect the degree of collaboration and decision making within and across enterprises and how CoPDISS helps to overcome this? Is the storage and management of knowledge the one of the key factor to engineering changes and error handling control in a collaboration and decision environment?","A Framework for Business Rules ","Classification of Early-Mild Subjects with Parkinson\u2019s Disease by Using Sensor-Based Measures of Posture, Gait, and Transitions ","Hybrid Neuro-Fuzzy Network Identification for Autonomous Underwater VehiclesAutonomous Underwater Vehicles (AUVs) are ideal platforms for aquatic search and rescue operations and exploration. The AUV poses serious challenges due to its complex, inherently nonlinear and time-varying dynamics. In addition, its hydrodynamic coefficients are difficult to model accurately because of their variations under different navigational conditions and manoeuvring in uncertain environments. This paper introduces an identifier scheme for identification of non-linear systems with disturbances based on Hybrid Neuro-Fuzzy Network (HNFN) technique. The method comprises of an automatic structure-generating phase using entropy based technique. The accuracy of the model is suitably controlled using the entropy measure. To improve the accuracy and also for generalization of the model to handle different data sets, Differential Evolution technique (DE) is employed. Finally, Hardware In-Loop (HIL) simulation and real-time experiments using the proposed algorithm to identify the 6-DOF UNSW Canberra AUV's dynamics are implemented. The modelling performance and generalisation capability are seen to be superior with our method.","Obtaining a 3D Model from a Facial Recognition in 2DThis paper shows the current status of an implementation with a composed device of depth and color camera. From the color image, a set of points associated with the face is obtained; later the main features of a human face are identified. The 3D model is constructed based on a previous 2D analy- sis using the haar-like features for detecting the human face. This application will be a part of a more complex system designed to assist the driver by monitoring both inside and outside the vehicle, i.e. intelligent systems of","Artificial Neural Network Approach for Land Cover Classification of Fused Hyperspectral and Lidar DataHyperspectral remote sensing images are consisted of sev- eral hundreds of contiguous spectral bands that can provide very rich information and has the potential to differentiate land cover classes with similar spectral characteristics. LIDAR data gives detailed height infor- mation and thus can be used complementary with Hyperspectral data. In this work, a hyperspectral image is combined with LIDAR data and used for land cover classification. A Principal Component Analysis (PCA) is applied on the Hyperspectral image to perform feature extraction and dimension reduction. The first 4 PCA components along with the LIDAR image were used as inputs to a supervised feedforward neural network. The neural network was trained in a small part of the dataset (less than 0.4%) and a validation set, using the Bayesian regularization backpropa- gation algorithm. The experimental results demonstrate efficiency of the method for hyperspectral and LIDAR land cover classification.","Testing Distributed Communication Protocols by Formal Performance Monitoring ","Application of Bat Algorithm and Fuzzy Systems to Model Exergy Changes in a Gas TurbineExergy analysis plays a major role in thermal systems. Using ex- ergy, apart from finding components for a potential for further improvement, fault detection and diagnosis, performance optimization, and environmen- tal impact assessment can be conducted. This chapter addresses the use of fuzzy systems for modeling exergy destructions in the main components of an industrial gas turbine. The details include: (i) system description and the challenges in developing first principle models, (ii) thermodynamic models for part load and full load operating conditions, (iii) model identification technique that uses fuzzy systems and a meta-heuristic nature inspired algo- rithm called Bat Algorithm, (iv) validation graphs for semi-empirical models, and (v) validation test for fuzzy models. In the validation of the fuzzy model, the inputs to the model are considered the same as the inputs as experienced by the gas turbine generator. The comparison tests between actual data and prediction demonstrate how promising the combined method is as compared to separate use of the fuzzy systems trained by a heuristic approach.","Fast dropout trainingPreventing feature co-adaptation by encouraging independent contributions from different features often improves classification and regression performance. Dropout training (Hinton et al., 2012) does this by randomly dropping out (zeroing) hidden units and input features during training of neural networks. However, repeatedly sampling a random subset of input features makes training much slower. Based on an examination of the implied objective function of dropout training, we show how to do fast dropout training by sampling from or integrating a Gaussian approximation, instead of doing Monte Carlo optimization of this objective. This approximation, justified by the central limit theorem and empirical evidence, gives an order of magnitude speedup and more stability. We show how to do fast dropout training for classification, regression, and multilayer neural networks. Beyond dropout, our technique is extended to integrate out other types of noise and small image transformations.","OBSTACLE AVOIDANCE WITH SIMULTANEOUS TRANSLATIONAL AND ROTATIONAL MOTION CONTROL FOR AUTONOMOUS MOBILE ROBOT ","Adaptive Region Growing for Automated Oil Palm Fruit Quality RecognitionBesides rubber and rice, oil palm or Elaeis Guineensis remains as one of the most important plantation crops in Malaysia. Unfortunately, the lack of experience in oil palm fruit grading among the plucking farmers results in wrong estimation when harvesting. This affects production, negatively. Meanwhile, region growing conventional image segmentation techniques need manually or fixed initial seed selection which, actually, increases the computational cost, as well as, implementation time. Hence, the main goal of this study is to improve the seed region growing algorithm in order to gain higher accuracy in segmenting color information for oil palm fruit image. This study presents n-Seed Region Growing (n-SRG) for color image segmentation by choosing adaptive numbers of seed. The data sample consists of 80 images which comprises and two ripeness classes (ripe and unripe).The proposed work has out-performed the k-mean clustering method with 86% and 80% of average accuracy rates correspondingly.","On the existence of positive solutions for a class of ( p ( x ) , q ( x ) )-Laplacian systemWe consider the system             1    inf    p   (  x  )   \u2264  sup  p   (  x  )     \u221e       ,   a,b,\u03b1,\u03b2:[0,+\u221e)\u2192(0,\u221e)     a  ,  b  ,  \u03b1  ,  \u03b2  :   [  0  ,  +  \u221e  )   \u2192   (  0  ,  \u221e  )         is a continuous function and   \u03a9=B(0,R)\u2282R N      \u03a9  =  B   (  0  ,  R  )   \u2282    R    N          is a bounded radial symmetric domain, and where            \u2212    \u0394    p   (  x  )     u  =  \u2212   div    (     |  \u2207  u  |     p   (  x  )   \u2212  2    \u2207  u  )         which is called the   p(x)     p   (  x  )        -Laplacian. We discuss the existence of positive solution via sub-super-solutions without assuming sign conditions on   f(0),h(0),g(0)     f   (  0  )   ,  h   (  0  )   ,  g   (  0  )         and   \u03b3(0)     \u03b3   (  0  )        .","Entropy and heterogeneity measures for directed graphsIn this paper, we aim to develop novel methods for measuring the structural complexity for directed graphs. Although there are many existing alternative measures for quantifying the structural properties of undirected graphs, there are relatively few corresponding measures for directed graphs. To fill this gap in the literature, we explore a number of alternative techniques that are applicable to directed graphs. We commence by using Chung's generalisation of the Laplacian of a directed graph to extend the computation of von Neumann entropy from undirected to directed graphs. We provide a simplified form of the entropy which can be expressed in terms of simple vertex in-degree and out-degree statistics. Moreover, we find approximate forms of the von Neumann entropy that apply to both weakly and strongly directed graphs, and that can be used to characterize network structure. Next we explore how to extend Estrada's heterogeneity index from undirected to directed graphs. Our measure is motivated by the simplified von Neumann entropy, and involves measuring the heterogeneity of differences in in-degrees and out-degrees. Finally, we perform an analysis which reveals a novel linear relationship between heterogeneity and resistance distance (commute time) statistics for undirected graphs. This means that the larger the difference between the average commute time and shortest return path length between pairs of vertices, the greater the heterogeneity index. Based on this observation together with the definition of commute time on a directed graph, we define an analogous heterogeneity measure for directed graphs. We illustrate the usefulness of the measures defined in this paper for datasets describing Erdos-Renyi, 'small-world', 'scale-free' graphs, Protein-Protein Interaction (PPI) networks and evolving networks.","A Lagrangian Relaxation Based Forward-Backward Improvement Heuristic for Maximising the Net Present Value of Resource-Constrained Projects ","Salient Object Detection via Fast Iterative Truncated Nuclear Norm Recovery ","Selecting an adaptive sequence for computing recursive M-estimators in multivariate linear regression modelsIn this paper, the authors consider an adaptive recursive algorithm by selecting an adaptive sequence for computing M-estimators in multivariate linear regression models. Its asymptotic property is investigated. The recursive algorithm given by Miao and Wu (1996) is modified accordingly. Simulation studies of the algorithm is also provided. In addition, the Newton-Raphson iterative algorithm is considered for the purpose of comparison.","Mood Dependent Music GeneratorMusic is one of the most expressive media to show and manipulate emotions, but there have been few studies on how to generate music connected to emotions.#R##N##R##N#Such studies have always been shunned upon by musicians affirming that a machine cannot create expressive music, as it's the composer's and player's experiences and emotions that get poured into the piece. At the same time another problem is that music is highly complicated (and subjective) and finding out which elements transmit certain emotions is not an easy task.#R##N##R##N#This demo wants to show how the manipulation of a set of features can actually change the mood the music transmits, hopefully awakening an interest in this area of research.","Knowledge Transfer Strategies for Vector Evaluated Particle Swarm Optimization ","Intersection cuts for mixed integer conic quadratic setsBalas introduced intersection cuts for mixed integer linear sets. Intersection cuts are given by closed form formulas and form an important class of cuts for solving mixed integer linear programs. In this paper we introduce an extension of intersection cuts to mixed integer conic quadratic sets. We identify the formula for the conic quadratic intersection cut by formulating a system of polynomial equations with additional variables that are satisfied by points on a certain piece of the boundary defined by the intersection cut. Using a software package from algebraic geometry we then eliminate variables from the system and get a formula for the intersection cut in dimension three. This formula is finally generalized and proved for any dimension. The intersection cut we present generalizes a conic quadratic cut introduced by Modaresi, Kilinc and Vielma.","Hyperspectral Medical Images Unmixing for Cancer Screening Based on Rotational Independent Component Analysis ","An Implicit and Parallel Chimera Type Domain Decomposition Method ","Improved Polar Scan-Matching Using an Advanced Line Segmentation Algorithm ","Average Delay Estimation in Discrete-Time Systems with Periodically Varying Parameters ","Towards a Methodology for Publishing Library Linked Data ","Symbolic control of stochastic switched systems via finite abstractionsStochastic switched systems are a class of continuous-time dynamical models with probabilistic evolution over a continuous domain and control-dependent discrete dynamics over a finite set of modes. As such, they represent a subclass of general stochastic hybrid systems. While the literature has witnessed recent progress in the dynamical analysis and controller synthesis for the stability of stochastic switched systems, more complex and challenging objectives related to the verification of and the synthesis for logic specifications (properties expressed as formulas in linear temporal logic or as automata on infinite strings) have not been formally investigated as of yet. This paper addresses these complex objectives by constructively deriving approximately equivalent (bisimilar) symbolic models of stochastic switched systems. More precisely, a finite symbolic model that is approximately bisimilar to a stochastic switched system is constructed under some dynamical stability assumptions on the concrete model. This allows to formally synthesize controllers (switching signals) over the finite symbolic model that are valid for the concrete system, by means of mature techniques in the literature.","Hybrid Tabu Search for Fuzzy Job ShopWe consider the fuzzy job shop scheduling problem, which is a variant of the well-known job shop problem, with uncertainty in task durations that we model using fuzzy numbers. We propose a tabu search algorithm for minimising the expected makespan based on reversing arcs within critical blocks. We test the algorithm and then combine it with a genetic algorithm from the literature so we can observe the synergy effect, obtaining better results with the hybrid algorithm than with its components by separate. Finally we compare our hybrid algorithm with a memetic algorithm from the literature and show that even in similar times, our method is better in terms of expected makespan.","Nested Hierarchical Dirichlet Process for Nonparametric Entity-Topic AnalysisThe Hierarchical Dirichlet Process HDP is a Bayesian nonparametric prior for grouped data, such as collections of documents, where each group is a mixture of a set of shared mixture densities, or topics, where the number of topics is not fixed, but grows with data size. The Nested Dirichlet Process NDP builds on the HDP to cluster the documents, but allowing them to choose only from a set of specific topic mixtures. In many applications, such a set of topic mixtures may be identified with the set of entities for the collection. However, in many applications, multiple entities are associated with documents, and often the set of entities may also not be known completely in advance. In this paper, we address this problem using a nested HDP nHDP, where the base distribution of an outer HDP is itself an HDP. The inner HDP creates a countably infinite set of topic mixtures and associates them with entities, while the outer HDP associates documents with these entities or topic mixtures. Making use of a nested Chinese Restaurant Franchise nCRF representation for the nested HDP, we propose a collapsed Gibbs sampling based inference algorithm for the model. Because of couplings between two HDP levels, scaling up is naturally a challenge for the inference algorithm. We propose an inference algorithm by extending the direct sampling scheme of the HDP to two levels. In our experiments on two real world research corpora, we show that, even when large fractions of author entities are hidden, the nHDP is able to generalize significantly better than existing models. More importantly, we are able to detect missing authors at a reasonable level of accuracy.","Key-Frame Selection Strategy Based on Edge Points Classification in 2D-to-3D Conversion ","Identifying Gene Knockout Strategy Using Bees Hill Flux Balance Analysis (BHFBA) for Improving the Production of Succinic Acid and Glycerol in Saccharomyces cerevisiaeStrains of Saccharomyces cerevisiae can be manipulated to improve product yield and growth characteristics. Optimization algorithms are developed to identify the effects of gene knockout on the results. However, this process is often faced the problem of being trapped in local minima and slow convergence due to repetitive iterations of algorithm. In this paper, we proposed Bees Hill Flux Balance Analysis (BHFBA) which is a hybrid of Bees Algorithm, Hill Climbing Algorithm and Flux Balance Analysis to solve the problems and improve the performance in predicting optimal sets of gene deletion for maximizing the growth rate and production yield of desired metabolite. Saccharomyces cerevisiae is the model organism in this paper. The list of knockout genes, growth rate and production yield after the deletion are the results from the experiments. BHFBA performed better in term of computational time, stability and production yield.","Design-Opportunities and Limitations on Additive Manufacturing Determined by a Suitable Test-SpecimenThe key-feature all additive manufacturing processes have in com- mon is parts being built up in layers. Due to this tool-less build-up principle, the degree of freedom in design is huge compared to conventional manufacturing processes. For instance rear sections, inner cavities, conformal cooling-channels and lightweight-structures can be realized without a significant rise of manufac- turing-costs. However there are some specific limitations coming along with the layer-wise build-up. Depending on layer-thickness and the orientation of a sur- face, the so-called stair-step effect occurs with different levels of intensity. Fur- thermore some additive manufacturing processes have to use support-structures. These structures are used to hold the part in place or to lead the pro-cess heat away from the melting-zone. In order to convey these limitations and to show how de-tailed and filigree parts can be generated, a test-specimen has been designed that suits processes with- and without support-structures. The geometry of the specimens bottom side contains chamfers and notches, so the amount of necessary supports is kept as low as possible and the specimen can be separated from its build-platform without complications. Furthermore, the specimen is designed as a web of test-areas, connected by bars. This way the curling effect that often leads to aborts in additive manufacturing processes is prevented and thus cannot have an influence on the geometries tested on the speci-men. The presentation is about showing first test results of Laser Beam Melted, Laser Sintered and Fused Layer Modeled specimens that have been evaluated by sight test and measured by a coordinate measuring machine. In addition the content of the individual test-areas will be ex-plained.","Binary Tree based Chinese Word SegmentationChinese word segmentation is a fundamental task for Chinese language processing. The granularity mismatch problem is the main cause of the errors. This paper showed that the binary tree representation can store outputs with different granularity. A binary tree based framework is also designed to overcome the granularity mismatch problem. There are two steps in this framework, namely tree building and tree pruning. The tree pruning step is specially designed to focus on the granularity problem. Previous work for Chinese word segmentation such as the sequence tagging can be easily employed in this framework. This framework can also provide quantitative error analysis methods. The experiments showed that after using a more sophisticated tree pruning function for a state-of-the-art conditional random field based baseline, the error reduction can be up to 20%.","Formal Modelling, Analysis and Verification of Hybrid SystemsHybrid systems is a mathematical model of embedded systems, and has been widely used in the design of complex embedded systems. In this chapter, we will introduce our systematic approach to formal modelling, analysis and verification of hybrid systems. In our framework, a hybrid system is modelled using Hybird CSP HCSP, and specified and reasoned about by Hybrid Hoare Logic HHL, which is an extension of Hoare logic to hybrid systems. For deductive verification of hybrid systems, a complete approach to generating polynomial invariants for polynomial hybrid systems is proposed; meanwhile, a theorem prover for HHL that can provide tool support for the verification has been implemented. We give some case studies from real world, for instance, Chinese High-Speed Train Control System at Level 3 CTCS-3. In addition, based on our invariant generation approach, we consider how to synthesize a switching logic for a considered hybrid system by reduction to constraint solving, to meet a given safety, liveness, optimality requirement, or any of their combinations. We also discuss other issues of hybrid systems, e.g., stability analysis.","Dependency Analysis for Critical Infrastructure Security Modelling: A Case Study within the Grid\u20195000 Project ","A balance storage nodes assignment for wireless sensor networksA balance storage nodes assignment problem is proposed for wireless sensor networks in order to save history data as much as possible when the network cannot connect to the sink node(s). Its aim is to assign storage nodes as evenly as possible to each source node, while it can minimize the storage path cost of the whole network. This problem can be reduced into a classic assignment problem by adding \"dummy\" source nodes, which is not easy to solve through the existing centric algorithms in sensor networks. Then two algorithms (Random Greedy Algorithm and Voronoi Graph Based Algorithm) are proposed in order to solve this problem. These two algorithms can be implemented distributed for the wireless sensor networks. The simulation implements and compares the performance of these two algorithms. The result shows that the Voronoi Graph Based Algorithm can satisfy the load balance storage for all source nodes and achieve approximate minimal storage path cost of the whole network.","Data Mining and Modelling for Wave Power Applications Using Hybrid SOM-NG Algorithm ","Comparison between PSO and AIS on the Basis of Identification of Material Constants in PiezoelectricsThe paper deals with an application of the artificial immune system (AIS) and particle swarm optimizer (PSO) to the identification problem of pie- zoelectric structures analyzed by the boundary element method (BEM). The AIS and PSO is applied to identify material properties of piezoelectrics. The AIS is a computational adaptive system inspired by the principles, processes and mechanisms of biological immune systems. The algorithms typically use the characteristics of the immune systems like learning and memory to simulate and solve a problem in a computational manner. The PSO algorithm is based on the models of the animals social behaviours: moving and living in the groups. PSO algorithm realizes directed motion of the particles in n-dimensional space to search for solution for n-variable optimisation problem.The main advantage of the bioinspired methods (AIS and PSO), contrary to gradient methods of op- timization, is the fact that it does not need any information about the gradient of fitness function.","Random Spatial Structure of Geometric Deformations and Bayesian NonparametricsAsclepios Project, INRIA Sophia Antipolis, Francechristof.seiler@stanford.eduAbstract. Our work is motivated by the geometric study of lower backpain from patient CT images. In this paper, we take a rst step towardsthat goal by introducing a data-driven way of identifying anatomicalregions of interest. We propose a probabilistic model of the geometricalvariability and describe individual patients as noisy deformations of arandom spatial structure (modeled as regions) from a common template.The random regions are generated using the distance dependent ChineseRestaurant Process. We employ the Gibbs sampler to infer regions froma set of noisy deformation elds. Each step of the sampler involves modelselection (Bayes factor) to decide about fusing regions. In the discussion,we highlight connections between image registration and Markov chainMonte Carlo methods.","Exploring Twitter Interactions through Visualization Techniques: Users Impressions and New Possibilities ","Enhancing Random Forests Performance in Microarray Data ClassificationRandom forests are receiving increasing attention for classification of microarray datasets. We evaluate the effects of a feature selection process on the performance of a random forest classifier as well as on the choice of two critical parameters, i.e. the forest size and the number of features chosen at each split in growing trees. Results of our experiments suggest that parameters lower than popular default values can lead to effective and more parsimonious classification models. Growing few trees on small subsets of selected features, while randomly choosing a single variable at each split, results in classification performance that compares well with state-of-art studies. contribution of trees whose nodes are populated by non-informative features. Pre-filtering features is a popular procedure that has proved to be useful to face the curse of dimensionality of gene expression data. When applied before growing a random forest, this process has to face an additional issue: asserting values for the two critical parameters of the random forest, i.e. the number of variables randomly chosen at each split, namely mtry, and the number of the trees in the forest, namely ntree. This paper evaluates the effects of a filtering process on the predictive performance of a random forest classifier as well as on the choice of its critical parameters. Using two popular microarray datasets, we carried out classification experiments by growing random forests both on the whole set of features and on different subsets of pre- filtered features: different parameter settings were explored in order to investigate the optimal trade-off between the number of trees and the number of variables randomly chosen at each split. Our results suggest that growing few trees on small subsets of pre-filtered features, with only one variable randomly chosen at each split, presents results which compare very well with state-of-art studies in literature.","The Blurring Boundaries Of Work-Related And Personal Media Use: A Grounded Theory Study On The Employee's Perspective. ","Chaos Driven Differential Evolution with Lozi Map in the Task of Chemical Reactor Optimization ","Increasing recall of process model matching by improved activity label matchingComparing process models and matching similar activities has recently emerged as a research area of business process management. However, the problem is fundamentally hard when considering realistic scenarios: e.g., there is a huge variety of terms and various options for the grammatical structure of activity labels exist. While prior research has established important conceptual foundations, recall values have been fairly low (around 0.26) --- arguably too low to be useful in practice. In this paper, we present techniques for activity label matching which improve current results (recall of 0.44, without sacrificing precision). Furthermore, we identify categories of matching challenges to guide future research.","Three-modality registration for guidance of minimally invasive cardiac interventionsImage guidance of minimally invasive cardiac interventions can be augmented by registering together different imaging modalities. In this paper, we propose a method to combine three modalities: X-ray fluoroscopy, trans-esophageal ultrasound and pre-procedure MRI or CT. The registration of the pre-procedure image involves a potentially unreliable manual initialisation of its position in an X-ray projection view. The method therefore includes an automatic correction using the esophagus location as an additional constraint. We test the method in a phantom experiment and find that initialising the pre-procedure image with up to 9mm offset from its correct position results in a 92% registration success rate. The esophagus constraint improves the capture range in the out-of-plane direction, which simplifies the manual initialisation.","SVM-SVDD: a new method to solve data description problem with negative examplesSupport Vector Data Description(SVDD) is an important method to solve data description or one-class classification problem. In original data description problem, only positive examples are provided in training. The performance of SVDD can be improved when a few negative examples are available which is known as SVDD_neg. Intuitively, these negative examples should cause an improvement on performance than SVDD. However, the performance of SVDD may become worse when some negative examples are available. In this paper, we propose a new approach \"SVM-SVDD\", in which Support Vector Machine(SVM) helps SVDD to solve data description problem with negative examples efficiently. SVM-SVDD obtains its solution by solving two convex optimization problems in two steps. We show experimentally that our method outperforms SVDD_neg in both training time and accuracy.","Computing Bounds of the MTTF for a Set of Markov ChainsWe present an algorithm to find some upper and lower bounds of the Mean Time To Failure (MTTF) for a set of absorbing Discrete Time Markov Chains (DTMC). We first present a link between the MTTF of an absorbing chain and the steady-state distribution of an ergodic DTMC derived from the absorbing one. The proposed algorithm is based on the polyhedral theory developed by Courtois and Semal and on a new iterative algorithm which gives bounds of the steady-state distribution of the associated ergodic DTMC at each iteration.","Fast and Exact Mining of Probabilistic Data StreamsDiscovering Probabilistic Frequent Itemsets (PFI) is very challenging since algorithms designed for deterministic data are not applicable in probabilistic data. The problem is even more difficult for probabilistic data streams where massive frequent updates need to be taken into account while respecting data stream constraints. In this paper, we propose FEMP (Fast and Exact Mining of Probabilistic data streams), the first solution for exact PFI mining in data streams with sliding windows. FEMP allows updating the frequentness probability of an itemset whenever a transaction is added or removed from the observation window. Using these update operations, we are able to extract PFI in sliding windows with very low response times. Furthermore, our method is exact, meaning that we are able to discover the exact probabilistic frequentness distribution function for any monitored itemset, at any time. We implemented FEMP and conducted an extensive experimental evaluation over synthetic and real-world data sets; the results illustrate its very good performance.","Soft cardinality constraints on XML data: How exceptions prove the business rule ","Related HOG Features for Human Detection Using Cascaded Adaboost and SVM ClassifiersRobust and fast human detection in static image is very important for real applications. Although different feature descriptors have been proposed for human detection, for HOG descriptor, how to select and combine more distinguish block-based HOGs, and how to simultaneously make use of the correlation and the local information of these selected HOGs still lack enough research and analysis. In this paper, we present a set of Related HOG (RHOG) features, including distinctive block-based HOGs (Ele-HOGs) which are selected by Adaboost and a global HOG descriptor which is concatenated by Ele-HOGs (CSele-HOG). Ele-HOG can discriminatively describe local distribution of human object while CSele-HOG contains global information. In addition, we propose a novel human detection framework of Cascaded Adaboost and SVM classifiers (CAS) based on RHOG features, which combines the advantages of Adaboost and SVM classifiers. Experimental results on INRIA dataset demonstrate the effectiveness of the proposed method.","Novel Chromatic Pupillometer: Portable Pupillometry Diagnostic SystemThis research study explores development of a novel chromatic pupillometer that can analyze the characteristics of a patient's pupil light reflex (PLR). Characteristics of the PLR are not only used to determine retinal function but also have been recently used as a non-invasive diagnostic for a variety of neurological disorders and diseased states. This device is a compact diagnostic goggle that contains both stimulating and recording abilities of the PLR. This paper will discuss the design and function of the prototype as well as present preliminary data on evaluation of a subset of cells within the PLR.","TLDRet: A Temporal Semantic Facilitated Linked Data Retrieval FrameworkTemporal features, such as date and time or time of an event, employ concise semantics for any kind of information retrieval, and therefore for linked data information retrieval. However, we have found that most linked data information retrieval techniques pay little attention on the power of temporal feature inclusion. We propose a keyword-based linked data information retrieval framework, called TLDRet, that can incorporate temporal features and give more concise results. Preliminary evaluation of our system shows promising performance.","Multi-Objective Optimization for Overlapping Community DetectionRecently, community detection in complex networks has attracted more and more attentions. However, real networks usually have number of overlapping communities. Many overlapping community detection algorithms have been developed. These methods usually consider the overlapping community detection as a single-objective optimization problem. This paper regards it as a multi-objective optimization problem and proposes a Multi-Objective evolutionary algorithm for Overlapping Community Detection MOOCD. This algorithm simultaneously optimize two objective functions to get proper community partitions. Experiments on artificial and real networks illustrate the effectiveness of MOOCD.","Qualitative Interviews online stellenIn der qualitativen empirischen Sozialforschung werden mit offenen Fragen operierende Interviews als weit verbreitete Erhebungsmethode verwendet. Sie beinhalten personliche Erzahlungen und personenbezogene Daten. Diese werden nicht nur von SozialforscherInnen analysiert, die am ursprunglichen Projekt beteiligt waren. Zunehmend stellt sich die Anforderung, Forschungsdaten auch zur Sekundaranalyse uber das Internet zur Verfugung zu stellen. Dafur muss der Schutz personenbezogener Daten gewahrleistet sein.","Inferring Hidden Trust Relationships in Social Networks for Encouraging Collaboration and Cooperation among IndividualsThis paper presents the T-SWEETS algorithm, a novel approach for inferring trust in social networks and its deployment in a social network knowledge- based management platform, titled Konnen Knowledge Organization in a Native Network ENvironment. An objective of trust inference is to recommend trust relationships. The features of T-SWEETS come from an inquiry with a group of 53 people. We also present results obtained from experiment conducted with a group of 57 people during the second half of 2012.","Development of Fatigue-Associated Measuresment to Determine Fitness for Duty and Monitor Driving Performance ","Learning Associative Spatiotemporal Features with Non-negative Sparse CodingMotion features based on optical ow are very powerful in tasks such as the recognition of human actions or gestures. Usually, they are combined with gradient information to form a set of spatiotemporal features. However, humans can recognize gestures and actions and thus derive the implied motion out of static images alone. We model this associative recognition within a learned hierarchy of non-negative sparse coding layers. In the rst stages, topology preserving gradient and motion features are processed separately. Afterwards, they are projected onto a combined inner representation, that is learned during the training phase. We show, that during recognition the learned, combined representation improves the recognition of human actions, even in the absence of explicit motion information.","Classification of Event Related Potentials of Error-Related Observations Using Support Vector Machines ","City 2.0 and tourism developmentCarefully cities have to evolve in order to help tourist during their travel. The huge use of web 2.0, must force the cities to be more and more implied in this area. The role of referenced website and those of community manager will be greater in the future and contributes to the attractiveness of the territories. Nowadays, the social web is obviously essential strategy in information retrieval or gathering during holidays preparation and will be more and more important to help travellers during the travel.","Shifting concepts to their associative concepts via bridgesThis paper presents a pair of formal concept search procedures to find associative connection of concepts via bridge concepts. A bridge is a generalization of a sub-concept of an initial concept. The initial concept is then shifted to other target concepts which are conditionally similar to the initial one within the extent of bridge. A procedure for mining target concepts under the conditional similarity with respect to the bridge is presented based on an object-feature incident relation. Such a bridge concept is constructed in the concept lattice of person-feature incident relation. The latter incident relation is defined by aggregating the former document-feature relation to have more condensed relation, while keeping the variation of possible candidate bridges. Some heuristic rule, named Mediator Heuristics, is furthermore introduced to reflect user's interests and intention. The pair of these two procedures provides an efficient method for shifting initial concepts to target ones via some bridges. We show their usefulness by applying them to Twitter data.","A Based on Single Image Authentication System in Aviation Security ","Reducing Uncertainty in Navigation and ExplorationA significant problem in designing mobile robot control systems involves coping with the uncertainty that arises in moving about in an unknown or partially unknown environment and relying on noisy or ambiguous sensor data to acquire knowledge about that environment. We describe a control system that chooses what activity to engage in next on the basis of expectations about how the information re- turned as a result of a given activity will improve 2 its knowledge about the spatial layout of its environment. Certain of the higher-level components of the control system are specified in terms of probabilistic decision models whose output is used to mediate the behavior of lower-level control components responsible for movement and sensing.","COSMO - emulation of internet traffic: poster abstractThis paper discusses for generating realistic network traffic for the emulated Internet [5]. For emulating entire of elements of the real Internet on our testbed, we have been trying on constructing emulated inter-AS network. In this paper, we explore the suitable traffic generator which is able to emulate the real Internet traffic in the testbed. However, the existing generators do not equip functions of generating the realistic payloads. This paper therefore designs COSMO, a new traffic generator, to meet with our requirements. The key idea is to replay the real Internet traffic, rather than making it. As an initial study, we focus on improving the realism of the generated traffic. The paper captures packets at our monitoring point, divides the traffic trace file into several chunks, and replays the traffic in the emulated Internet. Based on the experiment, the paper provides our preliminary evaluation and indicates the feasibility aspect from the realism in the emulated technology.","Domain Ontology Enrichment Based on the Semantic Component of LMF-Standardized Dictionaries ","Conflict Coordination Based on the Transformation Bridge for Collaborative Product Performance OptimizationTo quickly coordinate conflicts in product performance design, a transformation bridge method was proposed. Specifically, the design problems of performance conflicts were analyzed in terms of the quantification and collaboration. Based on the analysis, the mathematical models for conflict resolution and correlation function were developed. Thus the relationship between performance and design variables could be identified, and then used for searching similar cases from a repository. In addition, a core solution was developed by identifying the correlation among performance, combining the collaborative resolution method and case-based reasoning. The transformation bridge method was leveraging the extensibility of the basic-elements. Furthermore, the method for obtaining revised solutions was developed based on extension theory in particular the transformation operator and the cyclic transformation based on performance constraints, as the core of the approach to product performance optimization. The viability is evaluated in a case of screw air compressor design.","Deciding Data Object Relevance for Business Process Model AbstractionBusiness process model abstraction received considerable attention lately. So far, business process model abstraction is mainly based on control flow aspects ignoring data objects. Recently, data objects have been included in process model abstraction techniques. Thereby, the question arises which data objects are relevant for a specific abstraction level of a process model. To date, data object relevance is decided by control flow. But for data object abstraction independently from control flow aspects, the relevance question remains open. In this paper, we answer this question by introducing a set of data object relevance criteria focusing on data objects. These have been derived from use cases and have been evaluated with a first user study. Further, we show means to combine the presented criteria.","Research on electromagnetic coupling artificial neural network with spatial topologyIn this paper, an emerging artificial neural network (ECANN) is proposed. Abstracting from a latest research in neuroscience, electromagnetic coupling among neuron activities is introduced into the model. Besides, the overall network can be viewed as a system with physical significance of circuitry, and each neuron is presented as differential equation. At the mean time, the spatial grid topology is employed in order to develop its parallelism. This artificial neural network is designed for fitting and predicting dynamic data, and has successfully worked in simulation part of this paper.","The Soil Heavy Metal Information Accurate Collection and Evaluation about Lycium Barbarum Cultivation in Western China ","Modified Moment Method Estimator for the Shape Parameter of Generalized Gaussian Distribution for a Small Sample Size ","Modeling the dynamics of dengue feverDengue is a major international public health concern that impacts one-third of the world's population. There are four serotypes of the dengue virus (DENV). Infection with one serotype affords life-long immunity to that serotype but only temporary cross immunity (CI) to other serotypes. The risk of lethal complications is elevated upon re-infection, possibly because of the effect of antibody-dependent enhancement (ADE). In this paper we propose a system dynamics model that captures both host and vector populations, latency, and four dengue serotypes. This model allows one to study both CI and ADE. Modeling the Aedes vector adds complexity, but we consider this to be important because combating the mosquito vector may be the most practical intervention in the absence of an effective vaccine. Our results support the need to model the vector population and ADE to explain the observed epidemiological data.","Efficient Domain Decomposition of Dissipative Particle Dynamics via Choice of Pseudorandom Number GeneratorDomain decomposition of dissipative particle dynamics is complicated by the use of random pairwise forces as a component of a momentum-conserving thermostat. The conventional use of a pseudorandom number generator for each processor core leads to the need for an additional communication step to correctly assign random forces to particles in boundary halos. To circumvent this communication, the use of a three-seed pseudorandom number generator is proposed to allow multiple processor cores to evaluate the same forces. This kind of pseudorandom number generator will be applied to the general-purpose mesoscale modelling package DL_MESO to improve its parallel scalability for large processor core counts.","Partial Approximation of Multisets and Its Applications in Membrane ComputingPartial nature of real---life problems requires working out partial approximation schemes. Partial approximation of sets is based on classical set theory. Its generalization for multisets gives a plausible opportunity to introduce an abstract concept of \"to be close enough to a membrane\" in membrane computing. The paper presents important features of general maybe partial multiset approximation spaces, their lattice theory properties, and shows how partial multiset approximation spaces can be applied to membrane computing.","Web-Based Solution for Acquisition, Processing, Archiving and Diffusion of Endoscopy StudiesERDF - European Regional Development Fund#R##N#through the COMPETE Programme (operational programme for competitiveness) and by National#R##N#Funds through the FCT - Fundacao para a Ciencia e a Tecnologia (Portuguese Foundation#R##N#for Science and Technology) within project FCOMP-01-0202-FEDER-013853.","On monadic parametricity of second-order functionalsHow can one rigorously specify that a given ML functional $f : (\\texttt{int} \\to \\texttt{int}) \\to \\texttt{int}$ is pure, i.e., f produces no computational effects except those produced by evaluation of its functional argument? In this paper, we introduce a semantic notion of monadic parametricity for second-order functionals which is a form of purity. We show that every monadically parametric f admits a question-answer strategy tree representation. We discuss possible applications of this notion, e.g., to the verification of generic fixpoint algorithms. The results are presented in two settings: a total set-theoretic setting and a partial domain-theoretic one. All proofs are formalized by means of the proof assistant Coq.","Optimal interdiction of attack plansWe present a Stackelberg game model of security in which the defender chooses a mitigation strategy that interdicts potential attack actions, and the attacker responds by computing an optimal attack plan that circumvents the deployed mitigations. First, we offer a general formulation for deterministic plan interdiction as a mixed-integer program, and use constraint generation to compute optimal solutions, leveraging state-of-the-art partial satisfaction planning techniques. We also present a greedy heuristic for this problem, and compare its performance with the optimal MILP-based approach. We then extend our framework to incorporate uncertainty about attacker's capabilities, costs, goals, and action execution uncertainty, and show that these extensions retain the basic structure of the deterministic plan interdiction problem. Introduction of more general models of planning uncertainty require us to model the attacker's problem as a general MDP, and demonstrate that the MDP interdiction problem can still be solved using the basic constraint generation framework.","Improving Hash Table Hit Ratio of an ILP-Based Concept Discovery System with Memoization Capabilities ","The Piggy Bank Cryptographic TropeThis paper presents applications of the trope of the locked and sealed piggy-bank into which the secret can be easily inserted but from which it cannot be withdrawn without opening the box. We present a basic two-pass cryptographic scheme that can serve as template for a variety of implementations. Together with the sealed piggy-bank is sent a coded letter that lists and certifies the contents of the box. We show how this idea can help increase the security of cryptographic protocols for classical systems as well as those based on \"single-state\" systems. More specifically, we propose the use of a hashing digest (instead of the coded letter) to detect loss of key bits to the eavesdropper and use in communication systems where error correction is an important issue.","Service-Oriented Architecture (SOA) and Semantic Web Services for Web Portal Integration ","Checking Out: Download and Digital Library Exchange for Complex ObjectsDigital resources are becoming increasingly complex and are being used in diverse ways. For example, educational resources may be cataloged in digital libraries, used offline by educators and students, or used in a learning management system. In this paper we present the no- tion of \"checking out\" complex resources from a digital library for offline download or exchange with another digital library or learning manage- ment system. We present a mechanism that enables the customization, download and exchange of complex resources. We show how the mecha- nism also supports digital library and learning management system ex- change formats in a generic fashion with minimal overhead. We also show how checkouts grow linearly with respect to the complexity of the resources.","Training Log-Linear Acoustic Models in Higher-Order Polynomial Feature Space for Speech Recognition14th Annual Conference of the International Speech Communication Association, 25 augustus 2013","Resistance to bribery when aggregating soft constraintsWe investigate a multi-agent scenario where agents express their preferences over a large set of decisions via soft constraints. We consider sequential procedures (based on Plurality, Approval, and Borda) to aggregate agents' preferences and we study their resistance to bribery attempts to influence the result of the aggregation.","Development of an Unconventional Unmanned Coaxial Rotorcraft: GremLionIn this paper, we present an unmanned system design methodology for a fully functional unmanned rotorcraft system: GremLion, developed with all necessary avionics and a ground control station. It has been employed to par- ticipate in the 2012 UAVForge competition. The proposed design methodology consists of hardware construction, software development, dynamic modeling and flight control, as well as mission algorithms. The test results have been presented in this paper to verify the proposed design methodology.","A bacterial colony chemotaxis algorithm with self-adaptive mechanismAlthough communication mechanism between individuals was adopted in the existing bacterial colony chemotaxis algorithm, there still are some defects such as premature, lacking diversity and falling into local optima etc. In this paper, from a new angle of view, we intensively investigate self-adaptive searching behaviors of bacteria, and design a new optimization algorithm which is called as self-adaptive bacterial colony chemotaxis algorithm (SBCC). In this algorithm, in order to improve the adaptability and searching ability of artificial bacteria, a self-adaptive mechanism is designed. As a result, bacteria can automatically select different behavior modes in different searching periods so that to keep fit with complex environments. In the experiments, the SBCC is tested by 4 multimodal functions, and the results are compared with PSO and BCC algorithm. The test results show that the algorithm can get better results with high speed.","Outsourcing location selection with SODA: a requirements based decision support methodology and toolThis paper seeks to address the decision making problem in software development outsourcing scenarios in which a project manager is in charge of deciding about which software components will be outsourced and which ones will be developed internally. Therefore we propose a methodology and tool support which leverage the classification of a project's software components by means of a graph-based model of the components' requirements and their corresponding clustering. In the course of our design oriented research approach, a prototypical implementation of the methodology has been developed and evaluated. It illustrates the practical applicability of the proposed method. We thereby contribute to the location selection problem in distributed software projects and give guidance for in-house or external software production. The theoretical contribution consists of revealing an improved processing methodology for assessing software requirements and increasing the outsourcing success of a software project. Our contribution for practice is an implemented prototype for project leads of distributed teams.","An overview of the parallax BattleMind v1.5 for computer network defenceBattleMind (BM) version 1.5 is the first of a series of Artificial Intelligence systems for semi-automatically understanding, planning and conducting Computer Network Defence. It makes use of a wide range of existing techniques including classification and feature extraction, semantic web technologies, data fusion, ontologies, first order predicate logic based forward and backward chained reasoning, hierarchical task network planning and supervised learning. Novel contributions of our work compared to other AI based CND tools are: (1) explicitly modelling people and organisations as well as computers and networks as part of the overall system, and elements of the business processes that link them; and (2) using a broad range of high level data sources rather than just traditional low level data sources such as packet capture.","An Investigation of Multimodal Metaphors in E-Book Assessment Interfaces ","GASPI \u2013 A Partitioned Global Address Space Programming Interface ","Solving the Discrete Logarithm Problem for Packing Candidate Preferences ","Estimation of Operator Input and Output Workload in Complex Human-Machine-Systems for Usability Issues with iFlowUsability studies often use methods focused on product parameters. Test designs are processed in laboratories and evaluation is commonly performed by expert opinions. For validation studies we want to point out the importance of field studies and user and system oriented evaluation. For this purpose we want to present the methodological approach iFlow (information flow) as multiple assessment technique for usability issues in real or quasi-real (simulated) situations. The idea of iFlow is to assess input and output workload via video and audio recordings combined with subjective and objective measurement techniques of workload. In this contribution the iFlow method and an evaluative study in anesthesiology are presented. The added value to already existing methods and approaches is considered in the sensitivity of iFlow to identify situations of overload in a descriptive way. For design interventions it would be helpful to consult the iFlow chart to deduct cause and effect relations.","Usage of Multiple Process Assessment Models ","The link between inclusive design and innovation: some key elementsIt is often said that universal design and similar approaches can be a source of innovation. In this paper key elements in inclusive design are identified, and examples of innovations related to inclusive design are presented. Then, some core elements of the inclusive design process that will help spur innovation are identified. Based on this the link between inclusive design and innovation is discussed. Finally, some recommendations for an inclusive and innovative design process are presented.","The Business Impact Of Social Media Analytics ","Overview of the TREC 2013 Contextual Suggestion TrackAbstract : For participants familiar with the 2012 Contextual Suggestion Track we have provided a list of the main changes to this year's track: Contexts no longer include a temporal component (day of week, time of day, and season), contexts consist of only a location. Users were recruited from a crowdsourcing service (Mechanical Turk) as well as from the University of Waterloo student body. Suggestion attractiveness judgements are given on a 5-point, rather than a 3-point, scale. Submissions based off of the ClueWeb12 corpus were allowed in addition to submissions based off of the open web. A modified Time-Biased Gain (TBG) metric was used in addition to P@5 and MRR. This metric is described in section 4.3. The option to submit solely based on context or solely based or user profiles was removed. The file format used for profiles, contexts, and suggestions was switched from XML to CSV and JSON.","The Error Prevention Mechanisms of Pointing: Eye Focusing and/or Memory Enhancing? ","Inf-structuring Functions and Self-dual Marked Flattenings in bi-Heyting AlgebraThis paper introduces a generalization of self-dual marked flattenings defined in the lattice of mappings. This definition provides a way to associate a self-dual operator to every mapping that decomposes an element into sub-elements (i.e. gives a cover). Contrary to classical flattenings whose definition relies on the complemented structure of the powerset lattices, our approach uses the pseudo relative complement and supplement of the bi-Heyting algebra and a new notion of \\textit{inf-structuring functions} that provides a very general way to structure the space. We show that using an inf-structuring function based on connections allows to recover the original definition of marked flattenings and we provide, as an example, a simple inf-structuring function whose derived self-dual operator better preserves contrasts and does not introduce new pixel values.","Efficient online analysis of accidental fault localization for dynamic systems using hidden Markov modelThis paper proposes a novel approach to do online analysis of accidental fault localization for dynamic systems by using Hidden Markov Model (HMM). By introducing reasonable and appropriate abstraction of complex system, HMM is used to represent the fault and no-fault states of system's components and system's behaviour. The HMM is parametrized to be statistically equivalent to real system's behaviour. Inspired by the principles of Fault Tree Analysis and maximum entropy in Bayesian probability theory, we propose the algorithms to estimate HMM's parameters, instead of learning, because in real systems the learning data for accidental fault is difficult to obtain. We design a specific test bed to generate large quantity of test cases, and give out the experimental results to assess the accuracy and efficiency. Meanwhile, we apply the approach to a simple helicopter control system case study, and give out convincing results.","Investigation on Evolutionary Control and Optimization of Chemical Reactor ","Detection of Error-Prone Cases for Word Sense Disambiguation ","Efficient Variational Inference for Gaussian Process Regression Networks ","Efficient mining of contrast patterns on large scale imbalanced real-life data ","Erratum: Effect of Transliteration on ReadabilityUnfortunately, a wrong country is displayed in the authors' affiliations. Instead of \"Iran\" it should read \"India\".","Extenic Image Classifier and Its Application in the Land Use ClassificationThe theory of Extenic was put forward by the Chinese scientist, Prof. Cai wen, in 1983. As a new kind of artificial intelligence method, it has been used in the many areas, this paper use it to extract the land use information from the remote sensing image. The research area in this paper is the plan area of city of the Du Jiang Yan, which locates in the northwest of the Sichuan basin and the data used here is the HJ satellite image. It has four kinds of land use type in the ground, the forest land, the water body, the built-up land and the farm land, different land use type in the ground has different color in the false color image, and the 11 subtypes are divided according to the relationship analysis of the land use type and the pixel color of the image. The 11 standard matter-element models, which corresponding to 11 subtypes of the land use, are built at first, then calculate the extension correlation degrees of each pixel in the image to the 11 standard matter-element models and finally, and finally the pixel is deter- mined to belong the land use type which has the biggest extension correlation degree. The right rate of the classification is about 87.2% and the Kappa index is 0.86, it shows that the classifier based on the theory of the Extenic has the high precision in the classification of the remote sensing images.","Representing Motion Patterns with the Qualitative Rectilinear Projection CalculusThe Qualitative Rectilinear Projection Calculus (QRPC) is a novel re- presentation model for describing qualitatively motion patterns of two objects through the possible relationships among the rectilinear projection of their trajec- tories. The paper introduces the key issues of the model (i) the set of geometric relations defined in terms of the front-back and left-right dichotomies, (ii) how it can be possible enumerate an exhaustive set of qualitative states by the composi- tion of these relations and (iii) the possible transitions among states based on the notion of conceptual neighborhood. The representational ability of the model is illustrated by an example extracted from the traffic engineering field where the relative motion of two objects is analyzed and described in terms of the QRPC- states.","Hyperbolic harmonic brain surface registration with curvature-based landmark matchingBrain Cortical surface registration is required for inter-subject studies of functional and anatomical data. Harmonic mapping has been applied for brain mapping, due to its existence, uniqueness, regularity and numerical stability. In order to improve the registration accuracy, sculcal landmarks are usually used as constraints for brain registration. Unfortunately, constrained harmonic mappings may not be diffeomorphic and produces invalid registration. This work conquer this problem by changing the Riemannian metric on the target cortical surface to a hyperbolic metric, so that the harmonic mapping is guaranteed to be a diffeomorphism while the landmark constraints are enforced as boundary matching condition. The computational algorithms are based on the Ricci flow method and hyperbolic heat diffusion. Experimental results demonstrate that, by changing the Riemannian metric, the registrations are always diffeomorphic, with higher qualities in terms of landmark alignment, curvature matching, area distortion and overlapping of region of interests.","Multi-prototype label ranking with novel pairwise-to-total-rank aggregationWe propose a multi-prototype-based algorithm for online learning of soft pairwise-preferences over labels. The algorithm learns soft label preferences via minimization of the proposed soft rank-loss measure, and can learn from total orders as well as from various types of partial orders. The soft pairwise preference algorithm outputs are further aggregated to produce a total label ranking prediction using a novel aggregation algorithm that outperforms existing aggregation solutions. Experiments on synthetic and real-world data demonstrate state-of-the-art performance of the proposed model.","Fault-Impact models based on delay and packet loss for IEEE 802.11gIn this paper we derive fault-impact models for wireless network traffic as it could be used in the control traffic for smart grid nodes. We set up experiments using a testbed with 116 nodes which uses the protocol IEEE 802.11g. We develop models for packet loss, the length of consecutive packet loss or non-loss as well as for packet transmission time. The latter is a known challenge and we propose a sampling technique that benefits from the wireless as well as wired connections between the nodes in the testbed. The data obtained shows similarity with previous measurements. However, we progress the state of the art in two ways: we show measurements of packet transmission times and fit models to those and we provide some more detailed insight in the data. We find that with increasing link quality, the distributions of lossy and loss-free periods show major fluctuation. It is shown that in those cases, phase-type distributions can approximate the data better than traditional Gilbert models. In addition, the medium access time is also found to be approximated well with a PH distribution.","Image Segmentation Using Iterated Graph Cuts with Residual GraphIn this paper, we present a new image segmentation method using iterated graph cuts. In the standard graph cuts method, the data term is computed on the basis of the brightness/color distribution of object and background. In this case, some background regions with the brightness/color similar to the object may be incorrectly labeled as an object. We try to overcome this drawback by introducing a new data term that reduces the importance of brightness/color distribution. This reduction is realised by a new part that uses data from a residual graph that remains after performing the max-flow algorithm. According to the residual weights, we change the weights of t-links in the graph and find a new cut on this graph. This operation makes our method iterative. The results and comparison with other graph cuts methods are presented.","Latent topic analysis for predicting group purchasing behavior on the social webGroup-deal websites, where customers purchase products or services in groups, are an interesting phenomenon on the Web. Each purchase is kicked off by a group initiator, and other customers can join in. Customers form communities with people with similar interests and preferences (as in a social network), and this drives bulk purchasing (similar to online stores, but in larger quantities per order, thus customers get a better deal). In this work, we aim to better understand what factors influence customers' purchasing behavior for such social group-deal websites. We propose two probabilistic graphical models, i.e., a product-centric inference model (PCIM) and a group-initiator-centric inference model (GICIM), based on Latent Dirichlet Allocation (LDA). Instead of merely using customers' own purchase history to predict purchasing decisions, these two models include other social factors. Using a lift curve analysis, we show that by including social factors in the inference models, PCIM achieves 35% of the target customers within 5% of the total number of customers while GICIM is able to reach 85% of the target customers. Both PCIM and GICIM outperform random guessing and models that do not take social factors into account.","The Roles of Environmental Noises and Opinion Leaders in EmergencyThis paper proposes a dominant-submissive agent model on bounded confidence opinion dynamics under an emergency environment. In the proposed model, environmental noises and opinion leaders are involved in the collective opinion formation. A series of computer simulations demonstrate that environmental noises have a great impact on the collective opinion evolution. The interactions among individuals are strengthened as the variances of the environmental noises increase, and then a global group behavior emerge with a higher probability. On the other hand, the influence of opinion leaders on the collective opinion dynamics is limited. Firstly, when the fraction of opinion leaders is fixed in the social network, the number of agents following the opinion leaders decreases as the variance of the environmental noise exceeds a certain threshold. Secondly, the number of agents following the opinion leaders does not change obviously as the fraction of opinion leaders increases under a constant noisy environment.","UMAP: A Universal Layer for Schema Mapping LanguagesSchema mappings are fundamental notions in data exchange and integration for relating source and target schemas. Visual mapping languages provide graphical means to visually describe such transforma- tions. There is a plethora of tools and languages available however all use different notions and visualizations and are hardly extensible. In this paper we propose a new universal layer Umap for schema map- ping languages which provides a unified abstraction and middleware for high-level visual mapping languages. We use only standardized Uml and Ocl artifacts which allow for easy code generation in a number of target languages (e.g. C++ code) and for a modular extension mechanism to support complex schema mappings. We illustrate our layer by translat- ing key elements of Clip, a recent expressive visual mapping language, and show that Umap has enough expressive power to encode all Clip features. Moreover, we outline a strategy for automating the translation of any visual input language with a formal meta-model to Umap.","A Double Stage Random Access Scheme for Decentralized Single Radio Cognitive Networks ","A web-based interface for a system that designs sensor networksWe describe the approach taken in the design of the interface for a system that helps application engineers who are not trained in computer science/engineering to design sensor networks. We cite various taxonomies from the senor network literature that guided the design of the interface. We then describe the overall structure of the system to set the context for how the human interacts with it. We present some examples of the kind of data required to design a sensor network and describe how our interface collects that information. We note at many points in the presentation that a deep understanding of the data of the application allows for the design of an appropriate interface.","On the circular security of bit-encryptionMotivated by recent developments in fully homomorphic encryption, we consider the folklore conjecture that every semantically-secure bit-encryption scheme is circular secure, or in other words, that every bit-encryption scheme remains secure even when the adversary is given encryptions of the individual bits of the private-key. We show the following obstacles to proving this conjecture:#R##N##R##N#1 We construct a public-key bit-encryption scheme that is plausibly semantically secure, but is not circular secure. The circular security attack manages to fully recover the private-key.#R##N##R##N#The construction is based on an extension of the Symmetric External Diffie-Hellman assumption (SXDH) from bilinear groups, to l-multilinear groups of order p where l\u2265c \u00b7logp for some c&gt;1.#R##N##R##N#While there do exist l-multilinear groups (unconditionally), for l\u22653 there are no known candidates for which the SXDH problem is believed to be hard. Nevertheless, there is also no evidence that such groups do not exist. Our result shows that in order to prove the folklore conjecture, one must rule out the possibility that there exist l-multilinear groups for which SXDH is hard.#R##N##R##N#2 We show that the folklore conjecture cannot be proved using a black-box reduction. That is, there is no reduction of circular security of a bit-encryption scheme to semantic security of that very same scheme that uses both the encryption scheme and the adversary as black-boxes.#R##N##R##N#Both of our negative results extend also to the (seemingly) weaker conjecture that every CCA secure bit-encryption scheme is circular secure.#R##N##R##N#As a final contribution, we show an equivalence between three seemingly distinct notions of circular security for public-key bit-encryption schemes. In particular, we give a general search to decision reduction that shows that an adversary that distinguishes between encryptions of the bits of the private-key and encryptions of zeros can be used to actually recover the private-key.","On the utility of trading criteria based retraining in forex marketsThis research investigates the ability of genetic programming (GP) to build profitable trading strategies for the Foreign Exchange Market (FX) of three major currency pairs (EURUSD, USDCHF and EURCHF) using one hour prices from 2008 to 2011. We recognize that such environments are likely to be non-stationary. Thus, we do not require a single training partition to capture all likely future behaviours. We address this by detecting poor trading behaviours and use this to trigger retraining. In addition the task of evolving good technical indicators (TI) and the rules for deploying trading actions is explicitly separated. Thus, separate GP populations are used to coevolve TI and trading behaviours under a mutualistic symbiotic association. The results of 100 simulations demonstrate that an adaptive retraining algorithm significantly outperforms a single-strategy approach (population evolved once) and generates profitable solutions with a high probability.","Bi-modal Non-rigid Registration of Brain MRI Data Based on Deconvolution of Joint StatisticsImages of different contrasts in MRI can contain complementary information and can highlight different tissue types. Such datasets often need to be co-registered for any further processing. A novel and effective non-rigid registration method based on the restoration of the joint statistics of pairs of such images is proposed. The registration is performed with the deconvolution of the joint statistics and then with the enforcement of the deconvolved statistics back to the spatial domain to form a preliminary registration. The spatial transformation is also regularized with Gaussian spatial smoothing. The registration method has been compared to B-Splines and validated with a simulated Shepp-Logan phantom, with the BrainWeb phantom, and with real datasets. Improved results have been obtained for both accuracy as well as efficiency.","A review of security attacks on the GSM standardThe Global Systems for Mobile communications (GSM) is the most widespread mobile communication technology existing nowadays. Despite being a mature technology, its introduction dates back to the late eighties, it suffers from several security vulnerabilities, which have been targeted by many attacks aimed to break the underlying communication protocol. Most of these attacks focuses on the A5/1 algorithm used to protect over-the-air communication between the two parties of a phone call. This algorithm has been superseded by new and more secure algorithms. However, it is still in use in the GSM networks as a fallback option, thus still putting at risk the security of the GSM based conversations. The objective of this work is to review some of the most relevant results in this field and discuss their practical feasibility. To this end, we consider not only the contributions coming from the canonical scientific literature but also those that have been proposed in a more informal context, such as during hacker conferences.","Thermal 3D Mapping of Building Fa\u00e7ades ","Using machine learning to improve stochastic optimizationIn many stochastic optimization algorithms there is a hyperparameter that controls how the next sampling distribution is determined from the current data set of samples of the objective function. This hyperparameter controls the exploration /exploitation trade-off of the next sample. Typically heuristic \"rules of thumb\" are used to set that hyperparameter, e.g., a pre-fixed annealing schedule. We show how machine learning provides more principled alternatives to (adaptively) set that hyperparameter, and demonstrate that these alternatives can substantially improve optimization performance.","Efficient Mining of Combined Subspace and Subgraph Clusters in Graphs with Feature Vectors ","Reconstructing Gene Regulatory Network Using Heterogeneous Biological DataGene regulatory network is a model of a network that describes the relationships among genes in a given condition. However, constructing gene regulatory network is a complicated task as high-throughput technologies generate large-scale of data compared to number of sample. In addition, the data involves a substantial amount of noise and false positive results that hinder the downstream analysis performance. To address these problems Bayesian network model has attracted the most attention. However, the key challenge in using Bayesian network to model GRN is related to its learning structure. Bayesian network structure learning is NP-hard and computationally complex. Therefore, this research aims to address the issue related to Bayesian network structure learning by proposing a low-order conditional independence method. In addition we revised the gene regulatory relationships by integrating biological heterogeneous dataset to extract transcription factors for regulator and target genes. The empirical results indicate that proposed method works better with biological knowledge processing with a precision of 83.3% in comparison to a network that rely on microarray only, which achieved correctness of 80.85%.","An Unsupervised Content-Based Image Recognition Technique ","Personalized Semantic Search Using ODP: A Study Case in Academic DomainPersonalized search utilizes the user context in a form of profile to in- crease the information retrieval accuracy with user's interests. Recently, semantic search has greatly attracted researchers' attention over the traditional keyword- based search because of having capabilities to figure out the meaning of search query, understanding users' information needs accurately using semantic web technology. In this paper, a ODP (open directory project)-based approach for personalized semantic information search is proposed. A reference ontology is generated by utilizing ODP to model user's interests and semantic search space. User profile is initially derived by matching between user's details and the refer- ence ontology to model his/her interests and preference. Semantic search space is constructed by fuzzily classifying documents into the reference ontology. We also present an evaluation of our proposed method which indicates a considerable improvement of search accuracy with the field of application human judgment.","On data recovery in distributed databasesWe present an approach for data encoding and recovery of lost information in a distributed database system. The dependencies between the informational redundancy of the database and its recovery rate are investigated, and fast recovery algorithms are developed.","Bifocals: Analyzing WebView Vulnerabilities in Android ApplicationsWebViews allow Android developers to embed a webpage within an application, seamlessly integrating native application code with HTML and JavaScript web content. While this rich interaction simplifies developer support for multiple platforms, it exposes applications to attack. In this paper, we explore two WebView vulnerabilities: excess authorization, where malicious JavaScript can invoke Android application code, and file-based cross-zone scripting, which exposes a device's file system to an attacker.#R##N##R##N#We build a tool, Bifocals, to detect these vulnerabilities and characterize the prevalence of vulnerable code. We found    $$67$$         67          applications with WebView-related vulnerabilities (   $$11\\,\\%$$         11     %          of applications containing WebViews). Based on our findings, we suggest a modification to WebView security policies that would protect over    $$60\\,\\%$$         60     %          of the vulnerable applications with little burden on developers.","Proposing a Novel Monitoring and Early Notification System for Heart Diseases ","Elimination Techniques for Program AnalysisKey ideas in our recent work on automatically generating polynomial equalities and inequalities as invariants/inductive assertions for imperative programs are reviewed. Two approaches based on elimina- tion techniques are briefly discussed. The first approach is algebraic and is based on giving the semantics of programming language constructs in terms of polynomial ideals. The second approach is based on assum- ing a priori the shapes of inductive assertions of interest and then using quantifier elimination techniques to generate constraints on parameters specifying the shape. The key ideas of these approaches are illustrated through examples.","Easy-to-Use and Accurate Calibration of RGB-D Cameras from SpheresRGB-Depth (or RGB-D) cameras are increasingly being adopted for real-world applications, especially in areas of healthcare and at-home monitoring. As for any other sensor, and since the manufac- turer's parameters (e.g., focal length) might change between models, calibration is necessary to increase the camera's sensing accuracy. In this paper, we present a novel RGB-D camera-calibration algorithm that is easy-to-use even for non-expert users at their home; our method can be used for any arrangement of RGB and depth sensors, and only re- quires that a spherical object (e.g., a basketball) is moved in front of the camera for a few seconds. A robust image-processing pipeline au- tomatically detects the moving sphere and rejects noise and outliers in the image data. A novel closed-form solution is presented to accurately compute an initial set of calibration parameters which are then utilized in a nonlinear minimization stage over all the camera parameters includ- ing lens distortion. Extensive simulation and experimental results show the accuracy and robustness to outliers of our algorithm with respect to existing checkerboard-based methods. Furthermore, an RGB-D Calibra- tion Toolbox for MATLAB is made freely available for the entire research community.","An Unsupervised Machine Learning Approach to Body Text and Table of Contents Extraction from Digital Scientific ArticlesScientific articles are predominantly stored in digital document for- mats, which are optimised for presentation, but lack structural information. This poses challenges to access the documents' content, for example for information retrieval. We have developed a processing pipeline that makes use of unsuper- vised machine learning techniques and heuristics to detect the logical structure of a PDF document. Our system uses only information available from the cur- rent document and does not require any pre-trained model. Starting from a set of contiguous text blocks extracted from the PDF file, we first determine geomet- rical relations between these blocks. These relations, together with geometrical and font information, are then used categorize the blocks into different classes. Based on this logical structure we finally extract the body text and the table of contents of a scientific article. We evaluate our pipeline on a number of datasets and compare it with state-of-the-art document structure analysis approaches.","Proving Non-opacityGuerraoui and Kapalka defined opacity as a safety criterion for transactional memory algorithms in 2008. Researchers have shown how to prove opacity, while little is known about pitfalls that can lead to non-opacity. In this paper, we identify two problems that lead to non-opacity, we present automatic tool support for finding such problems, and we prove an impossibility result. We first show that the well-known TM algorithms DSTM and McRT don't satisfy opacity. DSTM suffers from a write-skew anomaly, while McRT suffers from a write-exposure anomaly. We then prove that for direct-update TM algorithms, opacity is incompatible with a liveness criterion called local progress, even for fault-free systems. Our result implies that if TM algorithm designers want both opacity and local progress, they should avoid direct-update algorithms.","Early active learning via robust representation and structured sparsityLabeling training data is quite time-consuming but essential for supervised learning models. To solve this problem, the active learning has been studied and applied to select the informative and representative data points for labeling. However, during the early stage of experiments, only a small number (or none) of labeled data points exist, thus the most representative samples should be selected first. In this paper, we propose a novel robust active learning method to handle the early stage experimental design problem and select the most representative data points. Selecting the representative samples is an NP-hard problem, thus we employ the structured sparsity-inducing norm to relax the objective to an efficient convex formulation. Meanwhile, the robust sparse representation loss function is utilized to reduce the effect of outliers. A new efficient optimization algorithm is introduced to solve our non-smooth objective with low computational cost and proved global convergence. Empirical results on both single-label and multi-label classification benchmark data sets show the promising results of our method.","The Influence of Proactivity on Interactive Help Agents ","Editorial: Sparse representations for image and video analysis ","Automatic Classification of Liver Diseases from Ultrasound Images Using GLRLM Texture Features ","A Novel Approach for a Hardware-Based Secure Process Isolation in an Embedded System ","Using Queuing Models for Large System Migration Scenarios \u2013 An Industrial Case Study with IBM System z ","The Timeframe of Adaptation to Electric Vehicle RangeWe explored how people learn to cope with the limited range of electric vehicles (EVs), and examined the relationship between personality traits and the amount of practice needed to achieve a maximum available range. Data from 56 participants who leased an EV in a 6-month field study were analyzed. The amount of practice needed until a participant achieved his maximum available range was assessed with four variables computed from data logger recordings: the amount of time, days, and distance the user drove the EV and the amount of days the user owned the EV. All four variables correlated strongly with each other (r \u2265 .75). The results showed that an average person needs approximately three months to complete adaptation to EV range and that speedy driving style, low need for cognition, high impulsivity, and high internal control beliefs are related to a longer adaptation timeframe.","Robust GM/WM segmentation of the spinal cord with iterative non-local statistical fusion. ","H \u221e filtering of markovian jumping neural networks with time delaysThis paper focuses on studying the filtering problem of Markovian jumping neural networks with time delays. Based on a stochastic Lyapunov functional, a delay-dependent design criterion is presented under which the resulting filtering error system is stochastically stable and a prescribed H\u221e performance is guaranteed. It is shown that the gain matrices of the desired filter and the optimal performance index are simultaneously obtained by handing a convex optimization problem subject to some coupled linear matrix inequalities, which can be efficiently solved by some standard algorithms.","The effect of lateral inhibitory connections in spatial architecture neural networkBased on the theories of lateral inhibition and artificial neural network (ANN), the different lateral inhibitory connections among the hidden neurons of SANN are studied. With the connect mode of activation-inhibition-activation, the SANN will obtain a higher learning accuracy and generalization ability. Furthermore, this inhibitory connection considers both the activation before and after been inhibited by surrounding neurons. The effectiveness of this inhibitory mode is demonstrated by simulation results.","A Semantic approach for effective document clustering using WordNetNow a days, the text document is spontaneously increasing over the internet, e-mail and web pages and they are stored in the electronic database format. To arrange and browse the document it becomes difficult. To overcome such problem the document preprocessing, term selection, attribute reduction and maintaining the relationship between the important terms using background knowledge, WordNet, becomes an important parameters in data mining. In these paper the different stages are formed, firstly the document preprocessing is done by removing stop words, stemming is performed using porter stemmer algorithm, word net thesaurus is applied for maintaining relationship between the important terms, global unique words, and frequent word sets get generated, Secondly, data matrix is formed, and thirdly terms are extracted from the documents by using term selection approaches tf-idf, tf-df, and tf2 based on their minimum threshold value. Further each and every document terms gets preprocessed, where the frequency of each term within the document is counted for representation. The purpose of this approach is to reduce the attributes and find the effective term selection method using WordNet for better clustering accuracy. Experiments are evaluated on Reuters Transcription Subsets, wheat, trade, money grain, and ship, Reuters 21578, Classic 30, 20 News group (atheism), 20 News group (Hardware), 20 News group (Computer Graphics) etc.","Adaptive Approach for Enhancement the Visual Quality of Low-Contrast Medical Images ","Web Service Discovery and Execution Using a Dialog-Based Approach ","Stopwords Detection in Bag-of-Visual-Words: The Case of Retrieving Maya HieroglyphsWe present a method for automatic detection of stopwords in visual vocabularies that is based upon the entropy of each visual word. We propose a specific formulation to compute the entropy as the core of this method, in which the probability density function of the visual words is marginalized over all visual classes, such that words with higher entropy can be considered to be irrelevant words, i.e., stopwords. We evaluate our method on a dataset of syllabic Maya hieroglyphs, which is of great interest for archaeologists, and that requires efficient techniques for indexing and retrieval. Our results show that our method produces shorter bag representations without hurting retrieval performance, and even improving it in some cases, which does not happen when using previous methods. Furthermore, our assumptions for the proposed computation of the entropy can be generalized to bag representations of different nature.","Dynamic Clustering Process to Calculate Affinity Degree of Users as Basis of a Social Network Recommender ","Multiplied complete fix-free codes and shiftings regarding the 3/4-conjectureGiven a nonnegative sequence \u03b1 of integers with Kraftsum at most 3/4, Ahlswede, Balkenhol and Khachatrian proposed the existence of a fix-free code with exactly \u03b1n words for any length n. In this article complete thin fix-free codes are constructed and both so-called n-closed systems and multiplication are used to enlarge this class. In addition, a sufficient criterion is given in terms of elementary sequence-shifting preserving the fix-freedom of the associated code.","A comparison study of clustering models for online review sentiment analysisIn this work, we conduct a comparison study of the online review sentiment clustering problem from a combined perspective of data preprocessing, VSM modeling and clustering algorithm. To that end, we first introduce some methods for data preprocessing. Then, we explore the impacts of the term weighting models for review representation. Finally, we present detailed experiment results of some review clustering techniques. The conclusions would be valuable for both the study and usage of clustering methods in online review sentiment analysis.","How applicable is ISO/IEC 29110 in Game Software Development?Software development in a small development team is a challenge, as people have to fulfill several roles, which in larger groups would have separate, dedicated people for the work. To help small development teams to organize their activities, ISO/IEC standardization body has developed the standard ISO/IEC 29110, Lifecycle profiles for Very Small Entities. Our study focuses on the application of this model in the game industry, an industry that develops software. However, the game industry has its own set of unusual features in software development, such as the demand for artistic vision, need for novelty and demand for creative designs. In this study we analyze how the standard would work in seven different game industry companies and identify a set of additions that would help these organizations to apply the standard in practice. Based on our results, the ISO/IEC 29110 should incorporate more support for iterative development to allow easier adaptation to real-life organizations.","Inverse Maximum Flow Problems under the Combining NormsConference Name:7th International Frontiers in Algorithmics Workshop and the 9th International Conference on Algorithmic Aspects in Information and Management, FAW-AAIM 2013. Conference Address: Dalian, China. Time:June 26, 2013 - June 28, 2013.","When Does Active Learning WorkActive Learning AL methods seek to improve classifier performance when labels are expensive or scarce. We consider two central questions: Where does AL work? How much does it help? To address these questions, a comprehensive experimental simulation study of Active Learning is presented. We consider a variety of tasks, classifiers and other AL factors, to present a broad exploration of AL performance in various settings. A precise way to quantify performance is needed in order to know when AL works. Thus we also present a detailed methodology for tackling the complexities of assessing AL performance in the context of this experimental study.","Using Reputation Instead of Tolls in Repeated Selfish Routing with Incomplete InformationWe study the application of reputation as an instigator of beneficial user behavior in selfish routing and when the network users rely on the network operator for information on the network traffic. In- stead of the use of tolls or artificial delays, the network operator takes advantage of the users' insufficient information, in order to manipulate them through the information he himself provides. The issue that arises then is what can the operator's gain be, without compromising by too much the trust users put on the information provided, i.e., by maintaining a reputation for (at least some) trustworthiness. Our main contribution is the modeling of such a system as a repeated game of incomplete infor- mation in the case of single-commodity general networks. This allows us to apply known folk-like theorems to get bounds on the price of anarchy that are better in the worst-case (if that is possible at all) than the well- known price of anarchy bounds in selfish routing without information manipulation.","An Open-source Development and Simulation Platform for Smart Wheelchairs ","Keeping user centred design (UCD) alive and well in your organisation: taking an agile approachUsing the analogy of user centred design (UCD) as a garden, we explore how to establish, grow and cultivate it to maturity in an organisation. We consider the importance of: having a clear and agreed intent and scope at the start; understanding the environment and culture; planning for success; focusing on the expected outcomes at each iteration; dealing with barriers and risks as they occur; implementing quickly in a scalable manner (according to the Agile methodology); conducting regular &amp;'health checks'; reporting progress; and celebrating achievements along the way.","A Rule-Based Morphosemantic Analyzer for French for a Fine-Grained Semantic Annotation of TextsWe describe DeriF, a rule-based morphosemantic analyzer developed for French. Unlike existing word segmentation tools, DeriF provides derived and compound words with various sorts of semantic information: (1) a defini- tion, computed from both the base meaning and the specificities of the morpho- logical rule; (2) lexical-semantic features, inferred from general linguistic properties of derivation rules; (3) lexical relations (synonymy, (co-)hyponymy) with other, morphologically unrelated, words belonging to the same analyzed corpus.","Efficient Extraction of High-Betweenness Vertices from Heterogeneous Networks ","Developing Simplified Chinese Psychological Linguistic Analysis Dictionary for MicroblogThe words that people use could reveal their emotional states, intentions, thinking styles, individual differences, etc. LIWC (Linguistic Inquiry and Word Count) has been widely used for psychological text analysis, and its dictionary is the core. The Traditional Chinese version of LIWC dictionary has been released, which is a translation of LIWC English dictionary. However, Simplified Chinese which is the world's most widely used language has subtle differences with Traditional Chinese. Furthermore, both English LIWC dictionary and Traditional Chinese version dictionary were both developed for relatively formal text. Microblog has become more and more popular in China nowadays. Original LIWC dictionaries take less consideration on microblog popular words, which makes it less applicable for text analysis on microblog. In this study, a Simplified Chinese LIWC dictionary is established according to LIWC categories. After translating Traditional Chinese dictionary into Simplified Chinese, five thousand words most frequently used in microblog are added into the dictionary. Four graduate students of psychology rated whether each word belonged in a category. The reliability and validity of Simplified Chinese LIWC dictionary were tested by these four judges. This new dictionary could contribute to all the text analysis on microblog in future.","Passive Profiling and Natural Interaction Metaphors for Personalized Multimedia Museum ExperiencesMuseums must balance the amount of information given on individual pieces or exhibitions in order to provide sufficient information to aid visitor understanding. At the same time they must avoid cluttering the environment and reducing the enjoyment of the exhibit. Moreover, each visitor has different interests and each might prefer more (or less) information on different artworks depending on their individual profile of interest. Finally, visiting a museum should not be a closed experience but a door opened onto a broader context of related artworks, authors, artistic trends, etc. In this paper we describe the MNEMOSYNE system that attempts to provide such a museum experience. Based on passive observation of visitors, the system builds a profile of the artworks of interest for each visitor. These profiles of interest are then used to personalize content delivery on an interactive table. The natural user interface on the interactive table uses the visitor's profile, a museum content ontology and a recommendation system to personalize the user's exploration of available multimedia content. At the end of their visit, the visitor can take home a personalized summary of their visit on a custom mobile application. In this article we describe each component of our approach as well as the first field trials of our prototype system built and deployed at our permanent exhibition space at Le Murate in the city of Florence.","Attentional biases during steering behaviorIn the current study, we examine eye movements of human operators during a combined steering and discrimination task. In this task, observers had to alternate their gaze between a central steering task and a discrimination task in the periphery. Our results show that the observer's gaze behavior is influenced by the motion direction of the steering task. Saccade reaction times (SRTs) of saccades to the discrimination target were shorter if the target appeared in the steering direction. SRTs back to the steering task were shorter when the steering target moved away from the discrimination target. These effects are likely the result of motion-related attention shifts and an interaction of the saccadic and smooth pursuit eye movement system.","End-to-End Performance of Multi-core Systems in Cloud Environments ","Anything Relationship Management (xRM) as Management Layer for the Hyper-connected SocietyThere is a strong consensus that collaboration and co-creation will become one of the main business drivers in the future. However, the question of how to set-up inter-organizational relationships and involve stakeholders in an efficient way still remains largely unsolved. This paper proposes Anything Relationship Management (xRM) as managerial and technological foundation and platform providing interoperability between different stakeholder groups. It provides an overview of the evolution of the relationship management concept, analyzes the current status of the xRM solution market and proposes an xRM-framework for collaborative networks and cyber-physical systems.","A Neural Network Approximation of L-MCRS Dynamics for Reinforcement Learning ExperimentsThe autonomous learning of the control of Linked Multi- component Robotic Systems (L-MCRS) is an open research issue. We are pursuing the application of Reinforcement Learning algorithms to achieve such control. However, accurate simulations needed for RL tri- als are time consuming, so that the process of training and validation becomes excesively long. In order to obtain results in affordable time, we perform the approximation of the detailed dynamic model of the L- MCRS by Artificial Neural Networks (ANN).","Modelling Destructive AssignmentsTranslating procedural object oriented code into constraints is required for many processes that reason about the execution of this code. The most obvious is for symbolic execution of the code, where the code is executed without necessarily knowing the concrete values. In this paper, we discuss translations from procedural object oriented code to constraints in the context of solving optimisation problems defined via simulation. A key difficulty arising in the translation is the modelling of state changes. We introduce a new technique for modelling destructive assignments that outperforms previous approaches. Our results show that the optimisation models generated by our technique can be as efficient as equivalent hand written models.","A Similarity Model for 3D Objects Based on Stable Sub-cloudsWe present an idea of a novel similarity model for objects represented by 3D point clouds that were generated by scans of real-world objects. Various existing approaches find descriptive points on the object surface or extract features of groups of points. However, 3D object scans when conducted outside a lab environment often suffer from imprecisions and noise artifacts, which many existing approaches do not handle well. To better tolerate these imperfections, our model extracts stable sub-clouds from the input point cloud, which represent classes of adjacent sub-clouds sharing similar features. We demonstrate experimentally that features generated from these sub-clouds can be used to establish a measure of similarity between objects. We show preliminary results of an application of this technique to point clouds of models scanned from real-world objects and demonstrate that this technique has good potential to deal with imperfect data by showing how the computed distance relates to degrees of modification of the data. Our technique extracts features from particularly resilient portions of the object and is thus better able to accommodate deficiencies in the input data.","Speckle Noise Reduction Using Fourth Order Complex Diffusion Based Homomorphic Filter ","Lojban++: an interlingua for communication between humans and AGIsLojban is a constructed language based on predicate logic, with no syntactic ambiguity and carefully controllable semantic ambiguity. It originated in the middle of the last century, and there is now a community of several hundred human speakers. It is argued here that Lojban++, a minor variation on Lojban, would be highly suitable as a language for communication between humans and early-stage AGI systems. Software tools useful for the deployment of Lojban++ in this manner are described, and their development proposed.","Forward Chaining for Hybrid ASPIn this paper, we define an analogue of the Forward Chain- ing (FC) algorithm due to Marek, Nerode, and Remmel (12) for Hybrid Answer Set Programming (H-ASP). The FC algorithm for normal logic programs takes as an input a well ordering \u227a of the non-Horn clauses of a normal logic program P and produces a stable model D \u227a for a subpro- gram A \u227a of P. It is the case that for every stable model M of P ,t here is a well ordering \u227a such that D \u227a = M and A \u227a = P.T hus the search for a stable model of P becomes a search for a well ordering \u227a such that A \u227a = P. We show that a similar result hold in case of FC for H-ASP. H-ASP is an extension of normal logic programming or Answer Set Pro- gramming (ASP), introduced by the authors in (2) that allows users to combine ASP type rules and numerical algorithms. The MFC algorithm, introduced by the authors in (1) is a Monte Carlo algorithm that com- bines the FC algorithm and the Metropolis-Hastings algorithm to search for stable models of normal logic programs. We shall briefly discuss how one can produce an analogue of the MFC algorithm to search for stable models of H-ASP programs.","Bidirectional Growth based Mining and Cyclic Behaviour Analysis of Web Sequential PatternsWeb sequential patterns are important for analyzing and understanding users behaviour to improve the quality of service offered by the World Wide Web. Web Prefetching is one such technique that utilizes prefetching rules derived through Cyclic Model Analysis of the mined Web sequential patterns. The more accurate the prediction and more satisfying the results of prefetching if we use a highly efficient and scalable mining technique such as the Bidirectional Growth based Directed Acyclic Graph. In this paper, we propose a novel algorithm called Bidirectional Growth based mining Cyclic behavior Analysis of web sequential Patterns (BGCAP) that effectively combines these strategies to generate prefetching rules in the form of 2-sequence patterns with Periodicity and threshold of Cyclic Behaviour that can be utilized to effectively prefetch Web pages, thus reducing the users perceived latency. As BGCAP is based on Bidirectional pattern growth, it performs only (log n+1) levels of recursion for mining n Web sequential patterns. Our experimental results show that prefetching rules generated using BGCAP is 5-10 percent faster for different data sizes and 10-15% faster for a fixed data size than TD-Mine. In addition, BGCAP generates about 5-15 percent more prefetching rules than TD-Mine.","Exploring Location-Aware Process ManagementContext-awareness has emerged as an important principle in the de- sign of flexible business processes. One important yet under-researched context variable is location; which we expect to have significant potential in making business processes truly agile. This paper proposes to extend context-aware Business Process Management (BPM) towards location-awareness in the man- agement of business processes. We propose a model that explains where and how location variables matter to a business process. We presents a set of evalu- ation criteria to determine whether the business process location-aware or not. We expect our research-in-progress, together with further research, to bring an improvement of BPM development in theory and in practice.","Indiscrete Models: Model Building and Model Checking over Linear TimeWe consider the task of model building and model checking for temporal logic specifications over general linear flows of time. We present a new notation for giving a detailed description of the compositional construction of such a model and an efficient procedure for finding it from the temporal specification. We then also present an algorithm for checking whether a particular temporal formula holds in a general linear model. Applications include reasoning about distributed and concurrent sys- tems, multi-agent systems, and understanding natural language.","Time-Based Exploratory Search in Scientific LiteratureState-of-the-art faceted search graphical user interfaces for digital libraries provide a wide range of filters perfectly suitable for narrowing down results for well-defined user needs. However, they fail to deliver summarized overview information for users that need to familiarize themselves with a new scientific topic. In fact, exploratory search remains one of the major problems for scientific literature search in digital libraries. Exploiting a user study about how computer scientists actually approach new subject areas we developed ESSENCE, a system for empowering exploratory search in scientific literature.","A Dress Coordination Robot System Which Can Improve User\u2019s Ability by a Dialogue Robot ","Interactive Segmentation of Media-Adventitia Border in IVUSIn this paper, we present an approach for user assisted seg- mentation of media-adventitia border in IVUS images. This interactive segmentation is performed by a combination of point based soft con- straint on object boundary and stroke based regional constraint. The edge based boundary constraint is imposed through searching the short- est path in a three-dimensional graph, derived from a multi-layer image representation. The user points act as attraction points and are treated as soft constraints, rather than hard constraints that the segmented bound- ary has to pass through the user specified points. User can also use strokes to specify foreground (region of interest). The probabilities of region of interest for each pixel are then calculated and their discontinuity is used to indicate object boundary. This combined approach is formulated as an energy minimization problem that is solved using a shortest path search algorithm. We show that this combined approach allows efficient and effective interactive segmentation, which is demonstrated through iden- tifying media-adventitia border in IVUS images where image artifact, such as acoustic shadow and calcification, are common place. Both qual- itative and quantitative analysis are provided based on manual labeled datasets.","A Novel Feature Selection Technique for SAGE Data Classification ","Simulation of Dynamic Path Planning for Real-Time Vision-Base Robots ","Identifying market price levels using differential evolutionEvolutionary data mining is used in this paper to investigate the concept of support and resistance levels in financial markets. Specifically, Differential Evolution is used to learn support/resistance levels from price data. The presence of these levels is then tested in out-of-sample data. Our results from a set of experiments covering five years worth of daily data across nine different US markets show that there is statistical evidence for price levels in certain markets, and that Differential Evolution can uncover them.","Experiment design for parameter estimation in sensing modelsIn this study, the problem of quality improvement for sensing models in wireless sensor networks is considered. A choice of sensing model strongly influences design of wireless sensor networks and performance of protocols, such as traffic aggregation, broadcasting, energy efficient routing, target or barrier coverage etc. For these reasons, it is useful to investigate the nature of sensing ability, and the manner in which it depends on the characteristics of wireless sensor networks. The author investigates the impact of experiment design on the evaluation of a sensing quality function. The goal of this work is to provide an approach for the statistically efficient estimation of sensing model parameters.","Interlocked surfaces: a dynamic multi-device collaboration systemIn this research, we propose \"Interlocked Surfaces\", which supports cooperation work between different devices. The system offers to connect different devices wirelessly and allow multiple users to view and edit documents simultaneously. We have developed a technique to share and view documents between different devices even they have difference screen sizes and resolutions. In a user study, we conducted experiments to evaluate the usefulness of the system. The result shows that users can perform the document inspection task more comfortably using the proposed system.","Iterative Model Refinement of Recommender MDPs Based on Expert FeedbackIn this paper, we present a method to iteratively refine the parameters of a Markov Decision Process by leveraging constraints implied from an expert's review of the policy. We impose a constraint on the parameters of the model for every case where the expert's recommendation differs from the recommendation of the policy. We demonstrate that consistency with an expert's feedback leads to non-convex constraints on the model parameters. We refine the parameters of the model, under these constraints, by partitioning the parameter space and iteratively applying alternating optimization. We demonstrate how the approach can be applied to both flat and factored MDPs and present results based on diagnostic sessions from a manufacturing scenario.","Virtual register renamingThis paper presents a novel high performance substrate for building energy-efficient out-of-order superscalar cores. The architecture does not require a reorder buffer or physical registers for register renaming and instruction retirement. Instead, it uses a large number of virtual register IDs for register renaming, a physical register file of the same size as the logical register file, and checkpoints to bulk retire instructions and to recover from exceptions and branch mispredictions. By eliminating physical register renaming and the reorder buffer, the architecture not only eliminates complex power hungry hardware structures, but also reduces reorder buffer capacity stalls when execution encounters long delays from data cache misses, thus improving performance. The paper presents performance and power evaluation of this new architecture using Spec 2006 benchmarks. The performance data was collected using an x86 ASIM-based performance simulator from Intel Labs. The data shows that the new architecture improves performance of a 2-wide out-of-order x86 processor core by an average of 4.2%, while saving 43% of the energy consumption of the reorder buffer and retirement register file functional block.","Exploiting user model diversity in forecast aggregationIn many contexts, people generate forecasts about events of interest, and decision-makers wish to aggregate these forecasts to improve their accuracy. These forecasts differ from signals in the physical sciences. In particular, sensor signals are noisy samples from a common underlying distribution, while human-generated forecasts are based on cognitive models that vary from one informant to another. As a result, human forecasts, unlike physical signals, are not guaranteed to be statisticallyindependent conditioned on the true outcome. These differences both provide new opportunities for aggregation, and impose restrictions that do not apply to physical signals. This paper describes the difference between forecasts and physical signals, outlines a strategy for exploiting these differences in aggregation, and demonstrates modest but statistically significant gains in the accuracy of aggregated forecasts using data from a large ongoing experiment in forecasting world events.","Speaker Attribution of Australian Broadcast News DataSpeaker attribution is the task of annotating a spoken audio archive based on speaker identities. This can be achieved using speaker diarization and speaker linking. In our previous work, we proposed an efficient attribution system, using complete-linkage clustering, for conducting attribution of large sets of two-speaker telephone data. In this paper, we build on our proposed approach to achieve a robust system, applicable to multiple recording domains. To do this, we first extend the diarization module of our system to accommodate multispeaker (&gt;2) recordings. We achieve this through using a robust cross-likelihood ratio (CLR) threshold stopping criterion for clustering, as opposed to the original stopping criterion of two speakers used for telephone data. We evaluate this baseline diarization module across a dataset of Australian broadcast news recordings, showing a significant lack of diarization accuracy without previous knowledge of the true number of speakers within a recording. We thus propose applying an additional pass of complete-linkage clustering to the diarization module, demonstrating an absolute improvement of 20% in diarization error rate (DER). We then evaluate our proposed multi-domain attribution system across the broadcast news data, demonstrating achievable attribution error rates (AER) as low as 17%. Index Terms: speaker attribution, diarization, linking, complete linkage, broadcast news.","Modified Deformable Parts Model for Side Profile Facial Feature Detection ","An application-aware cache replacement policy for last-level cachesCurrent day multicore processors employ multi-level cache hierarchy with one or two levels of private caches and a shared last-level cache (LLC). Efficient cache replacement policies at LLC are essential for reducing the off-chip memory traffic as well as contention for memory bandwidth. Cache replacement techniques for unicore LLCs may not be efficient for multicore LLCs as multicore LLCs can be shared by applications with varying access behavior, running simultaneously. One application may dominate another by flooding of cache requests and evicting the useful data of the other application.#R##N##R##N#This paper proposes a new cache replacement policy for shared LLC called Application-aware Cache Replacement (ACR). ACR policy prevents victimizing low-access rate application by a high-access rate application. It dynamically keeps track of maximum life-time of cache lines in shared LLC for each concurrent application and helps in efficient utilization of the cache space. Experimental evaluation of ACR technique for 2-core and 4-core systems using SPEC CPU 2000 and 2006 benchmark suites shows significant speed-up improvement over the least recently used and thread-aware dynamic re-reference interval prediction techniques.","Global robust exponential stability in lagrange sense for interval delayed neural networksThe problem of global robust exponential stability in Lagrange sense for the interval delayed neural networks (IDNNs) with general activation functions is investigated. Based on the Lyapunov stability, a differential inequality and linear matrix inequalities (LMIs) technique, some conditions to guarantee the IDNNs global exponential stability in Lagrange sense are provided. Meanwhile, the specific estimation of globally exponentially attractive sets of the addressed system are also derived. Finally, a numerical example is provided to illustrate the effectiveness of the method proposed.","Optimized Adaptive Hybrid Indexing for In-memory Column StoresModern applications and databases using dynamic storage environment are characterized by two challenging features: a little idle system time to devote in physical design; b little priori knowledge about the query and data workload. Traditional approaches to index building and maintenance do not work well in such dynamic environment; while adaptive indexing can be a remedy. An adaptive index is a partially created index. Refinement of the index is conducted during query execution. Database cracking and adaptive merging are two techniques for adaptive indexing. The former is advantageous at initialization, while the latter can converge to its optimal structure with a much faster speed. In this paper, we propose a hybrid approach by combining cracking and adaptive merging. We designed a cost model to measure the cost of data partition operations. Based on the model, we provide an algorithm to refine adaptive index. Experiments show that our hybrid approach can achieve appropriate performance tradeoff between database cracking and adaptive merging.","Detection of Human Abnormal Behavior of the Ship\u2019s Security ","Comparison of GHT-Based Approaches to Structural Motif RetrievalThe structure of a protein gives important information about its function and can be used for understanding the evolutionary relationships among proteins, predicting protein functions, and predicting protein folding. A structural motif is a compact 3D protein block referring to a small specific combination of secondary structural elements which appears in a variety of molecules. In this paper we present a comparison between few approaches for motif retrieval based on the Generalized Hough Transform (GHT). Performance comparisons, in terms of precision and computation time, are presented considering the retrieval of motifs composed by three to five SSs for more than 15 million searches. The approaches object of this study can be easily applied to the retrieval of greater blocks, up to protein domains, or even entire proteins.","Application of a Logical Reasoning Approach Based Petri Net in Agriculture Expert SystemFirst of all, a goal-guiding graphic reasoning approach that based on#N#                            the predicate/transition system has been proposed for the first-order#N#                            predicate logic. In process of reasoning, the premise is separated from#N#                            the conclusion, which has been taken as the beginning of the backward#N#                            reasoning that is purposeful and effective as well. Next, this reasoning#N#                            approach has been applied in the agriculture expert system to present a#N#                            method of solving problem, providing a new way for studying the#N#                            reasoning mechanism of the agriculture expert system.","Implementation of a System for Intelligent Summarization of Longitudinal Clinical RecordsPhysicians are required to interpret, abstract and present in free-text large amounts of clinical data in their daily tasks. This is especially true for chronic-disease domains, but also in other clinical domains. In our previous work, we have suggested a general framework for performing this task, given a time-oriented clinical database, and appropriate formal abstraction and summarization knowledge. We have recently developed a prototype system, CliniText, which demonstrates our ideas. Our prototype combines knowledge-based temporal data abstraction, textual summarization, abduction, and natural-language generation techniques, to generate an intelligent textual summary of longitudinal clinical data. We demonstrate both our methodology, and the feasibility of providing a free-text summary of longitudinal electronic patient records, by generating a discharge summary of a patient from the MIMIC database, who had undergone a Coronary Artery Bypass Graft operation.","Identifying Factors Influencing Hybrid Self-regulated and Collaborative Learning: Toward an End-User Training Framework ","Route Descriptions in Advance and Turn-by-Turn Instructions - Usability Evaluation of a Navigational System for Visually Impaired and Blind People in Public Transport ","On the complexity of undominated core and farsighted solution concepts in coalitional gamesIn this paper, we study the computational complexity of solution concepts in the context of coalitional games. Firstly, we distinguish two different kinds of core, the undominated core and excess core, and investigate the difference and relationship between them. Secondly, we thoroughly investigate the computational complexity of undominated core and three farsighted solution concepts---farsighted core, farsighted stable set and largest consistent se}.","User-centered investigation of social commerce designEvidence from relevant studies indicates that social commerce can benefit from a user-centered design. This study explores users' perception and preferences of social features implemented on current social commerce websites, focusing on two major categories of social commerce platforms. Results point to a number of important social features, such as the \"Comment\" button, allowing users to provide feedback, and encouraging users to respond to comments made by others. We also present and discuss the differences in user preferences of social features between the two social commerce platform categories. By considering the user perspective, this study aims to help business organizations develop successful social commerce systems.","Experimental Evaluation of WBAN Antenna Performance for FCC Common Frequency Band with Human Body ","Visualising the Attributes of Biological Cells, Based on Human Perception ","Vector-projection approach to curve framing for extruded surfacesCurve framing has numerous applications in computer graphics modeling, e.g., in the construction of extruded surfaces. Commonly used curve framing techniques such as the Frenet frame, parallel transport frame and 'up-vector' frame cannot handle all types of curves. Mismatch between the technique used and the curve being modeled may result in the extruded surfaces being twisted. We propose a simple end-to-end vector-projection approach to curve framing. Our results show that the technique yields less twists compared to those based on the Frenet frame.","Feature Selection Methods in Persian Sentiment AnalysisWith the enormous growth of digital content in internet, various types of online reviews such as product and movie reviews present a wealth of subjective information that can be very helpful for potential users. Sentiment analysis aims to use automated tools to detect subjective information from reviews. Up to now as there are few researches conducted on feature selection in sentiment analysis, there are very rare works for Persian sentiment analysis. This paper considers the problem of sentiment classification using different feature selection methods for online customer reviews in Persian language. Three of the challenges of Persian text are using of a wide variety of declensional suffixes, different word spacing and many informal or colloquial words. In this paper we study these challenges by proposing a model for sentiment classification of Persian review documents. The proposed model is based on stemming and feature selection and is employed Naive Bayes algorithm for classification. We evaluate the performance of the model on a collection of cellphone reviews, where the results show the effectiveness of the proposed approaches","Maize Seed Embryo and Position Inspection Based on Image Processing ","Visualization of infectious disease outbreaks in routine practice.Throughout the history of epidemiology, visualizations have been used as the interface between public-health professionals and epidemiological data. The aim of this study was to examine the impact of the level of abstraction when using visualizations on routine infectious disease control. We developed three interactive visualization prototypes at increasing levels of abstraction to communicate subsets of influenza outbreak surveillance information. The visualizations were assessed through workshops in an exploratory evaluation with infectious disease epidemiologists. The results show that despite the potential of processed, abstract, and information-dense representations, increased levels of abstraction decreased epidemiologists understanding and confidence in visualizations. Highly abstract representations were deemed not applicable in routine practice without training. Infectious disease epidemiologists work routines and decision-making need to be further studied in order to develop visualizations that meet both the quality requirements imposed by policy-makers and the contextual nature of work practice.","Ring Exploration by Oblivious Robots with Vision Limited to 2 or 3The problem of exploring a finite discrete space by autonomous mobile robots is a basic building block for many applications. Space to explore is partitioned into a finite number of locations represented by a graph, where nodes represent indivisible locations that can be sensed by the robots, and where edges represent the possibility for a robot to move from one location to the other. %, e.g., a building, a town, a factory, or a mine. We address the terminating exploration problem which requires that starting from a configuration where no two robots occupy the same node, every node needs to be visited by at least one robot, with the additional constraint that all robots eventually stop moving.","Medical Image Segmentation Using Multi-level Set Partitioning with Topological Graph PriorIn this paper, we propose an approach for multi-region segmentation based on a topological graph prior within a multi-level set MLS formulation. We consider topological graph prior information to evolve the contour based on a topological relationship presented via a graph relation. This novel method is capable of segmenting adjacent objects with very close gray level that would be difficult to segment correctly using standard methods. We describe our algorithm and show the graph prior technique to explain how it gives precise multi-region segmentation. We validate our algorithm with numerous abdominal and brain image databases and compare it to other multi-region segmentation methods to demonstrate its accuracy and computational efficiency.","Identifying Factors for Human Desire Inference in Smart Home Environments ","On the Uniform Sampling of CIELAB Color Space and the Number of Discernible ColorsThis paper presents a useful algorithmic strategy to sample uniformly the CIELAB color space based on close packed hexagonal grid. This sampling scheme has been used successfully in different research works from computational color science to color image processing. The main objective of this paper is to demonstrate the relevance and the accuracy of the hexagonal grid sampling method applied to the CIELAB color space. The second objective of this paper is to show that the number of color samples computed depends on the application and on the color gamut boundary considered. As demonstration, we use this sampling to support a discussion on the number of discernible colors related to a JND.","Partially Supervised Anomaly Detection Using Convex Hulls on a 2D Parameter Space ","An improved neighborhood-restricted association rule-based recommender systemAssociation rule mining is an actively studied topic in recommender systems. A major limitation of an association rule-based recommender system is the problem of reduced coverage. It is generally caused due to the usage of a single global minimum support (minsup) threshold in the mining process, which leads to the effect that no association rules involving rare items can be found. To confront the problem, researchers have introduced Neighborhood-Restricted rule-based Recommender System (NRRS) using the concept of multiple minsups. We have observed that NRRS is computationally expensive to use and can recommend uninteresting products to the users. With this motivation, this paper proposes an improved NRRS using the relative support measure. We call the proposed system as NRRS++. Experimental results show that NRRS++ can provide better recommendations and is runtime efficient than NRRS.","Synergy graphs for configuring robot team membersRobots are becoming increasingly modular in their design, allowing different configurations of hardware and software, e.g., different wheels, sensors, and algorithms. We are interested in forming a multi-robot team by configuring each robot (i.e., selecting the different modules) to best fit a task. This general problem is applicable to many domains, such as manufacturing in high-mix low-volume scenarios. In this paper, we formally define the Synergy Graph for Configurable Robots (SGraCR) model, where each robot module is modeled as a vertex in a graph, and we define how to compute the synergy of modules within a single robot, as well as between robots, using the structure of the graph. We define the synergy of a multi-robot team comprised of such configurable robots, and contribute a team formation algorithm that searches a SGraCR to approximate the optimal team. In addition, we contribute a learning algorithm that learns a SGraCR from a small set of training data containing the performance of teams. We evaluate our SGraCR model and algorithm in extensive experiments, both in simulation and with real robots, and compare with competing algorithms.","Alternatives to Threshold-Based Desire Selection in Bayesian BDI AgentsBayesian BDI agents employ bayesian networks to represent uncertain knowledge within an agent's beliefs. Although such models allow a richer belief representation, current models of bayesian BDI agents employ a rather limited strategy for desire selection, namely one based on threshold values on belief probability. Consequently, such an approach precludes an agent from selecting desires conditioned on beliefs with probabilities below a certain threshold, even if those desires could be achieved if they had been selected. To address this limitation, we develop three alternative approaches to desire selection under uncertainty. We show how these approaches allow an agent to sometimes select desires whose belief conditions have very low probabilities and discuss experimental scenarios.","Modeling Foreshadowing in Narrative Comprehension for Sentimental ReadersForeshadowing is a narrative technique of manipulating the reader's inferences about the story progression. This paper reviews research on foreshadowing and reader comprehension in narratology and cognitive science. We use the term sentimental reader to refer to sophisticated readers who make active efforts in their reading experiences, and then we list various examples of foreshadowing found in novels, films, and games, discussing their impact on the sentimental reader's reasoning process. We further present an example of interactive fiction associated with the use of foreshadowing and conclude with future work.","How to Build Integrated Climate Change Enabled EDSS ","Use Second Screen to Enhance TV Viewing ExperiencesIn this paper, we propose a second-screen interactive TV viewing scenario, and build an Android-based prototype to verify our concept and design. The demo app detects the TV program that a user is watching, and then dynamically pushes additional information through the second screen to the user. In this prototype, we apply audio fingerprinting technology to detect TV programs, and users do not have to manually surf hundreds of channels. In addition, face recognition and tennis event detection technologies have been employed to extract critical elements from the TV contents. With these content analysis tools, we can obtain video metadata more easily and need not rely on content providers. A usability test with 20 participants has been conducted. Our test shows participants are interested in our second screen app, and they would like more features and information from the app. Next, we plan to further refine the app's design to enhance user experience.","Case-based Selection of Business Process Modeling Tools: An Evaluation Criteria FrameworkModeling tools are one of the major success factors for business process management endeavors. They not only ultimately provide the modeling language to be used but also define the way of interaction when creating and using those models. Thereby, already the selection of the right modeling tool is a decisive factor for success or failure of any modeling project. Through a systematic literature review, we have identified a lack of a holistic criteria framework for the evaluation of business process modeling tools. To overcome this gap, we propose a structured evaluation criteria framework for modeling tools in this article. Our design enables an efficient selection while ensuring that all major decision factors have been considered. We evaluate our proposed framework in a real-life use case about sustainable process design for home care.","On the Change in Archivability of Websites Over TimeAs web technologies evolve, web archivists work to keep up so that our digital history is preserved. Recent advances in web technologies have introduced client-side executed scripts that load data without a referential identifier or that require user interaction (e.g., content loading when the page has scrolled). These advances have made automating methods for capturing web pages more difficult. Because of the evolving schemes of publishing web pages along with the progressive capability of web preservation tools, the archivability of pages on the web has varied over time. In this paper we show that the archivability of a web page can be deduced from the type of page being archived, which aligns with that page's accessibility in respect to dynamic content. We show concrete examples of when these technologies were introduced by referencing mementos of pages that have persisted through a long evolution of available technologies. Identifying these reasons for the inability of these web pages to be archived in the past in respect to accessibility serves as a guide for ensuring that content that has longevity is published using good practice methods that make it available for preservation.","A linear integer program to reduce air traffic delay in enroute airspaceDue to fast growing of sector of air transportation, air traffic management becomes more and more complex. Therefore, the ability of systems to manage air traffic presents difficulties.#R##N##R##N#In this paper, we address the Air Traffic Flow Management (ATFM) problem, as a new Linear Integer Program (LIP). It takes into account all flights phases, i.e., taking-off, cruising and landing. The model also allows rerouting decisions. All constraints of our model and objective function are linear, differently from the model of Bertsimas et al. [2] which contains non-linear constraints.#R##N##R##N#Finally, numerical simulations are presented at the end of this article showing the effectiveness of our new formulation.","Reading contexts for structured documents retrievalThis paper focuses on the retrieval of parts of structured document called doxels. We propose a notion of reading context of a doxel and we exploit it to extend an Indexing Language Model (LM) with Dirichlet smoothing. We interpret a context of a doxel as a propagation of the content of the connected doxels via document structure links. We experiment this model on INEX corpus 2009, and test different context propagations. We measure a significant increase in results using contexts, compared to a reference approach without the use of context for 3 types of doxels. Moreover, our proposal outperforms the best result obtained for the Focused evaluation for the Ad Hoc task at INEX 2009.","Spatio-temporal Manifold Embedding for Nearly-Repetitive Contents in a Video StreamThis paper presents a framework to identify and align nearly-repetitive contents in a video stream using spatio-temporal manifold embedding. The similarities observed in frame sequences are captured by defining two types of correlation graphs: an intra-correlation graph in the spatial domain and an inter-correlation graph in the temporal domain. The presented work is novel in that it does not utilise any prior information such as the length and contents of the repetitive scenes. No template is required, and no learning process is involved in the approach. Instead it analyses the video contents using the spatio-temporal extension of SIFT combined with a coding technique. The underlying structure is then reconstructed using manifold embedding. Experiments using a TRECVID rushes video proved that the framework was able to improve embedding of repetitive sequences over the conventional methods, thus was able to identify the repetitive contents from complex scenes.","Visualisation and Analysis of Affiliation Networks as Tools to Describe Professional Profiles ","Personal informatics in chronic illness managementMany people with chronic illness suffer from debilitating symptoms or episodes that inhibit normal day-to-day function. Pervasive tools offer the possibility to help manage these conditions, particularly by helping people understand their conditions. But, it is unclear how to design these tools, as prior designs have focused on effortful tracking and many see those tools as a burden to use. We report here on an interview study with 12 individuals with chronic illnesses who collect personal data. We learn that these people are motivated through self-discovery and curiosity. We explore how these concepts may support the design of tools that engage curiosity and encourage self-discovery, rather than emphasize the behaviour change aspect of chronic illness management.","Simulation Model of Knowledge Complexity in New Knowledge Transfer Performance ","Move Prediction in Go \u2013 Modelling Feature Interactions Using Latent Factors ","Reliable Self-assembly by Self-triggered Activation of Enveloped DNA TilesAlthough the design of DNA tiles has been optimised for efficient and specific self-assembly, assembly errors occur so often that applications for molecular computation remain limited. We propose the use of an enveloped tile consisting of a DX- base tile that carries a protec- tor tile to suppress erroneous tile assembly. The design of the enveloped tile promotes the dissociation of the protector tile from the base tile through a self-triggered activation process, which keeps the outputs of the base tile stay protected until both base tile inputs have bonded cor- rectly to the assembly. The enveloped tile design, the self-triggered acti- vation that removes the protector tile and preliminary modelling results are presented.","Teammate Relationships Improve Help-Seeking Behavior in an Intelligent Tutoring System ","Annotating Signs of Syntactic Complexity to Support Sentence SimplificationThis article presents a new annotation scheme for syntactic complexity in text which has the advantage over other existing syntactic annotation schemes that it is easy to apply, is reliable and it is able to encode a wide range of phenomena. It is based on the notion that the syntactic complexity of sentences is explicitly indicated by signs such as conjunctions, complementisers and punctuation marks. The article describes the annotation scheme developed to annotate these signs and evaluates three corpora containing texts from three genres that were annotated using it. Inter-annotator agreement calculated on the three corpora shows that there is at least \"substantial agreement\" and motivates directions for future work.","Feature evaluation for mobile applications: a design science approach based on evolutionary software prototypesThe success of mobile applications depends on the incorporation of key features specific to their intended use. This paper proposes a light-weight process model to facilitate the identification of key user interface features and key application logic features.#R##N##R##N#The iterative, incremental process model is aligned with design science research and is based on software product line engineering ideas. In each iteration several prototype variants are built and evaluated by the customer. Both construction and evaluation of prototypes are based on feature models.","Semantic Measures Based on RDF Projections: Application to Content-Based Recommendation Systems ","Searching blog sites with product reviewsRecently, buzz marketing sites gives the information that is useful for consumers and companies. They want to customer feedbacks of feeling and experience. However, the searched results contain huge numbers of commercial sites when user search review with traditional search engine. We search blog site that include review sentence. We need to decision whether document of blog site include review sentence. Thus we think that two process to decide blog site whether review blog site. The first process creates to data set for certain product that viewpoint feature word. In this paper, feature word is tow term in the evaluated perspective word and evaluated value word. Data set is information for making decision sentence whether review sentence. Second process is a search for review sentence. This process decided blog site whether review blog site. This process use extracted opinion tuples from one sentence of blog site document and created data set to decide sentence whether sentence is review sentence. This process decided review blog whether document of blog site include one and more review sentence. We proposed review blog site searching system that system have two process.","An Algebra of Causal ChainsIn this work we propose a multi-valued extension of logic programs under the stable models semantics where each true atom in a model is associated with a set of justifications, in a similar spirit than a set of proof trees. The main contribution of this paper is that we capture justifications into an algebra of truth values with three internal operations: an addition '+' representing alternative justifications for a formula, a commutative product '*' representing joint interaction of causes and a non-commutative product '.' acting as a concatenation or proof constructor. Using this multi-valued semantics, we obtain a one-to-one correspondence between the syntactic proof tree of a standard (non-causal) logic program and the interpretation of each true atom in a model. Furthermore, thanks to this algebraic characterization we can detect semantic properties like redundancy and relevance of the obtained justifications. We also identify a lattice-based characterization of this algebra, defining a direct consequences operator, proving its continuity and that its least fix point can be computed after a finite number of iterations. Finally, we define the concept of causal stable model by introducing an analogous transformation to Gelfond and Lifschitz's program reduct.","Clustering of gene expression profiles applied to marine researchThis work presents the results of applying two clustering techniques to gene expression data from the mussel Mytilus galloprovincialis. The objective of the study presented in this paper was to cluster the different genes involved in the experiment, in order to find those most closely related based on their expression patterns. A self-organising map (SOM) and the k-means algorithm were used, partitioning the input data into nine clusters. The resulting clusters were then analysed using Gene Ontology (GO) data, obtaining results that suggest that SOM clusters could be more homogeneous than those obtained by the k-means technique.","In-Memory basierte Real-Time Supply Chain PlanungVeranderte produktionslogistische Rahmenbedingungen und neue Ziele im Supply Chain Management (SCM) erfordern ein Redesign aktueller Supply Chain Planning (SCP)-Systeme. In-Memory-basierte betriebliche In- formationssysteme bieten viele Vorteile und konnen bei der Definition neuer SCM-Systeme zugrunde gelegt werden. Allerdings sind noch Defizite in der Datenorganisation und den User Interfaces zu uberwinden sowie Geschaftspro- zesse anzupassen. Basierend auf den Erfahrungen aus mehreren Forschungspro- jekten und den dort praktisch realisierten Demonstratoren werden die Eigen- schaften von Real-Time-SCP-Losungen definiert und anhand des Sales and Operations Planning (SOP)-Prozesses Perspektiven zur Uberwindung bestehen- der Defizite aufgezeigt.","Unified modeling language: the teen years and growing painsUnified Modeling Language (UML) is adopted by the Object Management Group as a standardized general-purpose modeling language for object-oriented software engineering. Despite its status as a standard, UML is still in a development stage and many studies have highlighted its weaknesses and challenges - including those related to human factor issues. Further, UML has grown considerably more complex since its inception. This paper traces the history of Unified Modeling Language (UML) from its formation to its current state and discusses the current state of the UML language. The paper first introduces UML and its various diagrams, and discusses its characteristics and features. The paper then looks at UML's strengths, challenges, and possible future development. The human factor issues with using UML are discussed and elaborated. Potential research questions related to UML are also highlighted.","Decentralised Cooperative Agent-Based Clustering in Intelligent Traffic CloudsContemporary traffic management systems will become more intelligent with advent of future Internet technologies. The systems are expected to become more simple, effective and comfortable for users, but this transformation will require the development of both new system architectures as well as enhanced processing and mining algorithms for large volumes of cloud data. In this study, we consider a conceptual ar- chitecture of a cloud-based traffic management system that applied to a multi-modal journey planning scenario. For this purpose, it is necessary to process large amounts of travel-time information. Information is col- lected by cloud service providers and processed for future route planning. In this paper, we focus on the data clustering step in the data mining process. The data collection and processing require an appropriate clus- tering algorithm to aggregate similar data. In particular, we support a process where a particular service provider can request additional infor- mation from others to be used in the clustering function, requiring a decentralised clustering algorithm. We present a cloud- based architec- ture for this scenario, develop a decentralised cooperative kernel-density based clustering algorithm, and evaluate the efficiency of the proposed approach using real-world traffic data from Hanover, Germany.","Recombination Operators in Genetic Algorithm \u2013 Based Crawler: Study and Experimental Appraisal ","Planning of relocation staff operations in electric vehicle sharing systemsThis paper designs a computerized operation planner for relocation staffs in electric vehicle sharing systems, in which uneven vehicle distribution can lead to severe service quality degradation. After relocation pairs are created based on the target vehicle distribution and vehicle-to-station matching, our scheme finds an operation sequence for a relocation team. To overcome the time complexity of the ordering problem, a genetic algorithm is developed. It encodes a relocation schedule based on numbering of relocation pairs, defines a fitness function accounting for the inter-relocation move, and finally tailors genetic operators. The performance measurement result obtained from a prototype implementation shows that the proposed scheme finds an efficient schedule having a converged fitness value with just small-size population. The difference in relocation distance does not go beyond 24.8 % even in the case of extremely unbalanced distribution for the given parameters.","Industrial scientific software: a set of interviews on software developmentAn ethnographic study is used to explore activities carried out by industrial scientists to successfully develop their software. The extremely rich data set that resulted helps paint a picture of their development context. Apparent are the mismatches between software development methods commonly described by the software engineering community and the practices successfully used by the industrial scientists. Instead of following any type of prescribed method, the scientists follow what has been described as an amethodical approach to software development. Acceptance of the validity of this approach could provide an important alternative to how we currently view software development.","ME VS . CYBER -ME - ANALYZING THE EFFECTS OF PERCEIVED STIGMA OF PHYSICALLY DISABLED PEOPLE ON THE DISGUISE OF THE REAL SELF IN VIRTUAL ENVIRONMENTSSeveral studies reveal the option to disguise a disability in online interaction, but none sufficiently analyzes the various factors contributing to a disguise. The primary aim of this paper is to quantify the impact of social psychological factors like stigma consciousness (i.e. expectation of prejudice and discrimination in social interaction) and self-consciousness on the disguise of the real self in online environments among people with physical disabilities. This paper uses data from an online survey with 130 participants to construct a conceptual model related to these factors. Findings reveal that stigma consciousness positively impacts the disguise of the real self. While the body and a physical disability may not be present in the online environment, it plays an important role in how people with disabilities present themselves when they expect stigmatization.","Effects of Neutralization Techniques and Rational Choice Theory on Internet Abuse in the Workplace ","A Prediction Algorithm for Real-Time Video Traffic Based on Wavelet PacketLong-term prediction is a key problem in real-time video traffic ap- plications. Most of real-time video traffic belong to VBR traffic and has specif- ic properties such as time variation, non-linearity and long range dependence. In this paper, feature extraction method of real-time video traffic based on multi- scale wavelet packet decomposition is proposed. On this basis, LMS algorithm is adopted to predict wavelet coefficients. Through reverse wavelet transforms of the predicted wavelet coefficients, the long-term prediction of real-time vid- eo traffic is realized. Numerical and simulation results show that this long-term prediction algorithm can accurately track the variation trend of video signal and obtain an excellent prediction result.","A study of information management in the patient surgical pathway in NHSScotland.We conducted a study of information management processes across the patient surgical pathway in NHSScotland. While the majority of general practitioners (GPs) consider electronic medical records systems as an essential and integral part of their work during the patient consultation, many were not fully satisfied with the functionalities of these systems. A majority of GPs considered that the national eReferral system streamlined referral processes. Almost all GPs reported marked variability in the quality of discharge information. Preoperative processes vary significantly across Scotland, with most services using paper-based systems. Insufficient use is made of information provided through the patient electronic referral leading to a considerable duplication of tasks already performed in primary care. Three health-boards have implemented electronic preoperative information systems. These have transformed clinical practices and facilitated communication and information-sharing among the multi-disciplinary team and within the health-boards. Substantial progress has been made towards improving information transfer and sharing within the surgical pathway in recent years. However, there remains scope for further improvements at the interface between services.","C.S. Peirce and Artificial Intelligence: Historical Heritage and (New) Theoretical Stakes* Abstract. This paper presents some points of proximity between Peirce's insights on the technical/artificial nature of cognition, and contemporary theories of ex- tended cognition. By doing so, it sheds some new light on the possible relevance of Peirce's philosophical approach for artificial intelligence, notably regarding the differences between the reasoning abilities of machines and those of humans. Precisely how much of the business of thinking a machine could possibly be made to perform, and what part of it must be left for the living mind, is a question not without conceivable practical importance; the study of it can at any rate not fail to throw needed light on the nature of the reasoning process. Peirce, (15:165)","Regional Effects on Query Reformulation PatternsThis paper describes an in-depth study of the effects of geographic region on search patterns; particularly query reformulations, in a large query log from the UK National Archives (TNA). A total of 1,700 sessions involving 9,447 queries from 17 countries were manually analyzed for their semantic composition and pairs of queries for their reformulation type. Results show country-level variations for the types of queries commonly issued and typical patterns of query reformulation. Understanding the effects of regional differ- ences will assist with the future design of search algorithms at TNA as they seek to improve their international reach.","Analysis of Semantic Content and Its Relation to Team Neurophysiology during Submarine Crew Training ","Building Expert Recommenders from Email-Based Personal Social Networks ","Automatic Fall Detection System with a RGB-D Camera using a Hidden Markov ModelFalls in the elderly is a major public health problem because of their frequency and their medical and social consequences. New smart assistive technologies and Health Telematics make it possible to provide elderly with more security and well being at home. A smart home can automatically monitor home activities for early warning in health changes or detecting dangerous situations. One of our objectives is to design an automatic system to detect fall at home, which in its final version will be made up of a network of RGB-D sensors. In this paper, we present a simple and robust method based on the identification and tracking of the center of mass of people evolving in an indoor environment. Using a simple Hidden Markov Model whose observations are the position of the center of mass, its velocity and the general shape of the body, we can surprisingly monitor the activity of a person with high accuracy and thus detect falls with very good accuracy without false positives. An experimental study, that is reported here, has been driven in our smart apartment lab. 26 subjects were asked to perform a predefined scenario in which they realized a set of eight postures. 2 hours of video (216 000 frames) were recorded for the evaluation, half of it being used for the training of the model. The system detected the falls without false positives. This result encourages us to use this system in real situation for a better study of its efficiency.","A game theory based approach for community detection in social networksThe attribute information of individuals, such as occupation, skill, faith, hobbies and interests, etc, and the structure information amongst individuals, such as mutual relationships between individuals, are two key aspects of information that are used to study individuals and communities in social networks. Considering only the attribute information or the structure relationship alone is insufficient for determining meaningful communities. In this paper, we report an on-going study, we propose an approach that incorporates the structure information of a network and the attribute information of individuals by cooperative games, and game theory is introduced to support strategic decision making in deciding how to recognize communities in social networks, such networks are featured by large number of members, dynamic and with varied ways of connections. This approach provides a model to rationally and logically detect communities in social networks. The Shapley Value in cooperative games is adopted to measure the preference and the contribution of individuals to a specific topic and to the connection closeness of a coalition. We then proposed an iterative formula for computing the Shapley Value to improve the computation efficiency, related theoretical analysis has also been performed. Finally, we further developed an algorithm to detect meaningful communities.","Supporting Career Counseling with User Modeling and Job Matching ","Critical Path-Based Iterative Heuristic for Workflow Scheduling in Utility and Cloud ComputingThis paper considers the workflow scheduling problem in utility and cloud computing. It deals with the allocation of tasks to suitable resources so as to minimize total rental cost of all resources while maintaining the precedence constraints on one hand and meeting workflow deadlines on the other. A Mixed Integer programming MILP model is developed to solve small-size problem instances. In view of its NP-hard nature, a Critical Path-based Iterative CPI heuristic is developed to find approximate solutions to large-size problem instances where the multiple complete critical paths are iteratively constructed by Dynamic Programming according to the service assignments for scheduled activities and the longest cheapest services for the unscheduled ones. Each critical path optimization problem is relaxed to a Multi-stage Decision Process MDP problem and optimized by the proposed dynamic programming based Pareto method. The results of the scheduled critical path are utilized to construct the next new critical path. The iterative process stops as soon as the total duration of the newly found critical path is no more than the deadline of all tasks in the workflow. Extensive experimental results show that the proposed CPI heuristic outperforms the existing state-of-the-art algorithms on most problem instances. For example, compared with an existing PCP partial critical path based algorithm, the proposed CPI heuristic achieves a 20.7% decrease in the average normalized resource renting cost for instances with 1,000 activities.","Towards Answer Set Programming with SortsExisting ASP languages lack support for conveniently specifying objects, their sorts and the sorts of the parameters of relations in an application domain. However, such support may allow a programmer to better structure the program, to automatically determine some syntax and semantic errors and to avoid thinking about safety of ASP rules -- non-declarative conditions on rules required by existing ASP systems. In this paper, we define the syntax and semantics of a knowledge representation language    $\\mathcal{SPARC}$    which offers explicit constructs to specify objects, relations, and their sorts. The language expands CR-Prolog -- an extension of ASP by consistency restoring rules. We introduce an implementation of    $\\mathcal{SPARC}$    based on its translation to DLV with weak constraints. A syntax checking algorithm helps to avoid errors related to misspellings as well as simple type errors. Another type checking algorithm flags program rules which, due to type conflicts, have no ground instantiations.","Presenting a fire alarm using natural language: the communication of temporal informationLanguage comprehension is an important issue in fire alarm systems. This study focuses on the expression of temporal information in a fire situation. Both absolute time and relative time were designed to compare the expression types of temporal information. The time sequence and spatial sequence were designed to explore the expressions of a complicated fire that has more than one point of origin. A 5-point Likert scale and ranking task were used to evaluate the comprehensibility of different presentation forms. The results show that using absolute time to describe the point of origin of the fire and its spreading state aided better comprehension. The mechanism and potential reasons are also discussed. In addition, some suggestions for future designs of fire alarm systems are proposed.","Differential l\u00e9vy-flights bat algorithm for minimization makespan in permutation flow shopsThe permutation flow shop problem (PFSP) is an NP-hard problem with wide engineering and theoretical background. In this paper, a differential Levy-flights bat algorithm (DLBA) is proposed to improve basic bat algorithm for PFSP. In DLBA, LOV rule is introduced to convert the continuous position in DLBA to the discrete job permutation, the combination of NEH heuristic and random initialization is used to initialize the population with certain quality and diversity, and a virtual population neighborhoods search is used to enhance the global optimal solution and help the algorithm to escape from local optimal. Experimental results and comparisons show the effectiveness of the proposed DLBA for PFSP.","Curriculum Optimization by Correlation Analysis and Its Validation ","Using Linked Data to Evaluate the Impact of Research and Development in Europe: A Structural Equation ModelEurope has a high impact on the global biomedical literature, having contributed with a growing number of research articles and a significant citation impact. However, the impact of research and development generated by European countries on economic, educational and healthcare performance is poorly understood. The recent Linking Open Data (LOD) project has made a lot of data sources publicly available and in human-readable formats. In this paper, we demonstrate the utility of LOD in assessing the impact of Research and Development (R&amp;D) on the economic, education and healthcare performance in Europe. We extract relevant variables from two LOD datasets, namely World Bank and Eurostat. We analyze the data for 20 out of the 27 European countries over a span of 10 years (1999 to 2009). We use a Structural Equation Modeling (SEM) approach to quantify the impact of R&amp;D on the different measures. We perform different exploratory and confirmatory factorial analysis evaluations which gives rise to four latent variables that are included in the model: (i) Research and Development (R&amp;D), (ii) Economic Performance (EcoP), (iii) Educational Performance (EduP), (iv) Healthcare performance (HcareP) of the European countries. Our results indicate the importance of R&amp;D to the overall development of the European educational and healthcare performance (directly) and economic performance (indirectly). The results also shows the practical applicability of LOD to estimate this impact.","Bacteria-inspired magnetic polymer composite microrobotsRemote-controlled swimming microrobots are promising tools for future biomedical applications. Magnetically actuated helical microrobots that mimic the propulsion mechanism of E. coli bacteria are one example, and presented here is a novel method to fabricate such microrobots. They consist of a polymer-nanoparticle composite, which is patterned using a direct laser writing tool. The iron-oxide nanoparticles respond to the externally applied low-strength rotating magnetic field, which is used for the actuation of the microrobots. It is shown that a helical filament can be rotated around its axis without the addition of a body part and without structuring the magnetization direction of the composite. The influence of the helicity angle on the swim behavior of the microrobots is examined and experimental results show that a small helicity angle of 20 degrees is preferred for weakly magnetized microstructures.","Experimental Evaluation of a Process Benchmarking Tool in a Green Business Process Management ContextUsing a combination of metamodels, ontologies, green performance indicators and metrics, we apply a novel approach in Semantic Business Pro- cess Benchmarking to the area of Green Business Process Management (Green BPM). Up to now, process benchmarking has mainly been a manual process; the approach described and empirically evaluated in this paper partially auto- mates the time-consuming and costly process analyses while introducing more flexibility regarding varying terminology, level of abstraction and modeling no- tation. Also, overviews of literature relevant to the field of Green Semantic BPM and commonly applied metrics in a Green BPM context are given.","Comparison of gene co-expression networks and bayesian networksInferring genetic networks is of great importance in unlocking gene behaviour, which in turn provides solutions for drug testing, disease resistance, and many other applications. Dynamic network models provide room for handling noisy or missing prelearned data. This paper discusses how Dynamic Bayesian Networks compare against coexpression networks as discussed by Zhang and Horvath [1]. These shall be tested out on the genes of yeast Saccharomyces cerevisiae. A method is then proposed to get the best out of the strengths of both models, namely, the causality inference from Bayesian networks and the scoring method from a modified version of Zhang and Horvath's method.","Modeling the structure of recommending interfaces with adjustable influence on usersRecommending interfaces are usually integrated with marketing processes and are targeted to increasing sales with the use of persuasion and influence methods to motivate users to follow recommendations. In this paper is presented an approach based on decomposition of recommending interface into elements with adjustable influence levels. A fuzzy inference model is proposed to represent the system characteristics with the ability to adjust the parameters of the interface to acquire results and increase customer satisfaction.","Practice and Usage-Oriented Service Adaptation: An Integrated Design Method for Collaborative Work in Construction ProjectsPractitioners of the construction sector require improved Information Technology IT Services to support their collaborative work. In usual service design processes, business experts gather requirements and collaborate with designers e.g. Software Engineers or HCI experts through modeling phases to develop adapted solutions. Our main hypothesis is that improving modeling and mapping of these different perspectives will enhance such service's design processes. Based on the analysis of parallel research fields, this paper addresses this issue, and proposes a method to adapt IT-supported services to business practices. This method is based on a structured approach aiming at 1 identifying Collective Practices, 2 focusing on actors' Individual Practices and Operations, 3 distinguishing different technology-related Usages and finally 4 selecting or designing adapted IT services relying on previous analysis. An example based on sustainable project practices illustrates the approach.","Automatic User-Specific Avatar Parametrisation and Emotion MappingIn this paper an approach for automatic user-specific 3D model generation and expression classification is proposed. User performance-driven avatar animation is recently in the focus of research due to the increasing amount of low-cost acquisition devices with integrated depth map computation. Thereby challenging is the user-specific emotion classification without a complex manual initial step. Correct classification and emotion intensity identification can only be done with known expression specific facial feature displacement which differs from user to user. The use of facial feature tracking on predefined 3D model expression animations is presented here as solution statement for automatic emotion classification and intensity calculation. Consequently with this approach partial occlusions of a presented emotion do not hamper expression identification based on the symmetrical structure of human faces. Thus, a markerless, automatic and easy to use performance-driven avatar animation approach is presented.","Error Detection and Correction of Gene Trees ","Improving Probabilistic Image Registration via Reinforcement Learning and Uncertainty EvaluationOne framework for probabilistic image registration involves assigning probability distributions over spatial transformations (e.g. distributions over displacement vectors at each voxel). In this paper, we propose an uncertainty measure for these distributions that examines the actual spatial displacements, thus departing from the classical Shannon entropy-based measures, which examine only the probabilities of these distributions. We show that by incorporating the proposed uncertainty measure, along with features extracted from the input images and intermediate displacement fields, we are able to more accurately predict the pointwise registration errors of an intermediate solution as estimated for a previously unseen input image pair. We utilize the predicted errors to identify regions in the image that are trustworthy and through which we refine the tentative registration solution. Results show that our proposed framework, which incorporates uncertainty estimation and registration error prediction, can improve accuracy of 3D image registrations by about 25%.","Hyperelastic susceptibility artifact correction of DTI in SPM\u00a9 Springer-Verlag Berlin Heidelberg 2013.Echo Planar Imaging (EPI) is a MRI acquisition technique that is the backbone of widely used investigation techniques in neuroscience like, e.g., Diffusion Tensor Imaging (DTI). While EPI offers considerable reduction of the acquisition time one major drawback is its high sensitivity to susceptibility artifacts. Susceptibility differences between soft tissue, bone and air cause geometrical distortions and intensity modulations of the EPI data. These susceptibility artifacts severely complicate the fusion of micro-structural information acquired with EPI and conventionally acquired structural information. In this paper, we introduce a new tool for hyperelastic susceptibility correction of DTI data (HySCO) that is integrated into the Statistical Parametric Mapping (SPM) software as a toolbox. Our new correction pipeline is based on two datasets acquired with reversed phase encoding gradients. For the correction, we integrated the variational image registration approach by Ruthotto et al. 2007 into the SPM batch mode. We briefly review the model, discuss involved parameter settings and exemplarily demonstrate the effectiveness of HySCO on a human brain DTI dataset.","Shaping an integrating kitchen space with gesture-based control systemThis article provides a summary of research into the integrating kitchen design: a kitchen designed for simultaneous use by people with mobility problems, including wheelchair bound persons as well as able-bodied people. By introducing mobile gesture controlled modules into kitchen furniture it is possible to dynamically adjust furniture for use in seating or standing positions. An important aspect of research problem is such location of elements which would optimize the simultaneous use of kitchen by two persons: able-bodied and disabled.","MicroFilter: real time filtering of microblogging contentMicroblogging systems have become a major trend over the Web. After only 7 years of existence, Twitter for instance claims more than 500 million users with more than 350 billion delivered update each day. As a consequence the user must today manage possibly extremely large feeds, resulting in poor data readability and loss of valuable information and the system must face a huge network load. In this demonstration, we present and illustrate the features of MicroFilter (MF in the the following), an inverted list-based filtering engine that nicely extends existing centralized microblogging systems by adding a real-time filtering feature. The demonstration proposed illustrates how the user experience is improved, the impact on the traffic for the overall system, and how the characteristics of microblogs drove the design of the indexing structures.","Approximation of Large Probabilistic Networks by Structured Population Protocols ","Sensitivity of the Solution Set to Second Order Evolution InclusionsIn this note we study second order evolution inclusions in the framework of evolution triple of spaces. The existence of mild solutions (i.e. trajectory-selection pairs) to the inclusion, and the upper and lower semicontinuity properties of the solution set with respect to a parameter are established.","The Design and Development of Object-Oriented UAV Image Change Detection System ","Dominance Driven SearchRecently, a generic method for identifying and exploiting dominance relations using dominance breaking constraints was proposed. In this method, sufficient conditions for a solution to be dominated are identified and these conditions are used to generate dominance breaking constraints which prune off the dominated solutions. We propose to use these dominance relations in a different way in order to boost the search for good/optimal solutions. In the new method, which we call dominance jumping, when search reaches a point where all solutions in the current domain are dominated, rather than simply backtrack as in the original dominance breaking method, we jump to the subtree which dominates the current subtree. This new strategy allows the solver to move from a bad subtree to a good one, significantly increasing the speed with which good solutions can be found. Experiments across a range of problems show that the method can be very effective when the original search strategy was not very good at finding good solutions.","When classification becomes a problem: using branch-and-bound to improve classification efficiencyIn a typical machine learning classification task there are two phases: training and prediction. This paper focuses on improving the efficiency of the prediction phase. When the number of classes is low, linear search among the classes is an efficient way to find the most likely class. However, when the number of classes is high, linear search is inefficient. For example, some applications such as geolocation or time-based classification might require millions of subclasses to fit the data. Specifically, this paper describes a branch-and-bound method to search for the most likely class where the training examples can be partitioned into thousands of subclasses. To get some idea of the performance of branch-and-bound classification, we generated a synthetic set of random trees comprising billions of classes and evaluated branch-and-bound classification. Our results show that branch-and-bound classification is effective when the number of classes is large. Specifically, branch-and-bound improves search efficiency logarithmically.","Algorithms for Testing Length Four Permutations ","Facility Use-Choice Model with Travel Costs Incorporating Means of Transportation and Travel Direction ","Who Benefits from Confusion Induction during Learning? An Individual Differences Cluster AnalysisRecent research has indicated that learning environments that intentionally induce confusion to promote deep inquiry can be beneficial for learning if students engage in confusion resolution processes and if relevant scaffolds are provided. However, it is unlikely that these environments will benefit all students, so it is necessary to identify the student profiles that most benefit from confusion induction. We investigated how individual differences (e.g., prior knowledge, interest, attributional complexity) impacted confusion and learning outcomes in an environment that induced confusion via false system feedback (e.g., negative feedback after a correct response). A k-means cluster analysis revealed four clusters that varied on cognitive ability and cognitive drive. We found that students in the high cognitive ability + high cognitive drive cluster reported more confusion after receiving false feedback compared to the other clusters. These students also performed better on tasks requiring knowledge transfer, but only when they were meaningfully confused.","Allegories for Database ModelingAllegories are categories modeled upon the category of sets and binary relations where sets are objects and binary relations are morphisms composed using joins. In this paper we present a new conceptual data modeling formalism based on the language of allegories. We show that allegories provide more convenient framework for modeling data than more traditional categorical approaches in which arrows are interpreted as functional dependencies and in which many to many or partial relationships have to be represented as spans. Finally, we demonstrate that by using allegories different than the allegory of sets and binary relations, for example the allegory of sets and lattice valued relations, one can model replicated data or data stored in a valid time temporal database.","Future Deployment of Technology in Healthcare Services - A Delphi ApproachIn an economy with a fast growing demand for services, productivity and innovation become crucial for the survival of service companies. In order to keep up with the change, these companies have to adopt new technologies in the service deployment. Also the healthcare industry is faced with a shift towards modern technology usage and personal services. However, due to budget restrictions, investments in new technologies have to be well considered and guarantee a swift return of investment and increase in productivity. In this paper, empirical results from different industries are presented. A Delphi study is used to get an outlook of the technology usage in the health and care provision industry. Therefore hypotheses are analyzed in detail to show possible impacts for the future. The results provide information about the significance of technology deployment for services and the potentials and barriers which go along with it in the healthcare business.","Enhanced Training for Cyber Situational AwarenessA study was conducted in which participants received either tool-based or narrative-based training and then completed challenges associated with network security threats. Three teams were formed: (1) Tool-Based, for which each participant received tool-based training; (2) Narrative-Based, for which each participant received narrative-based training and (3) Combined, for which three participants received tool-based training and two received narra- tive-based training. Results showed that the Narrative-Based team recognized the spatial-temporal relationship between events and constructed a timeline that was a reasonable approximation of ground truth. In contrast, the Combined team produced a linear sequence of events that did not encompass the relation- ships between different adversaries. Finally, the Tool-Based team demonstrated little appreciation of either the spatial or temporal relationships between events. These findings suggest that participants receiving Narrative-Based training were able to use the software tools in a way that allowed them to gain a greater level of situation awareness.","Combining Evidence and Meta-analysis in Software Engineering*/-)\ufffd */.)\ufffd *//)\ufffd +)))\ufffd */,.\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd #\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd$ \ufffd\ufffd \ufffd\ufffd!\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd#\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd$\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd!\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd&amp;\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd!\ufffd\ufffd!\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd !\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd%\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd!\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd$\ufffd\"(\ufffd\ufffd%\ufffd\ufffd\ufffd)\ufffd\"\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd$\ufffd\ufffd\ufffd \ufffd\ufffd$\ufffd\"(\ufffd\ufffd%\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd$ \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd#\ufffd%\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd##'\ufffd#\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd$\"\ufffd\ufffd '\ufffd\ufffd\ufffd\ufffd\ufffd$\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd+#$\ufffd\ufffd\ufffd%\ufffd\ufffd\"\ufffd(\ufffd\ufffd) \ufffd \ufffd'\ufffd%/\ufffd\ufffd\ufffd$\"\ufffd\ufffd#$'\ufffd +\ufffd \ufffd+#$\ufffd\ufffd\ufffd%\ufffd\ufffd\"\ufffd(\ufffd\ufffd) \ufffd \ufffd'\ufffd%/\ufffd\ufffd\ufffd$\"\ufffd\ufffd#$'\ufffd +\ufffd \ufffd+#$\ufffd\ufffd\ufffd%\ufffd\ufffd\"\ufffd(\ufffd\ufffd) \ufffd \ufffd'\ufffd%/\ufffd\ufffd\ufffd$\"\ufffd\ufffd#$'\ufffd +\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd#\ufffd\"(\ufffd%\ufffd\ufffd\ufffd\ufffd\ufffd#$' \ufffd+\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd#\ufffd\"(\ufffd%\ufffd\ufffd\ufffd\ufffd\ufffd#$' \ufffd+\ufffd \ufffd\ufffd$\ufffd\" \"\ufffd%(\ufffd\ufffd#$'\ufffd+\ufffd \ufffd\ufffd\ufffd \ufffd\ufffd#\ufffd\"(\ufffd%\ufffd\ufffd\ufffd\ufffd\ufffd#$' \ufffd+\ufffd \ufffd\ufffd$\ufffd\" \"\ufffd%(\ufffd\ufffd#$'\ufffd+\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd$\"\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd$\"\ufffd \ufffd\ufffd\ufffd )\ufffd$\ufffd\ufffd\ufffd\"\ufffd\ufffd\ufffd%\ufffd\ufffd\"\ufffd# '\ufffd$#\ufffd \ufffd\ufffd\ufffd\ufffd\"\ufffd.\ufffd\ufffd\ufffd\"\ufffd#$'\ufffd +\ufffd \ufffd\ufffd/\"\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd#\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd$\"\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd$\"\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd#\ufffd\"\ufffd %(\ufffd\ufffd#$'\ufffd+\ufffd \ufffd\ufffd\ufffd'#\ufffd\ufffd\"\ufffd' \ufffd \ufffd\ufffd#\ufffd\"\ufffd %(\ufffd\ufffd#$'\ufffd+\ufffd \ufffd\ufffd%\ufffd\ufffd\ufffd\"\ufffd#\ufffd\ufffd\"\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\"\ufffd.\ufffd\ufffd\ufffd\"\ufffd#$'\ufffd +\ufffd \ufffd\ufffd\ufffd'#\ufffd\ufffd\"\ufffd' \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd#\ufffd\"\ufffd %(\ufffd\ufffd#$'\ufffd+\ufffd \ufffd\ufffd#\ufffd\ufffd#$'\ufffd+\ufffd \ufffd* \ufffd\"$\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\"\ufffd!'\ufffd\ufffd\ufffd$+\ufffd#$' \ufffd+\ufffd \ufffd\ufffd#\ufffd\ufffd#$'\ufffd+\ufffd \ufffd* \ufffd\"$\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\"\ufffd!'\ufffd\ufffd\ufffd$+\ufffd#$' \ufffd+\ufffd \ufffd\ufffd#\ufffd\ufffd#$'\ufffd+\ufffd \ufffd* \ufffd\"$\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\"\ufffd!'\ufffd\ufffd\ufffd$+\ufffd#$' \ufffd+\ufffd \ufffd#\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd#\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd#\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd#\ufffd\ufffd!\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd#\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd \ufffd\ufffd\ufffd\ufffd$\ufffd\ufffd\ufffd\ufffd!\ufffd\ufffd\ufffd\ufffd #\ufffd\ufffd!\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd# \ufffd\ufffd \ufffd\ufffd\ufffd\ufffd$\ufffd\ufffd\ufffd\ufffd!\ufffd\ufffd\ufffd\ufffd","Controlling bloat through parsimonious elitist replacement and spatial structureThe concept of bloat -- the increase of program size without a corresponding increase in fitness -- presents a significant drawback to the application of genetic programming. One approach to controlling bloat, dubbed spatial structure with elitism (SS+E), uses a combination of spatial population structure and local elitist replacement to implicitly constrain unwarranted program growth. However, the default implementation of SS+E uses a replacement scheme that prevents the introduction of smaller programs in the presence of equal fitness. This paper introduces a modified SS+E approach in which replacement is done under a lexicographic parsimony scheme. The proposed model, spatial structure with lexicographic parsimonious elitism (SS+LPE), exhibits an improvement in bloat reduction and, in some cases, more effectively searches for fitter solutions.","Preserving the User's Privacy in Social Networking SitesIn the last years, social networking sites SNSs have enjoyed an undeniable success. Those web platforms have huge quantities of active users sharing lots of information everyday. Usually, user-generated content may be almost innocuous, however, some studies have shown that it may also contain very sensitive personal data. This situation may pose a serious privacy threat to the users due to the fact that third parties can gather and exploit that knowledge for their own benefit. There are some proposals in the literature that try to address this situation. Nevertheless, they fail to provide a practical solution capable of working with well-known SNSs. In this paper, we propose a new scheme that fills this gap. More specifically, we present a privacy-preserving system that enables the users to decide which individuals e.g., other users, third parties or even the SNS itself can access to their user profiles. We have implemented our scheme to be used by Facebook users. We have run some tests with our prototype and the results show that the added overhead is affordable.","Uncovering the etiology of autism spectrum disorders: genomics, bioinformatics, environment, data collection and exploration, and future possibilities.A clear and predictive understanding of the etiology of autism spectrum disorders (ASD), a group of neurodevelopmental disorders characterized by varying deficits in social interaction and communication as well as repetitive behaviors, has not yet been achieved. There remains active debate about the origins of autism, and the degree to which genetic and environmental factors, and their interplay, produce the range and heterogeneity of cognitive, developmental, and behavioral features seen in children carrying a diagnosis of ASD. Unlocking the causes of these complex developmental disorders will require a collaboration of experts in many disciplines, including clinicians, environmental exposure experts, bioinformaticists, geneticists, and computer scientists. For this workshop we invited prominent researchers in the field of autism, covering a range of topics from genetic and environmental research to ethical considerations. The goal of this workshop: provide an introduction to the current state of autism research, highlighting the potential for multi-disciplinary collaborations that rigorously evaluate the many potential contributors to ASD. It is further anticipated that approaches that successfully advance the understanding of ASD can be applied to the study of other common, complex disorders. Herein we provide a short review of ASD and the work of the invited speakers.","Power dynamics in spoken interactions: a case study on 2012 republican primary debatesIn this paper, we explore how the power differential between participants of an interaction affects the way they interact in the context of political debates. We analyze the 2012 Republican presidential primary debates where we model the power index of each candidate in terms of their poll standings. We find that the candidates' power indices affected the way they interacted with others in the debates as well as how others interacted with them.","Analysis of Advertisement based Business Model under Technological Advancements in Fair Use Personal Recording Services: A Law and Economics Approach ","Latent Class Models of Time Series Data: An Entropic-Based Uncertainty Measure ","A Dog Tail for Utility Robots: Exploring Affective Properties of Tail Movement ","The Object Memory Server for Semantic Product Memories ","Motion Event in Croatian, English, German and Italian Concerning Path Prefixes and Prepositions ","The Influence of Social Media Use on Willingness to Share Location InformationWillingness to share personal information is a strong indication of trust in persons and confidence in institutions. Mobile phones, high connectivity, and social media have opened up new ways of sharing personal information, and many are using these possibilities eagerly. Here we present results from a study on how social media use influences people's willingness to share location and other personal information. We conducted a survey about willingness to share and in addition ran an experiment where the treatment was use of Foursquare, a location-oriented social medium. The analysis shows that frequent social media users are more inclined to share location and other personal information than others. The difference varies, as they are not much more willing to share location information with persons, but more willing to share with social media and other institutions. Frequent users seem to have more confidence in institutions, both public and commercial, and are more willing to share location in exchange for location oriented services. A main finding is that the experience with social media itself is an important cause for the increased confidence.","Automatic Generation of SPL Structurally Valid Products Using Graph Transformations Approach ","Three-Way Decisions in Dynamic Decision-Theoretic Rough SetsIn the previous decision-theoretic rough sets DTRS, its loss function values are constant. This paper extends the constant values of loss functions to a more realistic dynamic environment. Considering the dynamic change of loss functions in DTRS with the time, an extension of DTRS, dynamic decision-theoretic rough sets DDTRS is proposed in this paper. An empirical study of climate policy making validates the reasonability and effectiveness of the proposed model.","Inferring human phenotype networks from genome-wide genetic associationsNetworks are commonly used to represent and analyze large and complex systems of interacting elements. We build a human phenotype network (HPN) of over 600 physical attributes, diseases, and behavioral traits; based on more than 6,000 genetic variants (SNPs) from Genome-Wide Association Studies data. Using phenotype-to-SNP associations, and HapMap project data, we link traits based on the common patterns of human genetic variations, expanding previous studies from a gene-centric approach to that of shared risk-variants. The resulting network has a heavily right-skewed degree distribution, placing it in the scale-free region of the network topologies spectrum. Additional network metrics hint that the HPN shares properties with social networks. Using a standard community detection algorithm, we construct phenotype modules of similar traits without applying expert biological knowledge. These modules can be assimilated to the disease classes. However, we are able to classify phenotypes according to shared biology, and not arbitrary disease classes. We present a collection of documented clinical connections supported by the network. Furthermore, we highlight phenotypes modules and links that may underlie yet undiscovered genetic interactions. Despite its simplicity and current limitations the HPN shows tremendous potential to become a useful tool both in the unveiling of the diseases' common biology, and in the elaboration of diagnosis and treatments.","Practical Context-Aware Permission Control for Hybrid Mobile ApplicationsThe rapid growth of mobile computing has resulted in the development of new programming paradigms for quick and easy development of mobile applications. Hybrid frameworks, such as PhoneGap, allow the use of web technologies for development of applications with native access to device's resources. These untrusted third-party applications desire access to user's data and device's resources, leaving the content vulnerable to accidental or malicious leaks by the applications. The hybrid frameworks present new opportunities to enhance the security of mobile platforms by providing an application-layer runtime for controlling an application's behavior.#R##N##R##N#In this work, we present a practical design of a novel framework, named MobileIFC, for building privacy-preserving hybrid applications for mobile platforms. We use information flow models to control what untrusted applications can do with the information they receive. We utilize the framework to develop a fine-grained, context-sensitive permission model that enables users and application developers to specify rich policies. We show the viability of our design by means of a framework prototype. The usability of the framework and the permission model is further evaluated by developing sample applications using the framework APIs. Our evaluation and experience suggests that MobileIFC provides a practical and performant security solution for hybrid mobile applications.","The green brain project --- developing a neuromimetic robotic honeybeeThe development of an 'artificial brain' is one of the greatest challenges in artificial intelligence, and its success will have innumerable benefits in many and diverse fields, including the creation of autonomous robotic agents. Most research effort is spent on modelling vertebrate brains. Yet smaller brains can display comparable cognitive sophistication, while being more experimentally accessible and amenable to modelling.","WidgetLens: a system for adaptive content magnification of widgetsOn displays with high pixel densities or on mobile devices and due to limitations in current graphical user interface toolkits, content can appear (too) small and be hard to interact with. We present WidgetLens, a novel adaptive widget magnification system, which improves access to and interaction with graphical user interfaces. It is designed for usage of unmodified applications on screens with high pixel densities, remote desktop scenarios, and may also address some situations with visual impairments. It includes a comprehensive set of adaptive magnification lenses for standard widgets, each adjusted to the properties of that type of widget. These lenses enable full interaction with content that appears too small. We also present several extensions.","Under the table: tap authentication for smartphonesCurrent smartphone authentication methods are known to be susceptible to even rudimentary attacks based on observation. In this paper, we propose an approach to authentication based on rich tapping patterns that addresses this problem. We present a novel tapping detection technique, using a single example as a template. We also report on two user studies (N = 30 and N = 19) where tapping authentication is compared to the leading alternatives, both in an \"out in the open\" and in an \"under the table\" condition. Results indicate that the tapping method approximates current standards of security and usability, but also affords inconspicuous authentication, thus allowing the user to self-protect in social settings.","Blue skies, impacts, and peer reviewThis paper describes the results of an on-line survey regarding the incorporation of societal impacts considerations into the peer review of grant proposals submitted to public science funding bodies. The survey investigated perceptions regarding the use of scientific peers to judge not only the intrinsic scientific value of proposed research, but also its instrumental value to society. Members of the scientific community have expressed - some more stridently than others - resistance to the use of such societal impact considerations. We sought to understand why. Results of the survey, based on a convenience sample of 428 participants (including individuals from four different funding agencies as well as non-academics), suggest that such resistance may be due to a lack of desire rather than a lack of confidence where judging impacts is concerned. In other words, it may be less that scientists feel unable to judge broader societal impacts and more that they are unwilling to do so.","The Current Landscape of Pitfalls in OntologiesA growing number of ontologies are already available thanks to development initiatives in many different#R##N#fields. In such ontology developments, developers must tackle a wide range of difficulties and handicaps,#R##N#which can result in the appearance of anomalies in the resulting ontologies. Therefore, ontology evaluation#R##N#plays a key role in ontology development projects. OOPS! is an on-line tool that automatically detects pitfalls,#R##N#considered as potential errors or problems, and thus may help ontology developers to improve their ontologies.#R##N#To gain insight in the existence of pitfalls and to assess whether there are differences among ontologies#R##N#developed by novices, a random set of already scanned ontologies, and existing well-known ones, data of 406#R##N#OWL ontologies were analysed on OOPS!\u2019s 21 pitfalls, of which 24 ontologies were also examined manually#R##N#on the detected pitfalls. The various analyses performed show only minor differences between the three sets#R##N#of ontologies, therewith providing a general landscape of pitfalls in ontologies.","Using Backward Induction Techniques in (Timed) Security Protocols VerificationThis paper shows a new way of automatic verification of properties of untimed and timed security protocols. To do this we use a modified version of previously introduced formal model based on a network of synchronized (timed) automata that expreses behaviour and distributed knowledge of users during pro- tocol executions. In our new approach we will use the backward induction method for searching of a tree of all real executions of an investigated protocol. Our ap- proach uses additionally the boolean encoding of constructed structures and SAT solvers for searching answers to the questions about investigated properties which are expressed as reachability or unreachability of undesired states in a considered model. We exemplify all our notions and formalisms on the well known NSPK, and show experimental results for checking authentication and security properties of a few untimed and timed protocols.","ReaderBench, an Environment for Analyzing Text Complexity and Reading StrategiesReaderBench is a multi-purpose, multi-lingual and flexible envi- ronment that enables the assessment of a wide range of learners' productions and their manipulation by the teacher. ReaderBench allows the assessment of three main textual features: cohesion-based assessment, reading strategies identification and textual complexity evaluation, which have been subject to empirical validations. ReaderBench covers a complete cycle, from the initial complexity assessment of reading materials, the assignment of texts to learners, the capture of metacognitions reflected in one's textual verbalizations and com- prehension evaluation, therefore fostering learner's self-regulation process.","Multi-Layer Mutually Reinforced Random Walk with Hidden Parameters for Improved Multi-Party Meeting Summarization ","Using facebook for collaborative academic activities in educationIn this article we will try to use the services of Facebook, in a controlled environment, so that teachers can carry out their teaching. From the educational point of view, Facebook provides a new starting point, collaborative work, from plugins development tailored to the needs of teachers in schools. And this requires to take into account the hierarchical structure and the distribution of groups and students in the center, and, to have a system to monitor the work of the students for assessment and grading. With the work proposed here, we do not intend to create a social network, conceived as \"Facebook\", but including a plugin that allows the use of \"Facebook\" like a Learning Management System (LMS). These features would make the social network \"Facebook\", offer collaborative services for members of the educational community, and compete with other applications, like Google Apps Education. Moreover, being a LMS in a collaborative and education environment, facilitate the management, rating and monitoring of student activities. The justification for this system comes from the high number of students and teachers who already have an account on the social network, and they are already used to their patterns of communication and interaction. This adaptation may allow greater use of Information and Communication Technologies (ICT) and government resources that have been allocated to the project Escuela 2.0.","Design of Efficient Reversible MultiplierReversible logic is emerging computing paradigm with applications in Ultra-low power Nano computing, quantum computing, Low power CMOS design, Optical Information Processing, Bioinformatics etc. In this paper, the 4x4 reversible multiplier circuit is proposed with the design of new reversible gate called RAM. The proposed multiplier circuit is efficient compared to the existing designs in terms of gate counts, garbage outputs, constant inputs and quantum cost. The design can be generalized to construct NxN reversible mul- tiplier circuit.","Author disambiguation in the YADDA2 software platform ","Innovations in visualizationWhile information is a crucial part of people's everyday lives, many people find that access to information via today's technologies is awkward, stressful, and overly intrusive in their lives. The problem is not with the information itself, but rather with its volume and the unwieldy ways currently provided for interacting with digital content. My research focus is to create interactive information visualizations so that they support people's everyday work and social practices as they interact with information. In this paper I will provide an eclectic overview of my research, particularly featuring the research done by my PhD students.","Estimation of the Environmental Impact on the Accuracy of Signal RecognitionThe problem of the random signals recognition system's adaptation to the variable environmental conditions is discussed. The constructive method that demonstrates possibilities to create recognition systems able to adapt to changing working conditions. The efficiency of the method is demonstrated by experiment analyzing the recognition of random signals in environments with different characteristics. The results demonstrate that the suggested method also can be useful in the development of the speech recognition devices operating in various environments.","Optimization of Adaptation - A Multi-objective Approach for Optimizing Changes to Design Parameters ","The Role of Gender and Age on User Preferences in Narrative ExperiencesStorytelling is interactivea-astorytellers seldom recite the same content, instead, they adapt the narrative to their audience. Storytellers both introduce new topics from time to time, and elaborate on the topics the audience has previously shown interest on. In our previous work, we created a digital storytelling system that simulates this process. The goal of this work is to investigate what is a good balance between the novel topics and the audience's existing interests. We conducted an empirical evaluation using our digital storytelling system. Distinct preferences were observed in relation to both age and gender, with women in general enjoying a more gradual shift in the presentation of novel material.","Use of Social Software in E-Business: A Cross-Sectional, Cross-Country StudySocial Software (SoS) is a term commonly used to describe a group of web based services that have capability to connect, disseminate information, network or blog. The popular SoS has created environments to attract millions of users and a favorable environment for businesses to exploit the benefit of having access to the users by adopting it as a business support tool. Studies indicate that SoS is being used by businesses for engaging with the general public, enhancing customer interaction and crisis communication. This paper analyses the status quo of the SoS use of enterprises from six countries and various industries in the context of e-business. The reported findings show that the surveyed enterprises mostly use the established SoS like Facebook and Twitter to engage with the customer but that there are also significant differences in SoS usage by country, industry and enterprise ranking.","Classification of Arrhythmia Types Using Cartesian Genetic Programming Evolved Artificial Neural Networks ","Feasible Joint Angle Continuous Function of Robotics Arm in Obstacles Environment Using Particle Swarm Optimization ","A linear method for determining intrinsic parameters from two parallel line-segmentsIn this paper, a linear method to determining intrinsic parameters from two parallel line-segments is proposed. Constrains based on the length ratio of line-segments are used to solve the camera calibration problem from images of two parallel line-segments under different conditions. And for each setting, we can get linear solution for intrinsic parameters of a usual camera. Simulated experiments are carried out to verify the theoretical correctness and numerical robustness of our results.","Tuning Cost Functions for Social NavigationHuman-Robot Interaction literature frequently uses Gaussian distributions within navigation costmaps to model proxemic constraints around humans. While it has proven to be effective in several cases, this approach is often hard to tune to get the desired behavior, often because of unforeseen interactions between different elements in the costmap. There is, as far as we are aware, no general strategy in the literature for how to predictably use this approach.#R##N##R##N#In this paper, we describe how the parameters for the soft constraints can affect the robot's planned paths, and what constraints on the parameters can be introduced in order to achieve certain behaviors. In particular, we show the complex interactions between the Gaussian's parameters and elements of the path planning algorithms, and how undesirable behavior can result from configurations exceeding certain ratios. There properties are explored using mathematical models of the paths and two sets of tests: the first using simulated costmaps, and the second using live data in conjunction with the ROS Navigation algorithms.","WHAT, I SHOULDN'T HAVE DONE THAT? : THE INFLUENCE OF TRAINING AND JUST-IN-TIME REMINDERS ON SECURE BEHAVIOROrganizations often implement Security Education, Training, and Awareness (SETA) programs to help improve secure behavior. SETA programs can be multifaceted; however, organizations often take a \u201cone-size-fits-all\u201d approach to improve security, without understanding how different SETA components influence behavior. In this research, we explain how two common SETA program components\u2014online training and reminders\u2014influence behavior through discrete theoretical mechanisms. First, we hypothesize that online training influences behavior through improving beliefs and intentions. However, because of dual-task interference, the relationship between beliefs and intentions may be hindered. We then explain how just-in-time reminders can help overcome dual-task interference and influence behavior directly. We test our hypotheses in a realistic experiment that operationalizes secure behavior as sensitive information disclosure. Our results confirm that training influences beliefs and intentions, and reminders influence behavior directly. Theoretical and practical implications are discussed regarding the use of multi-faceted SETA programs to improve actual secure behavior.","The Radiation Hybrid Map Construction Problem Is FPT ","Security-Informed Safety: If It\u2019s Not Secure, It\u2019s Not SafeTraditionally, safety and security have been treated as separate disciplines, but this position is increasingly becoming untenable and stakeholders are beginning to argue that if it\u2019s not secure, it\u2019s not safe. In this paper we present some of the work we have been doing on \u201csecurity-informed safety\u201d. Our approach is based on the use of structured safety cases and we discuss the impact that security might have on an existing safety case. We also outline a method we have been developing for assessing the security risks associated with an existing safety system such as a large-scale critical infrastructure.","Mining Query Logs of USPTO Patent ExaminersIn this paper we analyze a highly professional search setting of patent examiners of the United Patent and Trademark Office USPTO. We gain insight into the search behavior of USPTO patent examiners to explore ways for enhancing query generation in patent searching. We show that query generation is highly patent domain specific and patent examiners follow a strict scheme for generating text queries. Means to enhance query generation in patent search are to suggest synonyms and equivalents, co-occurring terms and keyword phrases to the searchable features of the invention. Further, we show that term networks including synonyms and equivalents can be learned from the query logs for automatic query expansion in patent searching.","Backhaul Topology Design and Weighted Max-Min Fair Capacity Allocation in Wireless Mesh Networks ","Expression Intensity Recognition Based on Multilayer Hybrid Classifier ","ViewS in User Generated Content for Enriching Learning Environments: A Semantic Sensing ApproachSocial user-generated content (e.g. comments, blogs) will play a key role in learning environments providing a rich source for capturing diverse viewpoints; and is particularly beneficial in ill-defined domains that encompass diverse interpretations. This paper presents Views - a framework for capturing viewpoints from user-generated textual content following a semantic sensing approach. It performs semantic augmentation using existing ontologies and presents the resultant semantic spaces in a visual way. Views was instantiated for interpersonal communication and validated in a study with comments on job interview videos, achieving over 82% precision. The potential of Views for enriching learning environments is illustrated in an exploratory study by analysing micro-blogging content collected within a learning simulator for interpersonal communication. A group interview with simulator designers evinced benefits for gaining insights into learner reactions and further simulator improvement.","Virtual Worlds as Platforms for Digital Entrepreneurship: The Role of Internal Governance and the Rule of LawBased on the principles of \u2018rule of law\u2019 this research-in-progress paper theorizes the key role of internal governance procedures within virtual worlds for promoting digital entrepreneurship. By fostering adequate trust, internal governance procedures within VWs, provide the requisite amount of certainty, transparency, predictability and legitimacy to the transactions carried out within the VWs. In summary, this research proposes a plausible framework for conceptualizing the adoption and diffusion of VWs as a platform for digital entrepreneurship.","Dynamic Channel Estimation over Fast Time-varying Channel for Vehicle Wireless CommunicationsIn vehicle wireless communications, channel characteristics vary rapidly due to the high velocity of the vehicle and rich surround- ing scatters. To guarantee a reliable transmission, dynamic channel esti- mation needs to track the channel changes in the duration of a packet. Within the framework of IEEE802.11p standard, we propose a new chan- nel estimation algorithm that combines data subcarriers and pilot sub- carriers to equalize channel response in both frequency domain and time domain. Depending on the changes of the channel, the channel response can be further dynamically equalized by combining the channel response of previous OFDM symbols. Simulations show significant improvement in terms of packet error rate (PER) comparing to the existing methods with little additional computation.","Dynamic Program Analysis for Database Reverse Engineering ","Geometric quantifier elimination heuristics for automatically generating octagonal and max-plus invariantsGeometric heuristics for the quantifier elimination approach presented by Kapur (2004) are investigated to automatically derive loop invariants expressing weakly relational numerical properties (such as l\u2264x\u2264h or l\u2264\u00b1x \u00b1y\u2264h) for imperative programs. Such properties have been successfully used to analyze commercial software consisting of hundreds of thousands of lines of code (using for example, the Astree tool based on abstract interpretation framework proposed by Cousot and his group). The main attraction of the proposed approach is its much lower complexity in contrast to the abstract interpretation approach (O(n2) in contrast to O(n4), where n is the number of variables) with the ability to still generate invariants of comparable strength. This approach has been generalized to consider disjunctive invariants of the similar form, expressed using maximum function (such as max (x+a,y+b,z+c,d)\u2264max (x+e,y+f,z+g,h)), thus enabling automatic generation of a subclass of disjunctive invariants for imperative programs as well.","Resource Allocation for Query Optimization in Data Grid Systems: Static Load Balancing StrategiesResource allocation is one of the principal stages of relational query processing in data grid systems. Static allocation methods allocate nodes to relational operations during query compilation. Existing heuristics did not take into account the multi-queries environment, where some nodes may become overloaded because they are allocated to too many concurrent queries. Dynamic resource allocation mechanisms are currently developed to modify the physical plan during query execution. In fact, when a node is detected to be overloaded, some of the operations on it will migrate. However, if the resource contention is too heavy in the initial execution plan, the operation migration cost may be very high. In this paper, we propose two load balancing strategies adopted during the static resource allocation phase, so that the workload is balanced at the beginning, the operation migration cost is decreased during the query execution, and therefore the average response time is reduced.","Developing a Building Information Modelling Educational Framework for the Tertiary Sector in New ZealandWhilst Building Information Modelling (BIM) is rapidly being acknowledged as a driver for change in the Architectural, Engineering and Construction sector across the globe, the introduction of BIM into graduate and postgraduate teaching programmes in the tertiary sector in New Zealand has been minimal to date. New Zealand has an advanced albeit small economy, and whilst BIM is being deployed increasingly with effect in industry, there is no national BIM education framework and only one tertiary sector institution offers any BIM teaching in New Zealand (NZ). This paper reviews the current approaches to incorporating BIM into degree and certificate programmes in 25 leading international universities, pedagogical approaches and BIM critical success factors. A draft of a BIM educational framework for NZ is proposed based on this review. An approach for further design, development and deployment of the framework is also offered. This paper is intended to initiate debate and to start to build consensus between the academic community and industry on a national BIM educational framework for New Zealand.","Bounded Model Checking for Propositional Projection Temporal LogicThis paper presents a bounded model checking approach for proposi- tional projection temporal logic (PPTL). To this end, first PPTL is briefly intro- duced. Then, bounded semantics of PPTL is defined according to its semantics in logic theory. Further, a reduction method from BMC to SAT is given in detail. In addition, an example is presented to illustrate how the approach works. Our experience shows that BMC approach for PPTL proposed in the paper is useful and feasible.","Sound Symbolic Linking in the Presence of PreprocessingFormal verification enables developers to provide safety and security guarantees about their code. A modular verification approach supports the verification of different pieces of an application in separation. We propose symbolic linking as such a modular approach, since it allows to decide whether or not earlier verified source files can be safely linked together i.e. earlier proven properties remain valid.#R##N##R##N#If an annotation-based verifier for C source code supports both symbolic linking and preprocessing, care must be taken that symbolic linking does not become unsound. The problem is that the result of a header expansion depends upon the defined macros right before expansion.#R##N##R##N#In this paper, we describe how symbolic linking affects the type checking process and why the interaction with preprocessing results in an unsoundness. Moreover, we define a preprocessing technique which ensures soundness by construction and show that the resulting semantics after type checking are equivalent to the standard C semantics. We implemented this preprocessing technique in VeriFast, an annotation-based verifier for C source code that supports symbolic linking, and initial experiments indicate that the modified preprocessor allows most common use cases. To the extent of our knowledge, we are the first to support both modular and sound verification of annotated C source code.","Exploiting annotations for the rapid development of collaborative web applicationsWeb application frameworks are a proven means to accelerate the development of interactive web applications. However, implementing collaborative real-time applications like Google Docs requires specific concurrency control services (i.e. document synchronization and conflict resolution) that are not included in prevalent general-purpose frameworks like jQuery or Knockout. Hence, developers have to get familiar with specific collaboration frameworks (e.g. ShareJS) which substantially increases the development effort. To ease the development of collaborative web applications, we propose a set of source code annotations representing a lightweight mechanism to introduce concurrency control services into mature web frameworks. Those annotations are interpreted at runtime by a dedicated collaboration engine to sync documents and resolve conflicts. We enhanced the general-purpose framework Knockout with a collaboration engine and conducted a developer study comparing our approach to a traditional concurrency control library. The evaluation results show that the effort to incorporate collaboration capabilities into a web application can be reduced by up to 40 percent using the annotation-based solution.","Supporting Data Privacy in P2P SystemsPeer-to-Peer (P2P) systems have been very successful for large-scale data sharing. However, sharing sensitive data, like in online social networks, without appropriate access control, can have undesirable impact on data privacy. Data can be accessed by everyone (by potentially untrusted peers) and used for everything (e.g., for marketing or activities against the owner's preferences or ethics). Hippocratic databases (HDB) provide an effective solution to this problem, by integrating purpose- based access control for privacy protection. However, the use of HDB has been restricted to centralized systems. This chapter gives an overview of current solutions for supporting data privacy in P2P systems, and develops in more details a complete solution based on HDB.","Verification of Static and Dynamic Barrier Synchronization Using Bounded PermissionsMainstream languages such as C/C++ (with Pthreads), Java, and .NET provide programmers with both static and dynamic barriers for synchronizing concurrent threads in fork/join programs. However, such barrier synchronization in fork/join programs is hard to verify since programmers must not only keep track of the dynamic number of partic- ipating threads, but also ensure that all participants proceed in correctly synchronized phases. As barriers are commonly used in practice, verifying correct synchronization of barriers can provide compilers and analysers with important phasing information for improving the precision of their analyses and optimizations. In this paper, we propose an approach for statically verifying correct synchronization of static and dynamic barriers in fork/join programs. We introduce the notions of bounded permissions and phase numbers for keep- ing track of the number of participating threads and barrier phases respec- tively. The approach has been proven sound, and a prototype of it (named VeriBSync) has been implemented for verifying barrier synchronization of realistic programs in the SPLASH-2 benchmark suite.","A Cartographic Labeling Method in Chinese CharactersTo be understood correctly, the features of a map must be labeled properly. In this paper, rules for three kinds of cartographic labeling were analyzed, and a method of cartographic labeling for point, polyline, and area features in Chinese characters is designed and implemented efficiently. This paper implements two ways of point-feature labeling. One is that labels are placed at the point sites; the other is that labels are placed on one of eight positions relative to each corresponding point-feature. For polyline-feature labeling, an algorithm for searching for a number of discrete candidate positions to place the Chinese labels one character by one character along polyline- features is implemented. For a very long polyline-feature, the label is placed more than once. If an area-feature is sufficiently large, based on skeletonisation technique, the skeleton line of the area-feature, that is candidate support lines for labeling, is found inside the area-feature. Then the area-feature label is placed along the skeleton line, and covers most of the area-feature. Experiments showed that the dynamic labeling results are satisfactory.","Cognitive Biases in New Technology Appropriation : An experiment on the impact of judgmental and presentational primingThis paper extends individual-based theories of adaptive structuration by exploring the role of cognitive biases in shaping the individual sensemaking of a new technology (i.e., an online product configurator). We question whether cognitive biases intervene in the sensemaking process to influence the ensuing appropriation of the technology. We experimentally trigger cognitive biases by priming participants (N=645) with positive/negative judgments about the technology and with textual/visual instructions about its features. As outcome variables, we measure subjective and objective faithfulness of appropriation (FOA), and satisfaction with the technology. Results indicate that negative judgment lowers users\u2019 satisfaction, but at the same time increases their objective FOA. Compared to textual priming, visual priming leads to higher satisfaction, and triggers an illusion of having appropriated the technology faithfully \u2013 although without influencing objective FOA. We conclude by showing implications for IS scholars and practitioners.","A Conceptualization of Complexity in IS-Driven Organizational TransformationsOrganizational transformations reliant on successful ICT system developments (continue to) fail to deliver projected benefits even when contemporary governance models are applied rigorously. Modifications to traditional program, project and systems development management methods have produced little material improvement to successful transformation as they are unable to routinely address the complexity and uncertainty of dynamic alignment of IS investments and innovation. Complexity theory provides insight into why this phenomenon occurs and is used to develop a conceptualization of complexity in IS-driven organizational transformations.#R##N##R##N#This research-in-progress aims to identify complexity formulations relevant to organizational transformation. Political/power based influences, interrelated business rules, socio-technical innovation, impacts on stakeholders and emergent behaviors are commonly considered as characterizing complexity while the proposed conceptualization accommodates these as connectivity, irreducibility, entropy and/or information gain in hierarchically approximation and scaling, number of states in a finite automata and/or dimension of attractor, and information and/or variety.","A New Approach to Develop a Dependable Security Case by Combining Real Life Security Experiences (Lessons Learned) with D-Case Development Process ","Taxonomic Prediction with Tree-Structured CovariancesTaxonomies have been proposed numerous times in the literature in order to encode semantic relationships between classes. Such taxonomies have been used to improve classification results by increasing the statistical efficiency of learning, as similarities between classes can be used to increase the amount of relevant data during training. In this paper, we show how data-derived taxonomies may be used in a structured prediction framework, and compare the performance of learned and semantically constructed taxonomies. Structured prediction in this case is multi-class categorization with the assumption that categories are taxonomically related. We make three main contributions: i We prove the equivalence between tree-structured covariance matrices and taxonomies; ii We use this covariance representation to develop a highly computationally efficient optimization algorithm for structured prediction with taxonomies; iii We show that the taxonomies learned from data using the Hilbert- Schmidt Independence Criterion HSIC often perform better than imputed semantic taxonomies. Source code of this implementation, as well as machine readable learned taxonomies are available for download from https://github.com/blaschko/tree-structured-covariance.","Finding Similar Legal Judgements under Common Law System ","A Comparative Study of the Effect of Blogs and Email on Virtual Team Performance ","Deadline-Aware Event Scheduling for Complex Event Processing SystemsComplex event processing CEP plays an important role in developing responsive stream processing applications, with emphasis on \"Velocity\" from Big Data perspective. However, in emerging applications with heavyweight query requirements, the big rule set and the event coupling relationship could result in a complicated event graph. Meanwhile, state-of-the-art graph-based event processing approach employs the depth-first strategy and assumes that all complex events are equally important, which are more likely to reduce the scalability. In this paper, we focus on assigning priorities to complex events heuristically for the event graph model. The proposed priority dispatching policies take the following aspects into account: the topological particularity, the relative deadline and the dynamic process of event correlation, with the goal of minimizing the average response time. Furthermore, a priority-driven event scheduling strategy is presented, which aims to support real-time reasoning requirement. Finally, the experimental comparison with the standard graph-based event processing technique shows that the proposed event scheduling can yield a substantial improvement in the specific performances.","The Efficiency in Time and Financial Resources Management of an Individual by Developing an Informatics Support ","A Distributed Resource Allocation Algorithm in Multiservice Heterogeneous Wireless NetworksIn this paper, radio resource allocation and users to access networks assignment in heterogeneous wireless networks is studied. Mo- bile terminals are assumed to have the capability of using multiple radio access technologies simultaneously. A joint optimization problem is for- mulated, which guarantees services for terminals and maximizes the sum utility of all base stations/access points. Our model applies to arbitrary heterogeneous scenarios where the air interfaces belong to the class of interference limited systems like CDMA-based UMTS or to a class with orthogonal resource assignment such as TDMA-based GSM, WLAN or OFDMA-based LTE. Dual decomposition is employed to solve this op- timization problem and a distributed iterative algorithm is developed. Simulation results demonstrate the validity of the proposed algorithm.","Efficient parallel block-max WAND algorithmLarge Web search engines are complex systems that solve thousands of user queries per second on clusters of dedicated distributed memory processors. Processing each query involves executing a number of operations to get the answer presented to the user. The most expensive operation in running time is the calculation of the top-k documents that best match each query. In this paper we propose the parallelization of a state of the art document ranking algorithm called Block-Max WAND. We propose a 2-steps parallelization of the WAND algorithm in order to reduce inter-processor communication and running time cost. Multi-threading tailored to Block-Max WAND is also proposed to exploit multi-core parallelism in each processor. The experimental results show that the proposed parallelization reduces execution time significantly as compared against current approaches used in search engines.","Analysing the Impact of Built-In and External Social Tools in a MOOC on Educational TechnologiesMOOCs have been a disruptive educational trend in the last months. Some MOOCs just replicate traditional teaching pedagogies, adding multimedia elements like video lectures. Others go beyond, trying to engage the massive number of participants by promoting discussions and relying on their contributions to the course. MOOC platforms usually provide some built-in social tools for this purpose, although instructors or participants may suggest others to foster discussions and crowdsourcing. This paper analyses the impact of two built-in Q&amp;A and forum and three external social tools Facebook, Twitter and MentorMob in a MOOC on educational technologies. Most of the participants agreed on the importance of social tools to be in touch with their partners and share information related to the course, the forum being the one preferred. Furthermore, the lessons learned from the enactment of this MOOC employing social tools are summarized so that others may benefit from them.","Visualization Support for Multi-criteria Decision Making in Geographic Information Retrieval ","Perceptual Analysis of Speech Signals from People with Parkinson\u2019s DiseaseParkinson's disease (PD) is a neurodegenerative disorder of the nervous central system and it affects the limbs motor control and the communication skills of the patients. The evolution of the disease can get to the point of affecting the intelligibility of the patient's speech. The treatments of the PD are mainly focused on improving limb symp- toms and their impact on speech production is still unclear. Considering the impact of the PD in the intelligibility of the patients, this paper explores the discrimination capability of different perceptual features in the task of automatic classification of speech signals from people with Parkinson's disease (PPD) and healthy controls (HC). The experiments presented in this paper are performed considering the five Spanish vowels uttered by 20 PPD and 20 HC. The considered set of features includes linear prediction coefficients (LPC), linear prediction cepstral Coefficients (LPCC), Mel-frequency cepstral coefficients (MFCC), perceptual linear prediction coefficients (PLP) and two versions of the relative spectra coefficients (RASTA). Accordin the results for vowels /e/ and /o/ it is not enough to consider one kind of perceptual features, it is required to perform combination of different coefficients such as PLP, MFCC and RASTA. For the case of the remaining vowels, the best results are obtained considering only one kind of perceptual features, PLP for vowel /a/ and MFCC for vowels /i/ and /u/.","Supervised Opinion Mining of Social Network Data Using a Bag-of-Words Approach on the Cloud ","Cross-Lingual Natural Language Querying over the Web of DataThe rapid growth of the Semantic Web offers a wealth of semantic knowledge in the form of Linked Data and ontologies, which can be considered as large knowledge graphs of marked up Web data. However, much of this knowl- edge is only available in English, affecting effective information access in the multilingual Web. A particular challenge arises from the vocabulary gap resulting from the difference in the query and the data languages. In this paper, we present an approach to perform cross-lingual natural language queries on Linked Data. Our method includes three components: entity identification, linguistic analysis, and semantic relatedness. We use Cross-Lingual Explicit Semantic Analysis to overcome the language gap between the queries and data. The experimental re- sults are evaluated against 50 German natural language queries. We show that an approach using a cross-lingual similarity and relatedness measure outperforms other systems that use automatic translation. We also discuss the queries that can be handled by our approach.","Towards integration of web data into a coherent educational data graphPersonalisation, adaptation and recommendation are central aims of Technology Enhanced Learning (TEL) environments. In this context, information retrieval and clustering techniques are more and more often applied to filter and deliver learning resources according to user preferences and requirements. However, the suitability and scope of possible recommendations is fundamentally dependent on the available data, such as metadata about learning resources as well as users. However, quantity and quality of both is still limited. On the other hand, throughout the last years, the Linked Data (LD) movement has succeeded to provide a vast body of well-interlinked and publicly accessible Web data. This in particular includes Linked Data of explicit or implicit educational nature. In this paper, we propose a large-scale educational dataset which has been generated by exploiting Linked Data methods together with clustering and interlinking techniques to extract import and interlink a wide range of educationally relevant data. We also introduce a set of reusable techniques which were developed to realise scalable integration and alignment of Web data in educational settings.","Low-complexity Multiclass Encryption by Compressed Sensing, Part II: Known-Plaintext AttacksDespite its intrinsic linearity, compressed sensing may be exploited to at least partially encrypt acquired signals from unintentional receivers: in the companion paper we have shown that the simplicity of its encoding allows the definition of a general, lightweight scheme in which transmitters distribute the same information to receivers of different classes enabled to recover it with different quality levels. In this investigation we quantify the robustness of such a scheme with respect to known-plaintext attacks. The odds of such an attack are shown by theoretical means, proving that the number of candidate encoding matrices matching a typical plaintext-ciphertext pair is astronomically large, thus making the search for the true encoding infeasible. These attacks are also simulated by applying compressed sensing to a variety of signals (speech, images and electrocardiographic traces) showing how this difficulty in extracting information on the true encoding matrix from a plaintext-ciphertext pair is reflected on the quality of the signals recovered by the attacker. The results clarify that, although not perfectly secure, CS grants a noteworthy level of security that may come at almost-zero cost and especially benefit resource-limited applications.","A Critical Review of Migrating Parallel Web Crawler ","Reusing Requirements in Global Software EngineeringKnowledge sharing and reuse in global software engineering (GSE) are challenging issues. Knowledge management (KM) is specifically impacted because on top of distance, culture and language mismatches, there is also the perceived risk of sharing something which could mean that others could take over some work. Mistrust and protectionism are often the consequence, leading to insufficient reuse. This is visible specifically in requirements engineering (RE), where all reuse should start. In this chapter, we will look to reuse in RE with a detailed look on how to improve knowledge sharing and collaboration in distributed environments. We first look into the state of the practice. Then we present a lightweight, reuse-based, global RE method called PANGEA (Process for globAl requiremeNts enGinEering and quAlity), based on natural language requirements and software engineering standards. Based on this method, we also build a prototypical tool, called PANTALASA (PANgea Tool And Lightweight Automated Support Architecture) which provides automated support for PANGEA. Its features are drawn from PANGEA and the state of the practice commercially available RE tools. A proto- type of PANTALASA was developed by using Semantic MediaWiki and Facebook and applied to a case study in the domain of hotel management. We could show with this method and prototype that collaboration and thus KM and reuse in RE are improved.","A Discrete Hybrid Bees Algorithm for Service Aggregation Optimal Selection in Cloud ManufacturingFacing to the globalization and increasing competition of manufacturing enterprise, how to integrate the existent manufacturing services in cloud manufacturing model to form the newly value-added services in order to fulfill the user requirements has become a significant issue in manufacturing area. In this context, a discrete hybrid Bees Algorithm DHBA is proposed to solve service optimal the selection in resource service aggregation. The problem of service aggregation with QoS global optimal is transformed into a multi-objective services aggregation optimization with QoS constraints, and DHBA is utilized to produce a near-optimal solution. A case study together with a set of simulation experiment is presented and the results demonstrate the effectiveness and feasibility of the proposed method.","A Comment on Budach's Mouse-in-an-Octant ProblemBudach's Mouse-in-an-Octant Problem (attributed to Lothar Budach in a 1980 article by van Emde Boas and Karpinski) concerns the behaviour of a very simple finite-state machine (\"the mouse\") moving on the integer two-dimensional grid. Its decidability is apparently still open. This note sketches a proof that an extended version of the problem (a super-mouse) is undecidable.","Merging Attention and Segmentation: Active Foveal Image Representation ","Overview of EIREX 2012: Social MediaThe third Information Retrieval Education through EXperimentation track (EIREX 2012) was run at the University Carlos III of Madrid, during the 2012 spring semester. EIREX 2012 is the third in a series of experiments designed to foster new Information Retrieval (IR) education methodologies and resources, with the specific goal of teaching undergraduate IR courses from an experimental perspective. For an introduction to the motivation behind the EIREX experiments, see the first sections of [Urbano et al., 2011a]. For information on other editions of EIREX and related data, see the website at this http URL The EIREX series have the following goals: a) to help students get a view of the Information Retrieval process as they would find it in a real-world scenario, either industrial or academic; b) to make students realize the importance of laboratory experiments in Computer Science and have them initiated in their execution and analysis; c) to create a public repository of resources to teach Information Retrieval courses; d) to seek the collaboration and active participation of other Universities in this endeavor. This overview paper summarizes the results of the EIREX 2012 track, focusing on the creation of the test collection and the analysis to assess its reliability.","Are the intrusive effects of SPAM probes present when operators differ by skill level and trainingThe Next Generation Air Transportation System (NextGen) plans to implement a series of automated tools into the National Airspace System to aid air traffic controllers (ATCos) in managing a two to three times increase in air traffic density. However, introducing automated technologies into a system like air traffic management (ATM) changes the responsibilities of the ATCo from an active controller to a passive monitor, which can result in lower levels of situation awareness (SA). To measure SA objectively in such a dynamic task as ATM, the Situation Present Awareness Method (SPAM) is often used. SPAM provides the operator with SA probes while the operator is performing the task. Some studies have shown that the use of SPAM to measure SA is intrusive because it provides the operator with a secondary task. The present study examines whether these intrusive effects of SPAM are present when the operator has achieved a high skill level at the time of test, and whether training operators to rely more or less on NextGen automated tools influence their performance when SPAM queries are presented as a secondary task.","Subjective Evaluation of Labeling Methods for Association Rule ClusteringAmong the post-processing association rule approaches, clustering is an interesting one. When an association rule set is clustered, the user is provided with an improved presentation of the mined patters. The domain to be explored is structured aiming to join association rules with similar knowledge. To take advantage of this organization, it is essential that good labels be assigned to the groups, in order to guide the user during the association rule exploration process. Few works have explored and proposed labeling methods for this context. Moreover, these methods have not been explored through subjective evaluations in order to measure their quality; usually, only objective evaluations are used. This paper subjectively evaluates five labeling methods used on association rule clustering. The evaluation aims to find out the methods that presents the best results based on the analysis of the domain experts. The experimental results demonstrate that there is a disagreement between objective and subjective evaluations as reported in other works from literature.","Ontological, Epistemological, and Teleological Perspectives on Service-Oriented Simulation Frameworks ","Collaboration Using Social Media: The Case of Podio in a Voluntary OrganizationSocial media enables a new model of managing knowledge that involves formal and informal communication, collaboration using a variety of applications. Using a case study approach, this article investigates the affordances of such Social Media enhanced Platforms SMeP for the management of knowledge work communication and collaboration. In particular it aims to address the following research questions: What are the affordances of SMeP for the management of knowledge work in a voluntary organization? How do individuals experience the opportunities and challenges of these collaborative platforms?#R##N##R##N#This paper presents the results of an empirical study on the adoption and use of social media in a voluntary organization. The findings pinpoints towards the potential use of SMeP for shaping new work practices but also towards the issues encountered when social media is introduced in organizations.","Bringing Relevance to Computing Courses through HistoryThis paper shows ways in which computing history can make the delivery of teaching computing courses relevant. The authors' approach involves using computing history as a recurring theme throughout courses by adapting relevant historical stories or material to enhance course delivery and to capture student interest. The use of computing history often makes a positive and constructive improvement in courses by making them more interesting, stimulating, and thereby, informing students with non-technical elements in their computing specialties. This approach to computing studies should prove to be a helpful addition to student studies and provide them with a stronger understanding of the computing field in their careers.","Semi-Supervised Dictionary Learning of Sparse Representations for Emotion RecognitionThis work presents a technique for the classification of emo- tions in human-computer interaction. Based on biophysiological data, a dictionary learning approach is used to generate sparse representations of blood volume pulse signals. Such features are then used for classification of the current emotion. Unlabeled data, i.e. data without information about class membership, is used to enrich the dictionary learning stage. Superior representation abilities of the underlying structure of the data are demonstrated by the learnt dictionaries. As a result, classification rates are improved. Experimental validation in the form of different clas- sification experiments is presented. The results are presented with a dis- cussion about the benefits of the approach and the existing limitations.","Rotor Time Constant Identification Approaches Based on Back-Propagation Neural Network for Indirect Vector Controlled Induction Machine ","An Area Efficient Wide Range On-Chip Delay Measurement Architecture ","A refuge location prediction system for when a tsunami has occurredDuring the 2011 Tohoku Earthquake and Tsunami, DMATs (Disaster Medical Assistance Teams) could not rescue victims efficiently with accurate location data, because the local governments had lost refuge location data and resident registers due to damage caused by the tsunami. In this paper, to support DMATs, a refuge prediction system based on the characteristics of disaster, landscape, and victims' psychology is proposed, which can function even if local governments lose information about victims and refuge locations. As an example, this system deals with tsunami. We demonstrate the effectiveness of this system by comparing the data of the 2011 Tohoku Earthquake and Tsunami and our prediction system.","Multi-Domain Adaptation for SMT Using Multi-Task LearningDomain adaptation for SMT usually adapts models to an individual specific domain. However, it often lacks some correlation among different domains where common knowledge could be shared to improve the overall translation quality. In this paper, we propose a novel multi-domain adaptation approach for SMT using Multi-Task Learning (MTL), with in-domain models tailored for each specific domain and a general-domain model shared by different domains. The parameters of these models are tuned jointly via MTL so that they can learn general knowledge more accurately and exploit domain knowledge better. Our experiments on a largescale English-to-Chinese translation task validate that the MTL-based adaptation approach significantly and consistently improves the translation quality compared to a non-adapted baseline. Furthermore, it also outperforms the individual adaptation of each specific domain.","Simplified Bid Languages \u2013 A Remedy to Efficiency Losses in Large Spectrum Auctions ","The Art of Aligning Business Expectations with Learning EffectivenessIn the first in a series of articles about building a an effective online training and certification program based on principles practiced at Google, Chris Jennings discusses how to get stakeholders on board when it comes time to invest in eLearning.","Intelligent Machine Space for Interacting with Human in Ubiquitous Virtual RealityVarious computing paradigms such as ubiquitous computing, pervasive computing, ambient intelligence, and ubiquitous virtual reality have appeared. Now we should consider interaction between human and robots in ubiquitous virtual reality known as DigiLog space. In this paper, we propose intelligent machine space for human robot interaction in DigiLog space. For the human robot interaction in DigiLog space, a robot has to recognize the current situation and select proper behavior by itself. It has to receive information and context from DigiLog space and transfer current state of robot itself bidirectional way. Moreover, the robot has to accept user's commands and provide proactive services to users.","Reduced ordering technique of impulsive noise removal in color imagesIn the paper a fast technique of impulsive noise removal in color images is described. The proposed method is assigning to pixels of the filtering window the sum of the distances to their k nearest neighbors. The difference between the trimmed sum assigned to the central pixel and to the pixel minimizing the cumulated distances is treated as a measure of pixel's distortion caused by the impulsive noise process. If the difference exceeds a global threshold value, then the central pixel of the processing window is replaced by the mean of the pixels from the window, which were found to be not corrupted, otherwise the central pixel is retained. The new filtering design is able to effectively suppress impulsive noise, while preserving fine image details. The performance comparison shows that the proposed filtering design yields significantly better denoising results than the most efficient filters developed for the impulsive noise suppression in color images.","Embedded System Architecture for Mobile Augmented Reality. Sailor Assistance Case StudyWith upcoming see-through displays new kinds of applications of Augmented Reality are emerging. However this also raises questions about the design of associated embedded systems that must be lightweight and handle object positioning, heterogeneous sensors, wireless communications as well as graphic computation. This paper studies the specific case of a promising Mobile AR processor, which is different from usual graphics applications. A complete architecture is described, designed and prototyped on FPGA. It includes hardware/software partitioning based on the analysis of application requirements. The specification of an original and flexible coprocessor is detailed. Choices as well as optimizations of algorithms are also described. Implementation results and performance evaluation show the relevancy of the proposed approach and demonstrate a new kind of architecture focused on object processing and optimized for the AR domain.","Detecting Community Structures in Microblogs from Behavioral Interactions ","Learning Objects Repository Management Using an Adaptive Quality Evaluation Multi-Agent SystemAvailability and correspondence with expectations are desired cha- racteristics in order to guarantee the quality of Learning Objects (LOs) retrieved from LO repositories during the search process. The administrators of these re- positories have the responsibility of ensuring the quality of LOs after applying their corresponding evaluation. The implementation of metrics applied on rele- vant characteristics of LOs is a crucial tool for LO evaluation.This paper pro- poses an approach that uses a Multi-Agent System (MAS) for assessing main LO characteristics, applying different methods and metrics being adjustable to different kinds of repositories by employing adaptive parser agents. By using metadata as main source of information, the metrics allow users to rate the qual- ity of LOs and generates alarms concerning inputs that do not meet the expected values.The system developed automatically evaluates a large number of re- sources to facilitate the work of the repository administrators before improving or publishing the LOs into a repository federation.","Adjusting the Design Target of Life-Cycle Aware HCI in Knowledge Work: Focus on Computing Practices ","Turn-Taking Behavior in a Human Tutoring Corpus. ","Efficient persistency management in complex event processing: a hybrid approach for gamification systemsComplex Event Processing (CEP) has been successfully applied in various domains. As of today, the management of external, durable, and encapsulated state in such systems has received little attention in research. An emerging kind of rule and event-based systems are platforms for gamification. These systems require an efficient management of entities containing state. In this paper, we are proposing a hybrid system capable of fast event processing on the one hand and global state, entity, and persistency management on the other hand. Moreover, we present and evaluate different synchronization strategies between an event processor and a business entity provider. We demonstrate that our extensions outperform conventional CEP solutions in terms of state persistency and ex post analytics by adding just a marginal performance overhead.","Vulnerability Analysis on Smart Cards Using Fault TreeIn smart card domain, attacks and countermeasures are advancing at a fast rate. In order to have a generic view of all the attacks, we propose to use a Fault Tree Analysis. This method used in safety analysis helps to understand and implement all the desirable and undesirable events existing in this domain. We apply this method to Java Card vulnerability analysis. We define the properties that must be ensured: integrity and confidentiality of smart card data and code. By modeling the conditions, we discovered new attack paths to get access to the smart card contents. Then we introduce a new security api which is proposed to mitigate the undesirable events defined in the tree models.","Evaluation of Novel Soft Computing Methods for the Prediction of the Dental Milling Time-Error Parameter ","Epipolar Plane Image Refocusing for Improved Depth Estimation and Occlusion Handling ","Asymmetric unification: a new unification paradigm for cryptographic protocol analysisWe present a new paradigm for unification arising out of a technique commonly used in cryptographic protocol analysis tools that employ unification modulo equational theories. This paradigm relies on: (i) a decomposition of an equational theory into (R,E) where R is confluent, terminating, and coherent modulo E, and (ii) on reducing unification problems to a set of problems $s =_{}^{?} t$ under the constraint that t remains R/E-irreducible. We call this method asymmetric unification. We first present a general-purpose generic asymmetric unification algorithm. and then outline an approach for converting special-purpose conventional unification algorithms to asymmetric ones, demonstrating it for exclusive-or with uninterpreted function symbols. We demonstrate how asymmetric unification can improve performanceby running the algorithm on a set of benchmark problems. We also give results on the complexity and decidability of asymmetric unification.","Automated Test Case Selection Using Feature Model: An Industrial Case StudyAutomated test case selection for a new product in a product line is challenging due to several reasons. First, the variability within the product line needs to be captured in a systematic way; second, the reusable test cases from the repository are required to be identified for testing a new product. The objective of such automated process is to reduce the overall effort for selection e.g., selection time, while achieving an acceptable level of the coverage of testing functionalities. In this paper, we propose a systematic and automated methodology using a Feature Model for Testing FM_T to capture commonalities and variabilities of a product line and a Component Family Model for Testing CFM_T to capture the overall structure of test cases in the repository. With our methodology, a test engineer does not need to manually go through the repository to select a relevant set of test cases for a new product. Instead, a test engineer only needs to select a set of relevant features using FM_T at a higher level of abstraction for a product and a set of relevant test cases will be selected automatically. We applied our methodology to a product line of video conferencing systems called Saturn developed by Cisco and the results show that our methodology can reduce the selection effort significantly. Moreover, we conducted a questionnaire-based study to solicit the views of test engineers who were involved in developing FM_T and CFM_T. The results show that test engineers are positive about adapting our methodology and models FM_T and CFM_T in their current practice.","Secure and Unfailing ServicesInternet is offering a variety of services, that are assembled to accomplish requests made by clients. While serving a request, security of the communications and of the data exchanged among services is crucial. Furthermore, communications occur along specific channels, and it is equally important to guarantee that the interactions between a client and a server never get blocked because either cannot access a selected channel. We address here both these problems, from a formal point of view. A static analysis is presented, guaranteeing that a composition of a client and of possibly nested services respects both security policies for access control, and compliance between clients and servers.","Comparisons of dynamic ECG recordings between two groups in china: a preliminary studyGeographic medicine is becoming important because it aims to provide an understanding of health problems and improve the health of people worldwide based on the various geographic factors influencing them. The research of geographical environment with health status is getting higher practical significance. In this paper we presented a cross-regional comparison experiment for dynamic ECG recordings from two distinct groups: one group is in Northeast China (NEC), the city of Shuangya Hill, Heilongjiang; another group involves subjects in the Shenzhen Institutes of Advanced Technology (SIAT), group subjects were from different place of China. Conventional Heart Rate Variability (HRV) parameters, such as SDNN-24, RMSSD, PNN50, SDANN index, SDNN index (time-domain indexes), TP, ULF, LF, UF, LF/UF (frequency-domain indexes), and VP, VT and AT (arrhythmia indexes) were analyzed. The results show that arrhythmia indexes of the two groups have a significant difference which reflects the health conditions are quite different. Accordingly, with further analysis of the frequency-domain indexes and time-domain indexes, it shows that the time-domain indexes were almost the same while the frequency-domain indexes shows there were a 20% average difference between the two groups. Apparently, for the analysis of HRV, the frequency-domain indexes are more persuasive than time-domain indexes.","Data Anonymization According to the Combination of Attributes on Social Network Sites ","Strength-Based decomposition of the property B\u00fcchi automaton for faster model checkingThe automata-theoretic approach for model checking of linear-time temporal properties involves the emptiness check of a large Buchi automaton. Specialized emptiness-check algorithms have been proposed for the cases where the property is represented by a weak or terminal automaton.#R##N##R##N#When the property automaton does not fall into these categories, a general emptiness check is required. This paper focuses on this class of properties. We refine previous approaches by classifying stronglyconnected components rather than automata, and suggest a decomposition of the property automaton into three smaller automata capturing the terminal, weak, and the remaining strong behaviors of the property. The three corresponding emptiness checks can be performed independently, using the most appropriate algorithm.#R##N##R##N#Such a decomposition approach can be used with any automata-based model checker. We illustrate the interest of this new approach using explicit and symbolic LTL model checkers.","AbstractSwarm \u2013 A Generic Graphical Modeling Language for Multi-Agent Systems ","Hybrid Algorithm for Job Scheduling: Combining the Benefits of ACO and Cuckoo Search ","A Comprehensive Study of the Usability of Multiple Graphical PasswordsRecognition-based graphical authentication systems (RBGSs) using #R##N#images as passwords have been proposed as one potential solution to the need #R##N#for more usable authentication.  The rapid increase in the technologies requiring #R##N#user authentication has increased the number of passwords that users have to #R##N#remember. But nearly all prior work with RBGSs has studied the usability of  a #R##N#single password. In this paper, we present the first  published comparison of the #R##N#usability of multiple graphical passwords with four different image types: #R##N#Mikon, doodle, art and everyday objects (food, buildings, sports etc.). A longi-tudinal experiment was  performed  with 100 participants over a period of 8 #R##N#weeks, to examine the usability performance of each of the image types. The re-sults of the study demonstrate that object images are most usable in the sense of #R##N#being more memorable and less time-consuming to employ, Mikon images are #R##N#close behind but doodle and  art images are significantly inferior. The results of #R##N#our study complement cognitive literature on the picture superiority effect, vis-ual search process and nameability of visually complex images.","Understanding Coarticulation in Musical ExperienceThe term coarticulation designates the fusion of small-scale events such as single sounds and single sound-producing actions into larger chunks of sound and body motion, resulting in qualitative new features at the medium- scale level of the chunk. Coarticulation has been extensively studied in linguis- tics and to a certain extent in other domains of human body motion, but so far not so much in music, so the main aim of this paper is to provide a background for how we can explore coarticulation in music. The contention is that coarticu- lation in music should be understood as based on a number of physical, biome- chanical and cognitive constraints, and that it is an essential shaping factor for several perceptually salient features of music.","Controlling Interaction with Digital Product Memories ","Unsupervised Gazette Creation Using Information DistanceNamed Entity extraction (NEX) problem consists of auto- matically constructing a gazette containing instances for each NE of in- terest. NEX is important for domains which lack a corpus with tagged NEs. In this paper, we propose a new unsupervised (bootstrapping) NEX technique, based on a new variant of the Multiword Expression Distance (MED) (1) and information distance (2). Efficacy of our method is shown using comparison with BASILISK and PMI in agriculture domain. Our method discovered 8 new diseases which are not found in Wikipedia.","Multiple real-time semantics on top of synchronous block diagramsSynchronous block diagrams form an established fundament for the model-based development of embedded real-time systems. Their synchronous reactive (SR), also called zero execution time, semantics offers indisputable advantages in designing, testing and verifying control algorithms but poses problems in the translation of multi-rate models into code. In this paper, we contrast the semantics of three different real-time programming paradigms and discuss a mechanism to represent them in models with SR semantics. This representation is based on MATLAB/Simulink blocks that are not characterized by the typical zero time behavior but whose execution may last for and optionally consume a finite amount of simulation time. Each such block represents a task in the sense of a real-time operating system. All tasks within a model may be scheduled with a static-priority approach. This allows us to observe simulations that are closer to the real timing behavior of control applications and also to consider preemption effects already in the simulation.","Multi-level communicability evaluation of a prototyping toolSemiotic engineering views human-computer interaction as a form of human communication between designers and users, mediated by a computer system. If we consider a design application, such as a prototyping tool, this communication is about the construction of a second communication, one between the user of the prototyping tool (in the role of the designer) and another user, who will interact with the system being designed. This article explores an extension to the Communicability Evaluation Method for design tools. This extension focuses not only on considering the kinds of communicability breakdowns, but also on what abstraction level they occur.","Ontological modeling of a class of linked economic crimesWe consider the ontological modeling of knowledge concerning the class of linked economic crimes, namely the fraudulent disbursement accompanied by money laundering. The applied method of conceptual modeling results in obtaining a layered ontological structure with the foundational ontology on top of it and the application ontology at its bottom. As the foundational level we use the constructive descriptions and situations ontology. The application level entities were manually separated from the motivating crime scenarios. The latter level covers both the conceptualization of \"a domain\" whose attributes and relations are of interest and \"a task\" that supports the realization of the functionality of a crime analysis application. The domain-based part of the ontology is engineered in the OWL language while the task-based part, designed to support knowledge extraction from databases, is implemented via rules in the SWRL language. The rules are used to extract data concerning: documents and their attributes, the formal hierarchy in a company and the parameters of transactions. They are also used to deduce sanctions against people engaged in a crime.","Deciding Bisimilarities on DistributionsProbabilistic automata (PA) are a prominent compositional concurrency model. As a way to justify property-preserving abstractions, in the last years, bisimulation relations over probability distributions have been proposed both in the strong and the weak setting. Different to the usual bisimulation relations, which are defined over states, an algorithmic treatment of these relations is inherently hard, as their carrier set is uncountable, even for finite PAs. The coarsest of these relation, weak distribution bisimulation, stands out from the others in that no equivalent state-based characterisation is known so far. This paper presents an equivalent state-based reformulation for weak distribution bisimulation, rendering it amenable for algorithmic treatment. Then, decision procedures for the probability distribution-based bisimulation relations are presented.","Defeating Tyranny of the Masses in Crowdsourcing: Accounting for Low-Skilled and Adversarial WorkersCrowdsourcing has emerged as a useful learning paradigm which allows us to instantly recruit workers on the web to solve large scale problems, such as quick annotation of image, web page, or document databases. Automated inference engines that fuse the answers or opinions from the crowd to make critical decisions are susceptible to unreliable, low-skilled and malicious workers who tend to mislead the system towards inaccurate inferences. We present a probabilistic generative framework to model worker responses for multicategory crowdsourcing tasks based on two novel paradigms. First, we decompose worker reliability into skill level and intention. Second, we introduce a stochastic model for answer generation that plausibly captures the interplay between worker skills, intentions, and task difficulties. This framework allows us to model and estimate a broad range of worker \"types\". A generalized Expectation Maximization algorithm is presented to jointly estimate the unknown ground truth answers along with worker and task parameters. As supported experimentally, the proposed scheme de-emphasizes answers from low skilled workers and leverages malicious workers to, in fact, improve crowd aggregation. Moreover, our approach is especially advantageous when there is an (a priori unknown) majority of low-skilled and/or malicious workers in the crowd.","Effect of accommodation training in foreign laborBy relaxing the contracted focus-adjustment muscles around the eyeball, such as the ciliary and extraocular muscles, improvement of the pseudo-myopia is expected. This understanding has led to the accommodation training in which the visual target is given by stereoscopic video clips. However, it is pointed out that the motion sickness can be induced by viewing stereoscopic video clips. In the measurement 1 of this study, we verify whether the new 3-dimensional (3D) technology reduce the severity of motion sickness in accordance with the stabilometry. We then evaluate short-term effects of the accommodation training utilizing new stereoscopic video clips on foreign labors (11 females) suffering from eye fatigue in the measurement 2. The foreign workers were trained in 3 days. We could show that the new 3D technology reduce the severity of motion sickness in accordance with the stabilometry. The effect of the accommodation training utilizing the new 3D video clip was investigated in foreign labors suffering from eye fatigue, and the eye strain was reduced by the continuous accommodation training for a short-term period.","Shape Reconstruction of Symmetric Surfaces Using Photometric StereoThe reconstruction of a 3D surface through one gray scale digital image does not admit a unique solution in the orthographic Shape from Shading (SfS) framework. With the aim to make this type of problem well-posed it is possible to use the Photometric Stereo (PS) technique. It allows to add information about the surface introducing other images of the object taken from the same point of view but modifying, for each photo, the direction of the light source. The methods that use the PS technique with the orthographic model of SfS need of, at least, three images. However, even if three images are used, there is the possibility that the SfS-PS problem continues to be ill-posed. This is the case when the three images are taken using three coplanar light vectors. This work analyses this kind of ill- posedness in order to understand how it is possible to establish a connection among the images that do not guarantee uniqueness. A further result in this paper is given by a geometrical characterization of the surfaces for which it is possible to solve the classic SfS problem.","Auctions vs Negotiations in Irregular MarketsThe classic result of Bulow and Klemperer [BK96] says that in a single-item auction recruiting one more bidder and running the Vickrey auction achieves higher revenue than running the optimal auction with the initial set of bidders, when values are drawn i.i.d. from a regular distribution. However distributions that violate the regularity condition are common and the i.i.d condition is quite restrictive. We give a version of Bulow and Klemperer's result to settings where bidders' values are drawn from non-iid. irregular distributions. The most prevalent reason for a bidder's distribution to be irregular is that the bidder is drawn from a heterogeneous population that consists of several groups of people with different valuation profiles (eg. students and seniors). A bidder drawn from such a population has a distribution that corresponds to a convex combination of the distributions of each population group. Though the individual distributions may satisfy the regularity condition, their convex combination violates it even in the simplest cases. We show that recruiting one person from each group and running the Vickrey auction gets at least half the revenue of the optimal auction in the original setting. Thus without knowing anything about the distribution, if the auctioneer knows that his population consists of several distinct groups, a targeted advertising campaign to recruit one bidder from each population group is nearly as effective as the optimal auction which is complicated to describe and discriminatory. Further, we show that for several natural classes of distributions for the underlying population groups like uniform, exponential, Gaussian and power-law, recruiting just one extra bidder is enough to get at least half of the optimal auction's revenue. Finally, we give the first non-trivial approximations via Vickrey auctions with a single reserve for non-i.i.d. irregular settings.","Automatic Generation Control of Multi-area Power System Using Gravitational Search Algorithm ","Two Improved Artificial Bee Colony Algorithms Inspired by Grenade Explosion Method ","Intra-operative Identification of the Subthalamic Nucleus Motor Zone Using GoniometersThe current state of the art for identification of motor related neural activity during deep brain stimulation (DBS) surgery utilizes manual movements of the patient's joints while observing the recorded raw data of a single electrode. Here we describe an intra-operative method for detection of the motor territory of the subthalamic nucleus (STN) during DBS surgery. The method incorporates eight goniometers that continuously monitor and measure the angles of the wrist, elbow, knee and ankle, bilaterally. The joint movement data and microelectrode recordings from the STN are synchronized thus enabling objective intra-operative assessment of movement-related STN activity. This method is now used routinely in DBS surgery at our institute. Advantages include objective identification of motor areas, simultaneous detection of movement for all joints, detection of movement at a joint that is not under examination, shorter surgery time, and continuous monitoring of STN activity for patients with tremor.","A hierarchical scheme of multiple feature fusion for high-resolution satellite scene categorizationScene categorization in high-resolution satellite images has attracted much attention in recent years. However, high intra-class variations, illuminations and occlusions make the task very challenging. In this paper, we propose a classification model based on a hierarchical fusion of multiple features. Highlights of our work are threefold: (1) we use four discriminative image features; (2) we employ support vector machine with histogram intersection kernel (HIK-SVM) and L1-regularization logistic regression classifier (L1R-LRC) in different classification stages, respectively. The soft probabilities of different features obtained by the HIK-SVM are discriminatively fused and fed into the L1R-LRC to obtain the final results; (3) we conduct an extensive evaluation of different configurations, including different feature fusion schemes and different kernel functions. Experimental analysis show that our method leads to state-of-the-art classification performance on the satellite scenes.","A Comparative Study of Multi-objective Evolutionary Trace Transform Methods for Robust Feature Extraction ","A practical approach to holistic b-twig pattern matching for efficient XML query processingEfficient twig pattern matching is essential to XML queries and other tree-based queries. Numerous so-called holistic algorithms have been proposed to process the twig patterns in XML queries. However, a more general form of twig patterns, called B-twig (or Boolean-twig), which allow arbitrary combination of all the three logical connectives, AND, OR, and NOT in the twig patterns, has not yet been adequately addressed. In this paper, a new approach accompanied with an optimal implementation algorithm is presented for efficiently processing B-twig XML queries. Experimental study confirms the viability and performance superiority of our new approach.","Testing an Agent Based E-Novel System \u2013 Role Based Approach ","Contactless electrical bioimpedance system for monitoring ventilation. A biodevice for vehicle environmentNowadays, automotive companies are focused in improving road traffic safety. For that, not only the vehicle performance is improved but also the driver behavior is monitored. This could be done in many ways. One of#R##N#them is to monitor a specific physiological parameter using a biodevice. That device should be reliable enough to use in a very noisy environment like a vehicle is. Furthermore, because long-term monitoring is required,any invasive and annoying method should be avoided. Therefore, an electrical bioimpedance device capable#R##N#of monitoring driver ventilation using several textiles electrodes has been designed and implemented","Experiments in newswire-to-law adaptation of graph-based dependency parsersWe evaluate two very different methods for domain adapta- tion of graph-based dependency parsers on the EVALITA 2011 Domain Adaptation data, namely instance-weighting (10) and self-training (9,6). Since the source and target domains (newswire and law, respectively) were very similar, instance-weighting was unlikely to be efficient, but some of the semi-supervised approaches led to significant improvements on development data. Unfortunately, this improvement did not carry over to the released test data.","Energy efficient in-network data indexing for mobile wireless sensor networksIn-network indexing is a challenging problem in wireless sensor networks (WSNs), particularly when sensor nodes are mobile. In the past, several indexing structures have been proposed for WSNs for answering in-network queries, however, their maintenance efficiency in the presence of mobile nodes is relatively less understood. Assuming that mobility of the nodes is driven by an underlying mobility control algorithm or application, we present a novel distributed protocol for efficient maintenance of distributed hierarchical indexing structures. The proposed protocol is generic, in the sense that it is applicable to any hierarchical indexing structure that uses binary space partitioning (BSP), such as k-d trees, Quadtrees and Octrees. It is based on locally expanding and shrinking convex regions such that update costs are minimized. Based on SIDnet-SWANS simulator, our experimental results demonstrate the effectiveness of the proposed protocol under different mobility models, mobility speeds, and query streams.","Plurality Voting with Truth-Biased AgentsWe study a game-theoretic model for Plurality, one of the most well- studied and widely-used voting rules. It is well known that the most standard game-theoretic approaches can be problematic in the sense that they lead to a multitude of Nash equilibria, many of which are counter-intuitive. Instead, we focus on a model recently proposed to avoid such issues (2,6,11). The main idea of the model is that voters have incentives to be truthful when their vote is not pivotal, i.e., when they cannot change the outcome by a unilateral deviation. This modification is quite powerful and recent simulations reveal that equilibria which survive this refinement tend to have nice properties. We undertake a theoretical study of pure Nash and strong Nash equilibria of this model under Plurality. For pure Nash equilibria we provide characterizations based on understanding some crucial properties about the structure of equilibrium profiles. These properties demonstrate how the model leads to filtering out unde- sirable equilibria. We also prove that deciding the existence of an equilibrium with a certain candidate as a winner is NP-hard. We then move on to strong Nash equilibria, where we obtain analogous characterizations. Finally, we also observe some relations between strong Nash equilibria and Condorcet winners, which demonstrate that this notion forms an even better refinement of stable profiles.","Parallel Preconditioner for the Finite Volume Element Discretization of Elliptic Problems ","Collaborative Engineering Paradigm Applied to the Aerospace IndustryAirbus designs and industrializes aircrafts using Concurrent Engineering techniques since decades. The introduction of new PLM methods, procedures and tools, and the need to reduce time-to-market, led Airbus Military to#R##N#pursue new working methods. Traditional Engineering works sequentially. Concurrent Engineering basically overlaps tasks between teams. Collaborative Engineering promotes teamwork to develop product, processes and resources from the conceptual phase to the start of the serial production. The CALIPSO-neo pilot project was launched to support the industrialization process of a medium size aerostructure. The aim is to implement the industrial Digital Mock-Up (iDMU) concept and its exploitation to create shop floor documentation. In a framework of a collaborative engineering strategy, the project is part of the efforts to deploy Digital Manufacturing as a key technology for the#R##N#industrialization of aircraft assembly lines. This paper presents the context, the conceptual approach and the methodology adopted.","The Meanings of the Generic Parts of Toponyms: Use and Limitations of Gazetteers in Studies of Landscape TermsAre the contents of toponyms meaningless, as it is often claimed in linguistic literature, or can the generic parts in toponyms, such as hill in Black Hill, be used to infer landscape descriptions? We investigate this question by, firstly, linking gazetteer data with topographic characteristics, and, secondly, by conducting analysis of how the use of landscape terms might have changed over time in a historic corpus. We thus aim at answering a linguistic, and ethnophysiographic, research question through digital input data and processing. Our study area is Switzerland and our main focus is on geographic eminences, and in particular on the use of the terms Spitze, Horn and Berg. We show that most prominent generic parts in toponyms show expected topographic characteristics. However, not all generic parts strictly follow this rule, as in the case of Berg. Some generic parts have lost their meaning in standard language over time (e.g. Horn). We therefore put a cautionary note on the use of generic parts in toponyms in landscape studies, but point out that the subtle details of these differences provide rich topics for future research.","VCCBox: Practical Confinement of Untrusted Software in Virtual Cloud ComputingRecent maturity of virtualization has enabled its wide adop- tion in cloud environment. However, legacy security issues still exist in the cloud and are further enlarged. For instance, the execution of un- trusted software may cause more harm to system security. Though con- ventional sandboxes can be used to constrain the destructive program behaviors, they suffer from various deficiencies. In this paper, we pro- pose VCCBox, a practical sandbox that confines untrusted applications in cloud environment. Leveraging the state-of-the-art hardware assisted virtualization technology and novel design, it is able to work effectively and efficiently. VCCBox implements its system call interception and ac- cess control policy enforcement inside the hypervisor and create an in- terface to dynamically load policies. The in-VMM design renders our system hard to bypass and easy to deploy in cloud environment, and dynamic policy loading provides high efficiency. We have implemented a proof-of-concept system based on Xen and the evaluation exhibits that our system achieves the design goal of effectiveness and efficiency.","A Hybrid Metaheuristic for the Bus Driver Rostering ProblemComunicacao apresentada 2nd International Conference on Operations Research and Enterprise Systems, 16-18 fevereiro 2013, Barcelona, Espanha","Incorporating Commercial and Private Data into an Open Linked Data Platform for Drug DiscoveryThe Open PHACTS Discovery Platform aims to provide an integrated information space to advance pharmacological research in the area of drug discovery. Effective drug discovery requires comprehensive data coverage, i.e. integrating all available sources of pharmacology data. While many relevant data sources are available on the linked open data cloud, their content needs to be combined with that of commercial datasets and the licensing of these commercial datasets respected when providing access to the data. Additionally, pharmaceutical companies have built up their own extensive private data collections that they require to be included in their pharmacological dataspace. In this paper we discuss the challenges of incorporating private and commercial data into a linked dataspace: focusing on the modelling of these datasets and their interlinking. We also present the graph-based access control mechanism that ensures commercial and private datasets are only available to authorized users.","COST Actions and Digital Libraries: Between Sustaining Best Practices and Unleashing Further Potential ","Adopting Standards in Nursing Health Record \u2013 A Case Study in a Portuguese Hospital ","The Hints from the Crowd ProjectCan the crowd be a source of information? Is it possible to receive useful hints from comments, blogs and product reviews? In the era of Web 2.0, people are allowed to give their opinion about everything such as movies, hotels, etc.. These reviews are social knowledge, that can be exploited to suggest possibly interesting items to other people.#R##N##R##N#The goal of the Hints From the Crowd HFC project is to build a NoSQL database system for large collections of product reviews; the database is queried by expressing a natural language sentence; the result is a list of products ranked based on the relevance of reviews w.r.t. the natural language sentence. The best ranked products in the result list can be seen as the best hints for the user based on crowd opinions the reviews.#R##N##R##N#The HFC prototype has been developed to be independent of the particular application domain of the collected product reviews. Queries are performed by evaluating a text-based ranking metric for sets of reviews, specifically devised for this system; the metric evaluates the relevance of product reviews w.r.t. a natural language sentence the query.#R##N##R##N#We present the architecture of the system, the ranking metric and analyze execution times.","Comparison of a one and two parameter family of transmission conditions for Maxwell's equations with dampingTransmission conditions between subdomains have a substantial influence on the convergence of iterative domain decomposition algorithms. For Maxwell's equations, transmission conditions which lead to rapidly converging algorithms have been developed both for the curl-curl formulation of Maxwell's equation, see [2, 3, 1], and also for first order formulations, see [7, 6]. These methods have well found their way into applications, see for example [9, 11, 10]. It turns out that good transmission conditions are approximations of transparent boundary conditions. For each form of approximation chosen, one can try to find the best remaining free parameters in the approximation by solving a min-max problem. Usually allowing more free parameters leads to a substantially better solution of the min-max problem, and thus to a much better algorithm. For a particular one parameter family of transmission conditions analyzed in [4], we investigate in this paper a two parameter counterpart. The analysis, which is substantially more complicated than in the one parameter case, reveals that in one particular asymptotic regime there is only negligible improvement possible using two parameters, compared to the one parameter results. This analysis settles an important open question for this family of transmission conditions, and also suggests a direction for systematically reducing the number of parameters in other optimized transmission conditions.","Scalable Domain Decomposition Algorithms for Contact Problems: Theory, Numerical Experiments, and Real World Problems ","VM Profile Based Optimized Network Attack Pattern Detection Scheme for DDOS Attacks in Cloud ","Study of interaction concepts in 3D virtual environmentThis paper describes what could be understood by interaction techniques and interaction concepts. In this work we focus in particular the second screen applications. Research of interaction techniques and concepts in this case investigates how to design interaction concepts with tablet as second screen, by remote connection with virtual environment on a primary screen. However, the actual samples used in this research are summarized by interactions like selection, manipulation and navigation aspects.","A membrane-inspired algorithm with a memory mechanism for knapsack problems *Membrane algorithms are a class of distributed and parallel algorithms inspired by the structure and behavior of living cells. Many attractive features of living cells have already been abstracted as operators to improve the performance of algorithms. In this work, inspired by the function of biological neuron cells storing information, we consider a memory mechanism by introducing memory modules into a membrane algorithm. The framework of the algorithm consists of two kinds of modules (computation modules and memory modules), both of which are arranged in a ring neighborhood topology. They can store and process information, and exchange information with each other. We test our method on a knapsack problem to demonstrate its feasibility and effectiveness. During the process of approaching the optimum solution, feasible solutions are evolved by rewriting rules in each module, and the information transfers according to directions defined by communication rules. Simulation results showed that the performance of membrane algorithms with memory cells is superior to that of algorithms without memory cells for solving a knapsack problem. Furthermore, the memory mechanism can prevent premature convergence and increase the possibility of finding a global solution.","Infinite Positive Semidefinite Tensor Factorization for Source Separation of Mixture Signals ","Taxonomy Development in Health-ITHealth-IT is attracting increasing attention in the research community. To understand the relevant constructs and the relationships among them, many authors present taxonomies or typologies for classifying different things in health-IT. Even with much attention to health-IT, there is still limited theoretical knowledge in this field. This may be attributed to our observation that the process of developing taxonomies has not been adequately addressed in the health-IT literature. In this paper we address this challenge by (a) a comprehensive literature survey that shows a high diversity in the field and that the related discussion of the structural nature has largely been ad hoc, (b) presenting methods for developing health-IT taxonomies, and, (c) contributing to the theoretical foundations of the field by a taxonomy for health-IT applications.","Introductions to description logics: a guided tourDescription Logics (DLs) are the logical formalism underlying the standard web ontology language OWL 2. DLs have formal semantics which are the basis for many powerful reasoning services. This paper provides an overview of basic topics in the field of Description Logics by surveying the introductory literature and course material with a focus on DL reasoning services. The resulting compilation also gives a historical perspective on DLs as a research area.","A Boosted Cascade of Directional Local Binary Patterns for Multispectral Palmprint Recognition ","Correcting Distortion of Views into AquariumIn this paper, we discuss a way to correct light distortion of views into an aquarium. When we see fish in an aquarium, they ap- pear closer also distorted due to light distortion. In order to correct the distortion, the light rays travelling in the aquarium directly towards an observer should hit him/her after emerging from the aquarium. A basic idea is to capture those light rays by a reference camera, then merge the rays as a single view, which is displayed to the observer. An experiment in a real world environment shows that light distortion of a view into an aquarium can be corrected using the multiple reference camera views.","Emerging Concepts between Software Engineering and Knowledge Management ","An Improvement of Subject Reacquisition by Reasoning and RevisionCCTV systems are broadly deployed in the present world. Despite this, the impact on anti-social and criminal behaviour has been minimal. Sub- ject reacquisition is a fundamental task to ensure in-time reaction for intelligent surveillance. However, traditional reacquisition based on face recognition is not scalable, hence in this paper we use reasoning techniques to reduce the compu- tational effort which deploys the time-of-flight information between interested zones such as airport security corridors. Also, to improve accuracy of reacquisi- tion, we introduce the idea of revision as a method of post-processing. We demon- strate the significance and usefulness of our framework with an experiment which shows much less computational effort and better accuracy.","Approximating Maximum Disjoint Coverage in Wireless Sensor Networks ","Automatic classification of web databases using domain-dictionariesThe identification, classification and integration of databases on the Web (also called web databases) as information sources is still a great challenge due to their constantly growing and diversification. The classification of such web databases according to their application domain is an important step towards the integration of deep web sources. Moreover, given the design and content heterogeneity that exists among the different web databases, their automatic classification become a great challenge and a highly demanded task, requiring techniques that allow to cluster web databases according to the domains they belong to. In this paper we present a strategy for automatic classification of web databases based on a new supervised approach. This strategy uses the visible information available on a group of specific-domain Web Query Interfaces (WQIs) to construct a dictionary or lexicon that will allow to better describe a particular domain of interest. The dictionary is enriched with synonyms. In our experiments, the dictionary was built from a set of randomly selected specific-domain WQIs. The automatic WQI classification based on dictionaries generated in this way showed efficient and competitive results compared against related work.","Inferring the demographics of search users: social data meets search queriesKnowing users' views and demographic traits offers a great potential for personalizing web search results or related services such as query suggestion and query completion. Such signals however are often only available for a small fraction of search users, namely those who log in with their social network account and allow its use for personalization of search results. In this paper, we offer a solution to this problem by showing how user demographic traits such as age and gender, and even political and religious views can be efficiently and accurately inferred based on their search query histories. This is accomplished in two steps; we first train predictive models based on the publically available myPersonality dataset containing users' Facebook Likes and their demographic information. We then match Facebook Likes with search queries using Open Directory Project categories. Finally, we apply the model trained on Facebook Likes to large-scale query logs of a commercial search engine while explicitly taking into account the difference between the traits distribution in both datasets. We find that the accuracy of classifying age and gender, expressed by the area under the ROC curve (AUC), are 77% and 84% respectively for predictions based on Facebook Likes, and only degrade to 74% and 80% when based on search queries. On a US state-by-state basis we find a Pearson correlation of 0.72 for political views between the predicted scores and Gallup data, and 0.54 for affiliation with Judaism between predicted scores and data from the US Religious Landscape Survey. We conclude that it is indeed feasible to infer important demographic data of users from their query history based on labelled Likes data and believe that this approach could provide valuable information for personalization and monetization even in the absence of demographic data.","Political and Economic Implications of Authoritarian Control of the Internet ","Loop elimination for database updatesThe additional expressive power of procedural extensions of query and update languages come at the expense of trading the efficient set-at-a-time processing of database engines for the much less efficient tuple-at-a-time processing of a procedural language. In this work, we consider the problem of rewriting for-loops with update statements into sequences of updates which do not use loops or cursors and which simultaneously carry out the action of several loop iterations in a set-at-a-time manner. We identify idempotence as the crucial condition for allowing such a rewriting. We formulate concrete rewrite rules for single updates in a loop and extend them to sequences of updates in a loop.","Dimensional reduction of cardiac models for effective validation and calibrationComplex 3D beating heart models are now available, but their complexity makes calibration and validation very difficult tasks. We thus propose a systematic approach of deriving simplified reduced-dimensional models, in \"0D\" --- typically, to represent a cardiac cavity, or several coupled cavities --- and in \"1D\" --- to model elongated structures such as fibers or myocytes. As illustrations of our approach, we demonstrate model validation based on experiments performed with papillary muscles, and calibration using patient-specific pressure-volume loops.","Vehicle Tracking by Simultaneous Detection and Viewpoint EstimationWe address the problem of vehicle detection and tracking for traffic monitoring in Smart City applications. We introduce a novel approach for vehi- cle tracking by simultaneous detection and viewpoint estimation. An Extended Kalman Filter (EKF) is adapted to describe the vehicle's motion when not only the pose of the object is measured, but also its viewpoint with respect to the cam- era. Specifically, we enhance the motion model with observations of the vehicle viewpoint jointly extracted by the detection step. The approach is evaluated on a novel and challenging dataset with different video sequences recorded at ur- ban environments, which is released with the paper. Our experimental validation confirms that the integration of an EKF with both detections and viewpoint esti- mations results beneficial.","Information Overload in Technology-based Education: a Meta-AnalysisEducational technology has transformed learning by facilitating collaboration with peers and teachers, enabling quick access to a wide range of information resources and the ability to create new information content. However, the ubiquitous nature and ease of use of technology leads to a plethora of recorded information. Processing this varied and often redundant information has overloaded students, which is detrimental to learning. The purpose of this paper is to review the literature related to the problem of information overload in the online educational domain, including causes, available solutions and its influence on knowledge construction. The results show that until recently the research focus has been on cognitive technological solutions rather than collaborative learning. New themes such as collaborative approaches for managing information overload and its implications on knowledge construction are emerging.","Performing Online and Offline: How DJs Use Social Networks ","Exploring Subscription Renewal Intention of Operational Cloud Enterprise Systems : A Socio-Technical Approach ","What Readers Want to Experience: An Approach to Quantify Conversational Maxims with Preferences for Reading BehaviourSearching information on web pages is a tedious task for#R##N#users as web servers provide complete web pages and do not tailor their#R##N#content to the user's current information need. This leaves an enormous amount#R##N#of workload for the user and influences his emotional attitude towards#R##N#the whole task even if a search engine has filtered pages that are relevant to#R##N#a user query. In this paper, we propose an approach to adapt the response to#R##N#queries to user preferences for his reading experience in order to leverage the#R##N#problem of information overload. With these preferences, it is possible to#R##N#select the most preferred content from a web page. In our view, the#R##N#preferences are a quantitative way to express conversational maxims. We present#R##N#our experimental approach to learn these preferences from annotated browsing#R##N#sessions and introduce a decision strategy for the selection of content on the#R##N#basis of the learned preferences.","Adaptive Uncertainty Quantification for Computational Fluid Dynamics ","Human Behaviour in HCI: Complex Emotion Detection through Sparse Speech FeaturesTo obtain a more human-like interaction with technical systems, those have to be adaptable to the users' individual skills, preferences, and current emotional state. In human-human interaction (HHI) the behaviour of the speaker is characterised by semantic and prosodic cues, given as short feedback signals. These signals minimally communicate certain dialogue functions such as attention, understanding, confirmation, or other attitudinal reactions. Thus, these signals play an important role in the progress and coordination of interaction. They allow the partners to inform each other of their behavioural or affective state without interrupting the ongoing dialogue.#R##N##R##N#Vocal communication provides acoustic details revealing the speaker's feelings, believes, and social relations. Incorporating discourse particles (DPs) in human-computer interaction (HCI) systems will allow the detection of complex emotions, which are currently hard to access. Complex emotions in turn are closely related to human behaviour. Hence, integrating automatic DP detection and complex emotion assignment in HCI systems provides a first approach to the integration of human behaviour understanding in HCI systems.#R##N##R##N#In this paper we present methods allowing to extract the pitch-contour of DPs and to assign complex emotions to observed DPs. We investigate the occurrences of DPs in naturalistic HCI and show that DPs may be assigned to complex emotions automatically. Furthermore, we show that DPs are indeed related to behaviour, showing an age-gender specific usage during naturalistic HCI. Additionally, we prove that DPs may be used to automatically detect and classify complex emotions during HCI.","Generalizations of ApproximationsIn this paper we consider a generalization of the indiscernibility relation, i.e., a relation R that is not necessarily reflexive, symmetric, or transitive. There exist 36 basic definitions of lower and upper approximations based on such relation R. Additionally, there are six probabilistic approximations, generalizations of 12 corresponding lower and upper approximations. How to convert remaining 24 lower and upper approximations to 12 respective probabilistic approximations is an open problem.","Transition constraints: a study on the computational complexity of qualitative changeMany formalisms discussed in the literature on qualitative spatial reasoning are designed for expressing static spatial constraints only. However, dynamic situations arise in virtually all applications of these formalisms, which makes it necessary to study variants and extensions dealing with change. This paper presents a study on the computational complexity of qualitative change. More precisely, we discuss the reasoning task of finding a solution to a temporal sequence of static reasoning problems where this sequence is subject to additional transition constraints. Our focus is primarily on smoothness and continuity constraints: we show how such transitions can be defined as relations and expressed within qualitative constraint formalisms. Our results demonstrate that for point-based constraint formalisms the interesting fragments are NP-complete in the presence of continuity constraints, even if the satisfiability problem of its static descriptions is tractable.","A Review into eHealth Services and Therapies: Potential for Virtual Therapeutic Communities - Supporting People with Severe Personality DisordereHealth has expanded hugely over the last fifteen years and continues to evolve, providing greater benefits for patients, health care professionals and providers alike. The technologies that support these systems have become increasingly more sophisticated and have progressed significantly from standard databases, used for patient records, to highly advanced Virtual Reality (VR) systems for the treatment of complex mental health illnesses. The scope of this paper is to initially explore e-Health, particularly in relation to technologies supporting the treatment and management of wellbeing in mental health. It then provides a case study of how technology in e-Health can lend itself to an application that could support and maintain the wellbeing of people with a severe mental illness. The case study uses Borderline Personality Disorder as an example, but could be applicable in many other areas, including depression, anxiety, addiction and PTSD. This type of application demonstrates how e-Health can empower the individuals using it but also potentially reducing the impact upon health care providers and services.","Spectrum Access Game for Cognitive Radio Networks with Incomplete Information ","A Brief Survey on Semi-Lagrangian Schemes for Image Processing ","Image Representation and Recognition Based on Directed Complex Network ModelImage structure representation is a vital technique in the image recognition. A novel image representation and recognition method based on directed complex network is proposed in this paper. Firstly, the key points are extracted from an image as the nodes to construct an initial complete undirected complex network. Then, the k-nearest neighbor evolution method is designed to form a series of directed networks. At last, the feature descriptor of the image is constructed by concatenating the structure features of each directed network to finally achieve image recognition. Experimental results demonstrate that the proposed method outperforms the traditional methods in image recognition and can describe the structure of images more effectively.","Artificial Immune System for Forecasting Time Series with Multiple Seasonal CyclesMany time series exhibit seasonal variations related to the daily, weekly or annual activity. In this paper a new immune inspired univariate method for forecasting time series with multiple seasonal periods is proposed. This method is based on the patterns of time series seasonal sequences: input ones representing sequences preceding the forecast and forecast ones representing the forecasted sequences. The immune system includes two populations of immune memory cells --- antibodies, which recognize both types of patterns represented by antigens. The empirical probabilities that the forecast pattern is detected by the kth antibody from the second population while the corresponding input pattern is detected by the jth antibody from the first population, are computed and applied to the forecast construction. The empirical study of the model including sensitivity analysis to changes in parameter values and the robustness to noisy and missing data is performed. The suitability of the proposed approach is illustrated through applications to electrical load forecasting and compared with ARIMA and exponential smoothing approaches.","Extreme Learning Machine Approach for On-Line Voltage Stability AssessmentIn recent years, voltage instability has become a major threat for the operation of many power systems. This paper proposes a scheme for on-line assessment of voltage stability of a power system for multiple contingencies using an Extreme Learning Machine (ELM) technique. Extreme learning machines are single-hidden layer feed- forward neural networks, where the training is restricted to the output weights in order to achieve fast learning with good performance. ELMs are competing with Neural Networks as tools for solving pattern recognition and regression problem. A single ELM model is developed for credible contingencies for accurate and fast estimation of the voltage stability level at different loading conditions. Loading margin is taken as the indicator of voltage instability. Precontingency voltage magnitudes and phase angles at the load buses are taken as the input variables. The training data are obtained by running Continuation Power Flow (CPF) routine. The effectiveness of the method has been demonstrated through voltage stability assessment in IEEE 30-bus system. To verify the effectiveness of the proposed ELM method, its performance is compared with the Multi Layer Perceptron Neural Network (MLPNN). Simulation results show that the ELM gives faster and more accurate results for on-line voltage stability assessment compared with the MLPNN.","Using Interpolation for the Verification of Security Protocols ","Proposal of Non-invasive Fingerprint Age Determination to Improve Data Privacy Management in Police Work from a Legal Perspective Using the Example of Germany ","Using HMMs and Depth Information for Signer-Independent Sign Language RecognitionIn this paper, we add the depth information to effectively locate the 3D position of the hands in the sign language recognition system. But, the information will be changed by the different testers and we can't do the recognition well. So, we use the incremental changes of the three-dimensional coordinates on a unit time as the feature parameter to fix the above problem. We record the changes of the three-dimensional coordinates in time, then using the hidden Markov models to recognize the variety of sign language movement changing on the time domain. Experiment verifies the proposed method is superior to traditional ones.","A quick tour of babelnet 1.1In this paper we present BabelNet 1.1, a brand-new release of the largest \"encyclopedic dictionary\", obtained from the automatic integration of the most popular computational lexicon of English, i.e. WordNet, and the largest multilingual Web encyclopedia, i.e. Wikipedia. BabelNet 1.1 covers 6 languages and comes with a renewed Web interface, graph explorer and programmatic API. BabelNet is available online at    http://www.babelnet.org       .","Parameterized design and evaluation of bandwidth compressor for floating-point data streams in FPGA-Based custom computingWe are applying bandwidth compression to enhance performance of FPGA-based custom computing. This paper presents and evaluates hardware design of a bandwidth compressor and decompressor for a floating-point data stream of various bit width. We show their structures parameterized for a bit width of an input word. Through FPGA-based prototype implementation, we evaluate the resource utilization, frequency, and compression ratio. The expermental results show that the compressor and decompressor for 32-bit and 64-bit floating-point numbers achieve bandwidth reduction at a ratio of 3.1 and 1.8 for 2D data of fluid dynamics computation, while they require only small area and operate at higher than 200MHz.","Utilizing Social Networks for User Model Priming: User Attitudes. ","An Effective Dynamic Gesture Recognition System Based on the Feature Vector Reduction for SURF and LCSSpeed Up Robust Feature (SURF) and Local Contour Sequence(LCS) are methods used for feature extraction techniques for dynamic gesture recognition. A problem presented by these techniques is the large amount of data in the output vector which difficult the classification task. This paper presents a novel method for dimensionality reduction of the features extracted by SURF and LCS, called Convexity Approach. The proposed method is evaluated in a gesture recognition task and improves the recognition rate of LCS while SURF while decreases the amount of data in the output vector.","UCD Guerrilla Tactics: A Strategy for Implementation of UCD in Sweden\u2019s Military Defense OrganizationsThe problem of how to implement user-centred design (UCD) is well established as a research topic within HCI. Yet there are unresolved issues in order for UCD to actually be used in practice. This paper will present a case study within Sweden s military defense organizations, concerning the introduc- tion of UCD. The overarching goal of the research was to bridge the gap be- tween work practices and systems development; focusing the efforts on intro- ducing usability work in the procurement process. We concluded early on that we needed to develop and formulate an approach that is probably common in practice but not described or used in research. We call this strategy UCD guer- rilla tactics, which entails to do the unexpected, to work pragmatically with change, and to use user centred methods to introduce UCD. Our main target group was future users and procurers of UCD methods. We aimed at demon- strating and involving them in the work through user centred activities. The tac- tics is also a reflexive and flexible approach based on continuous evaluation of what is feasible and potentially gives the largest outcome. This paper describes the guerrilla tactics, how it was applied in a case study and factors that should be considered when using it.","Estimation of User\u2019s State during a Dialog Turn with Sequential Multi-modal Features ","Breaking Points \u2014 A Continuously Developing Interactive Digital NarrativeBreaking Points is an interactive digital narrative (IDN) that puts the user in the position of a young woman who feels trapped in a daily routine she would like to escape from. The narrative design connects more important decisions with seemingly trivial ones and presents the user with immediate and delayed consequence in the form of narrative feedback, for a complex and more life-like experience. By aligning the experience of a single walkthrough with a day in the life of the heroine, the project invites replay. The project is also a study of authorial challenges and opportunities offered by different authoring modes, namely the switch from coding from scratch to the ASAPS environment. As the project is prepared for release on touch-based tablets, the paper focuses on how changes in the underlying technology have afforded continuous reshaping of the narrative.","Traditional CFD Boundary Conditions Applied to Blood Analog Flow through a Patient-Specific Aortic CoarctationFlow of a blood analog is modeled through a patient-specific aortic coarctation using ANSYS Fluent software. Details of the patient data aortic geometry and prescribed flow conditions were provided by the MICCAI-STACOM CFD Challenge website. The objective is to predict a blood pressure difference across the rigid coarctation under both rest and exercise stress conditions. The supplied STL geometry was used to create coarse and fine viscous meshes of 250K and 4.6M cells. Our CFD method employed laminar, Newtonian flow with a total pressure inlet condition and special outlet BCs derived from reconstructed flow waveforms. Analysis setup and outlet BCs were treated as a traditional non-physiological CFD problem. CFD results demonstrate that the supplied AscAo pressure waveform and flow distributions are well matched by our simulations. A non-uniform pressure gradient field is predicted across the coarctation with strong interactions with each supra-aortic vessel branch.","A fast generative spell corrector based on edit distanceOne of the main challenges in the implementation of web-scale online search systems is the disambiguation of the user input when portions of the input queries are possibly misspelt. Spell correctors that must be integrated with such systems have very stringent restrictions imposed on them; primarily they must possess the ability to handle large volume of concurrent queries and generate relevant spelling suggestions at a very high speed. Often, these systems consist of highend server machines with lots of memory and processing power and the requirement from such spell correctors is to minimize the latency of generating suggestions to a bare minimum.#R##N##R##N#In this paper, we present a spell corrector that we developed to cater to high volume incoming queries for an online search service. It consists of a fast, per-token candidate generator which generates spell suggestions within a distance of two edit operations of an input token. We compare its performance against an n-gram based spell corrector and show that the presented spell candidate generation approach has lower response times.","Design Matters: Mid-Term Results from a Multi-Design Fuel Economy Feedback Experiment ","A Network-Based Meta-analysis Strategy for the Selection of Potential Gene Modules in Type 2 DiabetesWe propose an integrative network-based meta-analysis strategy to enable the selection of potential gene markers for one of the most prevalent diseases worldwide, Type 2 diabetes (T2D), formally known as the non-insulin dependent diabetes mellitus. Comprehensive elucidation of the genes regulated through this disorder and their wiring will provide a more complete understanding of the overall gene network topology and their role in disease progression and treatment. The proposed strategy was able to find conservative gene modules which play interesting role in T2D, pointing to gene markers such as NR3C1, ADIPOR1 and CDC123. Network-based meta-analysis by enumerating conserved gene modules pave a practical approach to the identification of candidate gene markers across several related transcriptomic studies. The NEMESIS R pipeline for network-based meta-analysis is also provided.","Awareness and control for inter-widget communication: challenges and solutionsRecently, widget-based Web applications, i. e., mashups have gained momentum, as they make it possible to address the \"long tail\" of software needs. By enabling data and control flow among widgets --- inter-widget communication (IWC) --- integration of data and functionality can be defined by the end users themselves. However, IWC entails several problems that may reduce the overall user confidence in a system. Based on the results of user studies on the OMELETTE mashup platform, this paper analyzes the problem space and evaluates possible solutions to improve user perception of IWC. Further, a discussion of promising techniques is offered and pending challenges are identified.","ARM-COMS: ARm-Supported embodied COmmunication monitor systemRemote communication systems are getting popular these days, which makes it possible to enjoy audio/video communication over the network in high quality. However, remote communication using these systems is still not identical to face-to-face meeting due to several reasons which are still open issues. This study focuses on two of the issues. One is lack of tele-presence and the other one is lack of connection in communication. In order to tackle these issues, this study proposes an idea of connecting remote individuals through augmented tele-presence systems called ARM-COMS: ARm-supported eMbodied COmmunication Monitor System. ARM-COMS is composed of a desktop robotic arm and a tablet PC which is attached to it. The tablet PC presents audio/video images of a remote person just as typical video conference. However, ARM-COMS controls the physical movement of the tablet PC during the video conference to be consistent with physical motion of the remote participant as if the remote person were there and behaved in a face-to-face conversation. ARM-COMS also considers the meaningful physical position in space to show the connection with other person or topics. The tablet PC approaches to the speaking person as if embodied communication occurs. This paper shows the idea of ARM-COMS and presents some of the on-going work of the study to show the feasibility of the idea.","Position Paper: Privacy Risk Analysis Is about Understanding Conflicting Incentives ","Fast Implementation of a New Radial Symmetry Measure for PhotogrammetryIndustrial applications of photogrammetry usually involve the detection and recognition of targets placed on the surface of objects. The existing algorithms that allow to cope with the varying conditions of industrial environments are computationally very expensive. This paper proposes an implementation on graphics processing unit (GPU) for the detection of circular targets based on radial symmetry detection and parallel implementation in central processing unit (CPU) for location and recognition of these targets. The tests we have performed show the efficiency of GPU and CPU implementation in terms of execution times and performance.","The Disruptive Potential of Software as a Service: Validation and Application of an Ex-Ante MethodologyWe address current discussions on the potential of cloud computing to disrupt the structures of the software industry by selecting, validating and further developing a method for ex-ante identification of disruptive innovations that we imported from innovation management theory into the information systems area. Based on a review of a previous forecast in the area of web applications, we could show that this method was able to predict the likelihood for web applications to pose a minor disruptive threat to incumbents in the industry. Furthermore, we adapted and modified this method and applied it to the cloud computing market through the example of CRM software and the firms Salesforce and SAP. Our results indicate that Salesforce's on-demand software products in the CRM market show a high disruptive potential but at the same time the method also reveals that SAP response strategy limits its possible failure to this disruptive threat.","A Systematic Method to Evaluate and Compare the Performance of Physical Unclonable Functions ","Optimization as a Service: On the Use of Cloud Computing for Metaheuristic OptimizationCloud computing has emerged as a new technology that provides on-demand access to a large amount of computing resources. This makes it an ideal environment for executing metaheuristic optimization experiments. In this paper, we investigate the use of cloud computing for metaheuristic optimization. This is done by analyzing job characteristics from our production system and conducting a performance comparison between different execution environments. Additionally, a cost analysis is done to incorporate expenses of using virtual resources.","Sensor-Based Adaptation of User Interface on Android PhonesThe notion of context-aware computing is generally the ability for the devices to adapt their behavior to the surrounding environment, ultimately enhancing usability. Sensors are an important source of information input in any real world context and several previous research contributions look into this topic. In our research, we combine sensor-generated context information re- ceived both from the phone itself and information retrieved from cloud-based servers. All data is integrated to create a context-aware mobile device, where we implemented a new customized home screen application for Android enabled devices. Thus, we are also able to remotely configure the mobile devic- es independent of the device types. This creates a new concept of context- awareness and embraces the user in ways previously unavailable.","Comparison of Feedback Influence on Ring Oscillator Performance for IR-UWB Pulse Generator in 0.13 \u03bcm and 0.18 \u03bcm CMOS TechnologiesA CMOS three-stage ring oscillator is examined in UMC 0.13\u00a0\u03bcm and 0.18\u00a0\u03bcm technologies. The influence of PMOS transistor and resistor, as inverter feedbacks, on the ring oscillator frequency and the peak-to-peak amplitude is investigated in both technologies. Furthermore, as the ring oscillator usually drives a buffer in pulse generator/transmitter chain, dependence of its Figures of Merit on the buffer feedback is presented in the paper. Simulation results showed that the ring oscillator frequency is strongly dependent on the inverter feedback. The presented techniques can be used to increase (resistive feedback) and control (PMOS transistor feedback) the ring oscillator frequency. As the ring oscillator is a part of an IR-UWB (Impulse Radio Ultra Wide Band) pulse generator, its oscillating frequency determines the spectrum central frequency and has significant effect on spectrum fitting within UWB FCC mask.","Interactive Design and the Human Experience: What Can Industrial Design Teach UsWith more than a third of PC users, 37 percent are now turning to Smartphones and Tablets to surf the Internet and access entertainment. With this dynamic shift, the use of the wide-open Web has migrated to a semi-closed platform, or Apps, that uses the Internet for data transportation, something once performed by a browser. Users are accessing data all at the same time these devices are becoming intergraded into every aspect of modern life. User interfaces and experiences are changing and designers and developers have to become aware of addressing these changes.","Cutting Down the Energy Cost of Geographically Distributed Cloud Data CentersThe energy costs constitute a significant portion of the total cost of cloud providers. The major cloud data centers are often geographically distributed, and this brings an opportunity to minimize their energy cost. In this work, we model a geographically distributed data center network that is specialized to run batch jobs. Taking into account the spatio-temporal variation in the electricity prices and the outside weather temperature, we model the problem of minimizing the energy cost as a linear programming problem. We propose various heuristic solutions for the problem. Our simulations using real-life workload traces and electricity prices demonstrate that the proposed heuristics can considerably decrease the total energy cost of geographically distributed cloud data centers, compared to a baseline technique.","Dynamically improving collective environments through mood induction proceduresERDF - European Regional Development Fund#R##N#through the COMPETE Programme (operational programme for competitiveness)","Using Geographic Cost Functions to Discover Vessel Itineraries from AIS Messages ","Gradient Art: Creation and VectorizationThere are two different categories of methods for producing vector gradients. One is mainly interested in converting existing photographs into dense vector representations. By vector it is meant that one can zoom infinitely inside images, and that control values do not have to lie onto a grid but must represent subtle color gradients found in input images. The other category is tailored to the creation of images from scratch, using a sparse set of vector primitives. In this case, we still have the infinite zoom property, but also an advanced model of how space should be filled in-between primitives, since there is no input photograph to rely on. These two categories are actually extreme cases, and seem to exclude each other: a dense representation is difficult to manipulate, especially when one wants to modify topology; a sparse representation is hardly adapted to photo vectorization, especially in the presence of texture. Very few methods lie in the middle, and the ones that do require user assistance. The challenge is worth the effort though: it would permit to convert an image into a vector primitives easily amenable to stylization.","Defining and Validating a Multimodel Approach for Product Architecture Derivation and ImprovementSoftware architectures are the key to achieving the non-functional requirements NFRs in any software project. In software product line SPL development, it is crucial to identify whether the NFRs for a specific product can be attained with the built-in architectural variation mechanisms of the product line architecture, or whether additional architectural transformations are required. This paper presents a multimodel approach for quality-driven product architecture derivation and improvement QuaDAI. A controlled experiment is also presented with the objective of comparing the effectiveness, efficiency, perceived ease of use, intention to use and perceived usefulness with regard to participants using QuaDAI as opposed to the Architecture Tradeoff Analysis Method ATAM. The results show that QuaDAI is more efficient and perceived as easier to use than ATAM, from the perspective of novice software architecture evaluators. However, the other variables were not found to be statistically significant. Further replications are needed to obtain more conclusive results.","Applying Rogerian Psychologist in Human-Computer Interaction: A Case Study ","Exploring Information Flow Patterns Between News Portals and Microblogging Platforms ","Utilizing Concept Mapping in Intelligent Tutoring Systems ","On the poetry of designThis paper seeks to answer the questions why the original design concept was invented and what disciplines were responsible for its development. Therefore, significant works from the Classical Antiquity and Renaissance are selected for analyzing the invention of the original design. The paper comes to the conclusion that design was created from the disciplines poetry, music, philosophy, rhetoric, painting, sculpture and architecture. Especially, poetry was of particular importance for design. Finally, the paper describes how the poetry of design is related to interaction design.","EEG-MINE: Mining and Understanding Epilepsy DataGiven electroencephalogram time series data from patients with epilepsy, can we find patterns and regularities? The typical approach thus far is to use tensors or dynamical systems. Here, we present EEG-MINE, a nonlinear, chaos-based \"gray box model\", that blends domain knowledge with data observations. When applied to numerous, real EEG sequences, EEG-MINE (a) can successfully reconstruct the signals with high accuracy; (b) can spot surprising patterns within seizure EEG signals; and (c) may provide early warning of epileptic seizures.","Measuring the Performance of Electronic Health Records: A Case Study in Residential Aged Care in Australiac Center for Medical Informatics, Peking University Abstract and Objective Measuring the performance of electronic health records (EHR) is an important, yet un-resolved challenge. Various measurements have addressed different aspects of EHR suc- cess, yet a holistic, comprehensive measurement tool needs to be developed to capture the potential EHR success variables completely. A self-administered questionnaire survey instru- ment was developed based on the theoretical framework of the DeLone and McLean Information Systems Success Model. It measures nigh variables of EHR success: system quality, in- formation quality, service quality, training, self efficacy, inten- tion to use, use, user satisfaction and net benefits. The instru- ment was used to measure the performance of aged care EHR systems in three aged care organizations. The results suggest that the instrument was reliable.","Diffusing public sector services through high definition videoThe adoption of public services that have been delivered electronically are not necessarily uniformly accepted. This paper argues that the diffusion of high definition video communication as a complimentary mechanism for service delivery could not only alleviate this existing gap in adoption and diffusion of government services but also significantly improve services and save cost for governments. This paper introduces a holistic perspective on how video technology could be integrated in existing services using examples of health, education, and municipality services. This paper introduces a taxonomy of criteria that characterises high definition video communication for diffusing public services by examining the associated benefits, cost and risks.","Tree-Like Structures in Graphs: A Metric Point of View ","B2C Trading Platform Security Strategy Based on the Optimal Stopping Theory ","Bias Blaster \u2013 Aiding Cognitive Bias Modification- Interpretation through a bubble shooter induced gameflowThis paper presents the design and development of Bias Blaster. Bias Blaster is a proof-of-concept integrated bubble-shooter game with an evidence-based therapeutic intervention, i.e., Cognitive Bias Modification Interpretation (CBM-I). The game is tailor-made for patients of the Dutch national mental health organization (GGZ) recovering from a First-Episode Psychosis (FEP). Cognitive Bias ModificationInterpretation treats the self-stigma and its associated interpretation bias as experienced by patients recovering from a FEP. The amount and frequency of CBM-I items and training is regulated by the patient, through an integrated game-mechanic of the modified bubble shooter. The game implements a motivational and reinforcement paradigm, which paves the way for the use of the rigorous and demanding CBM-I therapy. Moreover, Bias Blaster exploits the natural game flow of the bubble shooter to increase resilience and adherence throughout the treatment of FEP patients. This paper presents the design and development process of the game. The lessons learned are summarized in implications for the design of serious games: design for \u201cacceptance\u201c and as a \u201cserious therapeutic\u201d.","Automatic Classification of Eye Blink Types Using a Frame-Splitting MethodHuman eye blinks include voluntary (conscious) blinks and involuntary (unconscious) blinks. If voluntary blinks can be detected automatically, then input decisions can be made when voluntary blinks occur. Previously, we proposed a novel eye blink detection method using a Hi-Vision video camera. This method utilizes split interlaced images of the eye, which are generated from 1080i Hi-Vision format images. The proposed method yields a time resolution that is twice as high as that of the 1080i Hi-Vision format. We refer to this approach as the frame-splitting method. In this paper, we propose a new method for automatically classifying eye blink types on the basis of specific characteristics using the frame-splitting method.","A Survey on Clustering Techniques for Situation Awareness ","Exogenous and Endogenous Based Spatial Attention Analysis for Human Implicit Intention UnderstandingIn this paper, we develop a novel human implicit intention understanding model by mimicking the human-like visual attention and brain information processing mechanisms. In other words, the proposed model considers a hybrid cognitive neural system, which comprises of spatial attention model obtained based on exogenous and endogenous attention models. Generally, information can be selected via top-down or endogenous mechanisms depending on the goals of the observers while salient objects or events attract spatial attention via bottom-up or exogenous mechanisms allowing a rapid and efficient reaction to unexpected but important events. Given a visual stimulus, the spatial analysis module identifies the objects of interest by correlating the salient areas obtained from the exogenous module and the eye gaze information obtained from the endogenous module. Then, corresponding to an intent, each of the identified objects are classified in to one of the two classes - intent object or non-intent object, by analyzing the features such as fixation length (FL), fixation count (FC) and pupil size (PS) corresponding to each object. In the proposed model, support vector machine (SVM) is trained for classifying the different objects. Experimental results show that the proposed model generates plausible performance based on hybrid cognitive neural system.","Adaptative Delay Aware Data Gathering Strategy for Wireless Sensor Networks ","Technical Section: Quasi-developable surface modeling of contours with curved triangular patchesSkinning, also called lofting, is a powerful and popular method for modeling complex shapes. A surface modeled by the current skinning techniques nevertheless may be far from being developable, which is an important property desired in the manufacturing industry such as ship-hull, wing and body of aircraft, garment, etc. In this paper, a novel approach to skinning surface modeling is proposed. The proposed method interpolates the given curves with a collection of G^1 continuous self-defined triangular patches, and these patches are assembled together by globally minimizing the integral Gaussian curvature, i.e., the degree of developability. The proposed algorithm has been tested on a set of examples and the test results have demonstrated its promising use in a variety of applications.","A method for service failure effects analysis based on customer satisfactionRecently, the importance of service is widely accepted. Service Engineering that aims to design a service from the engineering viewpoint has been proposed. In order to achieve a successful service, service providers should maintain service quality and always satisfy their customers. To be specific, the provision of highly reliable service is essential. To realize highly reliable services it is important to minimize the occurrence of service failures. This paper proposes a method for analyzing service failure effects in the service design phase. Specifically, we define service failure and propose a procedure to analyze service failure effects with models that are proposed in Service Engineering. The proposed method is verified through its application to a nursing-care service.","Policy Conflict Handling as a Monitoring Activity of Hospital Information Systems ","Investigating the Impact of Experience and Solo/Pair Programming on Coding Efficiency: Results and Experiences from Coding Contests ","Answering SPARQL queries modulo RDF Schema with pathsSPARQL is the standard query language for RDF graphs. In its strict instantiation, it only offers querying according to the RDF semantics and would thus ignore the semantics of data expressed with respect to (RDF) schemas or (OWL) ontologies. Several extensions to SPARQL have been proposed to query RDF data modulo RDFS, i.e., interpreting the query with RDFS semantics and/or considering external ontologies. We introduce a general framework which allows for expressing query answering modulo a particular semantics in an homogeneous way. In this paper, we discuss extensions of SPARQL that use regular expressions to navigate RDF graphs and may be used to answer queries considering RDFS semantics. We also consider their embedding as extensions of SPARQL. These SPARQL extensions are interpreted within the proposed framework and their drawbacks are presented. In particular, we show that the PSPARQL query language, a strict extension of SPARQL offering transitive closure, allows for answering SPARQL queries modulo RDFS graphs with the same complexity as SPARQL through a simple transformation of the queries. We also consider languages which, in addition to paths, provide constraints. In particular, we present and compare nSPARQL and our proposal CPSPARQL. We show that CPSPARQL is expressive enough to answer full SPARQL queries modulo RDFS. Finally, we compare the expressiveness and complexity of both nSPARQL and the corresponding fragment of CPSPARQL, that we call cpSPARQL. We show that both languages have the same complexity through cpSPARQL, being a proper extension of SPARQL graph patterns, is more expressive than nSPARQL.","Grounding linked open data in wordnet: the case of the OSM semantic networkIn recent years, the open data (LOD) paradigm has emerged as a promising approach to structuring, publishing, and sharing data online, using Semantic Web standards. From a geospatial perspective, one of the key challenges consists of bridging the gap between the vast amount of crowdsourced, semi-structured or unstructured geo-information and the Semantic Web. Notably, OpenStreetMap (OSM) has gathered billions of objects from its contributors in a spatial folksonomy. The contribution of this paper is twofold. First, we add a piece to the LOD jigsaw, the OSM Semantic Network, structuring it as a W3C Simple Knowledge Organization System (SKOS) vocabulary, and discussing its role in the constellation of geo-knowledge bases. Second, we devise Voc2WordNet, a mapping approach between a given vocabulary and WordNet, a pivotal component in the LOD cloud. Our approach is evaluated on the OSM Semantic Network against a human-generated alignment, obtaining high precision and recall.","Smoothly Extending e-Tourism Services with Personalized Recommendations: A Case Study ","Constructing Continuous Systems from Discrete Cellular AutomataThis paper studies a way of transforming discrete time and discrete space cellular automata into systems described by partial differ- ential equations with a similar behavior. The goal is to find new kinds of chaotic behaviors for systems ruled by partial differential equations.","What snippets say about pagesWhat is the likelihood that a Web page is considered relevant to a query, given the relevance assessment of the corresponding snippet? Using a new FederatedWeb Search test collection that contains search results from over a hundred search engines on the internet, we are able to investigate such research questions from a global perspective. Our test collection covers the main Web search engines like Google, Yahoo!, and Bing, as well as smaller search engines dedicated to multimedia, shopping, etc., and as such reflects a realistic Web environment. Using a large set of relevance assessments, we are able to investigate the connection between snippet quality and page relevance. The dataset is strongly heterogeneous, and care is required when comparing resources. To this end, a number of probabilistic variables, based on snippet and page relevance, are introduced and discussed.","A 3D Ear Acquisition System Design by Using Triangulation Imaging PrincipleThe human ear is a new feature in biometrics that has several merits over the more common face, fingerprint and iris. It can be easily captured from a distance without a fully cooperative subject. Also, the ear has a relatively stable structure that does not change much with the age and facial expressions. In this paper, we present a novel method of 3D ear acquisition system by using triangulation imaging principle, and the experiment results show that this design is efficient and can be used for ear recognition.","Emotional range in value-sensitive deliberationThis paper presents a model of agent's behavior that takes into account emotions and moral values. In our proposal, when the description of the current situation reveals that a moral value is 'at stake', the moral goal of re-establishing the threatened value is included among the active goals. The compliance with values generates positive emotions like pride and admiration, while the opposite brings to shame and self-reproach.#R##N##R##N#During the deliberation phase, the agent appraises her plans in terms of the emotional reward they are expected to yield, given the trade off between moral and individual goals. In this phase, the emotional reward affects the agent's choices about her behavior. After the execution phase, one's and others' actions are appraised again in terms of the agent's values, giving rise to moral emotions.#R##N##R##N#The paper shows how emotional appraisal can be coupled with the choice among possible lines of action, presenting a mapping between plans and emotions that integrates and extends preceding proposals.","ConNeKTion: A Tool for Handling Conceptual Graphs Automatically Extracted from Text ","Improving consensus clustering of texts using interactive feature selectionConsensus clustering and interactive feature selection are very useful methods to extract and manage knowledge from texts. While consensus clustering allows the aggregation of different clustering solutions into a single robust clustering solution, the interactive feature selection facilitates the incorporation of the users experience in text clustering tasks by selecting a set of high-level features. In this paper, we propose an approach to improve the robustness of consensus clustering using interactive feature selection. We have reported some experimental results on real-world datasets that show the effectiveness of our approach.","Developing and implementing an interoperable document-based electronic health record. ","Techno-Social Energy Infrastructure Siting: Sustainable Energy Modeling Programming (SEMPro)Technical, environment, social, economic and political constraints are critical barriers to the development of new renewable energy supplies. SEMPro is an agent-based, predictive analytics model of energy siting policy in the techno-social space that simulates how competing interests shape siting outcomes to identify beneficial policy for sustainable energy infrastructure. Using a high voltage transmission line as a case study, we integrate project engineering and institutional factors with GIS data on land use attributes and US Census residential demographics. We focus on modeling citizen attitudinal, Community Based Organization (CBO) emergence and behavioral diffusion of support and opposition with Bilateral Shapley Values from cooperative game theory. We also simulate the competitive policy process and interaction between citizens, CBOs and regulatory, utility and governmental stakeholders using non-cooperative game theory. We find CBO formation, utility message and NGO messaging have a positive impact on citizen comments submitted as a part of the Environmental Impact Statement process, while project need and procedure have a negative impact. As citizens communicate and exchange political opinions across greater distances with more neighbors, less CBOs form but those that do are more effective, increasing the number of messages citizens send.","Protecting Third Party Privacy in Digital Forensic Investigations ","Computational Algorithmic Generation of High-Quality Colour Patterns ","Impact of Report Message Scheduling (RMS) in 1G/10G EPON and GPON (Extended Version)A wide array of dynamic bandwidth allocation (DBA) mechanisms have recently been proposed for improving bandwidth utilization and reducing idle times and packets delays in passive optical networks (PONs). The DBA evaluation studies commonly assumed that the report message for communicating the bandwidth demands of the distributed optical network units (ONUs) to the central optical line terminal (OLT) is scheduled for the end of an ONU's upstream transmission, after the ONU's payload data transmissions. In this article, we conduct a detailed investigation of the impact of the report message scheduling (RMS), either at the beginning (i.e., before the pay load data) or the end of an ONU upstream transmission on PON performance. We analytically characterize the reduction in channel idle time with reporting at the beginning of an upstream transmission compared to reporting at the end. Our extensive simulation experiments consider both the Ethernet Passive Optical Networking (EPON) standard and the Gigabit PON (GPON) standard. We find that for DBAs with offline sizing and scheduling of ONU upstream transmission grants at the end of a polling cycle, which processes requests from all ONUs, reporting at the beginning gives substantial reductions of mean packet delay at high loads. For high-performing DBAs with online grant sizing and scheduling, which immediately processes individual ONU requests, or interleaving of ONUs groups, both reporting at the beginning or end give essentially the same average packet delays.","Social Network Effect on Bidding Strategy Adoption in Online P2P Lending Market ","ISICIL: Semantics and Social Networks for Business IntelligenceThe ISICIL initiative (Information Semantic Integration through Communities of Intelligence onLine) mixes viral new web applications with formal semantic web representations and processes to integrate them into corporate practices for technological watch, business intelligence and scientific monitoring. The resulting open source platform proposes three functionalities: (1) a semantic social bookmarking platform monitored by semantic social network analysis tools, (2) a system for semantically enriching folksonomies and linking them to corporate terminologies and (3) semantically augmented user interfaces , activity monitoring and reporting tools for business intelligence.","Coordination Using Social Policies in Dynamic Agent OrganizationsWe seek to engineer adaptive coordination between agents working in and across dynamic organizations in a complex, distributed setting. Guided by predefined social policies, agents can create social commitments at run time to achieve coordination of knowledge and behaviour. We demonstrate coordination requirements by providing example policies, drawing on the need for knowledge cultivation in an emergency management scenario.","Modeling Relationship Strength for Link Prediction ","Strategies for Scheduling Risk Mitigation in Software Project Management ","Parse Thicket Representation for Multi-sentence SearchWe develop a graph representation and learning technique for parse structures for sentences and paragraphs of text. This technique is used to improve relevance answering complex questions where an answer is included in multiple sentences. We introduce Parse Thicket as a sum of syntactic parse trees augmented by a number of arcs for inter-sentence word-word relations such as coreference and taxonomic. These arcs are also derived from other sources, including Rhetoric Structure theory, and respective indexing rules are introduced, which identify inter-sentence relations and joins phrases connected by these relations in the search index. Generalization of syntactic parse trees (as a similarity measure between sentences) is defined as a set of maximum common sub-trees for two parse trees. Generalization of a pair of parse thickets to measure relevance of a question and an answer, distributed in multiple sentences, is defined as a set of maximal common sub-parse thickets. The proposed approach is evaluated in the product search domain of eBay.com, where user query includes product names, features and expressions for user needs, and the query keywords occur in different sentences of text. We demonstrate that search relevance is improved by single sentence-level generalization, and further increased by parse thicket generalization. The proposed approach is evaluated in the product search domain of eBay.com, where user query includes product names, features and expressions for user needs, and the query keywords occur in different sentences of text.","A quadratic algorithm for testing of Z -codesWe consider a subclass of circular codes, namely Z-codes for bi-infinite words, that have numerous interesting properties appeared in many problems of combinatorics on words. Our major concern is a very basic problem, which is to test whether a language of finite words is a Z-code. As the main result of this paper, we give an efficient algorithm running in a quadratic polynomial time for testing of Z-codes when they are regular.","Defeat Information Leakage from Browser Extensions via Data ObfuscationToday web browsers have become the de facto platform for Internet users. This makes browsers the target of a lot of attacks. With the security considerations from the very beginning, Chrome offers more protection against exploits via benign-but-buggy extensions. However, more and more attacks have been launched via malicious extensions while there is no effective solution to defeat such malicious extensions. As user's sensitive information is often the target of such attacks, in this paper, we aim to proactively defeat information leakage with our iObfus framework. With iObfus, sensitive information is always classified and labeled automatically. Then sensitive information is obfuscated before any IO operation is conducted. In this way, the users' sensitive information is always protected even information leakage occurs. The obfuscated information is properly restored for legitimate browser transactions. A prototype has been implemented and iObfus works seamlessly with the Chromium 25. Evaluation against malicious extensions shows the effectiveness of iObfus, while it only introduces trivial overhead to benign extensions.","Interactive Image Segmentation via Graph Clustering and Synthetic Coordinates ModelingWe propose a method for interactive image segmentation. We construct a weighted graph that represents the superpixels and the connections between them. An efficient algorithm for graph clustering based on synthetic coordinates is used yielding an initial map of classified pixels. The proposed method minimizes a min-max Bayesian criterion that has been successfully used on image segmentation problem taking into account visual information as well as the given markers. Experimental results and comparisons with other methods demonstrate the high performance of the proposed scheme.","Development of a Multimedia Courseware for Slow Learner Children with Reading Difficulties: MyLINUSThis paper presents the development of a multimedia courseware namely 'My LINUS' as a medium in teaching and learning specially designed for slow learner with reading difficulties. The courseware will help slow learner children using an approach and a suitable technique/method with appropriate teaching materials essential for the learning process. The courseware integrates Literacy and Numeracy (LINUS) Syllabus officially prepared by the Ministry of Education for primary school children aged between 7 to 9 years old with the learning multimedia theme. The \"MyLINUS\" primarily consists of 2 sections for the modules and exercises. The modules consist of 3 sub-modules. Each module is designed to teach in certain domain starting from Module 1 till Module 3. Module 1 teaches the users on how to recognize and pronounce a letter. Module 2 teaches users on how to combine letters to form a word. Module 3 guides users on how to combine words and syllable to form complete sentences. A user acceptance test was conducted in two primary schools in Perak. The results help to support suitability and acceptability and the effectiveness of the courseware for further improvement. The findings of the evaluation indicate positive feedback about the courseware.","Two Agents Competing for a Shared MachineIn this paper we address a deterministic scheduling problem in which two agents compete for the usage of a single machine. The agents submit their tasks in successive steps to an external coordinator, who sequences them according to a known priority rule. We introduce the problem for three different shop configurations, namely when the agents' parts are transferred to the machine through two distinct linear conveyor belts, when they are transferred through circular conveyor belts, and when parts can be freely picked from the two agents' buffer. We consider the problem from different perspectives. First, we look at the problem from a centralized point of view as a bicriteria optimization problem and characterize the set of Pareto optimal solutions from the computational complexity perspective. Then, we address the problem from one agent's point of view. In particular, we propose algorithms suggesting to an agent how to sequence its own tasks in order to optimize its own objective function, regardless of the other agents objectives.","The Development of Korea: Computer Access Assessment System (K-CAAS) for Persons with Physical Disabilities ","Cache management strategy for CCN based on content popularityContent Centric Networking is a promising architecture for the Future Internet to deliver content at large-scale. It relies on named data and caching features which consists of storing content across the delivery path to serve forthcoming requests. As some content is more likely to be requested than other, caching only popular content may help to manage the cache of CCN nodes. In this paper, we present our new caching strategy adapted to CCN and based on the popularity of content. We show through simulation experiments that our strategy is able to cache less content while it still achieves a higher Cache Hit and outperforms existing default caching strategy in CCN.","Gesture interaction system for social web applications on smart TVsCurrently, the Web is a powerful channel to store and share personal information, particularly through the several social networks such as Facebook, Twitter or Flickr. These applications are used as privileged tools for communication and information availability. With the proliferation of new devices and with new types of user interfaces that can be used by social networking applications, suitable user interaction methods are becoming even more relevant.#R##N##R##N#In this paper we propose a natural, gesture based, user interface, to interact with a Flickr client application on a Smart TV. The interface is based on a depth sensor and on a image processing method for gestures identification. It can be used to search and browse pictures using only gestures.","A Data-Driven Prediction Framework for Analyzing and Monitoring Business Process Performances ","Towards Ontological Foundations for the Conceptual Modeling of EventsIn recent years, there has been a growing interest in the application of foundational ontologies, i.e., formal ontological theories in the philosophical sense, to provide a theoretically sound foundation for improving the theory and practice of conceptual modeling. In this paper, we present advances on our research on the ontological foundations of conceptual modeling by addressing the concept of events. We present a foundational ontology of events termed UFO-B together with its axiomatization in first-order logic. Moreover, we report on an implementation of UFO-B using the computational logic language Alloy, and discuss its consistency, validation and possible uses.","Two-Round Discrete Voronoi Game along a Line ","Correlation-Based Neural Gas for Visualizing Correlations between EEG Features ","Identification of ultramodified proteins using top-down spectraPost-translational modifications (PTMs) play an important role in various biological processes through changing protein structure and function. Some ultramodified proteins (like histones) have multiple PTMs forming PTM patterns that define the functionality of a protein. While bottom-up mass spectrometry (MS) has been successful in identifying individual PTMs within short peptides, it is unable to identify PTM patterns spread along entire proteins in a coordinated fashion. In contrast, top-down MS analyzes intact proteins and reveals PTM patterns along the entire proteins. However, while recent advances in instrumentation have made top-down MS accessible to many laboratories, most computational tools for top-down MS focus on proteins with few PTMs and are unable to identify complex PTM patterns. We propose a new algorithm, MS-Align-E, that identifies both expected and unexpected PTMs in ultramodified proteins. We demonstrate that MS-Align-E identifies many protein forms of histone H4 and benchmark it against the currently accepted software tools.","Design, Conduct and Analysis of a Biased Voting Experiment on Human BehaviorTo explore whether and how different social activities and phenome- na, network structures and incentive machanisms could influent human beha- vior in social networks, Prof. Kearns and his colleagues conducted a series of human participated behavior experiments (3). Recently, we recurred one of those experiments called biased voting to verify whether and how the factors work on Chinese students. In this paper, we presented not only on the difference we found in the result, but also the design and preparation of the experiment to make some contributions to researchers who are interested in such experiments. We shared our source code and experiment data so that new experiments can be conducted quickly and easily.","Bisimulation-Based Comparisons for Interpretations in Description LogicsWe study comparisons between interpretations in description logics with respect to \"logical consequences\" of the form of semi-positive concepts (like semi-positive concept assertions). Such comparisons are characterized by conditions similar to the ones of bisimulations. The simplest among the considered logics is a variant of PDL (propositional dynamic logic). The others extend that logic with inverse roles, nominals, quantified number restrictions, the universal role, and/or the concept constructor for expressing the local reflexivity of a role. The studied problems are: preservation of semi-positive concepts with respect to comparisons, the Hennessy-Milner property for comparisons, and minimization of interpretations that preserves semi-positive concepts.","Generating Stories with MoralsMorals play an important role in why storytelling developed, and help provide stories with structure. We describe a storytelling system which generates short stories that convey one of six common morals identified in Aesop's fables. Morals are represented in terms of patterns of character emotions that arise during the course of a story. To evaluate the system's effectiveness, we compare system-generated stories with human-authored stories and random event sequences. We find system-generated stories convey morals significantly better than random.","Construction of Differential Characteristics in ARX Designs Application to Skein ","Collaborative filtering on ordinal user feedbackWe propose a collaborative filtering (CF) recommendation framework which is based on viewing user feedback on products as ordinal, rather than the more common numerical view. Such an ordinal view frequently provides a more natural reflection of the user intention when providing qualitative ratings, allowing users to have different internal scoring scales. Moreover, we can address scenarios where assigning numerical scores to different types of user feedback would not be easy. The framework can wrap most collaborative filtering algorithms, enabling algorithms previously designed for numerical values to handle ordinal values. We demonstrate our framework by wrapping a leading matrix factorization CF method. A cornerstone of our method is its ability to predict a full probability distribution of the expected item ratings, rather than only a single score for an item. One of the advantages this brings is a novel approach to estimating the confidence level in each individual prediction. Compared to previous approaches to confidence estimation, ours is more principled and empirically superior in its accuracy. We demonstrate the efficacy of the approach on two of the largest publicly available datasets: the Netflix data and the Yahoo! Music data.","Leveraging multi-domain prior knowledge in topic modelsTopic models have been widely used to identify topics in text corpora. It is also known that purely unsupervised models often result in topics that are not comprehensible in applications. In recent years, a number of knowledge-based models have been proposed, which allow the user to input prior knowledge of the domain to produce more coherent and meaningful topics. In this paper, we go one step further to study how the prior knowledge from other domains can be exploited to help topic modeling in the new domain. This problem setting is important from both the application and the learning perspectives because knowledge is inherently accumulative. We human beings gain knowledge gradually and use the old knowledge to help solve new problems. To achieve this objective, existing models have some major difficulties. In this paper, we propose a novel knowledge-based model, called MDK-LDA, which is capable of using prior knowledge from multiple domains. Our evaluation results will demonstrate its effectiveness.","Don\u2019t Be Spoiled by Your Friends: Spoiler Detection in TV Program TweetsProviding a convenient mechanism for accessing the Internet, smartphones have led to the rapid growth of Social Networking Services (SNSs) such as Twitter and have served as a major platform for SNSs. Nowadays, people are able to check conveniently the SNS messages posted by their friends and followers via their smartphones. As a consequence, people are exposed to spoilers of TV programs that they follow. So far, there are two previous works that explored the detection of spoilers in texts, not SNS: (1) keyword matching method and (2) machine-learning method based on Latent Dirichlet Allocation (LDA). The keyword matching method evaluates most tweets as spoilers; hence its poor recall performance. The other method based on LDA, although successful on large text, works poorly on short segments of text such as those found on Twitter and evaluates most tweets as non-spoilers. This paper presents four features that are significant in the classification of spoiler tweets. Using those features, we classified spoiler tweets pertaining to a reality TV show (\u201cDancing with the Stars\u201d). We experimentally compared our method with previous methods, with our method achieving substantially higher precision compared to the keyword matching and LDA-based methods while maintaining comparable recalls.","NeuCubeRehab: A Pilot Study for EEG Classification in Rehabilitation Practice Based on Spiking Neural Networks ","Behavioral Biometric Identification on Mobile Devices ","Regression Testing for Model Transformations: A Multi-objective ApproachIn current model-driven engineering practices, metamodels are modified followed by an update of transformation rules. Next, the updated transformation mechanism should be validated to ensure quality and robustness. Model transformation testing is a recently proposed effective technique used to validate transformation mechanisms. In this paper, a more efficient approach to model transformation testing is proposed by refactoring the existing test case models, employed to test previous metamodel and transformation mechanism versions, to cover new changes. To this end, a multi-objective optimization algorithm is employed to generate test case models that maximizes the coverage of the new metamodel while minimizing the number of test case model refactorings as well as test case model elements that have become invalid due to the new changes. Validation results on a widely used transformation mechanism confirm the effectiveness of our approach.","Brand-Centric Recommendation with Inter-brand SimilaritiesWith the increasing popularity of mobile web, social networking services SNSs are an integral part of our everyday lives, since they are used for communicating with friends, for gaining information on other people or some items of interest, and even for business profits. Social network information is incorporated into recommender systems to improve their performance, but most of existing work is focused on user-centric cases in which items or venues are recommended for users. On the other hand, brands are also important social objects. For instance, in Foursquare, which is a location-based online SNS, brands provide information on venues and share the tips with their followers. Thus, it is important to recommend venues for brands so that brands select interesting venues for their followers, leading to brand-centric recommendation where the targets for recommendation are brands not users. In contrast to user-centric recommendation, brands have few social links to other brands, so trust between brands is difficult to use. In this paper we present a method for brand-centric recommendation where inter-brand similarities are implicitly determined by decomposing a brand-follower matrix. This social information on inter-brand similarity is incorporated into probabilistic matrix factorization to reveal brand latent factors as well as venue latent factors. Experiments on the dataset collected from Foursquare by web crawling demonstrate that our method improves the recommendation performance over existing matrix factorizations.","A Hybrid Distance-Based Method and Support Vector Machines for Emotional Speech Detection ","An Illumination Invariant Face Recognition Scheme to Combining Normalized Structural Descriptor with Single Scale Retinex ","A Privacy Preserving Representation for Web Service Communicators\u2019 in the Cloud ","The Impact of Demographics (Age and Gender) and Other User-Characteristics on Evaluating Recommender SystemsIn this paper we show the importance of considering demographics and other user characteristics when evaluating (research paper) recommender systems. We analyzed 37,572 recommendations delivered to 1,028 users and found that elderly users clicked more often on recommendations than younger ones. For instance, 20-24 years old users achieved click-through rates (CTR) of 2.73% on average while CTR for users between 50 and 54 years was 9.26%. Gender only had a marginal impact (CTR males 6.88%; females 6.67%) but other user characteristics such as whether a user was registered (CTR: 6.95%) or not (4.97%) had a strong impact. Due to the results we argue that future re- search articles on recommender systems should report detailed data on their us- ers to make results better comparable.","A Markov-Kalman Model of Land-Use Change Prediction in XiuHe Basin, ChinaA study of forecasting the dynamic change of regional land resources will reveal the characteristics and laws of the land use structure. Three periods of TM images of XiuHe basin in year 1990, 2000 and 2010 were used as data source, and a united model of markov and Kalman method which called Markov-Kalman filter model, was applied to simulation the dynamic changes of land use in the study area. When land use predictions were gotten based on Markov model, a measurement value with error from the TM images was utilized to calibrate the forecast result in Kalman filter model, and the optimal estimate as accurately as possible to the real value was gotten, and quantitative forecasts and analysis of land change were acquired. The experiment results show that the method can effectively improve the forecast precision, and analysis of the forecast results will help the government realize the future evolution trend of land use structure in XiuHe basin.","Vehicle Safety Device (Airbag) Specific Classification of Road Traffic Accident Patterns through Data Mining Techniques ","Research Challenges to Secure the Future Internet ","Formalization of Infinite Dimension Linear Spaces with Application to Quantum TheoryLinear algebra is considered an essential mathematical the- ory that has many engineering applications. While many theorem provers support linear spaces, they only consider finite dimensional spaces. In ad- dition, available libraries only deal with real vectors, whereas complex vectors are extremely useful in many fields of engineering. In this paper, we propose a new linear space formalization which covers both finite and infinite dimensional complex vector spaces, implemented in HOL-Light. We give the definition of a linear space and prove many properties about its operations, e.g., addition and scalar multiplication. We also formalize a number of related fundamental concepts such as linearity, hermitian operation, self-adjoint, and inner product space. Using the developed linear algebra library, we were able to implement basic definitions about quantum mechanics and use them to verify a quantum beam splitter, an optical device that has many applications in quantum computing.","Determinants of Smart Energy Demand Management: An Exploratory AnalysisThe unprecedented rise of population with increasing energy consumption has necessitated the stabilization of dwindling energy resources to secure the provision of energy. Electricity production and distribution through smart grids is a key component in delivering reliable, efficient, and low-carbon energy for a sustainable development of the society, and to meet the growing demands of electricity. Smart electricity grid is a complex system of systems that requires sophisticated collaboration tools and intelligent techniques with active participation from all its connected users. A dynamic role and a pro-active participation of consumers and societies with the integration of distributed energy resources are highly anticipated for the long-term sustenance of these grids. This paper discusses and identifies key determinants of the demand side sustainable collaboration in a smart way (resulting as what we address as smart energy demand) through the involvement of pro-active consumers","Robust Benchmark Set Selection for Boolean Constraint SolversWe investigate the composition of representative benchmark sets for evaluating and improving the performance of robust Boolean constraint solvers in the context of satisfiability testing and answer set programming. Starting from an analysis of current practice, we isolate a set of desiderata for guiding the development of a parametrized benchmark selection algorithm. Our algorithm samples a benchmark set from a larger base set or distribution comprising a large variety of instances. This is done fully automatically, in a way that carefully calibrates instance hardness and instance similarity. We demonstrate the usefulness of this approach by means of empirical results showing that optimizing solvers on the benchmark sets produced by our method leads to better configurations than obtained based on the much larger, original sets.","Factors that affect Information and Communication Technology Adoption by Small Businesses in ChinaEmerging economies appear to be powering growth in their regions. While China is seen to lead growth in the emerging markets of Asia, 98% of its manufacturing and production base is powered by small businesses. These businesses represent the majority of all businesses in emerging countries and their growth increases with their successful adoption of Information Technology. As the driving force behind the economic growth of China, Information and Communications Technologies (ICTs) are shaping the ways in which small businesses are able to grow. The majority of current research into the user acceptance and adoption of ICTs focusses on the perceptions of users in large organizations often in developed countries. Since the growth of an emerging economy such as China is being powered by ICTs, this paper investigates what factors affect the acceptance of ICTs by small business owners in two provinces in China. Following an analysis of data collected from small business in a high growth province and a largely rural province, this paper arrives at a set of factors that affect the acceptance of ICT in China and their outcomes on small business development. Further research is being conducted into the outcomes of acceptance on development.","Tacit knowledge formalization to support the adoption process of software quality modelsDue to the key role played by tacit knowledge in the adoption process of a quality model, this paper aims to present a first approach to formalize its expression so that it can be captured and stored for later reuse. It is propose to express tacit knowledge in the form of rules, and add a degree of belief to represent an expert judgment. The degree of belief is calculated by using the certainty factors theory to allow individual's expertise to be used in the evaluation of the rules.","Towards a Theory of Information Technology Platform Adoption ","Support for Non IT Savvy Teachers to Incorporate GamesThis research is to provide the tools for novice IT users to develop immersive games for teaching. The tools were developed in the context of a project in which Aboriginal Australian people, who are members of university or general communities, describe and explain their culture to non-Aboriginal students. Learning from Aboriginal cultural ways of teaching, these tools can be applied to other domains.#R##N##R##N#The teaching environment includes recorded narratives in an interactive cross-cultural training game which is to be used as part of the professional preparation of students working in health.#R##N##R##N#The paper focuses on the tools used to generate learning environment from the stories. This includes authoring the rules for the agent's emergent narrative in the teaching games, learning paths to link individual contribution into a coherent story, and scenarios generated using visual tools to support contributors.#R##N##R##N#The tools have been used to generate prototypes from a previously collected set of stories stories, constructing scenarios by compiling them from simpler interactions and this process will be used in future story collection workshops to provide story providers with better control of how they will contribute to the teaching framework.","Staffing Open Collaborative Projects Based on the Degree of Acquaintance ","A problem-solving perspective on governance and product design in open source software projects: Conceptual issues and exploratory evidencePrevious research shows that organization architecture relates to the architecture of a product under development, and recent studies compare proprietary versus open source software (OSS) as examples of integrated and distributed forms of software development, respectively. This study goes a step further to investigate the correspondence of organization and product architectures by comparing single-vendor with community OSS. Using a problem-solving perspective, the authors seek to explain when and why vendor firms use a community to solve their problems. Furthermore, the combination of literature-based insights with field interviews supports an exploration of the assumption that single-vendor OSS exhibits a less modular product architecture than community OSS. With design structure matrices, this study analyzes differences in software code architecture and specifies the studied relationship.","3D Experiences - Dassault Syst\u00e8mes 3DS Strategy to Support New Processes in Product Development and Early Customer InvolvementIn many industries the market sees a lot of change happening these days; new trends and challenges obviously need to be addressed as part of the product creation process. Dassault Systemes (3DS) is introducing a 3DEXPERIENCE PLATFORM to expand the usability of the digital smart product development in an accurate virtual universe beyond Product Lifecycle Management (PLM). The target is to provide the ability to place the customer at the heart of a system, integrating both company business processes and product development processes. It is a combination of science, art and technology to bring value to our customers by helping them to respond to the needs of their customers and creating 'magnetic' products with strong market appeals. 3DExperiences can be a catalyst for innovation, enabling any enterprise stake- holder to participate in the innovation process, contributing to drive value for the end consumer and create smart products from design to recycling. This presentation highlights some aspects of the new Dassault Systemes strategy; shows some of the solution experiences and how customers respond to them. 3DS is a scientific company positioned among the top 10 software companies worldwide and for more than 30 years has been helping companies to transform the way they design and produce their products.","Computational Aspects of Manipulation and Control in Judgment AggregationWe study computational aspects of various forms of manipulation and control in judgment aggregation, with a focus on the premise-based procedure. For manipulation, we in particular consider incomplete judgment sets and the notions of top-respecting and closeness-respecting preferences introduced by Dietrich and List [13]. This complements previous work on the complexity of manipulation in judgment aggregation that focused on Hamming-distance-induced preferences [14,6], which we also study here. Regarding control, we introduce the notion of control by bundling judges and show that the premise-based procedure is resistant to it in terms of NP-hardness.","Semi-Product-Form Solution for PEPA Models with Functional RatesWe consider the problem of finding a separable solution for the equilibrium state probabilities in a Markovian process algebra model, in which the action rates may depend on the behaviour of other compo- nents. To do this we consider regular cycles in the underlying state space and show that a semi-product form solution exists when the functions de- scribing the action rates have specific forms. The approach is illustrated with two examples, one a generalised version of a known state-dependent queueing network and the other in the domain of security protocols.","Map Edit Distance vs. Graph Edit Distance for Matching ImagesGeneralized maps are widely used to model the topology of nD objects (such as 2D or 3D images) by means of incidence and ad- jacency relationships between cells (0D vertices, 1D edges, 2D faces, 3D volumes, ...). Recently, we have introduced a map edit distance. This distance compares maps by means of a minimum cost sequence of edit operations that should be performed to transform a map into another map. In this paper, we introduce labelled maps and we show how the map edit distance may be extended to compare labeled maps. We exper- imentally compare our map edit distance to the graph edit distance for matching regions of different segmentations of a same image.","Methodological Issues in Support of Selected Tasks of the Virtual Manufacturing Planning ","The Complexity of Lattice-Based Fuzzy Description LogicsWe study the complexity of reasoning in fuzzy description logics with semantics based on finite residuated lattices. For the logic \\(\\mathcal SHI \\), we show that deciding satisfiability and subsumption of concepts, with or without a TBox, are ExpTime-complete problems. In \\(\\mathcal{ALCHI }\\) and a variant of \\(\\mathcal{SI }\\), these decision problems become PSpace-complete when restricted to acyclic TBoxes. This matches the known complexity bounds for reasoning in crisp description logics between \\(\\mathcal{ALC }\\) and \\(\\mathcal SHI \\).","Increased Communication Reliability for Delay-Sensitive Platooning Applications on Top of IEEE 802.11pCooperative driving in platooning applications has received much attention lately due to its potential to lower fuel consumption and improve safety and efficiency on our roads. However, the recently adopted standard for vehicular communication, IEEE 802.11p, fails to support the level of reliability and real-time properties required by highly safety-critical applications. In this paper, we propose a communication and real-time analysis framework over a dedicated frequency channel for platoon applications and show that our retransmission scheme is able to decrease the message error rate of control data exchange within a platoon of moderate size by several orders of magnitude while still guaranteeing that all delay bounds are met. Even for long platoons with up to seventeen members the message error rate is significantly reduced by retransmitting erroneous packets without jeopardizing the timely delivery of regular data traffic. \u00a9 2013 Springer-Verlag.","Attacking atmel's cryptomemory EEPROM with special-purpose hardwareAtmel's CryptoMemory devices are non-volatile memories with cryptographically secured access control. Recently, the authentication mechanism of these devices have been shown to be severely vulnerable. More precisely, to recover the secret key the published attack requires only two to six days of computation on a cluster involving 200 CPU cores. In this work, we identified and applied theoretical improvements to this attack and mapped it to a reconfigurable computing cluster, known as RIVYERA. Our solution provides significantly higher performance exceeding the previous implementation by a factor of 7.27, revealing the secret key obtained from the internal state in 0.55 days on average using only 30 authentication frames.","From model checking to model measuringWe define the model-measuring problem: given a model M and specification \u03d5, what is the maximal distance \u03c1 such that all models M\u2032 within distance \u03c1 from M satisfy (or violate) \u03d5. The model measuring problem presupposes a distance function on models. We concentrate on automatic distance functions, which are defined by weighted automata. The model-measuring problem subsumes several generalizations of the classical model-checking problem, in particular, quantitative model-checking problems that measure the degree of satisfaction of a specification, and robustness problems that measure how much a model can be perturbed without violating the specification. We show that for automatic distance functions, and \u03c9-regular linear-time and branching-time specifications, the model-measuring problem can be solved. We use automata-theoretic model-checking methods for model measuring, replacing the emptiness question for standard word and tree automata by the optimal-weight question for the weighted versions of these automata. We consider weighted automata that accumulate weights by maximizing, summing, discounting, and limit averaging. We give several examples of using the model-measuring problem to compute various notions of robustness and quantitative satisfaction for temporal specifications.","A Local Structure-Based Method for Nodes Clustering: Application to a Large Mobile Phone Social Network ","Robot Cognitive Stimulation for the ElderlyIn this paper, we present a new social intelligent robotic sys- tem used for cognitive stimulation therapy for individuals suffering from Mild Cognitive Impairment (MCI) and/or Alzheimer's disease. Our work aims increasing the cognitive attention of users by playing different games and therefore help slow down cognitive decline. The system records the users' task performance during the games and adapts the different levels of difficulty as a function of the users' game history. The games were tailored to the needs of each individual so as to address their different cognitive disabilities. Two studies are presented.","Spatial Econometrics Models in Web Server\u2019s Performance ","Path Planning in RoboCup Soccer Simulation 3D Using Evolutionary Artificial Neural Network ","Selecting Project Management Methodologies for Business Intelligence Projects - A Value Based Approach. ","Investigating the effects of font styles on perceived visual aesthetics of website interface designThe purpose of this study is to compare the effects of the two font styles (serif and sans-serif) on the users' perception of visual aesthetics of website interface design. Two font types were tests in this study, namely: \"Time News Roman\" representing the \"serif\" style and \"Calibri\" representing the \"sans-serif\" style. They were chosen because they are two of the widely used font types on the web and because they are the default font types of many of the most popular word processing and web developing software. Analysis of results showed that font type has a statistically significant effect on perceived visual aesthetics. The designs with the Time New Roman font was perceived as having better visual aesthetics. However, this effect was only significant on the overall perception of visual aesthetics; it wasn't significant in each of the four facets of visual aesthetics tested in this study.","A Framework for On-line Detection of Custom Group Movement Patterns ","Data Collection in Massively Multiplayer Online Games: Methods, Analytic Obstacles, and Case Studies ","Quasi-almostmedian graphsWe introduce quasi-almostmedian graphs as a natural nonbipartite generalization of almostmedian graphs. They are lling a gap between quasi-median graphs and quasi-semimedian graphs. We generalize some results of almostmedian graphs and deduce some results from a bigger class of quasi-semimedian graphs. The consequence of this is another characterization of almostmedian graphs as well as two new characterizations of quasi-median graphs.","Towards Automated Navigation over Multilingual Content ","The Convergence of Security and Usability: Defining a Framework for Mobile Design ","Behavioral Clustering for Point ProcessesGroups of parallel point processes may be analyzed with a variety of different goals. Here we consider the case in which one has a special interest in finding subgroups of processes showing a behavior that differs significantly from the other processes. In particular, we are interested in finding subgroups that exhibit an increased synchrony. Finding such groups of processes poses a difficult problem as its naive solution requires enumerating the power set of all processes involved, which is a costly procedure. In this paper we propose a method that allows us to efficiently filter the process set for candidate subgroups. We pay special attention to the possibilities of temporal imprecision, meaning that the synchrony is not exact, and selective participation, meaning that only a subset of the related processes participates in each synchronous event.","Symbolic Model-Based Testing for Industrial Automation Software ","An architecture for IPv6 lookup using parallel index generation unitsThis paper shows an area-efficient and high-speed architecture for IPv6 lookup using a parallel index generation unit (IGU). To reduce the size of memory in the IGU, we use a liner transformation and a row-shift decomposition. Also, this paper shows a design method for the parallel IGU. A single memory realization requires O(2n) memory size, where n denotes the length of prefix, while the IGU requires O(nk) memory size, where k denotes the number of prefixes. In IPv6 prefix lookup, since n is at most 64 and k is about 340 K, the IGU drastically reduces the memory size. Since the parallel IGU has a simple architecture compared with existing ones, it performs lookup by using complete pipelines. We loaded more than 340 K IPv6 pseudo prefixes on the Xilinx Virtex 6 FPGA. Its lookup speed is higher than one giga lookups per second (GLPS). As for the normalized area and lookup speed, our implementation outperforms existing FPGA implementations.","FuPerMod: A Framework for Optimal Data Partitioning for Parallel Scientific Applications on Dedicated Heterogeneous HPC PlatformsOptimisation of data-parallel scientific applications for modern HPC platforms is challenging in terms of efficient use of heterogeneous hardware and software. It requires partitioning the computations in proportion to the speeds of computing devices. Implementation of data partitioning algorithms based on computation performance models is not trivial. It requires accurate and efficient benchmarking of devices, which may share the same resources but execute different codes, appropriate interpolation methods to predict performance, and mathematical methods to solve the data partitioning problem. In this paper, we present a software framework that addresses these issues and automates the main steps of data partitioning. We demonstrate how it can be used to optimise data-parallel applications for modern heterogeneous HPC platforms.","MUSE: implementation of a design theory for systems that support convergent and divergent thinkingIt has been asserted that information systems (IS) can both enhance and undermine creativity. Earlier, we have proposed an IS design theory for systems that support individual creativity through fostering convergent and divergent thinking. In this paper we outline how we have transformed this abstract blueprint into a running software prototype. We chose cooking --- a familiar creative process --- as an exemplary domain to illustrate the form and function of the prototype. In future work, the prototype and the underlying design theory will be empirically evaluated using focus groups and laboratory experiments.","Effect of Codec Bit Rate and Packet Loss on Thai Speech Recognition over IP ","Concurrent Aerospace Thermoplastic Stiffened Panel Conceptual Design and Cost Estimation Using Knowledge Based Engineering ","Smart Time Series Prediction ","Pattern Discovery and Listing in GraphsGraphs are gaining increasing popularity in many application domains as they have the potential of modeling binary relations among entities. Along with textual and multimedia data, they are the main sources for producing large data sets. It is natural to ask how it is easy to extend the notion of patterns typically found in string matching and sequence analysis, to graphs and real-life networks. Unfortunately, even the basic problem of finding a simple path in a graph is NP-hard since this can establish if the graph is Hamiltonian. Also, the number of patterns can be exponentially large in the size of the graph, thus listing them is a challenge. We will discuss some output-sensitive and parameterized algorithms for listings patterns that are paths, cycles and trees, and provide a notion of \"certificate\" to attain this goal. This is joint work with Rui Ferreira.","The effects of display fidelity, visual complexity, and task scope on spatial understanding of 3D graphsImmersive display features can improve performance for tasks involving 3D, but determining which types of spatial analysis tasks are affected by immersive display features for different applications is not simple. This research adds to the knowledge of how the level of display fidelity (i.e., the realism provided by the display output) affects task performance for a variety of 3D spatial understanding tasks. In this study, we control visual display fidelity with the combination of stereoscopy, head-based rendering, and display area and study performance analysis of 3D graphs. Through a controlled study, we evaluated the relationship among display fidelity, visual complexity, task scope, and a user's personal spatial ability. Over a variety of task types, our results show significantly better overall task performance with higher display fidelity. We also found that visual complexity and task scope affect speed, with higher levels of either type of complexity leading to slower performance. These results show the importance of considering multiple factors when calculating the overall difficulty and complexity of a spatial task, and they suggest that visual clutter makes a greater impact on speed than correctness. Further, the study of different task types suggest enhanced virtual reality displays offer more benefits for spatial search and fine-grained component distinction, but may provide little gain than for sense of scale or size comparison.","Model-Based Estimation of 4D Relative Pressure Map from 4D Flow MR ImagesWe propose a new framework for 4D relative pressure map computations from 4D flow MRI that uses enhanced geometric models for the blood vessels and flow-aware surface and volumetric tags. The enhanced geometric modeling provides better accuracy compared to a simple voxelized mask, while tagging of inlets and outlets allows imposing physiologically meaningful boundary conditions, contributing to more accurate pressure computations. An integrated software suite for semi-automatic processing of 4D flow MR images, preparation and computation of the flow parameters is presented. This enables a fast and intuitive workflow, with accurate final results, ready in minutes.","Imagilar: A Real-Time Image Similarity Search System on Mobile PlatformWith the rapid development of mobile intelligent devices and wireless communications, users are gradually changing the way of consuming interesting content from the traditional personal computers to smart phones. Hence, we introduce a brand-new content-based image similarity search system which runs on mobile platform in real time. This paper outlines the system which has several novel components, including multi-feature composition, multi-feature indexing, and customized user interface with auxiliary Web data display.","Dynamic Heart Valve Cusp Bending Deformation AnalysisProper hemodynamics is a major issue in research of heart valve bio-prostheses. In the examination of these, the bending deforma- tion and fluttering of heart valve cusps is an interesting and influential aspect. An analysis of the deformation can support the understanding of correlations between hemodynamics and occurring mechanical stress. This contribution describes an approach to determine the dynamic bend- ing deformation of aortic heart valve bio-prostheses in high speed video recordings and to compare different fluttering characteristics. The bio- prostheses are recorded in an artificial circulation setup and observed during the opening and closure of a systolic phase. Based on a seg- mentation of the orifice area, a distance signal is derived for each cusp relative to a base line given by the commissure points. This distance sig- nal describes the static bending deformation of the cusps in one image frame. By observing the deformation during the phase of maximal flow, the dynamics of the cusps can be determined over time. The resulting fluttering is quantified by a frequency analysis of the time dependent dis- tance signal. Thus, significant fluttering characteristics can be modeled and compared.","Multiple Views for Supporting Lifelong, Highly Contextual and Ubiquitous Social Learning ","Adaptive Dynamic Load Balancing in Heterogeneous Multiple GPUs-CPUs Distributed Setting: Case Study of B&amp;B Tree SearchThe emergence of new hybrid and heterogenous multi-GPUs multi-CPUs large scale platforms offers new opportunities and poses new challenges when solving difficult optimization problems. This paper targets irregular tree search algorithms in which workload is unpredictable. We propose an adaptive distributed approach allowing to distribute the load dynamically at runtime while taking into account the computing abilities of either GPUs or CPUs. Using Branch-and-Bound and FlowShop as a case study, we deployed our approach using up to    $$20$$         20          GPUs and    $$128$$         128          CPUs. Through extensive experiments in different system configurations, we report near optimal speedups, thus providing new insights into how to take full advantage of both GPUs and CPUs power in modern computing platforms.","Visually extracting data records from the deep webWeb sites that rely on databases for their content are now ubiquitous. Query result pages are dynamically generated from these databases in response to user-submitted queries. Automatically extracting structured data from query result pages is a challenging problem, as the structure of the data is not explicitly represented. While humans have shown good intuition in visually understanding data records on a query result page as displayed by a web browser, no existing approach to data record extraction has made full use of this intuition. We propose a novel approach, in which we make use of the common sources of evidence that humans use to understand data records on a displayed query result page. These include structural regularity, and visual and content similarity between data records displayed on a query result page. Based on these observations we propose new techniques that can identify each data record individually, while ignoring noise items, such as navigation bars and adverts. We have implemented these techniques in a software prototype,  rExtractor , and tested it using two datasets. Our experimental results show that our approach achieves significantly higher accuracy than previous approaches. Furthermore, it establishes the case for use of vision-based algorithms in the context of data extraction from web sites.","High Performance Architecture for NSGA-II ","Evolutionary Generation of Small Oscillating Genetic Networks ","A Complex Systems Approach to Infectious Disease Surveillance and ResponseThe transmission of infectious diseases can be affected by various interactive factors at or across different scales, such as environmental factors (e.g., temperature) and physiological factors (e.g., immunity). In view of this, to effectively and efficiently monitor and response to an infectious disease, it would be necessary for us to systematically model these factors and their impacts on disease transmission. In this paper, we propose a complex systems approach to infectious disease surveillance and response that puts a special emphasis on complex systems modeling and policy-level decision making with consideration of multi-scale interactive factors and/or surveillance data of disease prevalence. We demonstrate the implementation of our approach by presenting two real-world studies, one on the air-borne influenza epidemic in Hong Kong and the other on the vector-borne malaria endemic in Yunnan, China.","MapReduce garbage collectionRecently, Hadoop, an open source implementation of MapReduce, has become very popular due to its characteristics such as simple programming syntax, and its support for distributed computing and fault tolerance. Although Hadoop is able to automatically reschedule failed tasks, it is powerless to deal with tasks with poor performance. Managing such tasks is vital as they lower the whole job's performance. Thus in this work, we design a novel garbage collection technique that identifies and collects \"garbage\" tasks. Three research questions are addressed in this work. The first, does collecting (shutting down) garbage (slow) tasks help in reducing the total job completion time and resources cost? The second, when is it most efficient to invoke the Garbage Collector? The third, how to identify garbage (slow) tasks and what are the major factors causing a task to slow down?. The proposed Garbage Collector is evaluated on Amazon EC2 using two metrics: (i) the time for a single job completion, and (ii) resource costs. The empirical results using the TeraSort benchmark show that collecting garbage tasks does reduce the job completion time by 16% and resources cost by 27%. The results also show that the Garbage Collector needs to be invoked before the job is 40% completed, otherwise it would be better to leave the slow tasks till the end of the job because at this point the cost of re-executing these slow tasks becomes high. Finally, our results show that CPU utilization is a good indicator of slow tasks.","Robustness Analysis of Z-type ZLE SolvingThe general method of Z-type model for online solution of Zhang linear equation (i.e., ZLE or termed time-varying linear equa- tion) is presented. Global exponential convergence of the Z-type ZLE model can be achieved theoretically. In this paper, robustness properties of the Z-type ZLE model in the presence of normal differentiation and dynamics-implementation errors are investigated. Both theoretical anal- ysis and computer-simulation results demonstrate the good robustness of the Z-type model for ZLE solving. In addition, the Z-type ZLE method is compared with G-type ZLE method in the Appendix.","A Model for the Analysis of Security Policies in Industrial NetworksThe analysis of security policies designed for ICS and SCADA can benefit significantly from the adoption of automatic/semi-automatic software tools that are able to work at a global (system) level. This implies the availability of a suitable model of the system, which is able to combine the abstractions used in the definition of policies with the access control and right management mechanisms usually present in the real system implementation. This paper introduces a modeling framework based on the Role Based Access Control (RBAC) technique that includes all the elements needed to support different kinds of automatic security analyses such as policy coherence checks and verifications of correct implementation of policies.","Main Usability Issues in Using Virtual Environments for Older Population Warning StudiesOver the last decades, Virtual Reality (VR) technology has emerged as a promising tool for numerous human performance assessments. Together with the expansion of such systems, several Virtual Environment (VE) usability criteria have been developed to ensure their optimal production and efficiency. However, the current status of such measures for warning research is scarce; and most importantly, design guidelines for defining VEs for middle-aged and older adult interactions with warnings are even more rare. In order to create effective and inclusive VEs for older age groups, warning researchers must be informed of the main age-related perceptual and cognitive changes that may hinder the experience, as well as should determine which of the usability issues are most important for a particular VE system. This paper provides a theoretical framework which seeks to highlight the main subject matters that embrace the design, implementation and evaluation of VE studies for older population warn- ing research.","Empathy and Its Modulation in a Virtual HumanEndowing artificial agents with the ability to empathize is believed to enhance their social behavior and to make them more likable, trustworthy, and caring.#R##N#Neuropsychological findings substantiate that empathy occurs to different degrees depending on several factors including, among others, a person\u2019s mood, personality, and social relationships with others. Although there is increasing interest in endowing artificial agents with affect, personality, and the ability to build social relationships, little attention has been devoted to the role of such factors in influencing their empathic behavior. In this paper, we present a computational model of empathy which allows a virtual human to exhibit different degrees of empathy. The presented model is based on psychological models of empathy and is applied and evaluated in the context of a conversational agent scenario.","Image Representation Using the Self-Organizing Map ","Interactive Hybrid Systems for Monitoring and Optimization of Micro- and Nano-machining ProcessesThe article describes a new concept of interactive hybrid systems for monitoring and optimization of micro- and nano-machining processes, which are equipped with voice and visual communication between the human operator and the system. These remote systems contain a speech interface and artificial intelligence. They are presented in exemplary application in the precision grinding process. The developed concept proposes an architecture of the systems equipped with a data analysis layer, process supervision layer, decision layer, communication subsystem by speech and natural language, and visual communication subsystem using voice descriptions. In the system, computational intelligence methods allow for real-time data analysis of monitored processes, configuration of the system, process supervision and optimization based on the process features and quality models. The concept allows for the development of universal and elastic systems which are independent of a type of manufacturing process, machining parameters and conditions.","Gray Level Image Enhancement by Improved Differential Evolution Algorithm ","Inferring Public and Private Topics for Similar Events ","A Verbal Interaction Measure Using Acoustic Signal Correlation for Dyadic Cooperation SupportWe introduce a method for detecting whether two users are engaged in focused interaction using a windowed correlation measure on their acoustic signals, assuming that a continued exchange of verbal turns contributes to anticorrelation of#R##N#acoustic activity. We tested our method with manually annotated transitions between focused and unfocused interaction stemming from experiments on AR-based coop-#R##N#eration within a research project on alignment in communication. The results show that a high degree and extended duration of speech activity anticorrelation reliably indicates focused interaction, and might thus be a valuable asset for situation-aware technical systems.","Learning with Social Technologies: Workplace Learner Experiences of Wiki and Blog and Perceptions of PLE ","Efficient Generation of Elementary SequencesGiven an irreducible non-primitive polynomial g of degree n over    $\\mathbb{F}_{2}[x]$    we aim to compute in parallel all the elementary sequences with minimal polynomial g i.e. one sequence from each class of equivalence under cyclic shifts. Moreover, they need to each be in a suitable phase such that interleaving them will produce an m-sequence with linear complexity degg; this m-sequence is therefore produced at the rate of q=2 n -1/ordg bits per clock cycle. A naive method would use q LFSRs so our aim is to use considerably fewer. We explore two approaches: running a small number of Galois LFSRs with suitable seeds and using certain registers, possibly with a small amount of buffering; alternatively using only one Galois or Fibonacci LFSR and computing certain linear combinations of its registers. We ran experiments for all irreducible polynomials of degree n up to 14 and for each n we found that efficient methods exist for at least one m-sequence. A combination of the two approaches above is also described.","Natural Feature Tracking Augmented Reality for On-Site Assembly Assistance Systems ","Mining Emerging Patterns of PIU from Computer-Mediated Interaction EventsIt has been almost 20 years since Internet services became an integral part of our lives. Especially recent popularization of SNS Social Network Services such as Facebook, more and more people are attracted to Internet. Internet provides many benefits to people, but yields a consequent disturbing phenomenon of obsession with Internet, which is called PIU Pathological Internet Use or IAD Internet Addiction Disorder in academia. PIU or IAD has negative effects on people's health of mind and body, therefore, it is necessary to detect PIU. Among tools of surfing Internet, since computer is the most widely interactive media, it is significant to mine PIU emerging patterns from human-computer interaction events. As a result, an emerging pattern mining method based on interactive event generators, called PIU-Miner, is proposed in this paper. Experimental results show that PIU-Miner is an efficient and effective approach to discovering PIU.","Cellular Automata Model of Some Organisms Population in Lake BaikalA cellular automata model of population dynamics of eight organisms in Lake Baikal is proposed and investigated. The model allows to take into account spatial organisms distribution, seasonal dependency of birth rates, possible habitat pollution and water streams. Computational experiment is presented. It demonstrates that population dynamics tends to stable oscillating process with period equal to 1 year. The model was verified within production-to-biomass and frequency of occurrence ratios.","User Acceptance of the Next Generation Digital Signage: A Perspective of Perceived Value ","Generating Protocol Software from CPN Models Annotated with PragmaticsModel-driven software engineering (MDSE) provides a foun- dation for automatically generating software based on models that focus on the problem domain while abstracting from the details of underlying implementation platforms. Coloured Petri Nets (CPNs) have been widely used to formally model and verify protocol software, but limited work exists on using CPN models of protocols as a basis for automated code generation. The contribution of this paper is a method for generating protocol software from a class of CPN models annotated with code gen- eration pragmatics. Our code generation method consists of three main steps: automatically adding so-called derived pragmatics to the CPN model, computing an abstract template tree, which associates pragmat- ics with code templates, and applying the templates to generate code which can then be compiled. We illustrate our method using a unidirec- tional data framing protocol.","Finding security vulnerabilities in a network protocol using parameterized systemsThis paper presents a novel approach to automatically finding security vulnerabilities in the routing protocol OSPF --- the most widely used protocol for Internet routing. We start by modeling OSPF on concrete networks with a fixed number of routers in a specific topology. By using the model checking tool CBMC, we found several simple, previously unpublished attacks on OSPF.#R##N##R##N#In order to search for attacks in a family of networks with varied sizes and topologies, we define the concept of an abstract network which represents such a family. The abstract network    ${\\cal A}$    has the property that if there is an attack on    ${\\cal A}$    then there is a corresponding attack on each of the concrete networks represented byi\u00be?   ${\\cal A}$   .#R##N##R##N#The attacks we have found on abstract networks reveal security vulnerabilities in the OSPF protocol, which can harm routing in huge networks with complex topologies. Finding such attacks directly on the huge networks is practically impossible. Abstraction is therefore essential. Further, abstraction enables showing that the attacks are general. That is, they are applicable in a large even infinite number of networks. This indicates that the attacks exploit fundamental vulnerabilities, which are applicable to many configurations of the network.","Usability and Utility Needs of Mobile Applications for Business Management among MSEs: A Case of Myshop in UgandaThis paper discusses the usability needs of mobile applications for basic business management for Micro and Small Scale Enterprises (MSEs) in developing countries. This is based on results from a user study carried out in Uganda on 30 MSEs. The study was carried out on MyShop, an easy to use mobile business management application for cash transactions and book keeping designed for micro-entrepreneurs. The study investigated learning to use MyShop, the support MyShop gives to the user and its usefulness, and value addition to users. The study also covered the pleasure and stimulation MyShop gives to users. Results from the study show that MSE owners/shopkeepers would like an application that is easy to use such as have an intuitive navigation and a simple and clear language. They would also like an application that supports their unique context like multiple people operating a shop, selling goods on credit, ownership of multiple businesses, use of low end phones and regular load shedding. In terms of value addition, MSEs would like the application to assist them in managing the daily operations and developing the business in the long term such as marketing, time saving and control over business.","Evolution Analysis of Modularity-Based Java System StructureIn order to study the modularity of system structure and analyze the law of system architecture evolution, we summarised three typical definitions about system modularity from different perspectives in this paper. Then we adopted the quantitative calculation method, established three optimization models, got some methods of module partition and evaluated and analyzed the effects of the different divisions. Finally, we used the Java class diagram (JDK) as an example, analyzed the modular structures of different JDK versions, interpreted the results, drew patterns and trends in the evolution of each version.","Exploring an Ichthyoplankton Database from a Freshwater Reservoir in Legal AmazonThe purpose of this study is to use data mining techniques for the exploratory analysis of a database of ichthyoplankton samples from a freshwater reservoir in Legal Amazon. This database has already been analyzed using statistical techniques, but these did not find a relationship between biotic and abiotic factors. The application of the Apriori algorithm allows us to generate association rules that yield an understanding of the process of fish spawning in Tocantins River. In this case, we demonstrate the effective use of data mining for the discovery of patterns and processes in ecological systems, and suggest that statistical methods often used by ecologists can be coupled with data mining techniques to generate hypotheses.","A Practical Approach for Finding Small {Independent, Distance} Dominating Sets in Large-Scale GraphsSuppose that in a network, a node can dominate (or cover, monitor, etc) its neighbor nodes. An interesting question asks to find such a minimum set of nodes that dominate all the other nodes. This is known as the minimum dominating set problem. A natural generalization assumes that a node can dominate nodes within a distance R \u2264 1, called the minimum distance dominating set problem. On the other hand, if the distance between any two nodes in the dominating set must be at least z \u2264 1, then the problem is known as the minimum independent dominating set problem. This paper considers to find a minimum distance-R independence-z dominating set for arbitrary R and z, which has applications in facility location, internet monitoring and others. We show a practical approach. Empirical studies show that usually it is very fast and quite accurate, thus suitable for Big Data analysis. Generalization to directed graphs, edge lengths, multi-dominating are also discussed.","Online Requirements and Portal Design for Female University Science and Technology Students in Kenya ","On Efficient Graph Substructure Selection ","An automatic approach to treebank error detection using a dependency parserTreebanks play an important role in the development of various natural language processing tools. Amongst other things, they provide crucial language-specific patterns that are exploited by various machine learning techniques. Quality control in any treebanking project is therefore extremely important. Manual validation of the treebank is one of the steps that is generally necessary to ensure good annotation quality. Needless to say, manual validation requires a lot of human time and effort. In this paper, we present an automatic approach which helps in detecting potential errors in a treebank. We use a dependency parser to detect such errors. By using this tool, validators can validate a treebank in less time and with reduced human effort.","An Attitude Determination System of Quad-rotor Aircraft Based on Extended Kalman Filter and Data Fusion TechniqueAn attitude determination system composed of gyroscopes, accelerometer and magnetometer is designed. An extended Kalman filter was used for estimating aircraft's state. The attitude can be determined via data fusion technique. The experimental results indicate that this combination could effectively restrain attitude error arising from the random drift of sensors. The system has the characteristics of small size, low cost and good reliability.","Performance of continuous time quantum walks under phase dampingWe study the resilience to decoherence of the glued trees continuous time algorithm described by Childs et al. in [STOC '03, Proc. 35th ACM Symposium on Theory of Computing, 59 (2004)]. We consider a discrete time reformulation of the problem and apply a phase damping channel to the coin state, studying the effect of such a mechanism on the probability of the walker appearing on the target vertex of the graph. We pay particular attention to any potential advantage coming from the use of weak decoherence for the spreading of the walker across the glued trees graph.","Investigation of the Harpist/Harp InteractionThis paper presents a contribution to the field of the musician/instrument interaction analysis. This study aims at investigating the mechanical parameters that govern the harp plucking action as well as the gestural strategies set up by harpists to control a musical performance. Two specific experimental procedures have been designed to accurately describe the harpist motion in realistic playing contexts. They consist in filming the plucking action and the harpists gestures using a high-speed camera and a motion capture system, respectively. Simultaneously, acoustical measurements are performed to relate the kinematic investigation to sound features. Results describe the musical gesture characteristics. Mechanical parameters governing the finger/string interaction are highlighted and their influence on the produced sound are discussed. Besides, the relationship between non sound-producing gestures and musical intent is pointed out. Finally, the way energy is shared between harpist arm joints according to various playing techniques is analyzed.","Velocity-Based Cardiac Contractility Personalization with Derivative-Free OptimizationCardiac contractility personalization from medical images is a major step for biophysical models to impact clinical practice. Existing gradient-based optimization approaches show promising results of identifying the maximum contractility from images, but the contraction and relaxation rates are not accounted for. A main reason is the limited choice of objective functions when their gradients are required. For complicated cardiac models, analytical evaluation of the gradient is very difficult if not impossible, and finite difference approximation may introduce numerical difficulties and is computationally expensive. We remove such limits by using derivative-free optimization, and propose a velocity-based objective function on identifying the maximum contraction, contraction rate, and relaxation rate simultaneously with intact model complexity. Experiments on synthetic data show that the parameters are better identified using the velocity-based optimization than the position-based one. Experiments on clinical data show that the framework can obtain personalized contractility consistent to the physiologies of the patients.","Solving extensive-form games with double-oracle methodsWe investigate iterative algorithms for computing exact Nash equilibria in two-player zero-sum extensive-form games. The algorithms use an algorithmic framework of double-oracle methods. The main idea is to restrict the game by allowing the players to play only some of the strategies, and then iteratively solve this restricted game and exploit fast best-response algorithms to add additional strategies to the restricted game for the next iteration. The experimental evaluation on different games shows that the double-oracle methods often provide significant improvement in running-time, and can find exact solution of much larger games compared to the existing approaches.","Efficiently Estimating the Probability of Extensions in Abstract Argumentation ","Optical Monitoring of Dialysis DoseUtilizing optics in hemodialysis estimating quality parameters for dialysis dose has been developed during the last ten years. In principle, two optical techniques have made progress toward clinical use, namely the ultraviolet (UV) absorbance- and the near infrared (NIR) techniques. Both methods have shown reliable results of estimating urea in the spent dialysate resulting in the possibility to calculate urea-based quality parameters of dialysis dose in terms of Kt/V and URR. Even nutrition parameters derived from optical urea estimations has been provided to be possible using the UV absorbance method. The UV absorbance method cannot measure urea as a single solute; instead the high correlation between urea concentration and UV absorbance in spent dialysate is utilized when estimating urea parameters. The NIR-method can measure urea directly using signal processing of the raw NIR spectra. Predicted urea concentrations from the NIR measurement show an excellent agreement to urea concentrations measured by the standard chemical assays. The UV-method has recently been commercialized as a monitoring tool for dialysis dose in terms of the urea-based parameters, Kt/V and URR. On-going research is now focusing to monitor even other waste solutes than urea in spent dialysate. This aims to move towards a more comprehensive picture of the dialysis clearance process that is strongly linked to morbidity and survival of the dialysis patients compared with current dialysis dose calculations.","Enhancing web revisitation by contextual keywordsWeb revisitation is a common behavior supported by many web history tools. Taking advantages of access context (like time, location, concurrent activity), context-based search of previously accessed web pages is also being investigated, due to the fact that context under which information is accessed tends to be more easily to remember than content. To mimic users' memory recall, we present a way to automatically capture user's access context from user's concurrent computer programs, and manage it in a probabilistic context tree for each accessed web page in a life cycle. An algorithm for contextual keyword search of accessed web pages, together with a revisitation feedback mechanism, are also given. We evaluate the proposed method on synthetic data and through a 6-week user study. The comparisons of revisit precision and recall show our method outperforms the existing contextual search method YouPivot. In the user study, our method can also work as effectively as popular methods (like bookmark, browse history) in recall rate (over 90%), while with less average time cost (16.25 seconds) than that (38.66 seconds) of those methods to complete a web revisitation task.","Detecting transmission power misbehaviour in wi-fi networksIn Wi-Fi networks, transmission (TX) power levels are constrained by regulatory limits. However, the emergence of flexible MAC drivers allows the easy modification of PHY and MAC layer parameters. This has enabled users to attempt to violate these limits. Such actions, which we refer to as TX power misbehaviour, allow users to achieve higher throughput due to the capture effect. Detecting this type of misbehaviour is challenging because of the inability to directly measure the TX power of a user's device. Therefore, in this paper, we propose detection methods for (a) determining if the TX power violates regulatory limits and (b) estimating the TX power value. Separate methods are proposed for single and multi-rate modes of operation. Simulation results verify that the proposed methods may be successfully used to detect TX power misbehaviour. Therefore, they can be implemented in a general misbehaviour detection and reaction architecture, also presented in this paper.","A Natural Language Account for Argumentation SchemesOne of the essential activities carried out by humans in their everyday linguistic interactions is the act of drawing a conclusion from given facts through some forms of reasoning. Given a sequence of statements (i.e. the premises), humans are able to infer or derive a conclusion that follows from the facts described in the premises. In the computational linguistics field, discourse analyses have been conducted to identify the discourse structure of connected text, i.e. the nature of the discourse relationships between sentences. In parallel, research in argumentation theory has proposed argumentation schemes as structures for defining various kinds of arguments. Although the two fields of study are strongly intertwined, only a few works have put them into relation. However, a clear natural language account for argumentation schemes is still missing. To address this open issue, our work analyses how argumentation schemes fit into the discourse relations in the Penn Discourse Treebank.","General Topic Annotation in Social Networks: A Latent Dirichlet Allocation ApproachIn this article, we present a novel document annotation method that can be applied on corpora containing short documents such as social media texts. The method applies Latent Dirichlet Allocation (LDA) on a corpus to in- itially infer some topical word clusters. Each document is assigned one or more topic clusters automatically. Further document annotation is done through a projection of the topics extracted and assigned by LDA into a set of generic categories. The translation from the topical clusters to the small set of generic categories is done manually. Then the categories are used to automatically an- notate the general topics of the documents. It is remarkable that the number of the topical clusters that need to be manually mapped to the general topics is far smaller than the number of postings of a corpus that normally need to be anno- tated to build training and testing sets manually. We show that the accuracy of the annotation done through this method is about 80% which is comparable with inter-human agreement in similar tasks. Additionally, using the LDA me- thod, the corpus entries are represented by low-dimensional vectors which lead to good classification results. The lower-dimensional representation can be fed into many machine learning algorithms that cannot be applied on the conven- tional high-dimensional text representation methods.","Event Matching Using Semantic and Spatial MemoriesWe address the problem of real-time matching and correlation of events which are detected and reported by humans. As in Twitter, facebook, blogs and phone calls, the stream of reported events are unstructured and require intensive manual processing. The plethora of events and their different types need a flexible model and a representation language that allows us to encode them for online processing. Current approaches in complex event processing and stream reasoning focus on temporal relationships between composite events and usually refer to pre-defined sensor locations. We propose a methodology and a computational framework for matching and correlating atomic and complex events which have no pre-defined schemas based on their content. Matching evaluation on real events show significant improvement compared to the manual matching process. B","A lightweight language for software product lines architecture descriptionThe architecture description of a software product line (SPL) is essential to make it clear how the architecture realizes the feature model and to represent both the domain and application engineering architectural artefacts. However, most architecture description languages (ADLs) for SPL have limited support regarding variability management and they do not express the relationship between features and the architecture, besides the lack of tools for graphical and textual modelling and a non-clear separation between the domain and application engineering activities. In order to overcome these deficiencies, this paper presents LightPL-ACME, an ADL whose main goal is to be a simple, lightweight language for the SPL architecture description, and enable the association between the architectural specification and the artefacts involved in the SPL development process, including the relationship with the feature model and the representation of both domain and application engineering elements.","Efficient Information Theoretic Clustering on Discrete LatticesWe consider the problem of clustering data that reside on discrete, low dimensional lattices. Canonical examples for this setting are found in image segmentation and key point extraction. Our solution is based on a recent approach to information theoretic clustering where clusters result from an iterative procedure that minimizes a divergence measure. We replace costly processing steps in the original algorithm by means of convolutions. These allow for highly efficient implementations and thus significantly reduce runtime. This paper therefore bridges a gap between machine learning and signal processing.","Soft Biometrics for Keystroke DynamicsAujourd'hui, il existe de multiples usages des systemes biometriques a de nombreuses fins telles que le controle d'acces physique, le controle de presence, le paiement electronique et autres. Cette these de doctorat porte sur l'authentification biometrique et nous proposons d'utiliser la dynamique de frappe au clavier afin d'eviter les problemes d'authentification par mot de passe. La dynamique de frappe au clavier mesure les rythmes qui se degagent lorsqu'on tape sur un clavier d'ordinateur. En ce sens, c'est une modalite biometrique comportementale, de meme que la dynamique de signature, la demarche ou la voix. Parmi les avantages de la dynamique de frappe au clavier par rapport a d'autres modalites, nous pouvons mentionner son faible cout et sa facilite d'usage : en effet, aucun capteur ni dispositif supplementaire n'est necessaire et les utilisateurs sont habitues a taper un mot de passe. En contrepartie, la dynamique de frappe presente de plus faibles performances que les autres modalites biometriques comme les empreintes digitales, le visage, l'iris. Cela peut s'expliquer par une variabilite intra-classe elevee. Une facon de gerer cette variabilite est de prendre en compte des informations supplementaires dans le processus de decision. Cela peut etre fait de differentes manieres : (i) en combinant la dynamique de frappe au clavier avec une autre modalite biometrique (multibiometrie); (ii) en optimisant l'etape d'enrolement (une donnee biometrique est exploitee pour la generation de la reference seulement si le niveau de qualite est suffisant); ou (iii) avec une solution nouvelle et prometteuse: la biometrie douce (profilage de l'utilisateur). Nous abordons dans cette these ces deux derniers aspects. Nous proposons plusieurs contributions afin d'ameliorer les performances des systemes de dynamique de frappe au clavier. Tout d'abord, nous avons cree notre propre jeu de donnees, qui est une nouvelle base de donnees biometrique appelee 'GREYC-NISLAB Keystroke'. Nous avons collecte les donnees de 110 utilisateurs en France et en Norvege. Cette nouvelle base est publique et contient des informations de profilage des utilisateurs: la facon de taper (une main ou deux mains), le genre, l'\u00e2ge et la lateralite manuelle (droiter ou gaucher). Nous avons effectue diverses etudes afin de determiner le taux de reconnaissance des criteres de biometrie douce : (i) la facon de taper (une main ou deux mains); (ii) le genre (masculin ou feminin); (iii) la classe d'\u00e2ge (moins de 30 ans ou plus de 30 ans); et (iv) la lateralite manuelle (droitier ou gaucher) des utilisateurs en fonction de leur facon de taper au clavier. Nous montrons qu'il est possible de reconnaitre le profil de l'utilisateur en fonction de ces criteres. Par la suite, nous proposons une fusion de differentes acquisitions de la dynamique de frappe afin d'accroitre les performances du systeme. Enfin, en combinant les processus d'authentification avec les profils de biometrie douce, nous presentons une amelioration de l'authentification. Les resultats de nos experiences montrent les avantages des methodes proposees.","The Tanl Lemmatizer Enriched with a Sequence of Cascading FiltersWe have extended an existing lemmatizer, which relies on a lexicon of about 1.2 millions form, where lemmas are indexed by rich PoS tags, with a sequence of cascading filters, each one in charge of dealing with specific issues related to out-of-dictionary words. The last two filters are devoted to resolve semantic ambiguities between words of the same syntactic category, by querying external resources: an enriched index built on the Italian Wikipedia and the Google index.","A Study about the Usability Evaluation of Social Systems from Messages in Natural LanguageSocial Systems are dynamic systems, with features like interactivity, collaboration, sharing, diversity and a large number of users, various forms of access, focusing on human relationships and their emotions. In HCI (Human-Computer Interaction) there are several techniques that assess the usability of systems. However, such techniques do not consider the data collected from messages when users are interacting and expressing their feelings related to some difficulty in interaction. This paper presents a study about the usability evaluation of Social Systems from messages in Natural Language.","Toward authorization as a service: a study of the XACML standardCloud computing has promoted the notion of service as the leading way to deliver and consume computing resources. Today, security is going down that road and the term security as a service is emerging. Authorization that consists in managing permissions is one of the main classic security services. We propose in this article to study how authorization could be delivered/consumed as a Service. We focus on the XACML standard that has been adopted by the cloud security community because of its native flexibility and adaptability properties. Although XACML seems to fulfill the requirements of authorization as a Service in theory, it is very complex to realize it in practice. We propose a service oriented component architecture together with the concept self-contained policy to cope with this issue. This approach allows both the cloud consumers to adapt the authorization system to their authorization policies and the cloud providers to minimize the cost of providing a flexible authorization service.","Real-time user modeling and prediction: examples from youtubeReal-time analysis and modeling of users for improving engagement, and interaction is a burgeoning area of interest with applications to web sites, social networks and mobile applications. Apart from scalability issues, this domain poses a number of modeling and algorithmic challenges. In this talk, as an illustrative example, we present DAL, a system that leverages real-time user activity/signals for dynamic ad loads, and designed to improve the overall user experience on YouTube. This system uses machine learning to optimize for user activity during a visit and helps decide on real-time advertising policies dynamically for the user. We conclude the talk with challenges and opportunities in this important area of real-time user analysis and social modeling.","A Study for Web Site Color Guideline for Universal Access for Color Vision Deficiencies: Focusing on the Best General Hospitals in Korea and in the United States ","What is the added value of negative links in online social networksWe investigate the \"negative link\" feature of social networks that allows users to tag other users as  foes  or as  distrusted  in addition to the usual  friend  and  trusted  links. To answer the question whether negative links have an added value for an online social network, we investigate the machine learning problem of predicting the negative links of such a network using only the positive links as a basis, with the idea that if this problem can be solved with high accuracy, then the \"negative link\" feature is redundant. In doing so, we also present a general methodology for assessing the added value of any new link type in online social networks. Our evaluation is performed on two social networks that allow negative links: The technology news website Slashdot and the product review site Epinions. In experiments with these two datasets, we come to the conclusion that a combination of centrality-based and proximity-based link prediction functions can be used to predict the negative edges in the networks we analyse. We explain this result by an application of the models of preferential attachment and balance theory to our learning problem, and show that the \"negative link\" feature has a small but measurable added value for these social networks.","Representations for Large-Scale Sequence Data Mining: A Tale of Two Vector Space ModelsAnalyzing and classifying sequence data based on structural similarities and differences is a mathematical problem of escalating relevance. Indeed, a primary challenge in designing machine learning algorithms to analyzing sequence data is the extraction and representation of significant features. This paper introduces a generalized sequence feature extraction model, referred to as the Generalized Multi-Layered Vector Spaces GMLVS model. Unlike most models that represent sequence data based on subsequences frequency, the GMLVS model represents a given sequence as a collection of features, where each individual feature captures the spatial relationships between two subsequences and can be mapped into a feature vector. The utility of this approach is demonstrated via two special cases of the GMLVS model, namely, Lossless Decomposition LD and the Multi-Layered Vector Spaces MLVS. Experimental evaluation show the GMLVS inspired models generated feature vectors that, combined with basic machine learning techniques, are able to achieve high classification performance.","OpenMADS: An Open Source Tool for Modeling and Analysis of Distributed SystemsIn this paper, we present OpenMADS, an open source tool for modeling and analysis of distributed systems. OpenMADS generates comprehensive availability models by using the input of SysML specifications and MARTE annotations, which are automatically translated into deterministic and stochastic Petri nets. The integrated use of analytic models (e.g., Petri Nets or Markov chains) with semi-formal modeling languages, like SysML or UML, can provide important insights to the designers regarding different distributed infrastructures, and consequently, allows them to choose the infrastructure that fits the company budget or satisfies a given service level agreement. To show the applicability of OpenMADS, we demonstrate the process of availability modeling and evaluation based on the example of a Web server system.","Parallel Scalar Multiplication on Elliptic Curves in Wireless Sensor Networks ","Online Communities and Dynamic Capabilities: A Cross-Case Examination of Sensing, Seizing, and Reconfiguration ","Personality-Based Active Learning for Collaborative Filtering Recommender SystemsRecommender systems (RSs) suffer from the cold-start or new user/item problem, i.e., the impossibility to provide a new user with accurate recommendations or to recommend new items. Active learning (AL) addresses this problem by actively selecting items to be presented to the user in order to acquire her ratings and hence improve the output of the RS. In this paper, we propose a novel AL approach that exploits the user's personality - using the Five Factor Model (FFM) - in order to identify the items that the user is requested to rate. We have evaluated our approach in a user study by integrating it into a mobile, context-aware RS that provides users with recommendations for places of interest (POIs). We show that the proposed AL approach significantly increases the number of ratings acquired from the user and the recommendation accuracy.","An Efficient Resource Allocation Method for Multimedia Cloud Computing ","Aligning Open, Physical, and Virtual Spaces in the CIS Sandbox ","Sustainability: An Unintended Consequence of the Integration of Digital Curation Core Competencies into the MLIS Curricula ","An optimal leakage detection strategy for underground pipelines using magnetic induction-based sensor networksIt is difficult to detect small leakages in underground pipelines with high accuracy and low-energy cost due to the inaccessible underground environments. To this end, the Magnetic Induction (MI)-based wireless sensor network for underground pipeline monitoring (MISE-PIPE) is introduced in [13]. The MISE-PIPE deploys high-density underground MI sensors along the pipelines, which provide necessary measurements for leakage detection with very high resolution. However, in order to provide accurate and low-cost leakage detection based on MISE-PIPE, an optimal deployment and activation strategy for those sensors is needed. In this paper, we provide an optimal strategy to detect leakages in underground pipelines based on the MISE-PIPE framework. Based on the proposed detection strategy, the error bound is derived to characterize the accuracy, while the energy consumption is analyzed to model the system energy cost. By trading off the accuracy and the energy consumption, an optimization function is developed to achieve the optimal performance.","Adaptive Register Allocation with a Linear Number of RegistersWe give an adaptive algorithm in which processes use multi-writer multi-reader registers to acquire exclusive write access to their own single-writer, multi-reader registers. It is the first such algorithm that uses a number of registers linear in the number of participating processes. Previous adaptive algorithms require at least i\u00be?n 3/2 registers.","Invasive Computing on High Performance Shared Memory Systems ","User-centered evaluation of a discovery layer system with google scholarDiscovery layer systems allow library users to obtain search results from multiple library resources and view results in a consistent format. The implementation of a discovery layer is expected to simplify users' workflow of searching for scholarly information. Previous studies on discovery layer systems focused on functionality and content, but not quality of search results from the user's perspective. The objective of this study was to obtain users' assessment of search results of a discovery layer system (Ex Libris Primo\u00ae) and compare that with a widely used scholarly search tool (Google Scholar). Results showed that Primo's search results relevancy is comparable to Google Scholar, but it received significantly lower usability and preference ratings. A number of usability issues of Primo were also identified from the study. Results of the study are used to improve the interface of Primo and adjust relevancy ranking options. The empirical method of search results assessment and feedback collection used in this study can be extended to similar user-centered system implementation and evaluation efforts.","Context as a system, product as a component, and the relationship as experienceCurrently, User Experience Design (UXD) is spotlighted as one of the most topical areas in design. It is an umbrella term that explains all aspects of a user's experience with a given context, including the interface, graphic design, industrial design, and interaction (Merholz P. , 2007). Particularly, the notion of UXD is rooted in human factors and ergonomics that focus on physical, cognitive and emotional interaction between human users, machines and a contextual environment. In the industrial design field, the idea of UXD is not a new but an ancient concept that has been discussed in different terms such as ergonomics, anthropometrics, and affordance, etc., and whose main focus is a positive and rich experience. The current development of SNS (Social Networking Services) and smartphone technology, however, has created possibilities for new types of user experience design. Sander (Sanders, 2002) mentions this possibility as new design space where \"designers will transform from being designers of \"stuff\" (e.g., products, communication pieces, etc.) to being the builders of scaffolds for experiencing.\", and where industrial designers will now confront different challenges to discover and develop new types of products with different interface designs for novel user experience. For example, tablet computers like the Apple iPad already have changed the activity of computing from a static environment to almost everywhere. Based on the theoretical framework that \"a context as a system, a product as a component, and the relationship between them as an experience\", we propose three main research questions. These questions are 1) how a current professional UX designer in practice has redefined UX design themselves, 2) what specific actions are performed and 3) what supports they provide for their client. Through careful in-depth interviews with seven professional UX designers in experience-centric design firms, including IDEO and Adaptive Path etc., in US and Canada, we propose several critical notions and foundational references for UX designers.","Survey on Co-operative P2P Information Exchange in Large P2P Networks ","New construction of error-tolerant pooling designsIn this paper a new class of error-tolerant pooling designs associated with finite vector spaces is presented. We construct dz-disjunct inclusion matrices using packings in finite projective spaces. For certain parameters our construction gives better performance than previously known ones. In particular, the construction gives a family of disjunct matrices with near optimal parameters.","Decision-Theoretic Sparsification for Gaussian Process Preference LearningWe propose a decision-theoretic sparsification method for Gaussian process preference learning. This method overcomes the loss-insensitive nature of popular sparsification approaches such as the Informative Vector Machine IVM. Instead of selecting a subset of users and items as inducing points based on uncertainty-reduction principles, our sparsification approach is underpinned by decision theory and directly incorporates the loss function inherent to the underlying preference learning problem. We show that by selecting different specifications of the loss function, the IVM's differential entropy criterion, a value of information criterion, and an upper confidence bound UCB criterion used in the bandit setting can all be recovered from our decision-theoretic framework. We refer to our method as the Valuable Vector Machine VVM as it selects the most useful items during sparsification to minimize the corresponding loss. We evaluate our approach on one synthetic and two real-world preference datasets, including one generated via Amazon Mechanical Turk and another collected from Facebook. Experiments show that variants of the VVM significantly outperform the IVM on all datasets under similar computational constraints.","Assumption-Based Argumentation for Decision-Making with Preferences: A Medical Case StudyWe present a formal decision-making framework, where decisions have multiple attributes and meet goals, and preferences are defined over individual goals and sets of goals. We define decision functions to select 'good' decisions according to an underlying decision criteria. We also define an argumentation-based computational mechanism to compute and explain 'good' decisions. We draw connections between decision-making and argumentation semantics: 'good' decisions are admissible arguments in a corresponding argumentation framework. To show the applicability of our approach, we use medical literature selection as a case study. For a given patient description, we select the most relevant medical papers from the medical literature and explain the selection.","Determining microblogging effectiveness for capturing quality knowledge ","Optimization for Policy Making: The Cornerstone for an Integrated ApproachPolicy making is a very complex task taking into account several aspects related to sustainability, namely impact on the environments, health of productive sectors, economic implications and social acceptance. Optimization methods could be extremely useful for analysing alternative policy scenarios, but should be complemented with several other techniques such as machine learning, agent-based simulation, opinion mining and visualization to come up with an integrated system able to support decision making in the overall policy design life cycle. I will discuss how these techniques could be merged with optimization and I will identity some open research directions.","Neighborhood-Based Dynamic Community Detection with Graph Transform for 0-1 Observed Networks ","An unstable hypergraph problem with a unique optimal solutionThere is a variety of problems in extremal combinatorics for which there is a unique configuration achieving the optimum value. Moreover, as the size of the problem grows, configurations that \"almost achieve\" the optimal value can be shown to be \"almost equal\" to the extremal configuration. This phenomenon, known as stability, has been formalized by Simonovits [A Method for Solving Extremal Problems in Graph Theory, Stability Problems, Theory of Graphs (Proc.Colloq., Tihany, 1966), 279---319] in the context of graphs, but has since been considered for several combinatorial structures. In this work, we describe a hypergraph extremal problem with an unusual combinatorial feature, namely, while the problem is unstable, it has a unique optimal solution up to isomorphism. To the best of our knowledge, this is the first such example in the context of (simple) hypergraphs.#R##N##R##N#More precisely, for fixed positive integers r and l with 1\u2264l l\u22652.","Technological Tools Virtual Collaborative to Support Knowledge Management in Project Management ","An Exploration of Text Analysis Methods to Identify Social Deliberative Skill ","Uma biblioteca de componentes para desenvolvimento de aplica\u00e7\u00f5es controladas por gestosThis article proposes a library to support the rapid development of gesture-driven application interfaces based on Kinect platform. The paper also presents a digital wall composed by virtual interactive objects is used in the paper as proof-of-concept for an initial evaluation of the library.","L -identification for uniformly distributed sources and the q -ary identification entropy of second orderIn this article we generalize the concept of identification for sources, which was introduced by Ahlswede, to the concept of L-identification for sources. This means that we do not only consider a discrete source but a discrete memoryless source (DMS) with L outputs. The task of L-identification is now to check for any previously given output whether it is part of the L outputs of the DMS. We establish a counting lemma and use it to show that, if the source is uniformly distributed, the L-identification symmetric running time asymptotically equals the rational number $$K_{L, q}=-\\sum_{l=1}^L(-1)^l{L \\choose l}\\frac{q^l}{q^l-1}\\enspace.$$ We then turn to general distributions and aim to establish a lower bound for the symmetric 2-identification running time. In order to use the above asymptotic result we first concatenate a given code sufficiently many times and show that for 2-identification the uniform distribution is optimal, thus yielding a first lower bound. This lower bound contains the symmetric (1-)identification running time negatively signed so that (1-)identification entropy cannot be applied immediately. However, using the fact that the (1-)identification entropy is attained iff the probability distribution consists only of q-powers, we can show that our lower bound is in this case also exactly met for 2-identification. We then prove that the obtained expression is in general a lower bound for the symmetric 2-identification running time and that it obeys fundamental properties of entropy functions. Hence, the following expression is called the q-ary identification entropy of second order     $$H_{\\mbox{\\tiny ID}}^{2,q}(P) =2\\frac{q}{q-1}\\left(1-\\sum_{u\\in{\\mathcal U}}p_u^2\\right)-\\frac{q^2}{q^2-1}\\left(1-\\sum_{u\\in{\\mathcal U}}p_u^3\\right)\\enspace.$$","Building a Standard Amazigh CorpusNatural language processing is showing more interest in the Amazigh language in recent years. Suitable resources for Amazighe are becoming a vital necessity for the progress of this research. Corpora are an important resource but Amazighe lacks sufficient resources in this field, therefore we have been conducted tobuildanAmazighecorpus.Inthispaper,wepresentpreliminaryresultsexperiment with a corpus for Standard Amazighe. We selected samples of published data from different Amazighe varieties. The selection was driven mainly by the amount of data available. We still demonstrate the completeness and representativeness of this corpus using metrics and show its suitability for language engineering experiments.","The conjunction fallacy and its impacts in the user's data acquisition processThere are moments within the process of creating an artifact, for instance at the initial requirements gathering or in the assessment phase, that users input data is collected. There may be an impact directly on the results of the analysis of this data if, for some reason, this data input is not accurate. This paper will focus on a specific phenomenon, known as the Conjunction Fallacy, which may lead users to commit errors of judgment that would impact directly in the accuracy of their evaluation of alternatives. In order to exemplify this issue, this paper presents experiments where, during the evaluation phase of the design of a product, it was verified the presence of the conjunction fallacy. It also presents a possible strategy to minimize the errors of judgment caused by the fallacy.","A Primitive for Revealing Stealthy Peripheral-Based Attacks on the Computing Platform\u2019s Main Memory ","Understanding adoption of a personal health record in rural health care clinics: revealing barriers and facilitators of adoption including attributions about potential patient portal users and self-reported characteristics of early adopting users.Personal health records (PHRs) are important for improving patient care. An important prerequisite to realize benefits of PHR use is patient recruitment. To understand clinic barriers to adoption, we used Rogers\u2019 Diffusion of Innovations theory to frame an examination of clinic staff perceptions of a new PHR and perceptions of likely patient portal users. Clinic staff reported many relative advantages and observable benefits of the PHR but also some distinct problems. Attributions about potential patient users included demographic, computer use, and personality characteristics staff expected in likely users. Analysis of patient survey data of early adopters compared to non-users revealed discrepancies between clinic staff expectations and early adopters\u2019 self-reports. Implications for improving adoption of PHRs include ensuring compatibility with existing systems and avoiding recruitment biases.","Social welfare maximization in participatory smartphone sensingParticipatory smartphone sensing has lately become more and more popular as a new paradigm for performing large-scale sensing, in which each smartphone contributes its sensed data for a collaborative sensing application. Most existing studies assume that smartphone users are strictly strategic and completely rational, which can achieve only sub-optimal system performance. Few existing studies can maximize a system-wide objective which takes both the platform and smartphone users into account. This paper focuses on the crucial problem of maximizing the system-wide performance or social welfare for a participatory smartphone sensing system. There are two great challenges. First, the social welfare maximization can not be realized on the platform side because the cost of each user is private and unknown to the platform in reality. Second, the participatory sensing system is a large-scale real-time system due to the huge number of smartphone users who are geo-distributed in the whole world. We propose a novel price-based decomposition framework, in which the platform provides a unit price for the sensing time spent by each user and the users return the sensing time via maximizing the monetary reward. This pricing framework is an effective incentive mechanism as users are motivated to participate for monetary rewards from the platform. The original problem is equivalently converted into an optimal pricing problem, and a distributed solution via a step-size-free price-updating algorithm is proposed. More importantly, the distributed algorithm ensures that the cost privacy of each user is not compromised. Experimental results show that our novel distributed algorithm can achieve the maximum social welfare of the participatory smartphone system.","Relevance Feedback in Content-Based Image Retrieval: A SurveyIn content-based image retrieval, relevance feedback is an interactive process, which builds a bridge to connect users with a search engine. It leads to much improved retrieval performance by updating a query and similarity measures according to a user's preference; and recently techniques have matured to some extent. Most previous relevance feedback approaches exploit short-term learning (intraquery learning) that deals with the current feedback session but ignoring historical data from other users, which potentially results in a great loss of useful information. In the last few years, long-term learning (inter-query learning), by recording and collecting feedback knowledge from different users over a variety of query sessions has played an increasingly important role in multimedia information searching. It can further improve the retrieval performance in terms of effectiveness and efficiency. In the published literature, no comprehensive survey of both short-term learning and long-term learning RF techniques has been conducted. To this end, the goal of this chapter is to address this omission and offer suggestions for future work. \u00c2\u00a9 Springer-Verlag Berlin Heidelberg 2013.","Mining taxonomies from web menus: rule-based concepts and algorithmsThe logical hierarchies of Web sites (i.e. Web site taxonomies) are obvious to humans, because humans can distinguish different menu levels and their relationships. But such accurate information about the logical structure is not yet available to machines. Many applications would benefit if Web site taxonomies could be mined from menus, but it was an almost unsolvable problem in the past. While a tag newly introduced in HTML5 and novel mining methods allow to distinguish menus from other contents today, it has not yet been researched, how the underlying taxonomies can be extracted, given the menus. In this paper we present the first detailed analysis of the problem and introduce rule-based concepts for addressing each identified sub problem. We report on a large-scale study on mining hierarchical menus of 350 randomly selected domains. Our methods allow extracting Web site taxonomy information that was not available before with high precision and high recall.","Agent-based simulation of cooperative hunting with UAVsSwarm intelligent systems are simple but robust, capable of solving complex problems that no single agent could attempt. While technological advancements have driven development of multi-agent systems across disciplines, emergent behavior inherent to swarms is a desirable yet difficult property to exploit. Solutions utilizing swarm behavior have been proposed for the Cooperative Cleaning Problem, which is applicable to UAVs cooperatively searching for evasive targets. This work proposes a new agent behavior capable of partitioning a search area, and when combined with previous swarm solutions, forms an optimization problem of how to best assign swarms to a complex topology. Agent-based simulations are developed to test swarm solutions.","Generation of the Certain Kind of Figures Using the Movement Sense of Localized Sound and Its Application ","Content validation for level of use of feature rich systems: a Delphi study of electronic medical records systems.Introduction. Feature usage is a pre-requisite to realising the benefits of investments in feature rich systems. We propose that conceptualising the dependent variable 'system use' as 'level of use' and specifying it as a formative construct has greater value for measuring the post-adoption use of feature rich systems. We then validate the content of the construct as a first step in developing a research instrument to measure it. The context of our study is the post-adoption use of electronic medical records (EMR) by primary care physicians.#R##N##R##N#Method. Initially, a literature review of the empirical context defines the scope based on prior studies. Having identified core features from the literature, they are further refined with the help of experts in a consensus seeking process that follows the Delphi technique.#R##N##R##N#Results.The methodology was successfully applied to EMRs, which were selected as an example of feature rich systems. A review of EMR usage and regulatory standards provided the feature input for the first round of the Delphi process. A panel of experts then reached consensus after four rounds, identifying ten task-based features that would be indicators of level of use. #R##N##R##N#Conclusions. To study why some users deploy more advanced features than others, theories of post-adoption require a rich formative dependent variable that measures level of use. We have demonstrated that a context sensitive literature review followed by refinement through a consensus seeking process is a suitable methodology to validate the content of this dependent variable. This is the first step of instrument development prior to statistical confirmation with a larger sample.","Towards a Model- and Learning-Based Framework for Security Anomaly DetectionFor critical areas, such as the health-care domain, it is com- mon to formalize workflow, traffic-flow and access control via models. Typically security monitoring is used to firstly determine if the system corresponds to the specifications in these models and secondly to deal with threats, e.g. by detecting intrusions, via monitoring rules. The chal- lenge of security monitoring stems mainly from two aspects. First, infor- mation in form of models needs to be integrated in the analysis part, e.g. rule creation, visualization, such that the plethora of monitored events are analyzed and represented in a meaningful manner. Second, new in- trusion types are basically invisible to established monitoring techniques such as signature-based methods and supervised learning algorithms. In this paper, we present a pluggable monitoring framework that fo- cuses on the above two issues by linking event information and modelling specification to perform compliance detection and anomaly detection. As input the framework leverages models that define workflows, event infor- mation, as well as the underlying network infrastructure. Assuming that new intrusions manifest in anomalous behaviour which cannot be fore- seen, we make use of a popular unsupervised machine-learning technique called clustering.","Engaging Users in Audio Labelling as a Movie Browsing Game with a PurposeNowadays, movies, video, audio and games have a strong presence in human life, being a massive source of entertainment. Increasingly, movies and videos are becoming accessible as enormous collections over the Internet, in social media and interactive TV, demanding for more powerful ways to search, browse and view them, that benefit from video content-based analysis and classification techniques. From the point of view of the content-based analysis methods, a challenging aspect is the constitution of collections of labelled data. Inspired by the Game With A Purpose approach we propose SoundsLike, a game that pursues two goals: 1) entertaining the user in movie browsing; 2) use this interaction to collect data and improve our content-based sound analysis techniques. SoundsLike is integrated in MovieClouds, an interactive web application designed to access, explore and visualize movies based on the information conveyed in the different tracks or perspectives of its content.","Bi-objective Optimization in Identical Parallel Machine Scheduling ProblemThis paper presents bi-objective identical parallel machine scheduling problem with minimization of weighted sum of makespan and number of tardy jobs simultaneously. It is a known fact that identical parallel machine scheduling problem with makespan and number of tardy jobs based criteria is NP hard. Metaheuristics has become most important choice for solving NP hard problems because of their multi-solution and strong neighborhood search capabilities in a reasonable time. In this work Simulated Annealing Algorithm (SA) and Genetic Algorithm (GA) has been proposed to optimize two different objectives namely (i) minimization of make span (ii) minimization of number of tardy jobs using combined objective function (COF). The effectiveness of the proposed algorithm have been analyzed by means of benchmark problem taken from the literatures and relative performance measures for the algorithm have also been computed and analyzed. Computational results show that GA outperforms SA by a considerable margin.","Applying Distance Histogram to retrieve 3D cardiac medical models.Three-dimensional models are being extensively used in the medical area in order to improve clinical medical examinations and diagnosis. The Cardiology field handles with several types of image slices to compose the diagnosis. MRI (Magnetic Resonance Imaging) is a non-invasive technique to detect anomalies from internal images of the human body that generates hundreds of images, which takes long for the specialist to analyze frame by frame and the diagnosis precision can be affected. Many cardiac diseases could be identified through shape deformation, but systems aimed to aid diagnosis usually identify shapes in two-dimensional (2D) images. Our aim is to apply a shape descriptor to retrieve three-dimensional cardiac models, obtained from a set of 2D slices, which were segmented and reconstructed from MRI images using their geometry information. Preliminary results show that the shape deformation in 3D models can be a good indicator to detect Congestive Heart Failure, a very common heart disease.","Application of Assistive Technology in a Concurrent Engineering Environment for the Special Products Development: A Case Study ","An Analysis of Speech Signals of the Choapam Variant Zapotec LanguageThe Zapotec language, as well as many other prehispanic languages in Mexico, is endangered for many reasons including a lack of use by the younger population who prefer to speak Spanish instead, and by the dying out of older native speakers. In this paper an analysis of the Choapam variant of Zapotec is presented; a list of words in this Zapotec was recorded, and a time and formant analysis was carried out in order to obtain basic information used to describe the language. The formant analysis focused on the vowels in the language, due complications which arise with them, and gives a first classification of them. Some of the difficulties experienced in the study, which are similar to those encountered with many other endangered languages, are detailed. Although this is a first approach to these languages analysis, it is hoped that the use of this information will contribute to further efforts aimed at helping preserve the language.","A diagnostic evaluation approach for english to hindi MT using linguistic checkpoints and error ratesThis paper addresses diagnostic evaluation of machine translation (MT) systems for Indian languages, English to Hindi MT in particular, assessing the performance of MT systems on relevant linguistic phenomena (checkpoints). We use the diagnostic evaluation tool DELiC4MT to analyze the performance of MT systems on various PoS categories (e.g. nouns, verbs). The current system supports only word level checkpoints which might not be as helpful in evaluating the translation quality as compared to using checkpoints at phrase level and checkpoints that deal with named entities (NE), inflections, word order, etc. We therefore suggest phrase level checkpoints and NEs as additional checkpoints for DELiC4MT. We further use Hjerson to evaluate checkpoints based on word order and inflections that are relevant for evaluation of MT with Hindi as the target language. The experiments conducted using Hjerson generate overall (document level) error counts and error rates for five error classes (inflectional errors, reordering errors, missing words, extra words, and lexical errors) to take into account the evaluation based on word order and inflections. The effectiveness of the approaches was tested on five English to Hindi MT systems.","Typologies of Computation and Computational ModelsWe need much better understanding of information processing and computation as its primary form. Future progress of new computational devices capable of dealing with problems of big data, internet of things, semantic web, cognitive robotics and neuroinformatics depends on the adequate models of computation. In this article we first present the current state of the art through systematization of existing models and mechanisms, and outline basic structural framework of computation. We argue that defining computation as information processing, and given that there is no information without (physical) representation, the dynamics of information on the fundamental level is physical/ intrinsic/ natural computation. As a special case, intrinsic computation is used for designed computation in computing machinery. Intrinsic natural computation occurs on variety of levels of physical processes, containing the levels of computation of living organisms (including highly intelligent animals) as well as designed computational devices. The present article offers a typology of current models of computation and indicates future paths for the advancement of the field; both by the development of new computational models and by learning from nature how to better compute using different mechanisms of intrinsic computation.","Discovering Typical Transcription-Factors Patterns in Gene Expression Levels of Mouse Embryonic Stem Cells by Instance-Based ClassifiersThe development of high-throughput technology in genome sequencing provide a large amount of raw data to study the regulatory functions of transcription factors (TFs) on gene expression. It is possible to realize a classifier system in which the gene expression level, under a certain condition, is regarded as the response variable and features related to TFs are taken as predictive variables. In this paper we consider the families of Instance-Based (IB) classifiers, and in particular the Prototype exemplar learning classifier (PEL-C), because IB-classifiers can infer a mixture of representative instances, which can be used to discover the typical epigenetic patterns of transcription factors which explain the gene expression levels. We consider, as case study, the gene regulatory system in mouse embryonic stem cells (ESCs). Experimental results show IB-classifier systems can be effectively used for quantitative modelling of gene expression levels because more than 50% of variation in gene expression can be explained using binding signals of 12 TFs; moreover the PEL-C identifies nine typical patterns of transcription factors activation that provide new insights to understand the gene expression machinery of mouse ESCs.","Sensory augmentation with distal touch: the tactile helmet projectThe Tactile Helmet is designed to augment a wearer's senses with a long range sense of touch. Tactile specialist animals such as rats and mice are capable of rapidly acquiring detailed information about their environment from their whiskers by using task-sensitive strategies. Providing similar information about the nearby environment, in tactile form, to a human operator could prove invaluable for search and rescue operations, or for partially-sighted people. Two key aspects of the Tactile Helmet are sensory augmentation, and active sensing. A haptic display is used to provide the user with ultrasonic range information. This can be interpreted in addition to, rather than instead of, visual or auditory information. Active sensing systems \"are purposive and information-seeking sensory systems, involving task specific control of the sensory apparatus\" [1]. The integration of an accelerometer allows the device to actively gate the delivery of sensory information to the user, depending on their movement. Here we describe the hardware, sensory transduction and characterisation of the Tactile Helmet device, before outlining potential use cases and benefits of the system.","On the Use of Monogenic Scale Space for Efficient Face Representation and Recognition ","Proxemic Interaction Applied to Public Screen in LabProxemics is the terminology used to describe spatial relationships among humans while communicating with each other. It could be interesting to apply the proxemics theory to the domain of human computer interaction, namely proxemic interaction. Computers, unlike people, find it hard to interpret instantly and precisely the user's nonverbal hints, such as body postures, movement, and distance. With the development of computer vision, these tasks can be performed with simple devices. In this paper, we build the abstract model for calculation in proxemic interaction, and further illustrate the prototype based on research life in the lab. We then describe evolution of the prototype through investigation of proxemic interaction. Finally, we ask users for their opinion via a preliminary user study and usability test. Our study shows that users are attracted by this kind of interaction, and especially by the application scenario in the lab with a large public screen.","Counting the Number of Solutions of KDMDGP InstancesWe discuss a method for finding the number of realizations in R K of certain simple undirected weighted graphs.","Estimation of Dominant Features of Commodities Based on Shopping Behavior Analysis ","Domination analysis of algorithms for bipartite boolean quadratic programsFor the bipartite boolean quadratic programming problem (BBQP) with m+n variables, an O(mn) algorithm is given to compute the average objective function value $\\mathcal{A}$ of all solutions where as computing the median objective function value is shown to be NP-hard. Also, we show that any solution with objective function value no worse than $\\mathcal{A}$ dominates at least 2m+n\u22122 solutions and this bound is the best possible. An O(mn) algorithm is given to identify such a solution. We then show that for any fixed rational number $\\alpha=\\frac{a}{b} &gt; 1$ and gcd(a,b)=1, no polynomial time approximation algorithm exists for BBQP with dominance ratio larger than $1-2^{\\frac{(1-\\alpha)}{\\alpha}(m+n)}$, unless P=NP. Finally, it is shown that some powerful local search algorithms can get trapped at a local maximum with objective function value less than $\\mathcal{A}$.","A Statistical Comparison of SimTandem with State-of-the-Art Peptide Identification Tools ","Efficient Implementation of Bayesian Hierarchical Model to Study Space Time Variability of Latent Heat Flux ","Encoding of stimuli in embodied neuronal networksInformation coding in the central nervous system is still, under many aspects, a mystery. In this work, we made use of cortical and hippocampal cultures plated on micro-electrode arrays and embedded in a hybrid neuro-robotic platform to investigate the basis of \"sensory\" coding in neuronal cell assemblies. First, we asked which features of the observed spike trains (e.g. spikes, bursts, doublets) may be used to reconstruct significant portions of the input signal, coded as a low-frequency train of stimulations, through optimal linear reconstruction techniques. We also wondered whether preparations of cortical or hippocampal cells might present different coding representations. Our results pointed out that identifying specific signal structures within the spike train does not improve reconstruction performance. We found, instead, differences tied to the cell type of the preparation, with cortical cultures showing less segregated responses than hippocampal ones.","The Strategies for Supporting Query Specialization and Query Generalization in Social Tagging SystemsIn this paper, we design a tag ranking method to provide multi-level keyword suggestion. The suggested keywords are used to effectively filter query results, which helps users to perform query specialization in social tagging systems. Besides, error-tolerant set containment queries are used to support various degrees of query generalization. We propose an index structure, which aggregates similar tag sets into clusters. A bounding mechanism is provided to efficiently deal with query processing for error-tolerant set containment queries on tag sets. These strategies can be used to support generalizations of a query. A systematic performance study is performed to show the effectiveness and the efficiency of the proposed methods.","Application of local activity theory of CNN to the coupled autocatalator modelThe study of chemical reactions with oscillating kinetics has drawn increasing interest over the last few decades. However the dynamical properties of the coupled nonlinear dynamic system are difficult to deal with. The local activity principle of the Cellular Nonlinear Network (CNN) introduced by Chua has provided a powerful tool for studying the emergence of complex behaviors in a homogeneous lattice formed by coupled cells. Based on the Autocatalator Model introduced by Peng.B, this paper establishes a two dimensional coupled Autocatalator CNN system. Using the analytical criteria for the local activity calculates the chaos edge of the Autocatalator CNN system. The numerical simulations show that the emergence may exist if the selected cell parameters are nearby the edge of chaos domain. The Autocatalator CNN can exhibit periodicity and chaos.","Evidence for Response Consistency Supports Polychronous Neural Groups as an Underlying Mechanism for Representation and MemoryIzhikevich [6] has proposed that certain strongly connected groups of neurons known as polychronous neural groups (or PNGs) might provide the neural basis for representation and memory. Polychronous groups exist in large numbers within the connection graph of a spiking neural network, providing a large repertoire of structures that can potentially match an external stimulus [6,8]. In this paper we examine some of the requirements of a representational system and test the idea of PNGs as the underlying mechanism against one of these requirements, the requirement for consistency in the neural response to stimuli. The results provide preliminary evidence for consistency of PNG activation in response to known stimuli, although these results are limited by problems with the current methods for detecting PNG activation.","Mobile EM field generator for ultrasound guided navigated needle insertionsNeedle insertions are an elementary tool for diagnostic and therapeutic purposes. Critical success factors are: Precise needle placement, avoidance of critical structures and short intervention time. Navigation solutions for ultrasound-based needle insertions have been presented but did not find widespread clinical application. This can be attributed to the complexity and higher costs introduced by additional tracking related equipment. Using a new compact electromagnetic (EM) field generator (FG), we present the first navigated intervention method that combines field generator and ultrasound (US) probe into a single mobile imaging modality that enables tracking of needle and patient. In a phantom study, we applied the system for navigated needle insertion and achieving a hit rate of 92% and a mean accuracy of 3.1mm (n=24). These results demonstrate the potential of the new combined modality in facilitating US-guided needle insertion.","Determinantal Complexities and Field Extensions ","Neural Moving Object Detection by Pan-Tilt-Zoom CamerasAutomated video surveillance using video analysis and un- derstanding technology has become an important research topic in the area of computer vision. Most cameras used in surveillance are fixed, al- lowing to only look at one specific view of the surveilled area. Recently, the progress in sensor technologies is leading to a growing dissemination of Pan-Tilt-Zoom (PTZ) cameras, that can dynamically modify their field of view. Since PTZ cameras are mainly used for object detection and tracking, it is important to extract moving object regions from im- ages taken with this type of camera. However, this is a challenging task because of the dynamic background caused by camera motion. After reviewing background subtraction-based approaches to mov- ing object detection in image sequences taken from PTZ cameras, we present a neural-based background subtraction approach where the back- ground model automatically adapts in a self-organizing way to changes in the scene background. Experiments conducted on real image sequences demonstrate the effectiveness of the presented approach.","Transductive Inference for Class-Membership Propagation in Web OntologiesThe increasing availability of structured machine-processable knowl- edge in the context of the Semantic Web, allows for inductive methods to back and complement purely deductive reasoning in tasks where the latter may fall short. This work proposes a new method for similarity-based class-membership predic- tion in this context. The underlying idea is the propagation of class-membership information among similar individuals. The resulting method is essentially non- parametric and it is characterized by interesting complexity properties, that make it a candidate for the application of transductive inference to large-scale contexts. We also show an empirical evaluation of the method with respect to other ap- proaches based on inductive inference in the related literature.","Towards a Tight Integration of Syntactic Parsing with Semantic Disambiguation by means of Declarative Programming ","Human Interaction Recognition by Spatial Structure ModelsIn this paper, we focus on the recognition and localization of human interactions in real-world videos. It is a difficult challenge be- cause of large variations in person appearance, camera viewpoint, length of video, intra-class variability, and etc. To address these challenges, we present a spatial structure model in this paper. In our model, the cru- cial movement of each category is represented using a segment of the entire video. To capture the spatial configuration of the human interac- tions within the video segment, a spatial structure model is built over the segment, and trajectory features are extracted within each cell. The proposed model is trained automatically from real-world videos that are annotated only with the classification label. We examine our approach on the TVHI dataset, which contain 4 complex human interaction ac- tion classes. The experimental results demonstrate the effectiveness of our model.","Towards the next generation intelligent BPM: in the era of big dataBig data opens a new dimension, space, to offer the advantage of gleaning intelligence from data and translating that into business benefits. It will lead to knowledge revolution in all sectors, including Business Process Management (BPM). This paper sheds light on key characteristics of intelligent BPM (iBPM) from an industrial point of view. A big data perspective on iBPM is then proposed, showing the challenges and potential opportunities in attempt to catalyze ideas from insight to application. China Mobile Communications Corporation's (CMCC) exploring and practice are provided, which also elicit the future research directions for enterprise applications.","Dempster-Shafer theory with smoothnessThis paper introduces the idea of a modified Dempster-Shafer theory. We adapt the belief characteristic of expert combination by introducing a penalty term which is specific to the investigated object. This approach is motivated by the observation that final decisions in the Dempster-Shafer theory might tend to fluctuations due to variations in sensor inputs on small time scales, even if the real phenomenological characteristic is stable.","The impact of lexical simplification by verbal paraphrases for people with and without dyslexiaText simplification is the process of transforming a text into an equivalent which is easier to read and to understand, preserving its meaning for a target population. One such population who could benefit from text simplification are people with dyslexia. One of the alternatives for text simplification is the use of verbal paraphrases. One of the more common verbal paraphrase pairs are the one composed by a lexical verb (to hug) and by a support verb plus a noun collocation (to give a hug). This paper explores how Spanish verbal paraphrases impact the readability and the comprehension of people with and without dyslexia dyslexia. For the selection of pairs of verbal paraphrases we have used the Badele.3000 database, a linguistic resource composed of more than 3,600 verbal paraphrases. To measure the impact in reading performance and understandability, we performed an eye-tracking study including comprehension questionnaires. The study is based on a group of 46 participants, 23 with confirmed dyslexia and 23 control group. We did not find significant effects, thus tools that can perform this kind of paraphrases automatically might not have a large effect on people with dyslexia. Therefore, other kinds of text simplification might be needed to benefit readability and understandability of people with dyslexia.","Adaptive Morphologic Regularizations for Inverse ProblemsRegularization is an well-known technique for obtaining stable solution of ill-posed inverse problems. In this paper we establish a key rela- tionship among the regularization methods with edge-preserving noise filtering method which leads to an efficient adaptive regularization methods. We show ex- perimentally the efficiency and superiority of the proposed regularization meth- ods for some inverse problems, e.g. deblurring and super-resolution (SR) image reconstruction.","Intelligent Texture Reconstruction of Missing Data in Video Sequences Using Neural Networks ","Dealing with Contradictory Evidence Using Fuzzy Trust in Semantic Web DataTerm similarity assessment usually leads to situations where contradictory evidence support has different views concerning the mean- ing of a concept and how similar it is to other concepts. Human experts can resolve their differences through discussion, whereas ontology map- ping systems need to be able to eliminate contradictions before similarity combination can achieve high quality results. In these situations, differ- ent similarities represent conflicting ideas about the interpreted meaning of the concepts. Such contradictions can contribute to unreliable map- pings, which in turn worsen both the mapping precision and recall. In order to avoid including contradictory beliefs in similarities during the combination process, trust in the beliefs needs to be established and untrusted beliefs should be excluded from the combination. In this chap- ter, we propose a solution for establishing fuzzy trust to manage belief conflicts using a fuzzy voting model.","Affective-Sensitive Operator \u201czhenshi\u201dIn modern Chinese, \"zhenshi\" is mainly used to elicit the subjective evaluation of the speaker and closely linked to the speaker's affective. It can be seen as an affective-sensitive operator. Based on the corpus of contemporary Chinese fiction, we analyze its syntactic features and lexical semantics in this article, and divide it into two categories: the objective truth and the subjective emphasis.","Walking in a virtual town to understand and learning about the life in the middle agesEdutainment refers to any form of entertainment aimed at an educational role; it enhances the learning environment and makes it much more engaging and fun-filled. The videogame is one of the most exciting and immediate tools of the edutainment applications since the game enables a type of multisensory and immersive relationship of the user through its interactive interface; Virtual Reality technology makes possible to create applications for edutainment purposes and to integrate different learning approaches. One of the important applications of edutainment is the reconstruction of 3D environments aimed at the study of cultural heritage. This paper presents some results of the MediaEvo Project that has led the researchers to use the reconstruction of a town in the Middle Ages in order to develop a multi-channel and multi-sensory platform for the edutainment in Cultural Heritage. MediaEvo project has permitted a didactic experimentation whereby simulation is considered as a precious teaching support tool. The educational MediaEvo game has prompted students to participate in and experience in a simulated and immersive environment of a town in the Middle Ages in order to connect the recreational actions, and to critically discover roles, functions and actions referring to Medieval life.","Rendering molecular surfaces using order-independent transparencyIn this paper we present a technique for interactively rendering transparent molecular surfaces. We use Puxels, our implementation of per-pixel linked lists for order-independent transparency rendering. Furthermore, we evaluate the usage of per-pixel arrays as an alternative for this rendering technique. We describe our real-time rendering technique for transparent depiction of complex molecular surfaces like the Solvent Excluded Surface which is based on constructive solid geometry. Additionally, we explain further graphical operations and extensions possible with the Puxels approach. The evaluation benchmarks the performance of the presented methods and compares it to other methods.","Visualization of Life Patterns through Deformation of Maps Based on Users' Movement DataThis paper proposes a system for visualizing individual and collective movement within dense geographical contexts, such as cities and urban neighborhoods. Specifically, we describe a method for creating \"spatiotemporal maps\" deformed according to personal movement and stasis. We implement and apply a prototype of our system to demonstrate its effectiveness in revealing patterns of spatiotemporal behavior, and in composing maps that more closely correspond to the node-oriented \"mental maps\" traditionally used by individuals in the act of navigation.","Leave a Comment! An In-Depth Analysis of User Comments on YouTubeUser comments are the most popular but also extremely controversial form of communication on YouTube. Their public image is very poor; users generally expect that most comments will be of little value or even in thorough- ly bad taste. Nevertheless, heaps of comments continue to be posted every day. We propose an explanation for this contradiction in user attitudes and behaviour based on a new comment classification approach which captures salient aspects of YouTube comments. We show that, based on our new classification, we are able to perform very fast lightweight semantic video analysis. In addition, our results indicate that users' video perceptions (Likes and Dislikes) are indeed in- fluenced by the dispersion of valuable and inferior comments.","Proposal of avatar generating method by composition of the portraits made by friendsRecently, the Remote communication through the Internet has been performed actively. And as a remote communication tool, the uses of graphic avatars are especially popular in Japan. However, in many cases, the avatar used on the communication is not mirrored to a user who creates the avatar himself using the application software provided for the remote communication support system. Therefore, the remote friends cannot imagine the appearance of the user from his/her avatar at all. In this research, we will propose a method of creating an avatar. The method shows that the avatar is constructed by merging some portraits, which are created by user's friends. We have developed the prototype systems for creating a portrait and an avatar composed of some portraits. This paper describes methods and systems of creating a portrait and an avatar. We performed some experiments to evaluate the usability of the proposed system and the quality of an avatar created on the proposed system. As an experimental result, it is revealed that the avatar, which is created on the proposed system, tends to be preferred by the user and friends.","Facial Expression Recognition Based on Adaptive Weighted Fusion Histograms ","Angle and position perception for exploration with active touchOver the past few decades the design of robots has gradually improved, allowing them to perform complex tasks in interaction with the world. To behave appropriately, robots need to make perceptual decisions about their environment using their various sensory modalities. Even though robots are being equipped with progressively more accurate and advanced sensors, dealing with uncertainties from the world and their sensory processes remains an unavoidable necessity for autonomous robotics. The challenge is to develop robust methods that allow robots to perceive their environment while managing uncertainty and optimizing their decision making. These methods can be inspired by the way humans and animals actively direct their senses towards locations for reducing uncertainties from perception [1]. For instance, humans not only use their hands and fingers for exploration and feature extraction but also their movements are guided according to what it is being perceived [2]. This behaviour is also present in the animal kingdom, such as rats that actively explore the environment by appropriately moving their whiskers [3].","Finding Rising Stars in Social NetworksThis paper addresses the problem of finding rising stars in academic social networks. Rising stars are the authors which have low research profile in the beginning of their career but may become prominent contributors in the fu- ture. An effort for finding rising stars named PubRank is proposed, which con- siders mutual influence and static ranking of conferences or journals. In this work an improvement of PubRank is proposed by considering authors' contri- bution based mutual influence and dynamic publication venue scores. Experi- mental results show that proposed enhancements are useful and better rising stars are found by our proposed methods in terms of average citations based performance evaluation. Effect of parameter alpha and damping factor is also studied in detail.","Borel determinacy of concurrent gamesJust as traditional games can be represented by trees, so concurrent games can be represented by event structures. We show the determinacy of such concurrent games with Borel sets of configurations as winning conditions, provided they are race-free and bounded-concurrent. Both properties are shown necessary. The determinacy proof proceeds via a reduction to the determinacy of tree games, and the determinacy of these in turn reduces to the determinacy of Gale-Stewart games.","Brain Biomarkers of Neural Efficiency during Cognitive-Motor Performance: Performing under Pressure ","Strategies for Creative Argumentation: Learned from Logs of Innovators Market GameBased on cases of Innovators Market Game (IMG), a gamified workshop where each participant plays the role of an inventor who creates and proposes actions in business, or of a consumer who evaluates the quality of those proposals, we investigated how proposed ideas can be, or can be revised to be, acceptable via the workshop. The analysis in this paper has been conducted on the data of players' log of argumentation - indirectly observable on the game-board where demands of consumers and proposed solutions of inventors are written reflecting the arguments in the workshop. We regard such an argumentation as a process to set the granularity of an argument suitable for putting into action. Based on the original constraint-based representation of classification of conflicts between a consumer and an inventor, that reflects the positions of latent constraints and intentions, we analyzed players' \"written\" log of argumentation in order to learn strategies for manipulating intentions and constraints of participants toward the creation of acceptable solutions.","An Efficient and Dynamic Concept Hierarchy Generation for Data AnonymizationProtecting individual sensitive specific information has become an area of concern over the past one decade. Several techniques like k-anonymity and l-diversity employing generalization/suppression based on concept hierar- chies (CHTS) were proposed in literature. The anonymization effectiveness de- pends on the CHT chosen from the various CHTS possible for a given attribute. This paper proposes a model for constructing dynamic CHT for numerical attributes which can be: 1) generated on the fly for both generaliza- tion/suppression; 2) dynamically adjusted based on a given k. The anonymized data using our method yielded 12% better utility when compared to existing methods. The results obtained after experimentation support our claims and are discussed in the paper.","Very Fast Similarity Queries on Semi-Structured Data from the Web ","Energy Evaluation Model for an Improved Centralized Clustering Hierarchical Algorithm in WSNWireless Sensor Networks (WSN) consists of battery-powered sensor nodes which collect data and route the data to the Base Station. Centralized Cluster-based routing protocols efficiently utilize limited energy of the nodes by selecting Cluster Heads (CHs) in each round. Selection of CHs and Cluster formation is performed by the Base Station. In each round, nodes transmit their location information and their residual energy to the Base Station. This operation is a considerable burden on these resource hungry sensor nodes. In this paper we propose a scheme whereby a small number of High-Energy nodes gather location information and residual energy status of the sensing nodes and transmit to the Base Station. This scheme eliminates CH advertisement phase in order to conserve energy. Based on the energy consumption by various types of nodes, we have derived an energy model for our algorithm which depicts the total energy consumption in the network.","Semantic annotation of the CEREALAB database by the AGROVOC linked datasetThe objective of the CEREALAB database is to help the breeders in choosing molecular markers associated to the most important traits. Phenotypic and genotypic data obtained from the integration of open source databases with the data obtained by the CEREALAB project are made available to the users. The CEREALAB database has been and is currently extensively used within the frame of the CEREALAB project.#R##N##R##N#This paper presents the main achievements and the ongoing research to annotate the CEREALAB database and to publish it in the Linking Open Data network, in order to facilitate breeders and geneticists in searching and exploiting linked agricultural resources. One of the main focus of this paper is to discuss the use of the AGROVOC Linked Dataset both to annotate the CEREALAB schema and to discover schema-level mappings among the CEREALAB Dataset and other resources of the Linking Open Data network, such as NALT, the National Agricultural Library Thesaurus, and DBpedia.","Using vectorization and parallelization to improve the application of the APH hamiltonian in reactive scatteringIn time-dependent quantum reactive scattering calculations, it is important to quickly and accurately apply the Hamiltonian, as this must be performed at every time-step. We present a method of separating the Hamiltonian for adiabatically-adjusting principal axes hyperspherical (APH) coordinates into its constituent parts, vectorizing these to reduce computational steps required in matrix multiplications, and finally parallelizing the application to reduce the time required to perform the calculation. This reduction in time is achieved with no modification of results for triatomic systems of either lithium or hydrogen.","An AHP-QFD Integrated Approach to Meet Three Dimensional Environmental Value Requirements in Sustainable E-Business Modelling ","Structured summarization for news eventsHelping users to understand the news is an acute problem nowadays as the users are struggling to keep up with tremendous amount of information published every day in the Internet. In this research, we focus on modelling the content of news events by their semantic relations with other events, and generating structured summarization.","The Development and Evaluation of an Interactive System for Age Related Musculoskeletal Rehabilitation in the Home ","Detection of nonverbal vocalizations using Gaussian Mixture Models: looking for fillers and laughter in conversational speechIn this paper, we analyze acoustic profiles of fillers (i.e. filled pauses, FPs) and laughter with the aim to automatically localize these nonverbal vocalizations in a stream of audio. Among other features, we use voice quality features to capture the distinctive production modes of laughter and spectral similarity measures to capture the stability of the oral tract that is characteristic for FPs. Classification experiments with Gaussian Mixture Models and various sets of features are performed. We find that Mel-Frequency Cepstrum Coefficients are performing relatively well in comparison to other features for both FPs and laughter. In order to address the large variation in the frame-wise decision scores (e.g., log-likelihood ratios) observed in sequences of frames we apply a median filter to these scores, which yields large performance improvements. Our analyses and results are presented within the framework of this year\u2019s Interspeech Computational Paralinguistics sub-Challenge on Social Signals.","How to decompose a binary matrix into three hv -convex polyominoesGiven a binary matrix, deciding wether it can be decomposed into three hv-convex matrices is an $\\cal NP$-complete problem, whereas its decomposition into two hv-convex matrices or two hv-polyominoes can be performed in polynomial time. In this paper we give a polynomial time algorithm that decomposes a binary matrix into three hv-polyominoes, if such a decomposition exists. These problems are motivated by the Intensity Modulated Radiation Therapy (IMRT).","Square root and division elimination in PVSIn this paper we present a new strategy for PVS that implements a square root and division elimination in order to use automatic arithmetic strategies that were not able to deal with these operations in the first place. This strategy relies on a PVS formalization of the square root and division elimination and deep embedding of PVS expressions inside PVS. Therefore using computational reflection and symbolic computation we are able to automatically transform expressions into division and square root free ones before using these decision procedures.","A multi-agent approach to energy-aware wireless sensor networks organizationWireless Sensor Networks when deployed in inaccessible or remote areas require sensing and communication algorithms that minimise energy consumption. This is needed to reduce battery replacement costs. At the same time, the information transmitted to the sink has to be good enough in order to make timely decisions on the environmental hazards being monitored. Sensor algorithms have to thus balance quality of information with energy consumption. We introduce in this paper an algorithm that uses multiagent co-ordination technology to organize the sensors in coalitions that share the burden of sensing and communicating. We provide experimental evidence of a good balance between information quality and energy consumption on a simulated river pollution phenomenon.","Supporting Requirements Elicitation PracticesIn this paper, we examine the practices in requirements elicitation activities from the perspective of a developer of software projects. By doing so, we want to contribute to a better understanding of how the main activities between stakeholders can be supported by IT, particularly social software. We have interviewed six key persons from five different software projects and identified the potential roles of social software to improve in five main activities of requirements elicitation. We present these critical points in the context of the cases and discuss them across the cases.","Decidability of model checking non-uniform artifact-centric quantified interpreted systemsArtifact-Centric Systems are a novel paradigm in service-oriented computing. In the present contribution we show that model checking bounded, non-uniform artifact-centric systems is undecidable. We provide a partial model checking procedure for artifact-centric systems against the universal fragment of a first-order version of the logic CTL. We obtain this result by introducing a counterpart semantics and developing an abstraction methodology operating on these structures. This enables us to generate finite abstractions of infinite artifact-centric systems, hence perform verification on abstract models.","Unifying the semantics of modular extensions of petri netsModularity is a mandatory principle to apply Petri nets to real world-sized systems. Modular extensions of Petri nets allow to create complex models by combining smaller entities. They facilitate the modeling and verification of large systems by applying a divide and conquer approach and promoting reuse. Modularity includes a wide range of notions such as encapsulation, hierarchy and instantiation. Over the years, Petri nets have been extended to include these mechanisms in many different ways. The heterogeneity of such extensions and their definitions makes it difficult to reason about their common features at a general level. We propose in this article an approach to standardize the semantics of modular Petri nets formalisms, with the objective of gathering even the most complex modular features from the literature. This is achieved with a new Petri nets formalism, called the LLAMAS Language for Advanced Modular Algebraic Nets (LLAMAS). We focus principally on the composition mechanism of LLAMAS, while introducing the rest of the language with an example. Our approach has two positive outcomes. First, the definition of new formalisms is facilitated, by providing common ground for the definition of their semantics. Second, it is possible to reason at a general level on the most advanced verification techniques, such as the recent advances in the domain of decision diagrams.","Sick patients have more data: the non-random completeness of electronic health records.As interest in the reuse of electronic health record (EHR) data for research purposes grows, so too does awareness of the significant data quality problems in these non-traditional datasets. In the past, however, little attention has been paid to whether poor data quality merely introduces noise into EHR-derived datasets, or if there is potential for the creation of spurious signals and bias. In this study we use EHR data to demonstrate a statistically significant relationship between EHR completeness and patient health status, indicating that records with more data are likely to be more representative of sick patients than healthy ones, and therefore may not reflect the broader population found within the EHR.","Keiran J. Dunne and Elena S. Dunne (eds.): Translation and localization project management: the art of the possible ","Search for sparse active inputs: a reviewThe theory of Compressed Sensing (highly popular in recent years) has a close relative that was developed around thirty years earlier and has been almost forgotten since --- the design of screening experiments. For both problems, the main assumption is sparsity of active inputs, and the fundamental feature in both theories is the threshold phenomenon: reliable recovery of sparse active inputs is possible when the rate of design is less than the so-called capacity threshold, and impossible with higher rates.#R##N##R##N#Another close relative of both theories is multi-access information transmission. We survey a collection of tight and almost tight screening capacity bounds for both adaptive and non-adaptive strategies which correspond to either having or not having feedback in information transmission. These bounds are inspired by results from multi-access capacity theory. We also compare these bounds with the simulated performance of two analysis methods: (i) linear programming relaxation methods akin to basis pursuit used in compressed sensing, and (ii) greedy methods of low complexity for both non-adaptive and adaptive strategies.","Incomplete Transition Complexity of Some Basic OperationsY. Gao et al. studied for the first time the transition com- plexity of Boolean operations on regular languages based on not nec- essarily complete DFAs. For the intersection and the complementation, tight bounds were presented, but for the union operation the upper and lower bounds differ by a factor of two. In this paper we continue this study by giving tight upper bounds for the concatenation, the Kleene star and the reversal operations. We also give a new tight upper bound for the transition complexity of the union, which refutes the conjecture presented by Y. Gao, et al.","Access Flow Monitoring Methods ","Computing Similarity Dependencies with Pattern StructuresFunctional dependencies provide valuable knowledge on the relations between the attributes of a data table. To extend their use, gen- eralizations have been proposed, among which purity and approximate dependencies. After discussing those generalizations, we provide an al- ternative definition, the similarity dependencies, to handle a similarity relation between data-values, hence un-crisping the basic definition of functional dependencies. This work is rooted in formal concept analysis, and we show that similarity dependencies can be easily characterized and computed with pattern structures.","Content-based chunk placement scheme for decentralized deduplication on distributed file systemsThe rapid growth of data size causes several problems such as storage limitation and increment of data management cost. In order to store and manage massive data, Distributed File System (DFS) is widely used. Furthermore, in order to reduce the volume of storage, data deduplication schemes are being extensively studied. The data deduplication increases the available storage capacity by eliminating duplicated data. However, deduplication process causes performance overhead such as disk I/O. In this paper, we propose a content-based chunk placement scheme to increase deduplication rate on the DFS. To avoid performance overhead caused by deduplication process, we use lessfs in each chunk server. With our design, our system performs decentralized deduplication process in each chunk server. Moreover, we use consistent hashing for chunk allocation and failure recovery. Our experimental results show that the proposed system reduces the storage space by 60% than the system without consistent hashing.","Distributed relational temporal difference learningRelational representations have great potential for rapidly generalizing learned knowledge in large Markov decision processes such as multi-agent problems. In this work, we introduce relational temporal difference learning for the distributed case where the communication links among agents are dynamic. Thus no critical components of the system should reside in any one agent. Relational generalization among agents' learning is achieved through the use of partially bound relational features and a message passing scheme. We further describe how the proposed concepts can be applied to distributed reinforcement learning methods that use value functions. Experiments were conducted on soccer and real-time strategy game domains with dynamic communication. Results show that our methods improve goal achievement in online learning with a greatly decreased number of parameters to learn when compared with existing distributed learning methods.","Linear Bayesian reinforcement learningThis paper proposes a simple linear Bayesian approach to reinforcement learning. We show that with an appropriate basis, a Bayesian linear Gaussian model is sufficient for accurately estimating the system dynamics, and in particular when we allow for correlated noise. Policies are estimated by first sampling a transition model from the current posterior, and then performing approximate dynamic programming on the sampled model. This form of approximate Thompson sampling results in good exploration in unknown environments. The approach can also be seen as a Bayesian generalisation of least-squares policy iteration, where the empirical transition matrix is replaced with a sample from the posterior.","Declarative Fuzzy Linguistic Queries on Relational DatabasesIn this paper we propose a declarative method to formulate fuzzy linguistic queries on Relational Database Management Systems. That is, flexible queries containing linguistic terms associate to the attributes of a table of a relational database. To this end, we adapt techniques originate from a proximity-based Logic Programming Language called Bousi~Prolog.","Training an articulatory synthesizer with continuous acoustic dataThis paper reports preliminary results of our effort to address the acoustic-to-articulatory inversion problem. We tested an approach that simulates speech production acquisition as a distal learning task, with acoustic signals of natural utterances in the form of MFCC as input, VocalTractLab \u2014 a 3D articulatory synthesizer controlled by target approximation models as the learner, and stochastic gradient descent as the training method. The approach was tested on a number of natural utterances, and the results were highly encouraging.","Foreground Segmentation from Occlusions Using Structure and Motion RecoveryThe segmentation of foreground objects in camera images is a fun- damental step in many computer vision applications. For visual effect creation, the foreground segmentation is required for the integration of virtual objects be- tween scene elements. On the other hand, camera and scene estimation is needed to integrate the objects perspectively correct into the video. In this paper, discontinued feature tracks are used to detect occlusions. If these features reappear after their occlusion, they are connected to the correct previ- ously discontinued trajectory during sequential camera and scene estimation. The combination of optical flow for features in consecutive frames and SIFT match- ing for the wide baseline feature connection provides accurate and stable feature tracking. The knowledge of occluded parts of a connected feature track is used to feed an efficient segmentation algorithm which crops the foreground image regions automatically. The presented graph cut based segmentation uses a graph contraction technique to minimize the computational expense. The presented application in the integration of virtual objects into video. For this application, the accurate estimation of camera and scene is crucial. The seg- mentation is used for the automatic occlusion of the integrated objects with fore- ground scene content. Demonstrations show very realistic results.","Evaluating novice and expert users on handheld video retrieval systemsContent-based video retrieval systems have been widely as- sociated with desktop environments that are largely complex in nature, targeting expert users and often require complex queries. Due to this complexity, interaction with these systems can be a challenge for reg- ular \"novice\" users. In recent years, a shift can be observed from this traditional desktop environment to that of handheld devices, which re- quires a different approach to interacting with the user. In this paper, we evaluate the performance of a handheld content-based video retrieval system on both expert and novice users. We show that with this type of device, a simple and intuitive interface, which incorporates the prin- ciples of content-based systems, though hidden from the user, attains the same accuracy for both novice and desktop users when faced with complex information retrieval tasks. We describe an experiment which utilises the Apple iPad as our handheld medium in which both a group of experts and novice users run the interactive experiments from the 2010 TRECVid Known-Item Search task. The results indicate that a carefully defined interface can equalise the performance of both novice and expert users.","Constraint Specification and Test Generation for OSEK/VDX-Based Operating SystemsThis work suggests a method for systematically constructing an environment model for automotive operating systems compliant with the OSEK/VDX international standard by introducing a constraint specification language, OSEK_CSL, and defining its underlying formal models. OSEK_CSL is designed for specifying constraints of OSEK/VDX using a pre-defined set of constraint types identified from the OSEK/VDX standard. Each constraint specified in OSEK_CSL is interpreted as a context-free language and is converted into push-down automata using NuSMV, which allows automated test sequence generation using LTL model checking. This approach supports selective applications of constraints and thus is able to control the \"degree\" of test sequences with respect to test purposes. An application of the suggested approach demonstrates its effectiveness in identifying safety problems.","An Attention Level Monitoring and Alarming System for the Driver Fatigue in the Pervasive EnvironmentIn recently years, driver fatigue detecting system has gained increasing attentions in the area of public security. Researchers have succeeded in applying the EEG signals to accurately detect individuals fatigue state in sustained attention tasks. However, these studies were performed under laboratory-oriented configurations using tethered, ponderous EEG equipment, which are not feasible to develop the fatigue detecting system in the real environment. This study focused on developing a portable attention level monitoring and alarming (ALMA) system, featuring a mobile NeuroSky MindSet and an android pad based real-time EEG processing platform, for the driver fatigue in the pervasive environment. A brain feature rule which can represent the brain gradual process from focus state to the fatigue state has been formulated. We evaluated the ability of attention level of the system in the simulated driving cockpit and demonstrated that the system can classify the subjects attention level in accordance with the rule in the real time.","Environmental data for the planning of off-shore wind parks from the EnerGEO Platform of Integrated Assessment (PIA)The EU-sponsored EnerGEO project aims at providing decision makers with a modelling platform to assess the environmental impacts of different sources of renewable energy. One of the pillars of the project is the Wind Energy Pilot, addressing the effects of offshore wind parks on air pollution and energy use. The methods used in the pilot and the underlying environmental databases are integrated into a WebGIS client tool and made available to the public. This paper is dedicated to describing the environmental databases and supporting data incorporated in the client tool. A 27-km resolution, 11-year wind database is created using the WRF model. The wind database is used to assess the wind climate in the north-west Atlantic region and to derive the potential power output from offshore wind parks. Auxiliary data concerning water depth, distance to shore and distance to the nearest suitable port are created to aid the planning and maintenance phases. Seasonal workability conditions are assessed using a 20-year wave database. The distance at which future wind parks should be placed to exhibit different wind climates is investigated.","A Genetic Algorithm Approach for the Multidimensional Two-Way Number Partitioning ProblemThis paper addresses the problem of partitioning a set of vectors into two subsets such that the sums per every coordinate should be exactly or approximately equal. This problem, introduced by Kojic [ 8 ], is called the multidimensional two-way number partitioning problem MDTWNPP and generalizes the classical two-way number partitioning problem. We propose an efficient genetic algorithm based heuristic for solving the multidimensional two-way number partitioning problem. The performances of our genetic algorithm have been compared with the existing numerical results obtained by CPLEX based on an integer linear programming formulation of the problem. The obtained preliminary results, in the case of medium and large instances, reveal that our proposed methodology performs very well in terms of both quality of the solutions and the computational times compared with the previous method of solving the MDTWNPP.","Enhancing Social Presence in Augmented Reality-Based Telecommunication SystemThe main contribution of this paper is to examine the new method of augmented reality from a telecommunication point of view. Then, we tried to present the fact that the concept of social presence is an important cue for developing telecommunication system based on augmented reality technology. The evaluation was conducted with 32 participants. According to the questionnaires results, the augmented reality based telecommunication system was better than 2 dimensional based display telecommunication system. To develop our concept, we should closely analyze communication patterns and improve our augmented reality based communication system.","Mining Top-k Frequent/Regular Patterns Based on User-Given Trade-Off between Frequency and Regularity ","A Scalable Spam Filtering ArchitectureThe proposed spam filtering architecture for MTA servers is a component based architecture that allows distributed processing and centralized knowledge. This architecture allows heterogeneous systems to coexist and benefit from a centralized knowledge source and filtering rules. MTA servers in the infrastructure contribute to a common knowledge, allowing for a more rational resource usage. The architecture is fully scalable, ranging from all-in-one system with minimal components instances, to multiple components instances distributed across multiple systems. Filtering rules can be implemented as independent modules that can be added, removed or modified without impact on MTA servers operation. A proof-of-concept solution was developed. Most of spam is filtered due to a grey-listing effect from the architecture itself. Using simple filters as Domain Name System black and white lists, and Sender Policy Framework validation, it is possible to guarantee a spam filtering effective, efficient and virtually without false positives.","Global Registration of Ultrasound to MRI Using the LC2 Metric for Enabling Neurosurgical GuidanceAutomatic and robust registration of pre-operative magnetic resonance imaging (MRI) and intra-operative ultrasound (US) is essen- tial to neurosurgery. We reformulate and extend an approach which uses a Linear Correlation of Linear Combination (LC 2 )-based similarity met- ric, yielding a novel algorithm which allows for fully automatic US-MRI registration in the matter of seconds. It is invariant with respect to the unknown and locally varying relationship between US image intensities and both MRI intensity and its gradient. The overall method based on this both recovers global rigid alignment, as well as the parameters of a free-form-deformation (FFD) model. The algorithm is evaluated on 14 clinical neurosurgical cases with tumors, with an average landmark-based error of 2.52 mm for the rigid transformation. In addition, we systemat- ically study the accuracy, precision, and capture range of the algorithm, as well as its sensitivity to different choices of parameters.","Let the Right One in: Discovering and Mitigating Permission GapsPermissions that are granted but unused, or permission gaps, are needless risks to systems and should be removed expeditiously. More insidiously, granted permissions may not always be revoked when they are no longer required. In practice, identifying permission gaps can be hard since another reference point besides granted permissions is usually unavailable. Therefore, we argue that permission gaps often must be estimated. We propose DeGap, a framework that uses standard system logs as a reference point and a common logic for estimating the gaps in various services. DeGap identified potentially overly relaxed SSH server configurations, incorrect permissions on sensitive files, and dormant user groups. Just discovering permission gaps may be insufficient; administrators need to know how they can be fixed. DeGap can also identify changes to service configurations towards reducing permission gaps.","What Makes an Instance Difficult for Black-Box 0\u20131 Evolutionary Multiobjective Optimizers? ","HW/SW tradeoffs for dynamic message scheduling in controller area network (CAN)Designers of distributed embedded control systems face many design challenges related to change of system configuration, functionality and number of participating computing nodes, which affect the usage of the communication bus. The concept of self-adaptivity of participating nodes plays an important role in reducing design effort while guaranteeing high system performance. The dynamic offset adaptation algorithm (DynOAA) for adaptive message scheduling reduces average message response times in CAN-based systems with high bus loads. This technique has in previous work proven its benefit in simulation. However, it is still necessary to test the algorithm in a real physical environment. In this paper, we use FPGAs with their capability of performing rapid system prototyping. Our design space exploration shows that both pure software and pure hardware implementations are possible. However, parts of the software implementation require a significant amount of computation. As a result a mixed HW/SW implementation is proposed.","FedSearch: Efficiently Combining Structured Queries and Full-Text Search in a SPARQL FederationCombining structured queries with full-text search provides a powerful means to access distributed linked data. However, executing hybrid search queries in a federation of multiple data sources presents a number of challenges due to data source heterogeneity and lack of statistical data about keyword selectivity. To address these challenges, we present FedSearch \u0097 a novel hybrid query engine based on the SPARQL federation framework FedX. We extend the SPARQL algebra to incorporate keyword search clauses as first-class citizens and apply novel optimization techniques to improve the query processing efficiency while maintaining a meaningful ranking of results. By performing on-the-fly adaptation of the query execution plan and intelligent grouping of query clauses, we are able to reduce significantly the communication costs making our approach suitable for top-k hybrid search across multiple data sources. In experiments we demonstrate that our optimization techniques can lead to a substantial performance improvement, reducing the execution time of hybrid queries by more than an order of magnitude.","A Contingent Model of Project Organization and Management ","Incremental language inclusion checking for networks of timed automataChecking the language inclusion between two models is a fundamental problem arising in application areas such as formal verification or refinement in top-down design. We propose an incremental procedure for checking the language inclusion between two real-time specifications, modeled as networks of deterministic timed automata, where the two specifications are equivalent up to one component. For such classes of systems we aim to improve the efficiency of the language inclusion check by exploiting the compositional nature of the problem and avoiding the explicit parallel composition of the timed automata in the network. We first develop a generic procedure that gives freedom to specific implementation choices. We then propose an instantiation of the procedure that is based on bounded model checking techniques. We illustrate the application of our approach in a case study and discuss promising experimental results.","Visual attention computational model using gabor decomposition and 2d entropyVisual attention is an important mechanism as it can be applied to many branches of computer vision and image processing such as segmentation, compression, detection, tracking and so on. Based on both capabilities and defects of existing models, the paper proposes a computational saliency-oriented model from the perspective of frequency domain. A saliency map can be generated by two main steps: firstly Gabor wavelet decomposition of the input image at certain levels is used to produce the feature components, and then these components are selected and fused in the sense of 2D entropy. The proposed algorithm outperforms most of state-of-the-art algorithms at human fixation prediction for both psychological patterns and natural images including salient objects with arbitrary sizes. Beyond that, biological plausibility of Gabor filter makes our approach more reliable and adaptive to various stimuli.","Toward living tactile sensorsThe authors aim to realize a \"Cell Tactile Sensor\" which is integrated tactile receptors built by cultured cells. We regard the cells cultured on the PDMS membrane as the force receptors. We here report on interesting experimental results as follows: at first, we designed the positions of cells by self-organization which is due to mechanical stimulations; secondly, we visualized the tactile information of cell tactile sensors by observing of the Ca2+ induced from mechanical stimulations. Therefore, a new tactile sensor which has environment adaptability is developed.","Learning to Parse Natural Language Commands to a Robot Control System ","Negobot: A Conversational Agent Based on Game Theory for the Detection of Paedophile Behaviour ","Analysis of DNA Barcode Sequences Using Neural Gas and Spectral Representation ","On the Stability of Ranks to Low Image Quality in Biometric Identification SystemsThe goal of a biometric identification system is to determine the identity of the input biometric probe. This is accomplished using a matcher which compares the input probe data against each labeled biometric data present in the gallery database. The output is a set of similarity scores that are ranked in decreasing order. The identity of the gallery entry corresponding to the highest similarity score (i.e., rank 1) is associated with that of the probe. In multibiometric systems, the out- puts of multiple biometric matchers are combined. Such a combination, or fusion, can be accomplished at the score level or rank level (apart from other levels of fusion). In the literature, rank is believed to be a stable statistic. However, this belief has not been experimentally demon- strated. The contribution of this paper is to investigate the stability of ranks to the image quality degradation in both unimodal and mul- timodal scenarios. Experiments were carried out using two databases: 1) West Virginia University (WVU) dataset, composed of four finger- prints per subject for 240 subjects, 2) Face and Ocular Challenge Series (FOCS) collection, composed of three frontal faces per subject for 407 subjects. Experimental results show that, in a unimodal scenario when dealing with low quality data, ranks are more stable than scores. How- ever, such a rank stability is not verified when fusing multiple matchers. Experiments demonstrate that, in the presence of low quality data, per- formance achieved by score-level fusion is better than that one achieved by rank-level fusion.","A real-time rendering technique for view-dependent stereoscopy based on face trackingIn our research, we propose and implement a virtual reality system with the common and widely used devices such as 3D screen and digital webcam. Our approach involves the combination of 3D stereoscopic rendering and face tracking technique in order to render a stereo scene based on the position of the viewer. Our approach is to calculate the offset values of face position to assign to the virtual camera position relatively. We employ a technique to change the typical symmetric frustum into asymmetric to achieve the head-coupled perspective. With our system, the rendered scene observed by human eyes remains realistic and the viewport can be seen as the physical window in the real environment. Therefore, the right perspective can be maintained regardless of viewer position.","Challenges in Mobile Teaching and Safety \u2013 A Case Study ","Paintrix: Color Up Your Life!Train stations, shopping malls and airports: all public places where we spend a lot of time, waiting for the train, for our friends and for the gate to open. While waiting, we get bored and we would like to entertain ourselves in order to kill time. The first thing that comes to our minds is playing a game or socializing using our smartphone. People around you are doing the exact same thing. Wouldn't it be great if you could play a game with those people, a game which requires collaboration and interaction with your surroundings?#R##N##R##N#This is exactly where Paintrix comes into play: gather people, form two teams and let them collaborate and compete at the same time. Teams have to solve the same puzzle against the clock. Be faster than your opposing team to win! How does this work?","Anytime Contract SearchHeuristic search is a fundamental problem solving paradigm in artificial intelligence.Weaddresstheproblemofdevelopingheuristicsearchalgorithmswhere intermediate results are sought at intervals of time which may or may not be known apriori.Inthispaper,weproposeanefficientanytimealgorithmcalledAnytimeCon- tract Search (based on the contract search framework) which incrementally explores the state-space with the given contracts (intervals of reporting). The algorithm works without restarting and dynamically adapts for the next iteration based on the current contract and the currently explored state-space. The proposed method is complete on bounded graphs. Experimental results with different contract sequences on the Sliding-tilePuzzleProblemandtheTravellingSalespersonProblem(TSP)showthat Anytime Contract Search outperforms some of the state-of-the art anytime search algorithms that are oblivious to the given contracts. Also, the non-parametric version of the proposed algorithm which is oblivious of the reporting intervals (making it an anytime algorithm) performs well compared to many available schemes.","A study for personal use of the interactive large public displayIn recent years, \"digital signage\" has been used for large screen displays in public spaces, such as stations or shopping malls. Some display terminals have used digital signage to dispatch information in an interactive format; thus, a user touches an electronic screen to obtain information, such as a map, store location, or advertisement, and receives it freely. Public systems commonly adopt user interfaces with touch panels on display terminals to facilitate interactive information exchange.#R##N##R##N#On the other hand, the popularity of personal computers and the explosive growth of the Internet now make it possible for users to handle a wide variety of information--regardless of location or time of day. Furthermore, users communicate not only information that may be seen by others but sometimes information not intended to be seen by others. In other words, even information of a highly confidential nature can be accessed anywhere and anytime. The information dissemination which cared about this point is desirable.#R##N##R##N#In this research, therefore, we will study information security and privacy as it pertains to large touch screens in public places. The goal of this research is to identify the variables associated with user safety when interfacing on large touch screens in public venues; additionally, we will propose a method for designing public space so that users can communicate interactively with reassurance of confidentiality.","Enhancing Flexible Querying Using Criterion TreesTraditional query languages like SQL and OQL use a so-called WHERE clause to extract only those database records that fulfil a specified condition. Conditions can be simple or be composed of conditions that are connected through logical operators. Flexible querying approaches, among others, generalized this concept by allowing more flexible user preferences as well in the specification of the simple conditions through the use of fuzzy sets, as in the specification of the logical aggregation through the use of weights. In this paper, we study and propose a new technique to further enhance the use of weights by working with so-called criterion trees. Next to better facilities for specifying flexible queries, criterion trees also allow for a more general aggregation approach. In the paper we illustrate and discuss how LSP basic aggregation operators can be used in criterion trees.","Neurophysiological Estimation of Team Psychological MetricsThe goal of this study was to explore the feasibility of continuous neurophysiological assessment of different psychological aspects of a team process. The teams consisted of the MBA students who discussed and at- tempted to solve a case problem dealing with corporate social responsibility (i.e. child labor). At the end of the team process, two types of psychological metrics (i.e., engagement and leadership) were assessed by team members, both at the individual and team levels. These metrics showed significant correlations with the team performance scores derived by four trained coders. Two of them rated the teams' solutions in terms of effective problem solving, decisiveness, and creativity. The other two coders rated the level of moral reasoning dis- played in the solutions. The psychological metrics were then estimated based on quantitative electroencephalography (qEEG). Different modeling techniques, such as linear and quadratic discriminant function analysis (DFA) and linear re- gression were applied to the processed qEEG data. The models were evaluated through auto-validation, but also through cross-validation to test stability of the models in the team-independent training setting. The experimental results sug- gested that qEEG could be effectively used in the team settings as an estimator of individual and team engagement, as well as the leadership qualities shown by team members. Our findings suggest that qEEG can help in understanding, and perhaps building, optimal teams and team processes.","Eyewitness Face Sketch Recognition Based on Two-Step Bias Modeling ","Multimodal Human-Robot Interface with Gesture-Based Virtual Collaboration ","A Syntactic Approach to PredictionA central question in the empirical sciences is; given a body of data how do we best attempt to make predictions? There are subtle differences between current approaches which include Minimum Message Length (MML) and Solomonoff's theory of induction (24). The nature of hypothesis spaces is explored and we observe a correla- tion between the complexity of a function and the frequency with which it is represented. There is not a single best hypothesis, as suggested by Occam's razor (which says prefer the simplest), but as etof functionally equivalent hypotheses. One set of hypotheses is preferred over another set because it is larger, thus giving the impression simpler functions gen- eralize better. The probabilistic weighting of one set of hypotheses is given by the relative size of its equivalence class. We justify Occam's razor by a counting argument over the hypothesis space. Occam's razor contrasts with the No Free Lunch theorems which state that it impossible for one machine learning algorithm to generalize better than any other. No Free Lunch theorems assume a distribution over functions, whereas Occam's razor assumes a distribution over programs.","AppendicitisScan Tool: A New Tool for the Efficient Classification of Childhood Abdominal Pain Clinical Cases Using Machine Learning ToolsThe abdominal pain is considered a very common disease during the childhood. One of the main diseases which are considered nowadays as the cause of childhood abdominal pain is the appendicitis which is very hard to be diagnosed in children. Moreover, even when it is diagnosed the doctors should decide about the type of appendicitis and take a crucial decision about the treatment (surgeon or medication). For these reasons, researchers in the last decade have focused on developing machine learning models to predict appen- dicitis from childhood abdominal pain clinical cases. However, most of these methods are limited to low performance and to using diagnostic factors which are not generally available. Moreover, none of them is available as a tool which could be used in practice. For all these reasons, we developed and applied a new ensemble methodology which combines the results of three machine learn- ing models: Artificial Neural Networks, Support Vector Machines and Random Forests. The implementation is available as a standalone tool named Appendici- tisScan Tool.","A Multi-Attribute Decision Making Model Based on Distance from Decision Maker's PreferencesThis paper proposes a new multi-attribute ranking procedure based on distance from decision-maker preferences. This method has two phases. In the first phase, the decision maker is asked to define the preferred performance for each attribute. In the second phase, Weighted Sum method and new distance-based normalization procedure are used to determine the overall performance rating of alternatives.","An Approach for Topic Trend Detection ","Lean Software Development \u2013 What Exactly Are We Talking About?As the Software Engineering landscape continues to evolve and new paradigms are introduced, there can be a tendency for both industry and academia to enthusiastically embrace new approaches and march forward under whatever banner conventional wisdom has decided to adopt. One such banner is Lean Software Development, a paradigm that continues to see a growth in interest driven by the need for cost reductions within industry. The term lean attracts the attention of business, but precisely how it applies within software development is still being debated. In addition, its relationship to the better understood agile methodologies is also a topic for debate. Having been drawn into this research area ourselves, we present here a review of Lean Software Development and try to distil out for the reader some understanding of this somewhat undefined topic. We conclude with some thoughts on where this subject might go to from here.","Designing Business Models for Platform as a Service: Towards a Design Theory. ","ASSISI: mixing animals with robots in a hybrid societyThis paper describes the newly started EU-funded FP7 project ASSISI|bf, which deals with mixed societies: A honeybee society integrated with a group of stationary and interacting autonomous robotic nodes and a group of fish integrated in a society of autonomous moving robots.","Towards the Electronic Publishing: An Assessment of Indian Publishing Mediahis paper describes the contribution of Indian publishing media in e-publishing. It outlines the range of publication such as subject, languages, Indian cities and publishing services into electronic publishing. Publishing portal of PublishersGlobal directory was extracted to find out the existing situation of leading publishers in electronic publishing in India. It is concluded that for e-publishing, publishers needs to make serious commitment to invest and develop the indigenous e-publishing market.","Modulating fusion in the McGurk effect by binding processes and contextual noise.In a series of experiments we showed that the McGurk effect may be modulated by context: applying incoherent auditory and visual material before an audiovisual target made of an audio \"ba\" and a video \"ga\" significantly decreases the McGurk effect. We interpreted this as showing the existence of an audiovisual \"binding\" stage controlling the fusion process. Incoherence would produce \"unbinding\" and result in decreasing the weight of the visual input in the fusion process. In this study, we further explore this binding stage around two experiments. Firstly we test the \"rebinding\" process, by presenting a short period of either coherent material or silence after the incoherent \"unbinding\" context. We show that coherence provides \"rebinding\", resulting in a recovery of the McGurk effect. In contrary, silence provides no rebinding and hence \"freezes\" the unbinding process, resulting in no recovery of the McGurk effect. Capitalizing on this result, in a second experiment including an incoherent unbinding context followed by a coherent rebinding context before the target, we add noise all over the contextual period, though not in the McGurk target. It appears that noise uniformly increases the rate of McGurk responses compared to the silent condition. This suggests that contextual noise increases the weight of the visual input in fusion, even if there is no noise within the target stimulus where fusion is applied. We conclude on the role of audiovisual coherence and noise in the binding process, in the framework of audiovisual speech scene analysis and the cocktail party effect.","Eigenfaces, Fisherfaces, Laplacianfaces, Marginfaces \u2013 How to Face the Face Verification Task ","Estimating the time between Twitter messages and future eventsWe describe and test three methods to estimate the remaining time between a series of microtexts (tweets) and the future event they refer to via a hashtag. Our system generates hourly forecasts. A linear and a local regression-based approach are applied to map hourly clusters of tweets directly onto time-to-event. To take changes over time into account, we develop a novel time series analysis approach that fi rst derives word frequency time series from sets of tweets and then performs local regression to predict time-to-event from nearest-neighbor time series. We train and test on a single type of event, Dutch premier league football matches. Our results indicate that in an 'early' stage, four days or more before the event, the time series analysis produces time-to-event predictions that are about one day off ; closer to the event, local regression attains a similar accuracy. Local regression also outperforms both mean and#N#median-based baselines, but on average none of the tested system has a consistently strong performance through time.","Video target tracking based on a new adaptive particle swarm optimization particle filterTo improve accuracy and robustness of video target tracking, a tracking algorithm based on a new adaptive particle swarm optimization particle filter (NAPSOPF) is proposed. A novel inertia weight generating strategy is proposed to balance adaptively the global and local searching ability of the algorithm. This strategy can adjust the particle search range to adapt to different motion levels. The possible position of moving target in the first frame image is predicted by particle filter. Then the proposed NAPSO is utilized to search the smallest Bhattacharyya distance which is most similar to the target template. As a result, the algorithm can reduce the search for matching and improve real-time performance. Experimental results show that the proposed algorithm has a good tracking accuracy and real-time in case of occlusions and fast moving target in video target tracking.","Machine Learning with Known Input Data Uncertainty Measure ","Genetic Optimization of Type-2 Fuzzy Weight Adjustment for Backpropagation in Ensemble Neural Network ","Developing Organizational Agility through IT Capability and KM Capability: The Moderating Effects of Organizational Climate. ","On Graph Entropy Measures for Knowledge Discovery from Publication Network Data ","A Prototype Implementation of OpenMP Task Dependency SupportOpenMP 3.0 introduced the concept of asynchronous tasks, independent units of work that may be dynamically created and sched- uled. Task synchronization is accomplished via the insertion of taskwait and barrier constructs. However, the inappropriate use of these con- structs may incur significant overhead owing to global synchronizations for specific algorithms on large platforms. The performance of such al- gorithms may benefit substantially if a mechanism of specifying finer gained point-to-point synchronization between tasks is available. In this paper we present extensions to the current OpenMP task directive to enable the specification of dependencies among tasks. A task waits only until the explicit dependencies as specified by the programmer are satis- fied, thereby enabling support for a dataflow model within OpenMP. We evaluate the extensions implemented in the OpenUH OpenMP compiler using LU decomposition and Smith-Waterman algorithms. By applying the extensions to the two algorithms, we demonstrate significant perfor- mance improvement over the standard tasking versions. When comparing our results with those obtained using related dataflow models - OmpSs and QUARK, we observed that the versions using our task extensions delivered an average speedup of 2-6x.","Applying Threshold SMOTE Algoritwith Attribute Bagging to Imbalanced DatasetsSynthetic minority over-sampling technique SMOTE is an effective over-sampling technique and specifically designed for learning from imbalanced data sets. However, in the process of synthetic sample generation, SMOTE is of some blindness. This paper proposes a novel approach for imbalanced problem, based on a combination of the Threshold SMOTE TSMOTE and the Attribute Bagging AB algorithms. TSMOTE takes full advantage of majority samples to adjust the neighbor selective strategy of SMOTE in order to control the quality of the new sample. Attribute Bagging, a famous ensemble learning algorithm, is also used to improve the predictive power of the classifier. A comprehensive suite of experiments tested on 7 imbalanced data sets collected from UCI machine learning repository is conducted. Experimental results show that TSMOTE-AB outperforms the SMOTE and other previously known algorithms.","Spatial Filtering for Underlay Cognitive SatComsHerein, we study an underlay beamforming technique for the coexistence scenario of satellite and terrestrial networks with the satellite return link as primary and the terrestrial uplink as secondary. Since satellite terminals are unique in that they always point towards the geostationary satellite, interference received by the terrestrial Base Station (BS) is concentrated in a specific angular sector. The priori knowledge that all the geostationary satellite terminals are facing south for the European coverage can be used in designing a beamformer at the terrestrial BS. Based on this concept, we propose a receive beamformer at the BS to maximize the Signal to Interference plus Noise Ratio (SINR) towards the desired user and to mitigate the interference coming from the interfering satellite terminals. The performances of Minimum Variance Distortionless (MVDR) and Linear Constrained Minimum Variance (LCMV) beamformers are compared for our considered scenario. It is shown that LCMV beamformer is better suited in rejecting interference even in case of Direction of Arrival (DoA) uncertainty of interfering satellite terminals as long as DoA range of the interfering sector is known to the beamformer. Furthermore, it is noted that MVDR beamformer is suitable for a large number of interferers.","A Fuzzy Logic-Based Approach to Uncertainty Treatment in the Rule Interchange Format: From Encoding to Extension ","Fiber connectivity integrated brain activation detectionInference of brain activation through the analysis of functional magnetic resonance imaging (fMRI) data is seriously confounded by the high level of noise in the observations. To mitigate the effects of noise, we propose incorporating anatomical connectivity into brain activation detection as motivated by how the functional integration of distinct brain areas is facilitated via neural fiber pathways. In this work, we formulate activation detection as a probabilistic graph-based segmentation problem with fiber networks estimated from diffusion MRI (dMRI) data serving as a prior. Our approach is reinforced with a data-driven scheme for refining the connectivity prior to reflect the fact that not all fibers are necessarily deployed during a given cognitive task as well as to account for false fiber tracts arising from limitations of dMRI tractography. Validating on real clinical data collected from 7 schizophrenia patients and 13 matched healthy controls, we show that incorporating anatomical connectivity significantly increases sensitivity in detecting task activation in controls compared to existing univariate techniques. Further, we illustrate how our model enables the detection of significant group activation differences between controls and patients that are missed with standard methods.","Algebraic Graph Transformations with InheritanceIn this paper, we propose a new approach to inheritance in the context of algebraic graph transformation by providing a suitable categorial framework which reflects the semantics of class-based inheri- tance in software engineering. Inheritance is modelled by a type graph T that comes equipped with a partial order. Typed graphs are arrows with codomain T which preserve graph structures up to inheritance. Mor- phisms between typed graphs are \"down typing\" graph morphisms: An object of class t can be mapped to an object of as ubclass oft .W e prove that this structure is an adhesive HLR category, i. e. pushouts along extremal monomorphisms are \"well-behaved\". This infers validity of clas- sical results such as the Local Church-Rosser Theorem, the Parallelism Theorem, and the Concurrency Theorem.","Amygdala Activation Is Associated with Sense of Presence during Viewing 3D-surround Cinematography ","Formal Verification of Distributed Branching Multiway Synchronization Protocols ","Movie Recommendation Framework Using Associative Classification and a Domain Ontology ","Methods for Generalizing the Propp-Based Story Generation MechanismThis paper discusses some methods for generalizing our Propp-based story generation mechanism. The mechanism has the following aspects: as the development of a system based on the literary theory by Propp and as the use in a more comprehensive architecture of narrative generation called the integrated narrative generation system. Considering the latter aspect especially, the generalization beyond the restriction of Propp's theory will become an important issue for the future development. The first half of this paper will introduce overviews of the Propp-based mechanism and the integrated narrative generation system. Then in the latter half, we will present four methods for the generalization.","A Case-Study of Ontology-Driven Semantic Mediation of Flower-Visiting Data from Heterogeneous Data-Stores in Three South African Natural History CollectionsFirst International Workshop on Semantics for Biodiversity, Montpellier, France, 26-27 May 2013. Published in Semantics for Biodiversity","Unsupervised Visual Changepoint Detection Using Maximum Mean DiscrepancyThe need to quantify similarity between two groups of ob- jects is prevalent throughout the signal processing world. Traditionally, measures such as the Kullback-Leibler divergence are employed, but these may require expensive computations of covariance or integrals. Maximum mean discrepancy is a modern distance measure that is com- putationally simpler - involving the inner product between the difference in means of two groups' feature distributions - yet statistically powerful, because these distributions are mapped into a high-dimensional, nonlin- ear feature space using kernels, whereupon the means are estimated via the Parzen estimator. We apply this metric and leverage several powerful data representations from the supervised image classification world, such as bag-of-visual-words and sparse combinations of SIFT descriptors, to locate scene change points in videos with promising results.","Bat Algorithm and Cuckoo Search: A TutorialNature-inspired metaheuristic algorithms have attracted much attention in the last decade, and new algorithms have emerged almost every year with a vast, ever-expanding literature. In this chapter, we briefly review two latest metaheuris- tics: bat algorithm and cuckoo search for global optimization. Bat algorithm was proposed by Xin-She Yang in 2010, inspired by the echolocation of microbats, while cuckoo search was developed by Xin-She Yang and Suash Deb in 2009, inspired by the brood parasitism of some cuckoo species. Both algorithms have shown superi- ority over many other metaheuristics over a wide range of applications.","Segmentation and Skeletonization on Arbitrary Graphs Using Multiscale Morphology and Active Contours ","A Decision Support Tool for the Risk Management of Offshore Wind Energy ProjectsThis paper provides a decision support tool (DST) to analyze and evaluate the project value of offshore wind energy projects within the frame- work of project finance. The DST is based on a discounted cash-flow model in combination with a Monte Carlo simulation (MCS) to measure project risks and manage these risks. To consider the special requirements of debt capital provid- ers in this context, key figures like the debt service cover ratio (DSCR) are cal- culated. The DST is realized in Excel/VBA with the Excel Add-In Oracle Crys- tal Ball. An offshore wind park example in the German North Sea is simulated to validate the underlying simulation model and the DST.","Program Checking with Less HassleThe simple and often imprecise specifications that programmers may write are a significant limit to a wider application of rigorous program verification techniques. Part of the reason why non-specialists find writing good specification hard is that, when verification fails, they receive little guidance as to what the causes might be, such as implementation errors or inaccurate specifications. To address these limitations, this paper presents two-step verification, a technique that combines implicit specifications, inlining, and loop unrolling to provide improved user feedback when verification fails. Two-step verification performs two independent verification attempts for each program element: one using standard modular reasoning, and another one after inlining and unrolling; comparing the outcomes of the two steps suggests which elements should be improved. Two-step verification is implemented in AutoProof, our static verifier for Eiffel programs integrated in EVE the Eiffel Verification Environment and available online.","Minimizing joint risk of mislabeling for iterative patch-based label fusionAutomated labeling of anatomical structures in medical images is very important in many neuroscience studies. Recently, patch-based labeling in the non-local manner has been widely investigated to alleviate the possible misalignment when registering atlases to the target image. However, the weights used for label fusion from the registered atlases in conventional methods are generally computed independently and thus lack the capability of preventing the ambiguous atlas patches from contributing to the label fusion. More critically, these weights are often calculated based only on the simple patch similarity, thus not necessarily providing optimal solution for label fusion. To address these issues, we present a novel patch-based label fusion method in multi-atlas scenario, for the goal of labeling each voxel in the target image by the best representative atlas patches that also have the lowest joint risk of mislabeling. Specifically, sparse coding is used to select a small number of atlas patches which best represent the underlying patch at each point of the target image, thus minimizing the chance of including the misleading atlas patches for labeling. Furthermore, we examine the joint risk of any pair of atlas patches in making similar labeling error, by analyzing the correlation of their morphological error patterns and also the labeling consensus among atlases. This joint risk will be further recursively updated based on the latest labeling results to correct the possible labeling errors. To demonstrate the performance of our proposed method, we have evaluated it on both whole brain parcellation and hippocampus segmentation, and achieved promising labeling results, compared with the state-of-the-art methods.","Smart Desk: A Single Interface Based File Sharing System ","Human Activity Recognition and Feature Selection for Stroke Early Diagnosis ","Event-based visual servoing with features\u2019 predictionThe research leading to these results has received funding from the Spanish Ministry of Education and Science and European FEDER funds, the Valencia Regional Government and the Research and Innovation Vice-president Office of the University of Alicante, through the research projects DPI2012-32390, GV2012/102 and PROMETEO/2013/085, GRE12-17, respectively.","Spoken Dialog Systems for Automated Survey InterviewingWe explore the plausibility of using automated spoken dialog systems (SDS) for administering survey interviews. Because the goals of a survey dialog system differ from more traditional information-seeking and transactional applications, different measures of task accuracy and success may be warranted. We report a large-scale experimental evaluation of an SDS that administered survey interviews with questions drawn from government and social scientific surveys. We compare two dialog confirmation strategies: (1) a traditional strategy of explicit confirmation on low-confidence recognition; and (2) no confirmation. With explicit confirmation, the small percentage of residual errors had little to no impact on survey data measurement. Even without confirmation, while there are significantly more errors, impact on the substantive conclusions of the survey is still very limited.","Collaborative development and maintenance of health terminologies.The quest for a standardized terminology that can meet the varying needs of healthcare practice, and requirements for secondary use, is ongoing. The number of potential users and the number of potential uses for standardized terminologies make collaborative development, rather than the traditional de jure approach, an imperative, and there appears to be significant worldwide interest in this area. In this article we describe an initiative of the International Council of Nurses (ICN), ICNP C-Space (Collaborative Space), which utilized a social media platform to encourage and facilitate global collaborative development of its terminology, the International Classification for Nursing Practice (ICNP\u00ae). We report on several years of experience of managing the platform and provide valuable lessons on collaborative terminology development. Our experience suggests that web-based platforms such as ICNP C-Space certainly offer the promise of a broader, wider-reaching, and more inclusive community of contributors to the terminology development process. However, there are also potential limitations for which we provide practical recommendations.","A Study on the Development and Application of Programming Language Education for Creativity Enhancement: Based on LOGO and Scratch ","Dynamic Attribute Based Group Signature with Attribute Anonymity and Tracing in the Standard Model ","Behavioural Verification in Embedded Software, from Model to Source CodeTo reduce the verification costs and to be more confident on software, static program analysis offers ways to prove properties on source code. Unfortunately, these techniques are difficult to apprehend and to use for non-specialists. Modelling allows users to specify some aspects of software in an easy way. More precisely, in embedded software, state machine models are frequently used for behavioural design. The aim of this paper is to bridge the gap between model and code by offering automatic generation of annotations from model to source code. These annotations are then verified by static analysis in order to ensure that the code behaviour conforms to the model-based design. The models we consider are UML state machines with a formal non-ambiguous semantics, the annotation generation and verification is implemented in a tool and applied to a case study.","Classification of Benign and Malignant DCE-MRI Breast Tumors by Analyzing the Most Suspect RegionClassification of breast tumors solely based on dynamic con- trast enhanced magnetic resonance data is a challenge in clinical re- search. In this paper, we analyze how the most suspect region as group of similarly perfused and spatially connected voxels of a breast tumor contributes to distinguishing between benign and malignant tumors. We use three density-based clustering algorithms to partition a tumor in re- gions and depict the most suspect one, as delivered by the most stable clustering algorithm. We use the properties of this region for each tumor as input to a classifier. Our preliminary results show that the classifier separates between benign and malignant tumors, and returns predictive attributes that are intuitive to the expert.","On the simultaneous analysis of clinical and omics Data - a comparison of globalboosttest and pre-validation Techniques ","DYNACARE: Dynamic Cardiac Arrest Risk Estimation ","Contrast Enhancement Mechanisms in the Retinothalamic CircuitryThe center-surround organization of the receptive fields of retinal ganglion cells highlights the presence of contrast in visual stimuli. As the receptive fields of thalamic relay cells follow the same organiza- tion, it is assumed that nothing or little processing is carried out at the thalamic stage before the information reaches higher processing areas. However, recent data in cat showing that the number of thalamic relay cells doubles those of retinal ganglion cells opens the door to question how contrast information is kept in an enlarged representation of the visual stimulus at the thalamic stage. This paper is aimed at providing a plausible explanation by means of simulations performed with a realistic dynamic model of the retinothalamic circuit.","Decision Model for Selecting a Cloud Provider: A Study of Service Model Decision PrioritiesThis article describes a methodology to support the decision-making process for Cloud customers, using the Analytic Hierarchy Process (AHP). For this purpose, we present a decision model to select an appropriate Cloud provider. Despite its success in the industry, Cloud Computing still struggles with fulfilling customer expectations regarding provider characteristics. Due to limited transparency of existing Cloud providers, the evaluation and selection becomes a key issue. With the help of this decision model Cloud providers can be selected on the infrastructure, platform or application level. Subsequently, seven IT executives were interviewed and the decisions related to each level are discussed. Furthermore, differences and similarities between the infrastructure, platform and application levels are presented as most companies have similar requirements for basic systems and standard Cloud use cases. We enrich existing research on Cloud Computing adoption and present a systematic approach to assess Cloud providers and to apply a prioritization of selection criteria for all Cloud models.","One Size Does Not Fit All: Different Cultures Require Different Information Systems Security Interventions ","An Improved Unrolling-Based Decision Procedure for Algebraic Data TypesReasoning about algebraic data types and functions that operate over these data types is an important problem for a large variety of applications. In this paper, we present a decision procedure for reasoning about data types using abstractions that are provided by catamorphisms: fold functions that map instances of algebraic data types into values in a decidable domain. We show that the procedure is sound and complete for a class of monotonic catamorphisms.#R##N##R##N#Our work extends a previous decision procedure that solves formulas involving algebraic data types via successive unrollings of catamorphism functions. First, we propose the categories of monotonic catamorphisms and associative-commutative catamorphisms, which we argue provide a better formal foundation than previous categorizations of catamorphisms. We use monotonic catamorphisms to fix an incompleteness in the previous unrolling algorithm and associated proof. We then use these notions to address two open problems from previous work: 1 we provide a bound on the number of unrollings necessary for completeness, showing that it is exponentially small with respect to formula size for associative-commutative catamorphisms, and 2 we demonstrate that associative-commutative catamorphisms can be combined within a formula whilst preserving completeness.","Effects of Virtual Training on Emotional Response * : A comparison between different emotion regulation strategies ","Extracting brain regions from rest fMRI with total-variation constrained dictionary learning.Spontaneous brain activity reveals mechanisms of brain func- tion and dysfunction. Its population-level statistical analysis based on functional images often relies on the definition of brain regions that must summarize efficiently the covariance structure between the multiple brain networks. In this paper, we extend a network-discovery approach, namely dictionary learning, to readily extract brain regions. To do so, we intro- duce a new tool drawing from clustering and linear decomposition meth- ods by carefully crafting a penalty. Our approach automatically extracts regions from rest fMRI that better explain the data and are more stable across subjects than reference decomposition or clustering methods.","Product Quality Inspection Combining with Structure Light System, Data Mining and RFID Technology ","A Qualitative Insight on Factors Enabling and Inhibiting Changes in Post Adoption IS Use in SMEs: A Case Study in Jamaica ","Simulating household activities to lower consumption peaks: demonstrationEnergy experts need fine-grained dynamics oriented tools to investigate household activities in order to improve power management in the residential sector. This paper presents the SMACH framework for modelling, simulating and analy- sis of household activities. It provides experts with a guided graphical interface easing the modelling of the household, its inhabitants and their activities. It also includes inhabi- tants adaptation capabilities to dynamically response to oc- casional and/or build emergent habits.","Playing Human Computation Games for Mobile Information Sharing: The Influence of Personality and Perceived Information QualityApplications that use gaming elements to harness human intelligence to tackle computational tasks are increasing in popularity and may be termed as Human Computation Games (HCGs). Recently, HCGs have been utilized to offer a more engaging experience for mobile information sharing. Yet, there is a lack of research that examines individuals' personality and behaviors related to HCGs. This understanding may be important in identifying HCG features that suit different personality orientations. Thus, this study aims to investigate the influence of individuals' personality and perceptions of information quality on intention to play HCG for mobile information sharing. In a study of 205 participants, results revealed that personality traits of extraversion and openness, as well as perceived information accuracy and relevancy were significant in predicting intention to play. Implications of our work are also discussed.","Design of Transducer Interface Agent and its Protocol for WSN Middleware ","Privacy-Preserving Multi-Party Reconciliation Secure in the Malicious ModelThe problem of fair and privacy-preserving ordered set reconciliation arises in a variety of applications like auctions, e-voting, and appointment reconciliation. While several multi-party protocols have been proposed that solve this problem in the semi-honest model, there are no multi-party protocols that are secure in the malicious model so far. In this paper, we close this gap. Our newly proposed protocols are shown to be secure in the malicious model based on a variety of novel non-interactive zero-knowledge-proofs. We describe the implementation of our protocols and evaluate their performance in comparison to protocols solving the problem in the semi-honest case.","The Two-Dimensional Vector Packing Problem with Courier Cost Structure ","Privacy-Aware Processing of Biometric Templates by Means of Secure Two-Party Computation ","Clusters Identification in Binary Genomic Data: The Alternative Offered by Scan Statistics Approach ","Wind Power Resource Estimation with Deep Neural NetworksThe measure-correlate-predict technique is state-of-the-art for assessing the quality of a wind power resource based on long term numerical weather prediction systems. On-site wind speed measurements are correlated to meteorological reanalysis data, which represent the best historical estimate available for the atmospheric state. The different variants of MCP more or less correct the statistical main attributes by making the meteorological reanalyses bias and scaling free using the on-site measurements. However, by neglecting the higher order correlations none of the variants utilize the full potential of the measurements. We show that deep neural networks make use of these higher order correlations. Our implementation is tailored to the requirements of MCP in the context of wind resource assessment. We show the application of this method to a set of different locations and compare the results to a simple linear fit to the wind speed frequency distribution as well as to a standard linear regression MCP, that represents the state-of-the-art in industrial aerodynamics. The neural network based MCP outperforms both other methods with respect to correlation, root-mean-square error and the distance in the wind speed frequency distribution. Site assessment can be considered one of the most important steps developing a wind energy project. To this end, the approach described can be regarded as a novel, high-quality tool for reducing uncertainties in the long-term reference problem of on-site measurements.","Fault Detection and Diagnosis of Electrical Networks Using a Fuzzy System and Euclidian Distance ","An emergency vehicle scheduling problem with time utility based on particle swarm optimizationIn this paper, utility function is introduced to the emergency vehicle scheduling problem. An exponential utility function of time is designed as an indicator of operational efficiency. A mathematic model for the emergency vehicle scheduling problem is constructed. A particle swarm optimization algorithm is designed for the proposed problem. In the PSO algorithm, N+K\u22121 dimensions encoding scheme are introduced. Finally, we study an experiment. PSO algorithm and MCPSO algorithm are applied. Comparing with the results of the MCPSO algorithm, the PSO algorithm performs better to solve the problem.","A Multiple Feature Integration Model to Infer Occupation from Social Media RecordsWith the rapid development of more and more social media applications, lots of users are connected with friends and their daily life and opinions are recorded. Social media provides us an unprecedented way to collect and analyze billions of users' information. Proper user attribute identification or profile inference becomes more and more at- tractive and feasible. However, the flourishing social records also pose great challenge in effective feature selection and integration for user pro- file inference. This is mainly caused by the text sparsity and complex community structures. In this paper, we propose a comprehensive framework to infer user's occupation from his/her social activities recorded in micro-blog message streams. A multi-source integrated classification model is set up with some fine selected features. We first identify some beneficial basic content features, and then we proceed to tailor a community discovery based latent dimension solution to extract community features. Extensive empirical studies are conducted on a large real micro-blog dataset. Not only we demonstrate the integrated model shows advantages over several baseline methods, but also we verify the effect of homophily in users' interaction records. The different effects of heterogeneous inter- active networks are also revealed.","Environmental Background Sounds Classification Based on Properties of Feature Contours ","User-Friendly Authentication and Authorization Using a Smartphone ProxyWe present a novel approach to authenticate and authorize a user, using her personal smartphone. The presented architecture is com- plemented with a proof-of-concept implementation. The implemented system architecture is based on a single sign-on solution (SSO), extended to allow the usage of the smartphone as authentication and authorization device. We evaluated the system within real-world scenarios, observing users' behavior using the novel technique. Based on our experiences, we summarize advances, made both in usability and security, for novel im- plementations using the proposed concept.","Inverse mapping with sensitivity analysis for partial selection in interactive evolution ","Constraint-Based Approaches for Balancing Bike Sharing SystemsIn order to meet the users' demand, bike sharing systems must be regularly rebalanced. The problem of balancing bike sharing systems BBSS is concerned with designing optimal tours and operating instructions for relocating bikes among stations to maximally comply with the expected future bike demands. In this paper, we tackle the BBSS by means of Constraint Programming: first, we introduce two novel constraint models for the BBSS including a smart branching strategy that focusses on the most promising routes. Second, in order to speed-up the search process, we incorporate both models in a Large Neighborhood Search LNS approach that is adapted to the respective CP model. Third, we perform a computational evaluation on instances based on real-world data, where we see that the LNS approach outperforms the Branch &amp; Bound approach and is competitive with other existing approaches.","Data Security and Privacy in 2025Security research aims at reducing the risk and consequences of attacks on information technology. Based on the projection of current trends, this vision paper makes an attempt at identifying potential security research challenges for the next 10 years.","Towards an Approach to Identify the Optimal Instant of Time for Information Capturing in Supply Chains ","GeneDBase \u2013 Genetic Database of Selected Species of Mammals in the Czech RepublicGeneDBase is a part of a research project titled \"Creating a genetic database of selected species of mammals in the Czech Republic to be used for sustainable transport development\". The aim of the research project is to assess the impact of roads on the fragmentation of animal populations and their genetic variability. Further, the objective is to create a genetic database of mammals comprising the data from collected samples of selected wild animals which could be used widely, not only for road planning, but also in other fields (agriculture, environmental protection, land-use planning).","A Continuous Shape Prior for MRF-Based SegmentationThe competition between discrete MRF based and continuous PDE based formulations has a very long history, especially in context of segmentation. Obviously, both have their advantages and drawbacks. Therefore the choice of a discrete or continuous framework is often driven by a particular application or even more often by personal preferences of a particular researcher. In this work we present a model for binary segmentation, where discrete and continuous parts are combined in a well founded and simple way. We discuss the properties of the proposed model, give a basic inference algorithm and validate it on a benchmark database.","From Service Design to Innovation through Services: Emergence of a Methodological and Systemic Framework ","Mantle: A Novel DOSN Leveraging Free Storage and Local SoftwareWe present Mantle, a novel framework for decentralized Online Social Networks (OSN). Mantle defines a privacy-preserving OSN kernel and can leverage any storage facilities for storing user data. Mantle is designed to execute all OSN specific logic on user devices. It supports the development of third-party applications and mediates all actions of the latter to protect user da- ta, metadata and interactions. In this work, we focus on Mantle's interaction and notification mechanisms, which use publish/subscribe model. The logically centralized structure of most of popular OSNs raises the issue of depen- dence on one single authority, in particular the Service Provider (SP), with full access to both data (such as shared content) and metadata (for example related to interactions, statistics) of its users. This raises the additional question of possible user profiling per- formed by the OSN provider also outside the borders of the actual OSN platform. Meanwhile, the operations and maintenance of the OSN platform (consumed bandwidth and storage, dedicated code and platform development, etc.) represent a huge cost for OSN providers, leading SPs to put users' privacy in the background. Furthermore, the presence per se of a unique SP as Central Authority implies the possibility of some form of censorship: how would an OSN react if their users started promoting a rival OSN? As another example, Facebook, Google and Twitter, have recently announced the possibili- ty of performing country-specific censorship so as to become compliant to legal requirements in different countries. Modern OSN providers explicitly put users in a condition of dependence on the platform itself in that: i) users can only interact with the members of the same plat- form, ii) migration from one platform to another, to the best of our knowledge, is not supported by any current mechanism and finally, iii) deleting your own profile from a platform currently only renders the content inaccessible, without any guarantee of actual deletion of the content. Thus, in a futuristic view of a Social Web, in which a substantial part of interactions are performed via social platforms, being bound to one single platform bears substantial risks. As an alternative to logically centralized architectures for Online Social Networks (OSNs), several decentralized approaches have been proposed (1, 2, 3). Such architec- tures (called DOSN) aim to preserve user privacy while offering a service analogous","Cascaded Reduction and Growing of Result Sets for Combining Object DetectorsIn this paper cascaded reduction and growing of result sets is introduced as a principle for combining the results of different object detectors. First, different candidate operating points are selected for each object detection algorithm. This procedure is based on the analysis of precision and recall of the individual methods. Selecting an appropri- ate operating point prior to fusion is important because it regulates the cardinal number of the result set. As diversity and correlation between object detectors also depend on the elements of the result sets, this and the application of set operations allow to create a final set of detected ob- jects by including missing and excluding false detections. The approach allows both diverse and correlated detectors to contribute to the per- formance of the combined detector. The performance of the proposed algorithm is compared to other combining algorithms. It outperforms or competes with existing state of the art combiners for several datasets. Additionally, the results provide a significant improvement in the inter- pretability of the combining rules. As a unique feature of the proposed algorithm, the found operating points can be used to reconfigure the ob- ject detection algorithms to adapt their individual results to the needs of the combination procedure allowing a reduction in runtime.","Hierarchical conformance checking of process models based on event logsProcess mining techniques aim to extract knowledge from event logs. Conformance checking is one of the hard problems in process mining: it aims to diagnose and quantify the mismatch between observed and modeled behavior. Precise conformance checking implies solving complex optimization problems and is therefore computationally challenging for real-life event logs. In this paper a technique to apply hierarchical conformance checking is presented, based on a state-of-the-art algorithm for deriving the subprocesses structure underlying a process model. Hierarchical conformance checking allows us to decompose problems that would otherwise be intractable. Moreover, users can navigate through conformance results and zoom into parts of the model that have a poor conformance. The technique has been implemented as a ProM plugin and an experimental evaluation showing the significance of the approach is provided.","How to sell hyperedges: the hypermatching assignment problemWe are given a set of clients with budget constraints and a set of indivisible items. Each client is willing to buy one or more bundles of (at most) k items each (bundles can be seen as hyperedges in a k-hypergraph). If client i gets a bundle e, she pays bi,e and yields a net profit wi,e. The Hypermatching Assignment Problem (HAP) is to assign a set of pairwise disjoint bundles to clients so as to maximize the total profit while respecting the budgets. This problem has various applications in production planning and budget-constrained auctions and generalizes well-studied problems in combinatorial optimization: for example the weighted (unweighted) k-hypergraph matching problem is the special case of HAP with one client having unbounded budget and general (unit) profits; the Generalized Assignment Problem (GAP) is the special case of HAP with k = 1.#R##N##R##N#Let e &gt; 0 denote an arbitrarily small constant. In this paper we obtain the following main results:#R##N##R##N#\u2022 We give a randomized (k + 1 + e) approximation algorithm for HAP, which is based on rounding the 1-round Lasserre strengthening of a novel LP. This is one of a few approximation results based on Lasserre hierarchies and our approach might be of independent interest. We remark that for weighted k-hypergraph matching no LP nor SDP relaxation is known to have integrality gap better than k \u2212 1 + 1/k for general k [Chan and Lau, SODA'10].#R##N##R##N#\u2022 For the relevant special case that one wants to maximize the total revenue (i.e., bi,e = wi,e), we present a local search based (k + O (\u221ak))/2 approximation algorithm for k = O(1). This almost matches the best known (k + 1 + e)/2 approximation ratio by Berman [SWAT'00] for the (less general) weighted k-hypergraph matching problem.#R##N##R##N#\u2022 For the unweighted k-hypergraph matching problem, we present a (k + 1 + e)/3 approximation in quasipolynomial time. This improves over the (k + 2)/3 approximation by Halldorsson [SODA'95] (also in quasipolynomial time). In particular this suggests that a 4/3 + e approximation for 3-dimensional matching might exist, whereas the currently best known polynomial-time approximation ratio is 3/2.","An API-based Search System for One Click Access to InformationThis paper proposes a prototype One Click access system, based on previous work in the field and the related 1CLICK-2@NTCIR10 task. The proposed solution integrates methods from into a three tier algorithm: query categorization, information extraction and output generation and offers suggestions on how each of these can be implemented. Finally, a thorough user-based evaluation concludes that such an information retrieval system outperforms the textual preview collected from Google search results, based on a paired sign test. Based on validation results suggestions for future improvements are proposed.","Using light guiding to structure everyday lifeWe present an approach using room lighting for strengthening individual daily structure or changing structure of daily routines if required. This new healing environment concept includes a monitoring system based on standard passive infrared presence sensors as well as a zonal and ambient room lighting system using direct and indirect lighting with variable light intensities and light colors.","Clinical Time Series Prediction with a Hierarchical Dynamical SystemIn this work we develop and test a novel hierarchical frame- work for modeling and learning multivariate clinical time series data. Our framework combines two modeling approaches: Linear Dynamical Systems (LDS) and Gaussian Processes (GP), and is capable to model and work with time series of varied length and with irregularly sampled observations. We test our framework on the problem of learning clinical time series data from the complete blood count panel, and show that our framework outperforms alternative time series models in terms of its predictive accuracy.","Development of the Home Arm Movement Stroke Training Environment for Rehabilitation (HAMSTER) and Evaluation by Clinicians ","Towards Understanding Software Process Variability from Contextual Evidence of Change ","The trading between virtual mobile operator and wireless service provider in the two-tier femtocell networkThis paper considers the problem that the virtual mobile operator (VMO) buys services from the wireless service provider (WSP) to serve its users. When faced with poor indoor coverage or at the edge of marcocell, the WSP would ask nearby femto base stations (FBSs) to help serve the VMO. We focus on the interesting questions when the WSP prefers to ask help from FBSs and how WSP, VMO and FBSs adjust their strategies to maximize their profits. A two-stage Stackelberg game is built for the situation when the WSP serve the VMO by itself and a four-stage Stackelberg game is considered when the WSP rents FBSs by offering spectrum bands to FBSs. We firstly define the utility functions of VMO, WSP and FBSs to reflect their satisfaction and cost in participating into the game and then give the analysis based on the backward induction method. Meanwhile, the competition among FBSs when the WSP allocates spectrum bands for FBSs' help is formulated as a non-cooperative spectrum competition game (NSCG) and the existence and uniqueness of the Nash equilibrium in NSCG is proved. Simulation results of the two service modes show the WSP can obtain more profits through renting FBSs in poor coverage areas.","Towards a Domain-Specific Language for Patterns-Oriented Parallel ProgrammingPattern-oriented programming has been used in parallel code development for many years now. During this time, several tools (mainly frameworks and libraries) proposed the use of patterns based on pro- gramming primitives or templates. The implementation of patterns using those tools usually requires human expertise to correctly set up commu- nication/synchronization among processes. In this work, we propose the use of a Domain Specific Language to create pattern-oriented parallel programs (DSL-POPP). This approach has the advantage of offering a higher programming abstraction level in which communication/synchro- nization among processes is hidden from programmers. We compensate the reduction in programming flexibility offering the possibility to use combined and/or nested parallel patterns (i.e., parallelism in levels), al- lowing the design of more complex parallel applications. We conclude this work presenting an experiment in which we develop a parallel ap- plication exploiting combined and nested parallel patterns in order to demonstrate the main properties of DSL-POPP.","Supporting Content Contextualization in Web based Applications on Mobile Devices.Mobile devices, in the form of smartphones, are endowed with rich capabilities in terms of multimedia, sensors and connectivity. The wide adoption of these devices allows using them across differen ...","Testing the Generalization of Feedforward Neural Networks with Median Neuron Input Function ","Emotion and Memory in Technology Adoption and DiffusionData collected from 338 health care workers were used to test a proposed model that inspiration, memory, and inspirational memory affect end user intention to adopt a digitized patient record software application. Structural equation modeling showed that, as expected, inspiration from managers and trainers affected the individual behavior of the end users. Inspiration had an interactive impact through memory on collective acceptance of the technology, thereby affecting subsequent evaluations and behavior. The proposed model was nomologically validated through the use of a portable platform loaded with software for the electronic collection of operational-level health care data. Embedded metrics measured participants\u2019 memory as operationalized by task completion time, number of errors, and completeness of the data. This paper contributes to the literature by introducing inspiration as a key driver that improves memory to affect end user intention to use digitized patient record technology.","Vision Substitution Experiments with See ColOrSee ColOr is a mobility aid for visually impaired people that uses the auditory channel to represent portions of captured images in real time. A distinctive feature of the See ColOr interface is the simulta- neous coding of colour and depth. Four main modules were developed, in order to replicate a number of mechanisms present in the human visual systems. In this work, we first present the main experiments carried out in the first years of the project; among them : the avoidance of obstacles, the recognition and localization of objects, the detection of edges and the identification of coloured targets. Finally, we introduce new undergoing experiments in Colombia with blind persons, whose purpose is (1) to de- termine and to touch a target; (2) to navigate and to find a person; and (3) to find particular objects. Preliminary results illustrate encouraging results.","Automatic Decomposition and Allocation of Safety Integrity Levels Using a Penalty-Based Genetic Algorithm ","Bivariate Spatial Clustering Analysis of Point Patterns: A Graph-Based Approach ","An Alternative Approach to the Median of a Random Interval Using an L2 MetricSince the Aumann-type expected value of a random interval is not robust, the aim of this paper is to propose a new central tendency measure for interval-valued data. The median of a random interval has already been defined as the interval minimizing the mean distance, in terms of an L-1 metric extending the Euclidean distance, to the values of the random interval. Inspired by the spatial median, we now follow a more common approach to define the median using an L-2 metric.","Aerial Ball Perception Based on the Use of a Single Perspective Camera ","A Multi-objective Genetic Algorithm to Rank State-Based Test CasesWe propose a multi-objective genetic algorithm method to prioritize state-based test cases to achieve several competing objectives such as budget and coverage of data flow information, while hopefully detecting faults as early as possible when executing prioritized test cases. The experimental results indicate that our approach is useful and effective: prioritizations quickly achieve maximum data flow coverage and this results in early fault detection; prioritizations perform much better than random orders with much smaller variance.","Distributed Binary Consensus in Dynamic Networks ","An efficient vector-based representation for coalitional gamesWe propose a new representation for coalitional games, called the coalitional skill vector model, where there is a set of skills in the system, and each agent has a skill vector--a vector consisting of values that reflect the agents' level in different skills. Furthermore, there is a set of goals, each with requirements expressed in terms of the minimum skill level necessary to achieve the goal. Agents can form coalitions to aggregate their skills, and achieve goals otherwise unachievable. We show that this representation is fully expressive, that is, it can represent any characteristic function game. We also show that, for some interesting classes of games, our representation is significantly more compact than the classical representation, and facilitates the development of efficient algorithms to solve the coalition structure generation problem, as well as the problem of computing the core and/or the least core. We also demonstrate that by using the coalitional skill vector representation, our solver can handle up to 500 agents.","Rotation-Aware LayerPaint System3D painting is an important texturing tool in computer graphics. Research efforts have been made to pursue an intuitive and effective 3D painting interface. Among those methods, WYSIWYG interface has been widely used because that it is close to the experience of 2D drawing. However, the navigation on the complicated 3D model is still a problem, where self-occluding often occurs. This paper proposes a rotation-aware LayerPaint system. A stroke-driven navigation is proposed to enable intuitive navigation for complicated model. To solve the missing of layer information upon rotation in the dynamic LayerPaint system, we present a Region-Of-Interest tracking algorithm. Finally, we present a rotation-aware Layerpaint system that supports rotation-aware painting operations.","Automated Image Processing to Quantify Cell Migration ","Including Functional Usability Features in a Model-Driven Development MethodThe Software Engineering (SE) community has historically focused on working#R##N#   with models to represent functionality and persistence, pushing interaction#R##N#   modelling into the background, which has been covered by the Human Computer#R##N#   Interaction (HCI) community. Recently, adequately modelling interaction, and#R##N#   specifically usability, is being considered as a key factor for success in#R##N#   user acceptance, making the integration of the SE and HCI communities more#R##N#   necessary. If we focus on the Model-Driven Development (MDD) paradigm, we#R##N#   notice that there is a lack of proposals to deal with usability features from#R##N#   the very first steps of software development process. In general, usability#R##N#   features are manually implemented once the code has been generated from#R##N#   models. This contradicts the MDD paradigm, which claims that all the#R##N#   analysts\u2019 effort must be focused on building models, and the code generation#R##N#   is relegated to model to code transformations. Moreover, usability features#R##N#   related to functionality may involve important changes in the system#R##N#   architecture if they are not considered from the early steps. We state that#R##N#   these usability features related to functionality can be represented#R##N#   abstractly in a conceptual model, and their implementation can be carried out#R##N#   automatically.","Detection and Evaluation of Physical Therapy Exercises by Dynamic Time Warping Using Wearable Motion Sensor UnitsWe develop an autonomous system that detects and evaluates physical therapy exercises using wearable motion sensors. We propose an algorithm that detects all the occurrences of one or more template signals (representing exercise movements) in a long signal acquired during a physical therapy session. In matching the signals, the algorithm allows some distortion in time, based on dynamic time warping (DTW). The algorithm classifies the executions in one of the exercises and evaluates them as correct/incorrect, giving the error type if there is any. It also providesaquantitativemeasureofsimilaritybetweeneachmatchedexecutionandits template. To evaluate the performance of the algorithm in physical therapy, a dataset consisting of one template execution and ten test executions of each of the three execution types of eight exercises performed by five subjects is recorded, having a total of 120 and 1,200 exercise executions in the training and test sets, respectively, as well as many idle time intervals in the test signals. The proposed algorithm detects 1,125 executions in the whole test set. 8.58% of the 1,200 executions are missed and 4.91% of the idle time intervals are incorrectly detected as executions. The accuracy is 93.46% only for exercise classification and 88.65% for simultaneous exercise and execution type classification. The proposed system may be used for both estimating the intensity of the physical therapy session and evaluating the executions to provide feedback to the patient and the specialist.","Spotique: A New Approach to Local MessagingThis paper describes a new approach to local messaging. Our application combines passive monitoring for smart phones and cloud based messaging for mobile OS (operational system). Passive monitoring can determine the location of mobile subscribers (mobile phones, actually) without the active participation of the users. Mobile users do not need to mark own location on social networks (check-in), they do not need to run on their phones the location track applications. In the same time, Cloud Messaging allows interested parties to directly deliver their information to mobile users who find themselves near a selected point. This is the main content of the service - how to combine the monitoring and notifications.","From Extraction of Logical Specifications to Deduction-Based Formal Verification of Requirements ModelsThe work relates to formal verification of requirements models using deductive reasoning. Elicitation of requirements has significant impact on the entire software development process. Therefore, formal verification of requirements models may influence software cost and reliability in a positive way. However, logical specifications, considered as sets of temporal logic formulas, are difficult to specify manually by inexperienced users and this fact can be regarded as a significant obstacle to practical use of deduction-based verification tools. A method of building requirements models, including their logical specifications, is presented step by step. Requirements models are built using some UML diagrams, i.e. use case diagrams, use case scenarios, and activity diagrams. Organizing activity diagrams into predefined workflow patterns enables automated extraction of logical specifications. The crucial aspect of the presented approach is integrating the requirements engineering phase and the automatic generation of logical specifications. Formal verification of requirements models is based on the deductive approach using the semantic tableaux reasoning method. A simple yet illustrative example of development and verification of a requirements model is provided.","A page navigation technique for overlooking content in a digital magazineAlthough electronic book readers have became popular in recent years, page navigation techniques used for these readers are not necessarily appropriate for all kinds of books. In this study, an observation experiment is conducted to investigate how people read paper-based magazines. Based on the findings in the experiment, the authors propose new page navigation techniques specialized for digital magazines. The techniques adopt the operation of flipping through the pages. A user study confirms that the techniques are useful for overlooking content in a digital magazine and able to support readers to find articles that meet their interests.","On the tree structure used by lazy propagation for inference in bayesian networksLazy Propagation (LP) is a propagation scheme for belief update in Bayesian networks based upon Shenoy-Shafer propagation. So far the secondary computational structure has been a junction tree (or strong junction tree). This paper describes and shows how different tree structures can be used for LP. This includes the use of different junction trees and the maximal prime subgraph decomposition organised as a tree. The paper reports on the results of an empirical evaluation on a set of real-world Bayesian networks of the performance impact of using different tree structures in LP. The results indicate that the tree structure can have a significant impact on both time and space performance of belief update.","A case study on the application of probabilistic conditional modelling and reasoning to clinical patient data in neurosurgeryWe present a case-study of applying probabilistic logic to the analysis of clinical patient data in neurosurgery. Probabilistic conditionals are used to build a knowledge base for modelling and representing clinical brain tumor data and expert knowledge of physicians working in this area. The semantics of a knowledge base consisting of probabilistic conditionals is defined by employing the principle of maximum entropy that chooses among those probability distributions satisfying all conditionals the one that is as unbiased as possible. For computing the maximum entropy distribution we use the MEcore system that additionally provides a series of knowledge management operations like revising, updating and querying a knowledge base. The use of the obtained knowledge base is illustrated by using MEcore's knowledge management operations.","A PSO-Optimized Nash Equilibrium-Based Task Scheduling Algorithm for Wireless Sensor NetworkFor the dynamic load characteristics of Wireless sensor network, we propose the idea of parallel Coalition and introduce the game theory into the solving of dynamic task allocation problem. In this paper, we design the model of multiple task allocation based on Nash equilibrium, and use runtime of task, Transmission energy consumption and Residual energy to design the utility function of Games. Then we use PSO to find to the point of Nash equilibrium. By using this method, guarantee the task execution effectiveness and improve the utilization rate of networks. Simulation results prove the validity of the algorithm, and can effectively prolong the lifetime of the network.","Gossip Protocols for Renaming and SortingWe devise efficient gossip-based protocols for some fundamental distributed tasks. The protocols assume an n-node network supporting point-to-point communication, and in every round, each node exchanges information of size Ologn bits with at most one other node.#R##N##R##N#We first consider the renaming problem, that is, to assign distinct IDs from a small ID space to all nodes of the network. We propose a renaming protocol that divides the ID space among nodes using a natural push or pull approach, achieving logarithmic round complexity with ID space {1,',1+e n}, for any fixed e&gt;0. A variant of this protocol solves the tight renaming problem, where each node obtains a unique ID in {1,',n}, in Olog2 n rounds.#R##N##R##N#Next we study the following sorting problem. Nodes have consecutive IDs 1 up to n, and they receive numerical values as inputs. They then have to exchange those inputs so that in the end the input of rank k is located at the node with ID k. Jelasity and Kermarreci\u00be?[20] suggested a simple and natural protocol, where nodes exchange values with peers chosen uniformly at random, but it is not hard to see that this protocol requires \u03a9n rounds. We prove that the same protocol works in Olog2 n rounds if peers are chosen according to a non-uniform power law distribution.","Face Recognition Using Multi-scale ICA Texture Pattern and Farthest Prototype Representation ClassificationIn this paper, we present a novel approach to improve the per- formance of face recognition. To represent face images, we propose an ef- fective texture descriptor, i.e., multi-scale ICA texture pattern (MITP). MITP generates multiple encoded images according to the order of response images by learned independent component analysis (ICA) filters of various scales, and then concatenates the MITP histograms from non-overlapping subregions of the encoded images into a single histogram. Based on a fun- damental concept that a specific class can be modeled by a single query- dependent prototype, we introduce a simple classifier without parameter tuning, in which the decision is made using the farthest prototype rule. Moreover, a simple feature remapping strategy can further boost the per- formance. Experiments on two widely-used face databases demonstrate the effectiveness of our approach over other methods.","Towards a holistic tool for the selection and validation of usability method sets supporting human-centered designThe establishment of human-centered design within system development processes is still a challenge. Numerous usability methods exist that aim to increase usability and user experience of a system. Nevertheless, the selection of appropriate methods remains to be difficult, as there exist many different factors that have a significant influence on the appropriateness of the methods in their context of use. This paper presents a new concept for the selection of usability methods. It focuses on a) the selection of appropriate usability methods with regard to their applicability in the various stages of system development and b) accounting for interdependencies between multiple methods by balancing them with respect to the usability dimensions effectiveness, efficiency and satisfaction.","Modeling Spatiotemporal Wild Fire Data with Support Vector Machines and Artificial Neural NetworksForest fires have not only devastating catastrophic environmental consequences, but they also have serious negative social impact. Exploitation of related spatiotemporal data could potentially lead to the development of reliable models, towards forecasting of the annual burned area. This paper takes advantage of the regression capabilities of modern Soft Computing approaches. More specifically numerous Artificial Neural Networks' and e-Regression Support Vector Machines' models were developed, each one assigned locally to a distinct Greek forest department (GFD). The whole research effort was related to Greek wild fires incidents for the period 1983-1997 and to all of the GFDs. The performance of both methods has proven to be quite reliable in the vast majority of the cases and a comparative analysis was also used to reveal potential advantages or weaknesses.","Extracting, Identifying and Visualisation of the Content, Users and Authors in Software Projects ","Demons Methods for Digital Mammography RegistrationImage registration is regarded as an important tool for the analysis of temporal mammograms, specially for lesion detection. How- ever, it has not been widely adopted due to the complexity of the problem and the limitations of the algorithms. This work evaluates the suitabil- ity of Diffeomorphic Demons for temporal mammographic registration. Analysis in a dataset of 440 images from 53 different patients (perform- ing over 3300 registrations) shows a better registration quality using different objective measures compared to standard Rigid and Non-Rigid algorithms. In addition, a study of the effects of lesions in the registra- tion is performed, indicating that registration results (specially for the Demons) can be potentially used for lesion detection.","A simulation enabled procedure for eco-efficiency optimization in production systemsEnvironmental sustainability in manufacturing has been experiencing increasing attention in practice and academia over the last decades. Manufacturing companies strive to improve their eco-efficiency, which is commonly understood as delivering high value products at lower cost and environmental impact. They need tools and methods to translate this strategic goal onto the operational shop floor level. This paper presents a procedure for optimizing the eco-efficiency of production systems, supported by a discrete-event material flow simulation model. Its application is shown in a case with a company from the Swiss consumer goods industry.","Concurrent Execution of Data Mining Queries for Spatial Collocation Pattern DiscoveryIn spatial databases, Collocation Pattern Discovery is a very important data mining technique. It consists in searching for types of spatial objects that are frequently located together. Due to high requirements for CPU, memory or storage space, such data mining queries are often executed at times of low user activity. Multiple users or even the same user experimenting with different parameters can define many queries during the working hours that are executed, e.g., at off-peak night-time hours. Given a set of multiple spatial data mining queries, a data mining system may take advantage of potential overlapping of the queried datasets. In this paper we present a new method for concurrent processing of multiple spatial collocation pattern discovery queries. The aim of our new algorithm is to improve processing times by reducing the number of searches for neighboring objects, which is a crucial step for the identification of collocation patterns.","Nonlinear Extension of the IRLS Classifier Using Clustering with Pairs of Prototypes ","Set-theoretic models of computationsThe purpose of this paper is to present some set-theoretic models of computation. This topic and its usefulness are clearly related to those presented in the book by Hoare and He: \"Unifying Theories of Programming\" [12]. However, we prefer to use here the term \"computation\" to that of \"programming\" as our purpose is not so much to unify various ways of programming (using different programming languages) but rather to see how various mechanical computation paradigms (be they sequential, distributed, parallel, and so on) can be given a unified mathematical theory. Our purpose is also to study how these computations can be specified and then developed by means of refinements and proofs.","Consistent Ontologies Evolution Using Graph GrammarsOntologies are often used for the meta-modelling of dynamic domains, therefore it is essential to represent and manage their changes and to adapt them to new requirements. Due to changes, an ontology may become invalid and non-interpretable. This paper proposes the use of the graph grammars to formalize and manage ontologies evolution. The ob- jective is to present an a priori approach of inconsistencies resolutions to adapt the ontologies and preserve their consistency. A framework com- posed of different graph rewriting rules is proposed and presented using the AGG (Algebraic Graph Grammar) tool. As an application, the ar- ticle considers the EventCCAlps ontology developed within the CCAlps European project.","Anonymous and Transferable Electronic Ticketing SchemeElectronic tickets demonstrate, without the use of paper, the possession of an authorization or access to a determined service. In this scenario, some security requirements must be accomplished. Moreover, some determined services should guarantee the anonymity of the users in the system. In addition to these requirements, the transferability of a ticket from one user to another (without involving a third party) is useful but also generates other issues to be solved in terms of security, as several attacks could be performed. In this article we present an electronic ticketing system with anonymity and transferability based on the use of group signatures, giving a solution to enable linkability between several group signatures, and also proving their ownership with the use of Zero-Knowledge Proofs (ZKPs).","Dynamic Steiner Tree in Planar Graphs ","Editorial: Guest editorial: Special issue on data mining for information security ","NP-Hardness of Speed Scaling with a Sleep StateA modern processor can dynamically set it's speed while it's active, and can make a transition to sleep state when required. When the processor is operating at a speed $s$, the energy consumed per unit time is given by a convex power function $P(s)$ having the property that $P(0) &gt; 0$ and $P\"(s) &gt; 0$ for all values of $s$. Moreover, $C &gt; 0$ units of energy is required to make a transition from the sleep state to the active state. The jobs are specified by their arrival time, deadline and the processing volume. #R##N#We consider a scheduling problem, called speed scaling with sleep state, where each job has to be scheduled within their arrival time and deadline, and the goal is to minimize the total energy consumption required to process these jobs. Albers et. al. proved the NP-hardness of this problem by reducing an instance of an NP-hard partition problem to an instance of this scheduling problem. The instance of this scheduling problem consists of the arrival time, the deadline and the processing volume for each of the jobs, in addition to $P$ and $C$. Since $P$ and $C$ depend on the instance of the partition problem, this proof of the NP-hardness of the speed scaling with sleep state problem doesn't remain valid when $P$ and $C$ are fixed. In this paper, we prove that the speed scaling with sleep state problem remains NP-hard for any fixed positive number $C$ and convex $P$ satisfying $P(0) &gt; 0$ and $P\"(s) &gt; 0$ for all values of $s$.","Object Categorization in Context Based on Probabilistic Learning of Classification Tree with Boosted Features and Co-occurrence StructureThis paper proposes a probabilistic method of object categorization in context through learning a classification tree with boosted features and co-occurrence structure. In this method, object classes are obtained for each scene category, a classification tree with boosted features is generated for all the object classes and co-occurrence is analyzed among object categories in scenes. In recognition, object categories in a scene are simultaneously determined based on a classification tree search using composite boosted features under co-occurrence constraint and a foreground object is inferred based on object category composition of scene categories. Through experiments using images of plural categories in an image data set, it is shown that object categorization performance is improved by using boosted features and co-occurrence structure, especially by using both of them.","TEXIVE: Detecting Drivers Using Personal Smart Phones by Leveraging Inertial SensorsIn this work, we address a fundamental and critical task of detecting the behavior of driving and texting using smartphones carried by users. We propose, design, and implement TEXIVE that leverages various sensors integrated in the smartphone and realizes our goal of distinguishing drivers and passengers and detecting texting using rich user micro-movements and irregularities that can be detected by sensors in the phone before and during driving and texting. Without relying on external infrastructure, TEXIVE has an advantage of being readily implemented and adopted, while at the same time raising a number of challenges that need to be carefully addressed for achieving a successful detection with good sensitivity, specificity, accuracy, and precision. Our system distinguishes the driver and passengers by detecting whether a user is entering a vehicle or not, inferring which side of the vehicle s/he is entering, reasoning whether the user is siting in front or rear seats, and discovering if a user is texting by fusing multiple evidences collected from accelerometer, magnetometer, and gyroscope sensors. To validate our approach, we conduct extensive experiments with several users on various vehicles and smartphones. Our evaluation results show that TEXIVE has a classification accuracy of 87.18%, and precision of 96.67%.","User Authentication for Mobile DevicesThe paper is intended as a short review of user authentication problem for mobile devices. The emphasis is put on smartphones and tablets, that nowadays are very similar to miniaturized personal computers with much more sensors of various origin. The sensors are described with remarks on their usefulness for user authentication. Deficiencies of traditional user authentication methods based on knowledge are pointed out and the need for new \u2013 more secure but also comfortable \u2013 user authentication mechanisms is reasoned. Preliminary user authentication systems employing biometric features are discussed and hence the generally unused potential of biometrics for mobile devices is demonstrated.","Sustainable Supply Chain Management through Compliance of Stakeholders\u2019 Requirements: A Study on Ready-Made Garment (RMG) Industry of Bangladesh ","An Interface Model of Software Components ","Rapid Development of Civic Computing Services: Opportunities and ChallengesDesigning the right computing service for citizens can be extremely difficult without participatory and iterative service development processes. We discuss opportunities and challenges for quick, participatory service development by citizens, based on our experiences with two experimental context-aware services.","Strategy for the Development of a Walk-In-Place Interface for Virtual RealityMany features of a Virtual Reality system can influence the immer- sion and the sense of presence. Navigation is one of those features, since pro- prioceptive and vestibular cues can have a positive impact on immersion and sense of presence. This is especially important for studies about human beha- vior, where behavioral responses should be as close as in the real world. Differ- ent types of interfaces are been developed to be more natural and closer to mov- ing in a real environment. A Walk-In-Place (WIP) interface can be used in small rooms and gives some proprioceptive and vestibular cues. A participant walks in the same place and a device captures that movement and translates it to movement inside the Virtual Environment. This paper presents a strategy for implementing a WIP interface using only one inertial orientation sensor, placed above the knee, mainly about the calibration and real-time detection phases and the approach taken on direction changing.","Automatic Processing of Linguistic Data as a Feedback for Linguistic TheoryThe paper describes a method of identifying a set of inter- esting constructions in a syntactically annotated corpus of Czech - the Prague Dependency Treebank - by application of an automatic proce- dure of analysis by reduction to the trees in the treebank. The procedure clearly reveals certain linguistic phenomena that go beyond 'dependency nature' (and thus generally pose a problem for dependency-based for- malisms). Moreover, it provides a feedback indicating that the annota- tion of a particular phenomenon might be inconsistent. The paper contains discussion and analysis of individual phenomena, as well as the quantification of results of the automatic procedure on a subset of the treebank. The results show that a vast majority of sentences from the subset used in these experiments can be analyzed automatically and it confirms that most of the problematic phenomena belong to the language periphery.","The finest regular coarsening and recursively-regular subdivisionsWe generalize the notion of regular polyhedral subdivision of a point (or vector) configuration in a new direction. This is done after studying some related objects, like the finest regular coarsening and the regularity tree of a subdivision. Properties of these two objects are derived, which confer more structure to the class of non-regular subdivisions, relating them to its (in a sense) closest regular subdivision. We introduce the class of recursively-regular subdivisions and show that it is a proper superclass of the regular subdivisions and a proper subclass of the visibility-acyclic subdivisions. We also show that recursively-regular triangulations of a given configuration are in general not connected by geometric bistellar flips. Finally, some algorithms related to these new concepts are given and applications of the main results of the article are pointed out. In particular, relations to covering by floodlights, covering by homotheties, tensegrity of spider webs and a high-dimensional graph embedding problem are presented.","Pragmatic approach to cost benefit analysis of user centered designUser-centered design (UCD) is an effective method for understanding users' needs and improving usability. Introducing UCD to the existing development process increases new development activities, so it is important to analyze the cost benefits of UCD, but it is not clear how to measure the effectiveness of these benefits for actual projects in companies. It is not clear which analysis is more appropriate, quantitative or qualitative. We propose a pragmatic approach to analyzing the cost benefits of UCD. We analyzed the effectiveness of 22 projects in our company using this approach.","Human Computation in Electronic Literature ","Improvement of Oilfield Services Quality Through Concurrent Engineering Techniques ","Yablo Sequences in Truth TheoriesWe investigate the properties of Yablo sentences and for- mulas in theories of truth. Questions concerning provability of Yablo sentences in various truth systems, their provable equivalence, and their equivalence to the statements of their own untruth are discussed and answered.","Modelling Visual Appearance of HandwritingWe present an experimental validation of a model of hand- writing style that builds upon a neuro-computational model of motor learning and execution. We hypothesize that handwriting style emerges from the concatenation of highly automated writing movements, called invariants, that have been learned by the subject in correspondence to the most frequent sequence of characters the subject is familiar with. We also assume that the actual shape of the ink trace contains enough infor- mation to characterize the handwriting style. The experimental results on a data set containing genuine, disguised, and forged (both skilled and naive) documents show that the model is an effective tool for modeling intra-writer and inter-writers variability and provides quantitative esti- mation of the difference between handwriting styles that is in accordance with the difference in the visual appearance of the handwriting.","Routine use of the \"ADE scorecards\", an application for automated ADE detection in a general hospital. ","Configurations and couplings: an exploratory studyThis is an exploratory study to see if configurations that were coupled to an output variable could be found in data. The focus in this study was on the modal configurations, which are profiles of best fit for clusters, and their average cluster scores for an output variable. A multistage procedure explained in the paper below was applied to a crime dataset to identify the modal configurations for a sample of cities and towns of the USA and their links to the incidence of violent crime. Three coupled configurations were found including one that was indicative of an African American Configuration having the highest rate of violent crime followed by one indicative of a High Divorce Configuration and one indicative of an Economic Hardship Configuration. The results indicated that using this multistage procedure is feasible for finding modal configurations and their couplings in data. The advantages of this approach are discussed and future directions with the research are outlined.","An Adaptive Model Restarts HeuristicWe propose an adaptive heuristic for model restarts that aligns sym- metry breaking with the dynamic branching heuristic. Experiments show that this method performs very well compared to other symmetry breaking methods.","Virtual exhibitions on the web: from a 2d map to the virtual worldThe optimization of the process of implementing virtual exhibitions on the Web represents an interesting research area devoted to simplify the design and the production of virtual exhibitions, particularly for people with a scarce technical skill and strong competencies in the area to which the exhibition is related to.#R##N##R##N#In the present paper we propose a web environment facilitating the production of virtual exhibition through a series of operations: from the virtual representation of the physical structure, starting from the image of a 2D map that is processed to optimize the walls identification, to the management of the artworks shown in the exhibition, including the selection of the artworks and their positioning in the physical structure. Finally the virtual exhibition may be released to the visitors, making the virtual world available for the download on the client side.#R##N##R##N#Several technologies have been adopted in order to reach a user friendly backoffice environment, suitable for being used by naive (from the technology point of view) users, concentrated on the subject related to the virtual exhibition: the OpenCV library which make possible to produce the physical scenario in which the exhibition will take place evaluating the measures from 2D maps, the SVG graphic format per representing the map after having detected the boundaries of the provided 2D map, Ajax, X3D and X3DOM which enable the virtual environment representation.#R##N##R##N#As a testbed we present the virtual museum of Villa Fidelia in Spello, PG, Italy.","What's in a 'nym'? Synonyms in Biomedical Ontology MatchingTo bring the Life Sciences domain closer to a Semantic Web realization it is fundamental to establish meaningful relations between biomedical ontologies. The successful application of ontology matching techniques is strongly tied to an effective exploration of the complex and diverse biomedical terminology contained in biomedical ontologies. In this paper, we present an overview of the lexical components of several biomedical ontologies and investigate how different approaches for their use can impact the performance of ontology matching techniques. We propose novel approaches for exploring the different types of synonyms encoded by the ontologies and for extending them based both on internal synonym derivation and on external ontologies.#R##N##R##N#We evaluate our approaches using AgreementMaker, a successful ontology matching platform that implements several lexical matchers, and apply them to a set of four benchmark biomedical ontology matching tasks. Our results demonstrate the impact that an adequate consideration of ontology synonyms can have on matching performance, and validate our novel approach for combining internal and external synonym sources as a competitive and in many cases improved solution for biomedical ontology matching.","Verification of Golog Programs over Description Logic Actions ","Parameterized Digital Hardware Design of Pulse-Coupled Phase Oscillator Model toward Spike-Based Computing ","A short note on estimating intelligence from user profiles in the context of universal psychometrics: prospects and caveatsThere has been an increasing interest in inferring some personality traits from users and players in social networks and games, respectively. This goes beyond classical sentiment analysis, and also much further than customer profiling. The purpose here is to have a characterisation of users in terms of personality traits, such as openness, conscientiousness, extraversion, agreeableness, and neuroticism. While this is an incipient area of research, we ask the question of whether cognitive abilities, and intelligence in particular, are also measurable from user profiles. However, we pose the question as broadly as possible in terms of subjects, in the context of universal psychometrics, including humans, machines and hybrids. Namely, in this paper we analyse the following question: is it possible to measure the intelligence of humans and (non-human) bots in a social network or a game just from their user profiles, i.e., by observation, without the use of interactive tests, such as IQ tests, the Turing test or other more principled machine intelligence tests?","A Virtual Patient to Assess Pediatric Intensive Care Unit (PICU) Nurses\u2019 Pain Assessment and Intervention PracticesPediatric intensive care (PICU) nurses play a crucial role in managing children's pain. While virtual patient (VP) technology has shown significant benefits in assisting with the practice of healthcare, there has been little research effort in this particular setting. This pa- per presents a pilot evaluation study to determine the validity of VP vignettes - including PICU nurses' recognition of the facial expressions (smiling and grimacing) of VPs and nurses' descriptions as to whether the VP vignettes are consistent with their professional experiences. The results of our initial study (n=20) confirm that nurses identified given ex- pressions correctly (98.5%) and validated the similarity of the vignettes to their experiences with patients in the PICU (87%). A better under- standing of nurses' pain management practices will aid the development of future VP interventions.","A Comparative Study to Determine the Effective Window Size of Turkish Word Sense Disambiguation Systems ","Opaque Indifference and Corporate Social Responsibility: A Moral License for Offshore BPO?Offshore Business Process Outsourcing (OBPO) is the delegation of one or more business processes to an external service provider (usually a global in-house centre or a third party). The focus of OBPO research is often the cost benefits of global BPO services. As demands by stakeholders for organisational justification of OBPO decisions and activities increase, reducing resistance to OBPO, particularly where global in-house centres provide services to onshore end-users, requires managing attitudes to OBPO in the community. Improving an organisation\u2019s Social License to Operate relies on the community of stakeholders tacitly approving an organisation\u2019s activities, based on acceptance of organisation\u2019s legitimacy and ethics. The concept of \u2018opaque indifference\u2019 (OI) and corporate social responsibility both play a role in improving end-user and stakeholder satisfaction and acceptance of OBPO.","Recognizing Outer 1-Planar Graphs in Linear TimeA graph is outer 1-planar o1p if it can be drawn in the plane such that all vertices are on the outer face and each edge is crossed at most once. o1p graphs generalize outerplanar graphs, which can be recognized in linear time and specialize 1-planar graphs, whose recognition is    $\\mathcal{NP}$   -hard.#R##N##R##N#Our main result is a linear-time algorithm that first tests whether a graphi\u00be?G is o1p, and then computes an embedding. Moreover, the algorithm can augment G to a maximal o1p graph. If G is not o1p, then it includes one of six minors see Fig. 3, which are also detected by the recognition algorithm. Hence, the algorithm returns a positive or negative witness for o1p.","A hybrid model for an e-learning system which develops metacognitive skills at studentsOne of the goals of academic education is to train students in view of acquiring metacognitive skills, thus becoming self-regulated learners prepared for for lifelong learning. The research in this area has proved that metacognition can be taught and learned and that self-regulation behavior can be guided and constrained by the features of the learning environment. In order to become an educational environment, attractive and at the same time efficient for the students and which would enable students to develop their metacognitive skills, the e-learning system needs continuous improvments. This paper presents a hybrid model of an e-learning system, MEM - Metacognitive E-learning system Model, which aims to develop metacognitive skills in students, based on three learning principles of the InTime model, principles which are adapted from Peter Ewell's point of view regarding the complexity of the learning process, and on the metacognitive regulations.","Towards automated deployment of distributed adaptation systemsThe development of a single software product is inefficient when groups of product are related since the development cost could be high. In addition, some products need to be self-adaptive in order to take into account the execution context changes. In this case, the implementation and management of the adaptation mechanisms variability is challenging especially for distributed systems due to the distribution issues. We address in this paper such issues by proposing a method for the software engineering of distributed adaptation systems. We propose an architectural model for distributed management of dynamic adaptation. We define also a graph grammar based approach to automate the tasks needed to construct and configure the adaptation system.","Cloudwave: distributed processing of \"big data\" from electrophysiological recordings for epilepsy clinical research using Hadoop.Epilepsy is the most common serious neurological disorder affecting 50\u201360 million persons worldwide. Multi-modal electrophysiological data, such as electroencephalography (EEG) and electrocardiography (EKG), are central to effective patient care and clinical research in epilepsy. Electrophysiological data is an example of clinical \u201cbig data\u201d consisting of more than 100 multi-channel signals with recordings from each patient generating 5\u201310GB of data. Current approaches to store and analyze signal data using standalone tools, such as Nihon Kohden neurology software, are inadequate to meet the growing volume of data and the need for supporting multi-center collaborative studies with real time and interactive access. We introduce the Cloudwave platform in this paper that features a Web-based intuitive signal analysis interface integrated with a Hadoop-based data processing module implemented on clinical data stored in a \u201cprivate cloud\u201d. Cloudwave has been developed as part of the National Institute of Neurological Disorders and Strokes (NINDS) funded multi-center Prevention and Risk Identification of SUDEP Mortality (PRISM) project. The Cloudwave visualization interface provides real-time rendering of multi-modal signals with \u201cmontages\u201d for EEG feature characterization over 2TB of patient data generated at the Case University Hospital Epilepsy Monitoring Unit. Results from performance evaluation of the Cloudwave Hadoop data processing module demonstrate one order of magnitude improvement in performance over 77GB of patient data. (Cloudwave project: http://prism.case.edu/prism/index.php/Cloudwave)","Information geometry of influence diagrams and noncooperative gamesWhat is the \"value of information\" in non-cooperative games with imperfect information? To answer this question, we propose to quantify information using concepts from Shannon's information theory. We then relate quantitative changes to the information structure of a game to changes in the expected utility of the players. Our approach is based on the Multi-Agent Influence Diagram representation of games. We develop a generalization of the concept of marginal utility in decision scenarios to apply to infinitesimal changes of the channel parameters in noncooperative games. Using that framework we derive general conditions for negative value of information, and show that generically, these conditions hold in all games unless one imposes a priori constraints on the allowed changes to information channels. In other words, in any game in which a player values some aspect of the game's specification beyond the information provided in that game, there will be an infinitesimal change to the parameter vector specifying the game that increases the information but hurts the player. Furthermore, we derive analogous results for N &gt; 1 players, i.e., state general conditions for negative value of information simultaneously for all players. We demonstrate these results numerically on a decision problem as well as a leader-follower game and discuss their general implications.","LinDA: A Service Infrastructure for Linked Data Analysis and Provision of Data Statistics ","Evaluating comfort levels of a workstation with an individually controlled heating and lighting systemComfort complaints, such as high or low temperatures, lack of privacy and concentration loss, are regularly reported in today's offices. Most comfort aspects, such as lighting, ventilation, decoration and climate are regulated on global level, while for optimal comfort experience customized settings on personal level is desired, which requires a more direct personal control. A method is described to evaluate comfort levels of a workstation with individually controlled radiant heating and lighting. The aim is to examine the band-width of peoples' comfort zone of radiant temperature and illumination when doing office work.","Handover Performance Evaluation of 4G Mobile Networks ","Improved clustering for intrusion detection by principal component analysis with effective noise reductionPCA (Principal Component Analysis) is one of the most wildly used dimension reduction technique, which is often applied to identify patterns in complex data of high dimension [1]. In GA-KM [2], we have proposed GA-KM algorithm and have experimented using KDD-99 data set. The result showed GA-KM is efficient for intrusion detection. However, due to the hugeness of the data set, the experiment needs to take a long time to finish. To solve this deficiency, we combine PCA and GA-KM in this paper. The goal of PCA is to remove unimportant information like the noise in data sets which have high dimension, and retain the variation present in the original dataset as much as possible. The experimental results show that, compared to GA-KM [2], the proposed method is better in computational expense and time (through dimension reduction) and is also better in intrusion detection ratios (through noise reduction).","Residue Classes of the PPT SequencePrimitive Pythagorean triples (PPT) may be put into different equivalence classes using residues with respect to primes. We show that the probability that the smaller odd number associated with the PPT triple is divisible by prime p is 2/(p+1). We have determined the autocorrelation function of the Baudhayana sequences obtained from the residue classes and we show these sequences have excellent randomness properties. We provide analytical explanation for the peak and the average off-peak values for the autocorrelation function. These sequences can be used specifically in a variety of key generation and distribution problems and, more generally, as pseudorandom sequences.","Public Announcements, Private Actions and Common Knowledge in S5 StructuresIn this paper we take the S5 definition of knowledge, and have a new look at logics combining modalities for public announcements, action models, common knowledge and relativized common knowledge. In particular, we prove two expressivity results which previously have only been shown for the case where knowledge is represented using arbitrary Kripke models but have remained open for the case of S5 models: public announcement logic with relativized common knowledge is strictly more expressive than public announcement logic with common knowledge, and action model logic with common knowledge is strictly more expressive than public announcement logic with common knowledge. We also propose and study a definition of relativized common knowledge for action model logic.","Law enforcement in norm-governed learning agentsWe study law enforcement mechanisms within a population of norm-governed learning agents. We show that a traditional analysis based on expected utility can be misleading, because learning agents tend to comply even though their surveillance is stopped. This has significant implications for the design of self-organising institutions with endogenous resources, where the cost of monitoring and norm enforcement has to be taken into consideration.","Access control in multi-party wireless sensor networksEmerging real world WSNs seldom exist as single owner, single application, isolated networks, but instead comprise of sensor nodes owned by multiple parties. These sensors offer multiple services to users locally or across the Internet, and travel between multiple WSNs. However, users should only have access to a limited subset of services. Due to a need for direct interactions of users with nodes, authentication and authorisation at the node level is critical. This paper presents an access control infrastructure consisting of three parts: 1) an authentication protocol to ensure authenticity of messages, 2) a role based authorisation framework to perform access control, and 3) a user management service to enable user and permission management. A prototype implementation on the ContikiOS demonstrates the validity and feasibility of node local role based access control on low power micro-controllers.","Identification of postural transitions using a waist-located inertial sensorAnalysis of human movement is an important research area, specially for health applications. In order to assess the quality of life of people with mobility problems like Parkinson's disease (PD) or stroke patients, it is crucial to monitor their daily life activities. The main goal of this work is to characterize basic activities and their transitions using a single sensor located at the waist. This paper presents a novel postural detection algorithm which is able to detect and identify 6 different postural transitions, sit to stand, stand to sit, bending up/down and lying to sit and sit to lying transitions with a sensitivity of 86.5% and specificity of 95%. The algorithm has been tested on 31 healthy volunteers and 8 PD patients who performed a total of 545 and 176 transitions respectively. The proposed algorithm is suitable to be implemented in real-time systems for on-line monitoring applications.","LO-C(L)A(S)P: a Model for Supporting the Development of Learning Objects with Sound Manipulation and Social Resources for Music EducationIn this paper we describe a model for supporting the development of learning objects that are closer to the music domain and to the student\u2019s digital social reality. A case study considering a music education activity, which was created using the proposed model, was conducted with high school students to demonstrate the applicability and benefits of our approach. Results show the importance of considering the proposed model on guiding courseware development for music education. Moreover, it was noticed that students perceive social and sound integrated resources as important elements on their learning process.","R/quest: A Question Answering SystemIn this paper, we discuss our novel, open-domain question answering Q/A system, R/quest. We use web page snippets from GoogleTM to extract short paragraphs that become candidate answers. We performed an evaluation that showed, on average, 1.4 times higher recall and a slightly higher precision by using a question expansion method. We have modified the Cosine Coefficient Similarity Measure to take into account the rank position of a candidate answer and its length. This produces an effective ranking scheme. We have a new question refinement method that improves recall. We further enhanced performance by adding a Boolean NOT operator. R/quest on average provides an answer within the top 2 to 3 paragraphs shown to the user. We consider this to be a considerable advance over search engines that provide millions of ranked web pages which must be searched manually to find the information needed.","Statistical and Constraint Programming Approaches for Parameter Elicitation in Lexicographic Ordering ","Certified Parsing of Regular LanguagesWe report on a certified parser generator for regular languages using the Agda programming language. Specifically, we programmed a transformation of regular expressions into a Boolean-matrix based representation of nondeterministic finite automata (NFAs). And we proved (in Agda) that a string matches a regular expression if and only if the NFA accepts it. The proof of the if-part is effectively a function turning acceptance of a string into a parse tree while the only-if part gives a function turning rejection into a proof of impossibility of a parse tree.","Unlinkable content playbacks in a multiparty DRM systemWe present a solution to the problem of privacy invasion in a multiparty digital rights management scheme. (Roaming) users buy content licenses from a content provider and execute it at any nearby content distributor. Our approach, which does not need any trusted third party--in contrast to most related work on privacy-preserving DRM--is based on a re-encryption scheme that runs on any mobile Android device. Only a minor security-critical part needs to be performed on the device's smartcard which could, for instance, be a SIM card.","Damping sentiment analysis in online communication: discussions, monologs and dialogsSentiment analysis programs are now sometimes used to detect patterns of sentiment use over time in online communication and to help automated systems interact better with users. Nevertheless, it seems that no previous published study has assessed whether the position of individual texts within on-going communication can be exploited to help detect their sentiments. This article assesses apparent sentiment anomalies in on-going communication --- texts assigned significantly different sentiment strength to the average of previous texts --- to see whether their classification can be improved. The results suggest that a damping procedure to reduce sudden large changes in sentiment can improve classification accuracy but that the optimal procedure will depend on the type of texts processed.","Fourier spectral of PalmCode as descriptor for palmprint recognitionStudy on automatic person recognition by palmprint is currently a hot topic. In this paper, we propose a novel palmprint recognition method by transforming the typical palmprint phase code feature into its Fourier frequency domain. The resulting real-valued Fourier spectral features are further processed by horizontal and vertical 2DPCA method, which proves highly efficient in terms of computational complexity, storage requirement and recognition accuracy. This paper also gives a contrast study on palm code and competitive code under the proposed feature extraction framework. Besides, experimental results on the Hongkong PolyU Palmprint database demonstrate that the proposed method outperforms many currently reported local Gabor pattern approaches for palmprint recognition.","A Genetic Algorithm-Evolved 3D Point Cloud DescriptorIn this paper we propose a new descriptor for 3D point clouds that is fast when compared to others with similar performance and its parameters are set using a genetic algorithm. The idea is to obtain a descriptor that can be used in simple computational devices, that have no GPUs or high computational capabilities and also avoid the usual time-consuming task of determining the optimal parameters for the descriptor. Our proposal is compared with other similar algorithms in a public available point cloud library PCL [1]. We perform a comparative evaluation on 3D point clouds using both the object and category recognition performance. Our proposal presents a comparable performance with other similar algorithms but is much faster and requires less disk space.","Qualitative study for designing peripheral communication between hospitalized children and their family membersThis paper describes an effort to develop a new communication supporting environment which engenders a greater sense of social proximity among geographically distributed families, particularly between hospitalized children and their families. We conducted a qualitative study including two in-depth field interviews with in-hospital school teachers and the mother of a hospitalized child. The results from qualitative analysis provided us with insight into the organization of the interactions between the hospitalized child and the family. On the basis of the results, we established a set of design principles and developed four different types of technology prototypes for peripheral communication. The design principles played a splicing role in binding the heterogeneous processes of qualitative research and the development of prototypes. Future works involve the enhancement of design principles and prototypes, and methodological improvements.","Next Generation of Physical Training Environments: Bringing in Sensor Systems and Virtual Reality Technologies ","The Leader Company\u2019s Innovation Strategy and its Role Within the Aerospace Industry in Sao Jose Dos Campos: Brazil ","User-Managed Access Control in Web Based Social Networks ","A Potential Technological Solution for Reducing the Achievement Gap Between White And Black Students ","Outlier gene set analysis combined with top scoring pair provides robust biomarkers of pathway activityCancer is a disease driven by pathway activity, while useful biomarkers to predict outcome (prognostic markers) or determine treatment (treatment markers) rely on individual genes, proteins, or metabolites. We provide a novel approach that isolates pathways of interest by integrating outlier analysis and gene set analysis and couple it to the top-scoring pair algorithm to identify robust biomarkers. We demonstrate this methodology on pediatric acute myeloid leukemia (AML) data. We develop a biomarker in primary AML tumors, demonstrate robustness with an independent primary tumor data set, and show that the identified biomarkers also function well in relapsed AML tumors.","The Evaluation of Online Social Network\u2019s Nodes Influence Based on User\u2019s Attribute and Behavior ","The IMPL Policy Language for Managing Inconsistency in Multi-Context SystemsMulti-context systems are a declarative formalism for inter- linking knowledge-based systems (contexts) that interact via (possibly nonmonotonic) bridge rules. Interlinking knowledge provides ample op- portunity for unexpected inconsistencies. These are undesired and come in different categories: some may simply be repaired automatically, while others are more serious and must be inspected by a human operator. In general, no one-fits-all solution exists, since these categories depend on the application scenario. To nevertheless tackle inconsistencies in a gen- eral and principled way, we thus propose a declarative policy language for inconsistency management in multi-context systems. We define its syntax and semantics, discuss methodologies for applying the language in real world applications, and outline an implementation by rewriting to acthex , a formalism extending Answer Set Programs.","Dimensionality reduction via isomap with lock-step and elastic measures for time series gene expression classificationIsometric feature mapping (Isomap) has proven high potential for nonlinear dimensionality reduction in a wide range of application domains. Isomap finds low-dimensional data projections by preserving global geometrical properties, which are expressed in terms of the Euclidean distances among points. In this paper we investigate the use of a recent variant of Isomap, called double-bounded tree-connected Isomap (dbt-Isomap), for dimensionality reduction in the context of time series gene expression classification. In order to deal with the projection of temporal sequences dbt-Isomap is combined with different lock-step and elastic measures which have been extensively proposed to evaluate time series similarity. These are represented by three      $\\mathcal L_p$  -norms, dynamic time warping and the distance based on the longest common subsequence model. Computational experiments concerning the classification of two time series gene expression data sets showed the usefulness of dbt-Isomap for dimensionality reduction. Moreover, they highlighted the effectiveness of      $\\mathcal L_1$  -norm which appeared as the best alternative to the Euclidean metric for time series gene expression embedding.","PRocH: proof reconstruction for HOL lightPRocH is a proof reconstruction tool that imports in HOL Light proofs produced by ATPs on the recently developed translation of HOL Light and Flyspeck problems to ATP formats. PRocH combines several reconstruction methods in parallel, but the core improvement over previous methods is obtained by re-playing in the HOL logic the detailed inference steps recorded in the ATP (TPTP) proofs, using several internal HOL Light inference methods. These methods range from fast variable matching and more involved rewriting, to full first-order theorem proving using the MESON tactic. The system is described and its performance is evaluated here on a large set of Flyspeck problems.","Optimal L(\u03b41, \u03b42, 1)-labeling of eight-regular gridsAbstract   Given a graph   G  =  (  V  ,  E  )  , an   L  (    \u03b4    1    ,    \u03b4    2    ,    \u03b4    3    )  -labeling is a function  f  assigning to nodes of  V  colors from a set   {  0  ,  1  ,  \u2026  ,    k    f    }   such that   |  f  (  u  )  \u2212  f  (  v  )  |  \u2a7e    \u03b4    i     if  u  and  v  are at distance  i  in  G . The aim of the   L  (    \u03b4    1    ,    \u03b4    2    ,    \u03b4    3    )  -labeling problem consists in finding a coloring function  f  such that the value of     k    f     is minimum. This minimum value is called     \u03bb      \u03b4    1    ,    \u03b4    2    ,    \u03b4    3      (  G  )  .  In this paper we study this problem on the eight-regular grids for the special values   (    \u03b4    1    ,    \u03b4    2    ,    \u03b4    3    )  =  (  3  ,  2  ,  1  )   and   (    \u03b4    1    ,    \u03b4    2    ,    \u03b4    3    )  =  (  2  ,  1  ,  1  )  , providing optimal labelings. Furthermore, exploiting the lower bound technique, we improve the known lower bound on     \u03bb    3  ,  2  ,  1     for triangular grids.","A Multicast Authentication Protocol (MAP) for Dynamic Multicast Groups in Wireless Networks ","On XML Document Transformations as Schema Evolves: A Survey of Current Approaches ","Ouch! How Embodied Damage Indicators in First-Person Shooting Games Impact Gaming ExperienceIn this paper we present results from an exploratory study on first-person shooting game damage indicators, comparing a red flash, a paper doll, and an x-ray mechanism, observing impact on gaming experience.","Characterization of Cancer and Normal Intracellular Images by the Power Law of a Fuzzy Partition FunctionalThe discovery of detailed structures of spatial organelles within a single cell obtained by state-of-the-art molecular imaging tech- nology has provided essential biological information for gaining insights into the study of complex human diseases. In particular, such informa- tion is helpful for cancer modeling and simulation. This paper presents a novel concept for characterizing the intracellular space of cancer and normal cells using the mathematical principle of power laws applied to a fuzzy partition functional for cluster validity. Experimental results and comparison with image texture analysis suggest the promising applica- tion of the proposed method.","Detection of Human Retina Images Suspect of Glaucoma through the Vascular Bundle Displacement in the Optic Disc ","Towards a Strategy Design Method for Corporate Data Quality ManagementLarge, multidivisional enterprises need corporate data of high quality in order to meet a number of strategic business requirements, such as enterprise- wide process harmonization, integrated customer management or compliance. Therefore, many enterprises today are in the process of establishing Corporate Data Quality Management (CDQM), which requires an overarching CDQM strategy. This paper presents a method for the development and implementation of a CDQM strategy. On the one hand the method provides guidance to a CDQM team. On the other hand, for corporate executives the method ensures that the CDQM strategy is derived from their objectives and that their require- ments are systematically taken into account and fulfilled. Besides the method it- self, the paper illustrates the entire design process which encompasses, among others, focus group and expert interviews, participative case studies and a multi- perspective evaluation.","Automatic refinement of service compositionsWe propose a method for the automatic refinement of web service compositions: given a composite web service specification over abstract modules, our method generates lower-level versions of this composition. The refinement process is based on query rewriting techniques extended to take into account not only functional and non-functional requirements but also semantic information. Experimental results illustrate the performance and scalability of the method.","PhotoLoop: Implicit Approach for Creating Video Narration for SlideshowPeople often have difficulty in browsing a massive number of pictures. To solve this problem, we focused on the activities of people who share slideshows with their friends: that is, they often talk about the each picture shown on the display. We think these activities are useful as narrations for the slideshows. Therefore, we propose a novel slideshow system, PhotoLoop, which can automatically capture people's activities while watching slideshows using video/audio recordings and integrates them slideshows and video narrations to create attractive contents. In this paper, first, we describe people's behavior while watching slideshows. Next, we present the PhotoLoop prototype based on our observations. Finally, we confirm the effectiveness of the system through evaluation and discussion.","People-Centered Software Development: An Overview of Agile Methodologies ","Learning a Bounded-Degree Tree Using Separator QueriesSuppose there is an undirected tree T containing n nodes and having bounded degree d. We know the nodes in T but not the edges. The problem is to output the tree T by asking queries of the form: \"Does the node y lie on the path between node x and node z?\". In other words, we can ask if removing node y disconnects node x from node z. Such a query is called a separator query. Assume that each query can be answered in constant time by an oracle. The objective is to minimize the time taken to output the tree in terms of n. Our main result is an O(dn 1.5 log n) time algorithm for the above","Recent Progress on Object Classification and DetectionObject classification and detection are two fundamental prob- lems in computer vision and pattern recognition. In this paper, we discuss these two research topics, including their backgrounds, challenges, recent progress and our solutions which achieve excellent performance in PAS- CAL VOC competitions on object classification and detection. Moreover, potential directions are outlined for future research.","Extracting Blood Vessel in Sclera-Conjunctiva Image Based on Fuzzy C-means and Modified Cone Responses ","Application of Local Binary Pattern to Windowed Nonlocal Means Image Denoising ","An example of an application of the semiotic inspection method in the domain of computerized patient record system.Efficiently navigating through an interface and conducting work tasks in flow is what GUI designers strive for. Dental professionals, who alternate between examination and treat-ment of a patient and insertion of data into the Computerized Patient Record system, particularly need an interface that would facilitate the workflow. In this paper we present an in-spection evaluation of an existing and widely used Computer-ized Patient Record system. The Semiotic Inspection Method was applied with the expectation that the method could pro-vide evidence that task flow, navigation and wayfinding were major usability issues of the interface. Also expected was that the Semiotic Inspection would reveal the means and strategies used in the interface in order to communicate the flow. The analysis conducted using the Semiotic Inspection Method showed inconsistencies in the communication of the way for-ward through the interface. In addition, the profile of the us-ers, regarding digital skills, appears to be ambiguous. Finally, the strategies used in the interface for conveying the workflow could be identified as well.","A New Contract between Business and Business AnalystsSince the advent of business processes management it has been recognized that its main objective is optimization of enterprise\u2019s performance. However, the focus of business analysis has changed significantly over the years. Initially business analysts focused on discovery and modelling of business processes. They aimed to identify opportunities for application of information technologies in business process automation and to determine resources needed for business process execution. More recently, the attention has shifted towards business process monitoring and optimization, while the current trends concern with business process intelligence for agile decision-making. Businesses expect that the business analysts will identify opportunities for continuous business process improvement by providing contextualized, high quality and secure information. In the light of these new business expectations, the keynote speech identifies today\u2019s challenges faced by the business analysts and describes the current practice in dealing with these challenges.","Tracking Behavioral Construct Use through Citations: A Relation Extraction ApproachThe ever-increasing number of publications in the behavioral sciences has yielded a large set of behavioral theories, constructs and their relationships. In this study, we propose a novel method to discover this data set through construct-level citations. In behavioral science, the reuse, adaptation and modification of an existing behavioral construct often requires an explicit citation. However, finding the construct-level citations are not trivial, since citations are at the paper level of analysis. Based on stateof-the-art information extraction techniques, we propose an automatic construct-level citation extraction method, which consists of five steps: article crawling, article annotation, citation extraction, construct extraction and referring relation extraction. Serving as a proof-of-concept, our method is applied to a data set consisting of publication of two Information Systems journals, and is evaluated against human decisions. The initial results represent a promising opportunity of the application of our proposed method to a large set of behavioral publications.","Multiobjective Differential Evolution Algorithm Using Binary Encoded Data in Selecting Views for Materializing in Data WarehouseIn this paper, we define the view selection process for materializing in data warehouse as a multiobjective optimization problem. We have implemented multiobjective Differential Evolution (DE) algorithm for binary encoded data to solve this problem. In our approach, to control population in intermediate generations of the differential evolution process by maintaining diversity in solution space with necessary elitism, the solutions of intermediate generations are first ranked according to their pareto dominance levels and then the diversity among solution vectors in solution space is measured. The algorithm is found to be suitable in selecting significant representitive solutions from a large number of nondominating solutions of the view selection problem.","Proximity and Motion Planning on \u21131-Rigid Planar Periodic Graphs ","How Supply Chain Governance Influences Information Sharing Behaviors: A Multiple Case Study Approach ","A Novel Intrusion Tolerant System Based on Adaptive Recovery Scheme (ARS) ","Optimizing Classroom Environment to Support Technology Enhanced Learning ","Mining Maximal Sequential Patterns without Candidate Maintenance ","A genealogical study of the origin of pashtunsThe study of the descent of different races and the investigation of their common ancestors has been of the interest of different disciplines since long. With the advancement of the genetic studies in the recent decades, the researchers have been attracted to utilize the potential of the genealogical studies to find the origin of different races of the world. The origin of Pashtuns is not is one of the most disputed both among historians and pashtuns themselves. This study aims to investigate about the origin of the Pashtuns based on the hypothesis drawn from the most popular claims. The genetic data for the 718 unrelated male subjects was studied. 16 Y-STR binary markers were used in this study. AMOVA was carried out for the data by using the YHRD online service and haplotype search was also carried out using YHRD. The results obtained are compared with the previously conducted similar studies.","The Pairwise Piecewise-Linear Embedding for Efficient Non-Linear ClassificationLinear classifiers are much faster to learn and test than non-linear ones. On the other hand, non-linear kernels offer improved performance, albeit at the increased cost of training kernel classifiers. To use non-linear mappings with efficient linear learning algorithms, explicit embeddings that approximate popular kernels have recently been proposed. However, the embedding process is often costly and the results are usually less accurate than kernel methods. In this work we propose a non-linear feature map that is both very efficient, but at the same time highly expressive. The method is based on discretization and interpolation of individual features values and feature pairs. The discretization allows us to model different regions of the feature space separately, while the interpolation preserves the original continuous values. Using this embedding is strictly more general than a linear model and as efficient as the second-order polynomial explicit feature map. An extensive empirical evaluation shows that our method consistently outperforms other methods, including a wide range of kernels. This is in contrast to other proposed embeddings that were faster than kernel methods, but with lower accuracy.","Zero-Sum Flow Numbers of Hexagonal GridsAs an analogous concept of nowhere-zero flows for directed and bi-directed graphs, we consider zero-sum flows for undirected graphs in this article. For an undirected graph G ,a zero-sum k-flow is an as- signment of non-zero integers whose absolute values less than k to the edges, such that the sum of the values of all edges incident with each vertex is zero. Furthermore we generalize the notion via considering a combinatorial optimization problem, which is to calculate the zero-sum minimum flow number of a graph G, namely, the least integer k for which G may admit a zero-sum k-flow. The Zero-Sum 6-Flow Con- jecture was raised by Akbari et al. in 2009: If a graph with a zero-sum flow, it admits a zero-sum 6-flow. It turns out that this conjecture was proved to be equivalent to the classical Bouchet 6-flow conjecture for bi- directed flows. In this paper, we study zero-sum minimum flow numbers of graphs induced from plane tiling by regular hexagons in an arbitrary way, namely, the hexagonal grid graphs. In particular we are able to verify the Zero-Sum 6-Flow Conjecture for the class of hexagonal grid graphs by determining the zero-sum flow number of any non-trivial hexagonal grid graph is 3 or 4. We further use the concept of dual graphs to specify classes of infinite families of hexagonal grid graphs with min- imum flow numbers 3 and 4 respectively. Further open problems are included.","A Method to Solve the Traveling Salesman Problem Using Ant Colony Optimization Variants with Ant Set Partitioning ","A survey of web archive search architecturesWeb archives already hold more than 282 billion documents and users demand full-text search to explore this historical information. This survey provides an overview of web archive search architectures designed for time-travel search, i.e. full-text search on the web within a user-specified time interval. Performance, scalability and ease of management are important aspects to take in consideration when choosing a system architecture. We compare these aspects and initialize the discussion of which search architecture is more suitable for a large-scale web archive.","Asymmetry as a Measure of Visual SaliencyA salient image region is defined as an image part that is clearly different from its surround in terms of a number of attributes. In bottom-up processing, these attributes are defined as: contrast, color difference, brightness, and orientation. By measuring these attributes, visual saliency algorithms aim to predict the regions in an image that would attract our attention under free viewing conditions, i.e., when the observer is viewing an image without a specific task such as searching for an object. To quantify the interesting locations in a scene, the output of the visual saliency algorithms is usually expressed as a two dimensional gray scale map where the brighter regions correspond to the highly salient regions in the original image. In addition to advancing our understanding of human visual system, visual saliency models can be used for a number of computer vision applications. These applications include: image compression, computer graphics, image matching &amp; recognition, design, and human-computer interaction.In this thesis the main contributions can be outlined as: first, we present a method to inspect the performance of Itti\u2019s classic saliency algorithm in separating the salient and non-salient image locations. Based on our results we observed that, although the saliency model can provide a good discrimination for the highly salient and non-salient regions, there is a large overlap between the locations that lie in the middle range of saliency. Second, we propose a new bottom-up visual saliency model for static two-dimensional images. In our model, we calculate saliency by using the transformations associated with the dihedral group D4. Our results suggest that the proposed saliency model outperforms many state-of-the-art saliency models. By using the proposed methodology, our algorithm can be extended to calculate saliency in three-dimensional scenes, which we intend to implement in the future. Third, we propose a way to perform statistical analysis of the fixations data from different observers and different images. Based on the analysis, we present a robust metric for judging the performance of the visual saliency algorithms. Our results show that the proposed metric can indeed be used to alleviate the problems pertaining to the evaluation of saliency models. Four, we introduce a new approach to compress an image based on the salient locations predicted by the saliency models. Our results show that the compressed images do not exhibit visual artifacts and appear to be very similar to the originals. Five, we outline a method to estimate depth from eye fixations in three-dimensional virtual scenes that can be used for creating so-called gaze maps for three-dimensional scenes. In the future, this can be used as ground truth for judging the performance of saliency algorithms for three-dimensional images.We believe that our contributions can lead to a better understanding of saliency, address the major issues associated with the evaluation of saliency models, highlight on the contribution of top-down and bottom-up processing based on the analysis of a comprehensive eye tracking dataset, promote use of human vision steered image processing applications, and pave the way for calculating saliency in three-dimensional scenes.","The influence of emergent technologies on decision-making processes in virtual teams. ","Human Error in Aviation: The Behavior of Pilots Facing the Modern TechnologyAbstract. All the official records of aircraft accidents investigated by official preventing and detecting agencies always has concluded that the human as guilty or as a major component in accidents, a rate close to eighty percent. One must consider that the pilot receives an artifact that started its manufacturing project a few years before being delivered into his hands. He is now responsible for keeping it in the air, safely, weighing 50,000 pounds or more and carrying five tonnes of highly flammable fuel and has about two hundred people aboard. This complex machine depends on the perfect working condition. Human beings are fallible and aviation history shows that these devices have and will continue presenting defects. Innserido this way for technical perfection and operating the aircraft, the pilot is invariably, in the end, is the one who is always within the artifact when it crashes and usually pay a high price: his life. Keywords: Mental Health Pilots, modern technology in aviation.","Using subtree agreement for complex tree integration tasksHierarchical structures are common in modern applications. Tree integration is one of the tools for them that is not fully researched. We define a complex tree to model other common hierarchical structures. Complex tree integration is parametrized by specific integration criteria. Sub-tree agreement is a group of criteria that describes the relation of sub-tree number and structure between input trees and the integrated tree. This paper provides several definitions of sub-tree agreement, the most important properties of these criteria, and examples of algorithms based on sub-tree agreement.","Causal attribution and control: between consciousness and psychical half-shadow application to flight operationsThe key of the development of HMI technologies lies in the acquisition of knowledge and the integration of disciplines by industrials that are in the scope of cognitive neurosciences. The purpose of this paper is to provide new models to be applied in human centered design loops for cockpit in aeronautics. Two different problems are introduced: (1) the purpose of consciousness in action control, (2) the transformation induced by automation in term of agency. For each of this problem, we detail how the problem is currently tackled by cognitive ergonomics society, and how neurosciences could help in the comprehension of the different mechanisms involved. Perspectives are proposed for each of this issue.","Speech based Password Protected Cyber ApplicationsWhenever we think of cyber applications, we visualize the model that gives the idea that we are sitting in front of computer at home or workplace connected to internet and performing all the work that generally we have to go and do on a specific place for example e-shopping, e-banking, e-education etc. In case of e-shopping, we view all the products on the computer screen with all details by a single mouse click, select the product and do all further money transaction through net. When we think of security, is it 100% secure? No, not at all because though it is password protected, the password is a text base secrete code that can be open. Therefore this paper is concentrated on preparation of speech based password protected applications.","Statistical relational data integration for information extractionThese lecture notes provide a brief overview of some state of the art large scale information extraction projects. Consequently, these projects are related to current research activities in the semantic web community. The majority of the learning algorithms developed for these information extraction projects are based on the lexical and syntactical processing of Wikipedia and large web corpora. Due to the size of the processed data and the resulting intractability of the associated inference problems existing knowledge representation formalism are often inadequate for the task. We will present recent advances in combining tractable logical and probabilistic models that bring statistical language processing and rule-based approaches closer together. With these lecture notes we hope to convince the attendees that there are numerous synergies and research agendas that can arise when uncertainty-based data-driven research meets rule-based schema-driven research. We also describe certain theoretical and practical advances in making probabilistic inference scale to very large problems.","Feature Extraction and HMM-Based Classification of Gait Video Sequences for the Purpose of Human IdentificationThe authors present results of the research on human recognition based on the video gait sequences from the CASIA Gait Database. Both linear (principal component analysis; PCA) and non-linear (isometric features mapping; Isomap and locally linear embedding; LLE) methods were applied in order to reduce data dimensionality, whereas a concept of hidden Markov model (HMM) was used for the purpose of data classification. The results of the conducted experiments formed the main subject of analysis of classification accuracy expressed by means of the Correct Classification Rate (CCR).","Degree vs. Manner Well: A Case Study in Selective Binding ","The Influence of Engineering Theory and Practice on Philosophy of AIEver since the early days of Artificial Intelligence (AI), the complexity of its relationship with philosophy has been under observation. Some devoted their efforts to a systematic foundation of philosophy of AI, taking for granted its placement within philosophy of science. Such endeavors were based on the view of AI as a scientific discipline, primarily aimed at answering questions about the nature of intelligence. Thus, it was natural to consider philosophy of AI, like philosophy of physics and of biology, as part of philosophy of science. We believe, however, that this position must be reconsidered today in the light of the issues recently tackled by AI and of the emergence of new fields of analysis: philosophy of technology and philosophy and engineering. In this paper we analyze how the view of AI as engineering influences philosophy of AI. Moreover, we argue that philosophy of AI, under this influence, can contribute to the foundation of the emerging philosophy of engineering.","Towards Integrating Emotion into Intelligent ContextContext-aware systems have traditionally employed a limited range of contextual data. While research is addressing an increasingly broad range of contextual data, the level of intelligence generated in context-aware systems is restricted by the failure to effectively implement emotional response. This paper considers emotion as it relates to context and the application of computational intelligence in context-aware systems. Following an introduction, personalization and the computational landscape is considered and context is introduced. Computational intelligence and the relationship to the Semantic Web is discussed with consideration of the nature of knowledge and a brief overview of knowledge engineering. Cognitive conceptual models and semiotics are introduced with a comparative analysis and approaches to implementation. Ongoing research with illustrative 'next generation' intelligent context-aware systems incorporating emotional responses are briefly considered. The paper concludes with a discussion where the challenges and opportunities are addressed; there are closing observations, consideration of future directions for research, and identification of open research questions. \u00a9 2013 Springer-Verlag.","Exception Handling for Error Reporting in Parsing Expression GrammarsParsing Expression Grammars (PEGs) are a new formalism to describe a top-down parser of a language. However, error handling techniques that are often applied to top-down parsers are not directly applicable to PEGs. This problem is usually solved in PEGs using a heuristic that helps to simulate the error reporting technique from top- down parsers, but the error messages are generic. We propose the intro- duction of labeled failures to PEGs for error reporting, as labels help to produce more meaningful error messages. The labeled failures approach is close to that of generating and handling exceptions often used in pro- gramming languages, being useful to annotate and label grammar pieces that should not fail. Moreover, our approach is an extension to the PEGs formalism that is expressive enough to implement some previous work on parser combinators. Finally, labeled failures are also useful to compose grammars preserving the error messages of each separate grammar.","Privacy-Friendly Checking of Remote Token BlacklistsConsulting a remote blacklist as part of verifying a token should not come at the cost of privacy. In particular, the blacklist provider should be unable to identify which tokens are being verified. The contents of the blacklist should also be protected; that is, it should not be pos- sible to learn the contents of the blacklist, for example by querying the blacklist provider a large number of times. This paper defines a range of desirable properties for privacy preserving blacklist checking protocols, and surveys existing technical solutions to this problem. We propose adaptations where appropriate, and provide concrete performance esti- mates for the use case of checking whether or not a passport has been reported lost or stolen. As part of verifying a token it is sometimes necessary to check with a remote authority, in an online fashion, whether or not the token has been blacklisted. 'Transport layer security' (TLS) clients such as browsers, for example, can be configured to query a remote 'online certificate status protocol' (OCSP) server as part of verifying a server certificate. This query contains the serial number of the encountered certificate, and the OCSP server's response indicates whether or not the corresponding certificate has been revoked. Similarly, as part of verifying an official document such as an identity card or a passport, inspection systems sometimes issue a query to remote authorities that maintain document blacklists. This query, too, contains the serial number of the document and the response indicates whether or not the document has been blacklisted. Currently deployed systems for blacklist checking reveal the identity of the token to the remote authority. This situation is unfortunate, because it under- mines the privacy of the token owner. In the OSCP setting, for example, the server gets to know with whom the verifier is about to communicate (namely the owner of the token), and in the official document verification scenario, the remote database authority gets to know whose documents are being verified. Since inspection systems are typically located at well-known locations such as border crossings and airports, this reveals citizens' travel patterns. A more privacy-friendly approach to revocation checking involves pushing the entire blacklist to every verifier. In this way, verifiers can perform the black- list check locally, without consulting any remote authority. In fact, 'certificate","Variational Bayesian Approximation for Linear Inverse Problems with a Hierarchical Prior Models ","Light Ray Concentration Reduces the Complexity of the Wavelength-Based Machine on PSPACE LanguagesThe wavelength-based machine, or simply w-machine, is an optical computational model, dealing with light rays and simple optical devices. w-Machine benefits from the parallel nature of light and co- existence of different wavelengths in a light ray to perform computation. In this paper, we have introduced a novel operation for w-machine, called the concentration operation, which enables to concentrate light rays as a single light ray, and check if the obtained light ray is dark or not, using white-black imaging. In this paper, we have investigated the impact of the concentration operation to computational complexity of w-machine for Turing PSPACE languages, and we have shown that every Turing PSPACE language is computable by a uniform series of concentration enabled w- machines, in polynomial time and exponential size.","Revisiting Abstract Argumentation FrameworksThis paper argues that many extensions of Dung's framework incor- porating relations additional to binary attacks, are best viewed as abstractions of human rather than computational models of reasoning and debate. The pa- per then discusses how these additional relations may be reified into object level knowledge, thus enabling reconstruction of the extended framework as a Dung framework, and providing rational guidance for further reasoning and debate.","Exploring the potential of an electronic documentation system to reduce length of stay. ","Risk-Based models of attacker behavior in cybersecurityEven as reliance on information and communication technology networks continues to grow, and their potential security vulnerabilities become a greater threat, very little is known about the humans who perpetrate cyber attacks--what are their strategies, resources, and motivations? We present a new framework for modeling such cyber attackers. Utilizing observable information (i.e., network alerts, security implementations, systems logs), we can characterize attackers based on the risk they are willing to incur and delineate them based on skill level. These classifications can facilitate decision-making and resource allocation to counteract cybersecurity incidents. We look at two specific models of attacker risk and discuss empirical results from a prototype implementation of this modeling framework using real-world network data.","Mechanising turing machines and computability theory in Isabelle/HOLWe formalise results from computability theory in the theorem prover Isabelle/HOL. Following the textbook by Boolos et al, we formalise Turing machines and relate them to abacus machines and recursive functions. We \"tie the know\" between these three computational models by formalising a universal function and obtaining from it a universal Turing machine by our verified translation from recursive functions to abacus programs and from abacus programs to Turing machine programs. Hoare-style reasoning techniques allow us to reason about concrete Turing machine and abacus programs.","Efficient Analysis of Reliability Architectures via Predicate Abstraction ","Rethinking design theory in information systemsDesign Theory has been written about extensively in Information Systems (IS), but remains heavily problematic. Some researchers explicitly exclude design theory as an outcome of Design Science Research (DSR), others disagree about the form and purpose of design theories, many consider design theories to be too complicated to construct, some journal editors and researchers give low priority to design theory, and very few DSR publications propose design theories.#R##N##R##N#This paper reviews and critically examines the IS literature on design theories, the nature of technological design artefacts compared to phenomena in the natural, biological, and social domains, and whether design theory is 'prescriptive' or 'explanatory'.#R##N##R##N#Using a DSR approach, the paper makes recommendations concerning the form and use of design theory, in order to move toward a resolution of the disagreements about design theory and progress the development of clearer and more useful formalisations of knowledge for practical use.","A Novel Improved Discrete ABC Algorithm for Manpower Scheduling Problem in RemanufacturingRemanufacturing technique is a widely used approach in modern industries. But the very first step of this technique is disassembling. This disassembling operation requires an efficient employee pool and their alloca- tion to several steps of disassembling. In this paper, we have proposed a im- proved ABC algorithm that can be used to solve the manpower scheduling problem for the disassembling operation in remanufacturing industry. We test this algorithm on several instances along with some existing state-of-art algo- rithms. The results prove the efficiency of this algorithm to solve manpower scheduling problem in remanufacturing.","Effects of RPG on middle school players' intrapersonal intelligenceElectronic game is a rising resource which is used to develop the players' multiple intelligences. This paper tested the intrapersonal intelligence of 192 middle school students who play role-playing game (RPG) by questionnaire, aiming at exploring the effects of RPG on intrapersonal intelligence. The results showed that RPG has a positive effect on students' intrapersonal intelligence, and the effect is subject to factors such as age, frequency of playing games and RPG type. It concluded that Role-playing game could help improving students' intrapersonal intelligence, and gave some suggestions about the development of RPG and students' intrapersonal intelligence in the future. The study highlighted a new approach of developing middle school students' multiple intelligences in the current educational environment.","Public Information System Interface Design Research ","Unified entity search in social media communityThe search for entities is the most common search behavior on the Web, especially in social media communities where entities (such as images, videos, people, locations, and tags) are highly heterogeneous and correlated. While previous research usually deals with these social media entities separately, we are investigating in this paper a unified, multi-level, and correlative entity graph to represent the unstructured social media data, through which various applications (e.g., friend suggestion, personalized image search, image tagging, etc.) can be realized more effectively in one single framework. We regard the social media objects equally as \"entities\" and all of these applications as \"entity search\" problem which searches for entities with different types. We first construct a multi-level graph which organizes the heterogeneous entities into multiple levels, with one type of entities as  vertices  in each level. The  edges  between graphs pairwisely connect the entities weighted by  intra-relations  in the same level and  inter-links  across two different levels distilled from the social behaviors (e.g., tagging, commenting, and joining communities). To infer the strength of intra-relations, we propose a  circular propagation  scheme, which reinforces the mutual exchange of information across different entity types in a cyclic manner. Based on the constructed unified graph, we explicitly formulate entity search as a global optimization problem in a unified Bayesian framework, in which various applications are efficiently realized. Empirically, we validate the effectiveness of our unified entity graph for various social media applications on million-scale real-world dataset.","TrustPos Model: Trusting in Mobile Users' LocationWhile social games based on geo-location are gaining popularity, determining the authenticity of the players' geo-position becomes a challenge, since there are ways to counterfeit it, quite accessible to everyone. We propose a solution based on global spatial and temporal observation of the players' interactions. In this paper we present TrustPos, a trust engine model that associates a trustworthiness factor to each player based on the context of the interactions with both the game and other players. The novelty of TrustPos is the fact that our model is based on an internal network of players linked through their interactions, as opposed to previous approaches that are strongly specialized to concrete domains as peer-to-peer networks and social recommenders, not adaptable to location trust concerns.","Algorithm portfolios based on cost-sensitive hierarchical clusteringDifferent solution approaches for combinatorial problems often exhibit incomparable performance that depends on the concrete problem instance to be solved. Algorithm portfolios aim to combine the strengths of multiple algorithmic approaches by training a classifier that selects or schedules solvers dependent on the given instance. We devise a new classifier that selects solvers based on a cost-sensitive hierarchical clustering model. Experimental results on SAT and MaxSAT show that the new method outperforms the most effective portfolio builders to date.","On Acronyms in Chinese: A Prosodic PerspectiveAcronym is one way to create new words on the basis of existing ex- pressions, but it is required to meet the codes of a language and its natural rhythm. In Chinese, disyllable is the best unit in the prosodic model. In order to form disyllables, some information is even dropped out. The creation of mono- syllabic and trisyllablic acronyms is limited. Monosyllables can appear only in disyllabic feet; while trisyllables only appear on the condition that the disyllabic words cannot meet ideographic requirement. Trisyllabic words have disyllabliz- ing tendency. Few acronyms with four or five syllables can be found due to the fact that they go against the principle of economy. Acronym, formed on the basis of the Economy Principle, is a kind of convenient and practical way to simplify expressions. It meets the needs of daily communication. Acronyms are generally derived from complex words or fixed phrases. In the literature, Chinese acronyms are studied from many aspects. Tian Zong &amp; Xiao Jiugen(2006) have studied its forming methods or mechanism and Zhang Zhiguo &amp; Yang Ling (2003) its causes. Its features, principles and some other aspects are also discussed in some theses or dissertations. Generally speaking, when scholars carry out research on acronyms, they focus mainly on their classification, causes, features, and the relationship between the original words and acronyms. Moreover, According to some scholars, statistics shows that more than 70% of the acronyms are disyllables. Our question is: is the number of syllables related with the formation of acronym? If the answer is yes, how does the number of syllable affect the formation of the acronyms?","HPACS: A High Privacy and Availability Cloud Storage Platform with Matrix EncryptionAs the continuous development of cloud computing and big data, data storage as a service in the cloud is becoming increasingly popular. More and more individuals and organizations begin to store their data in cloud rather than building their own data centers. Cloud storage holds the advantages of high reliability, simple management and cost-effective. However, the privacy and availability of the data stored in cloud is still a challenge. In this paper, we design and implement a High Privacy and Availability Cloud Storage HPACS platform built on Apache Hadoop to improve the data privacy and availability. A matrix encryption and decryption module is integrated in HDFS, through which the data can be encoded and reconstructed to/from different storage servers transparently. Experimental results show that HPACS can achieve high privacy and availability but with reasonable write/read performance and storage capacity overhead as compared with the original HDFS.","Real-Time Visual Ground-Truth System for Indoor Robotic ApplicationsThe robotics community is concerned with the ability to infer and compare the results from researchers in areas such as vision percep- tion and multi-robot cooperative behavior. To accomplish that task, this paper proposes a real-time indoor visual ground truth system capable of providing accuracy with at least more magnitude than the precision of the algorithm to be evaluated. A multi-camera architecture is proposed under the ROS (Robot Operating System) framework to estimate the 3D position of objects and the implementation and results were contex- tualized to the Robocup Middle Size League scenario.","Comparison of K-Means and Fuzzy C-Means Data Mining Algorithms for Analysis of Management Information: An Open Source CaseThis research presents the knowledge discovery using Data Mining from the organization and with a KPI management point of view. The stages presented here are based on techniques and Data Mining models, with emphasis on clustering techniques, such as the C-MEANS algorithm. We both consider the classic and fuzzy perspectives, namely Fuzzy C-MEANS and K-MEANS, and then compare the results based on the level of support which each algorithm provides to information management. The CRISP-DM methodology is used in our implementation, which is then applied to three case studies.","That's What Friends Are For: Inferring Location in Online Social Media Platforms Based on Social RelationshipsSocial networks are often grounded in spatial locality where individuals form  relationships with those they meet nearby.  However, the location of  individuals in online social networking platforms is often unknown.  Prior  approaches have tried to infer individuals' locations from the content they  produce online or their online relations, but often are limited by the  available location-related data.  We propose a new method for social networks  that accurately infers locations for nearly all of individuals by spatially  propagating location assignments through the social network, using only a  small number of initial locations.  In five experiments, we demonstrate the  effectiveness in multiple social networking platforms, using both precise and  noisy data to start the inference, and present heuristics for improving  performance.  In one experiment, we demonstrate the ability to infer the  locations of a group of users who generate over 74% of the daily Twitter  message volume with an estimated median location error of 10km.  Our results  open the possibility of gathering large quantities of location-annotated data  from social media platforms.","Distributed Data Placement via Graph PartitioningWith the widespread use of shared-nothing clusters of servers, there has been a proliferation of distributed object stores that offer high availability, reliability and enhanced performance for MapReduce-style workloads. However, relational workloads cannot always be evaluated efficiently using MapReduce without extensive data migrations, which cause network congestion and reduced query throughput. We study the problem of computing data placement strategies that minimize the data communication costs incurred by typical relational query workloads in a distributed setting. #R##N#Our main contribution is a reduction of the data placement problem to the well-studied problem of {\\sc Graph Partitioning}, which is NP-Hard but for which efficient approximation algorithms exist. The novelty and significance of this result lie in representing the communication cost exactly and using standard graphs instead of hypergraphs, which were used in prior work on data placement that optimized for different objectives (not communication cost). #R##N#We study several practical extensions of the problem: with load balancing, with replication, with materialized views, and with complex query plans consisting of sequences of intermediate operations that may be computed on different servers. We provide integer linear programs (IPs) that may be used with any IP solver to find an optimal data placement. For the no-replication case, we use publicly available graph partitioning libraries (e.g., METIS) to efficiently compute nearly-optimal solutions. For the versions with replication, we introduce two heuristics that utilize the {\\sc Graph Partitioning} solution of the no-replication case. Using the TPC-DS workload, it may take an IP solver weeks to compute an optimal data placement, whereas our reduction produces nearly-optimal solutions in seconds.","LALBLC a program testing the equivalence of dpda'sWe describe the program LALBLC which tests whether two deterministic pushdown automata recognize the same language.","The Method of Improving the Structure of the Decision Tree Given by the ExpertsThis paper presents the problem of sequential decision making in the pat- tern recognition task. This task can be presented using a decision tree. In this case, it is assumed that the structure of the decision tree is determined by experts. The classification process is made in each node of the tree. This paper proposes a way to change the structure of the decision tree to improve the quality of classification. The split criterion is based on the confusion matrix. The obtained results were verified on the basis of the example of the computer-aided medical diagnosis.","The Complexity Boundary of Answer Set Programming with Generalized Atoms under the FLP SemanticsIn recent years, Answer Set Programming ASP, logic programming under the stable model or answer set semantics, has seen several extensions by generalizing the notion of an atom in these programs: be it aggregate atoms, HEX atoms, generalized quantifiers, or abstract constraints, the idea is to have more complicated satisfaction patterns in the lattice of Herbrand interpretations than traditional, simple atoms. In this paper we refer to any of these constructs as generalized atoms. It is known that programs with generalized atoms that have monotonic or antimonotonic satisfaction patterns do not increase complexity with respect to programs with simple atoms if satisfaction of the generalized atoms can be decided in polynomial time under most semantics. It is also known that generalized atoms that are nonmonotonic being neither monotonic nor antimonotonic can, but need not, increase the complexity by one level in the polynomial hierarchy if non-disjunctive programs under the FLP semantics are considered. In this paper we provide the precise boundary of this complexity gap: programs with convex generalized atom never increase complexity, while allowing a single non-convex generalized atom under reasonable conditions always does. We also discuss several implications of this result in practice.","Remote usability evaluation using eye tracking enhanced with intelligent data analysisIn this paper we present a new cost-effective method for usability evaluation using eye tracking enhanced with intelligent data analysis. In this method we propose application of a low-cost infrared camera and free Ogama software. Moreover we present how the standard data analysis, which is usually made manually by experts, may be enhanced by application of intelligent data analysis. We applied well known expert system, which is using fuzzy reasoning. To build such a system we should first define a model of \"desired\" eye tracking record for a given poster, or more general web page or the whole application.","Efficient Usage of Collective Classification Algorithms for Collaborative Decision MakingCollective classification algorithms with underlying network structure of related entities are a powerful modelling tool that can address collaborative decision making problems. The paper presents the usage of collective classification algorithms for classification problem in which unknown nodes are assigned with classes based on the classes of known nodes. In such problem the classification decision for particular node is inferred from collaborative knowledge of nodes with known classes and underlying network connections. The paper considers Iterative Classification ICA and Loopy Belief Propagation LBP algorithms applied in various network configurations for collaborative decision making. The experimental results revealed that greater number of output classes decreases classification accuracy and LBP outperforms ICA for dense network structures while it is worse for sparse networks.","A Robust People Tracking Algorithm Using Contextual Reasoning for Recovering Detection Errors ","Some Problems of Integrating Industrial Network Control Systems Using Service Oriented Architecture ","Investigating the Limits of Monte-Carlo Tree Search Methods in Computer Go ","Ontology-Based QoS Aggregation for Composite Web ServicesDetermining the QoS (quality of service) of composite Web services is of high importance for both service providers and service consumers. Hetero- geneity of service descriptions, however, often hinders the aggregation of QoS parameters. We propose ontology-based QoS aggregation that integrates the semantics of QoS parameters and their aggregation into the overall aggregation process. The contribution is a QoS aggregation ontology and a QoS aggregation method that uses this ontology. We demonstrate the usefulness of our proposal for designers of composite services and assess its computational efficiency.","Automatic Evaluation of Carotid Intima-Media Thickness in Ultrasounds Using Machine LearningCardiovascular diseases (CVD) are the main cause of death and disability in the world. Atherosclerosis is responsible for a large pro- portion of cardiovascular diseases. The atherosclerotic process is a degen- erative condition, mainly affecting the medium- and large-size arteries, that develops over many years. It causes thickening and the reduction of elasticity in the blood vessels. An early diagnosis of this condition is crucial to prevent patients from suffering more serious pathologies. The evaluation of the Intima-Media Thickness (IMT) of the Common Carotid Artery (CCA) in B-mode ultrasound images is considered the most useful tool for the investigation of preclinical atherosclerosis. This paper pro- poses an effective image segmentation procedure for the measurement of the IMT in an automatic way, avoiding the user dependence and the inter-rater variability. Segmentation is raised as a pattern recognition problem and a neural network ensemble has been trained to classify the image pixels. The suggested approach is tested on a set of 25 ultrasound images and its validation is performed by comparing the automatic seg- mentations with manual tracings.","Pattern Matching with Non Overlapping Reversals - Approximation and On-line Algorithms ","Designing, Implementing and Testing a Mobile Application to Assist with Pediatric-to-Adult Health Care Transition ","Nurse Rostering: a Complex Example of Personnel Scheduling with Perspectives ","A Unified Metric for Categorical and Numerical Attributes in Data Clustering ","Intuitive Large Image Database Browsing Using Perceptual Similarity Enriched by CrowdsThe main objective of image browsers is to empower users to find a desired image with ease, speed and accuracy from a large database. In this pa- per we present a novel approach at creating an image browsing environment based on human perception with the aim of providing intuitive image naviga- tion. In our approach, similarity judgments form the basic structural organiza- tion for the images in our browser. To enrich this we have developed a scalable crowd sourced method of augmenting a database with a large number of additional samples by capturing human judgments from members of a crowd. Experiments were conducted involving two databases that demonstrate the effectiveness of our method as an intuitive, fast browsing environment for large image databases.","Expertise Ranking of Users in QA CommunityCommunity Question Answering services (CQAs) have be- come ubiquitous, and are widely used. Hence, it would be beneficial if we can mine useful inferences from these data sets to improve these ser- vices. For example, if we can infer or identify expertise of users' from these data sets, we can route questions to the right people. With the identification of expertise, number of experts needed to cover a set of topics (in a CQA service) can also be optimized. This paper addresses the problem of inferring expertise. Current approaches infer expertise using traditional link-based meth- ods such as PageRank or HITS, and others (e.g., number of answers given by a user or Z score). Although an ask-answer graph can be generated for a CQA data set based on the ask-answer paradigm (who answers whose questions), this graph is different, in its semantics, from the web graphs. We posit that both graph structure and domain information related to an answerer (e.g., answer quality) is critical for inferring the expertise of users. Based on this observation, we propose the ExpertRank framework to compute users' expertise. We establish that the information used has a bearing on the accuracy of results. We present our algorithm along with extensive experimental analysis that indicates superiority of our approach as compared to other link-based methods.","HybHap: A Fast and Accurate Hybrid Approach for Haplotype Inference on Large DatasetsWe introduce HybHap, a new approach for haplotype inference problem on large genotype datasets. HybHap is a hybrid method, based on the Parsimonious tree-grow idea, which resorts to Markov chains, in order to maximize the probability that the haplotypes will be shared by more genotypes in the dataset. Several experiments with large biological datasets taken from HapMap were performed to compare HybHap with two well known algorithms: fastPHASE and PTG. The results show that HybHap is a rather robust, reliable, and efficient method that runs orders of magnitude faster than the others, producing results of comparable accuracy, hence being much more suitable to deal with the challenge of genome wide tasks.","Creating a Corpus of Geospatial Natural LanguageThe description of location using natural language is of interest for a number of research activities including the automated interpretation and generation of natural language to ease interaction with geographic information systems. For such activities, examples of geospatial natural language are usually collected from the personal knowledge of researchers, or in small scale collection activities specific to the project concerned. This paper describes the process used to develop a more generic corpus of geospatial natural language.#R##N##R##N#The paper discusses the development and evaluation of four methods for semi-automated harvesting of geospatial natural language clauses from text to create a corpus of geospatial natural language. The most successful method uses a set of geospatial syntactic templates that describe common patterns of grammatical geospatial word categories and provide a precision of 0.66. Particular challenges were posed by the range of English dialects included, as well as metaphoric and sporting references.","Human Action Recognition from RGB-D Frames Based on Real-Time 3D Optical Flow Estimation ","Dynamic Condition Response Graphs for Trustworthy Adaptive Case Management ","Flow Models for Project Scheduling with Transfer Delays and Financial ConstraintsThis paper deals with two extensions of the Resource Con- strained Project Scheduling Problem (RCPSP), which involve resource transfer delays and \"Financial\" resources. Flow models are used in order to formalize those extended RCPSP, which contain the standard RCPSP and lead us to the Timed Flow Polyhedron and to several structural re- sults. This framework gives rise to generic Insertion operators, as well as greedy/local search algorithms. We end with numerical tests.","Multi-Level Meta-Modelling to Underpin the Abstract and Concrete Syntax for Domain-Specific Modelling LanguagesH-S also wishes to acknowledge the support of the Australian Research Council through grant DP0878172. Thisiscontribution 12/01 of the Centre for Object Technology Applications and Research within the Human Centred Technology Design centre at the University of Technology, Sydney.","Understanding E-Learning Continuance Intention: Towards A Conceptual Model ","Emerging Techniques for the Engineering of Self-Adaptive High-Integrity Software ","A Semantic-Based Architecture for Managing Knowledge-Intensive Organizations: The ARISTOTELE Platform ","Development of an Enterprise Architecture Management Capability Catalog ","Don\u2019t Text While Driving: The Effect of Smartphone Text Messaging on Road Safety during Simulated Driving ","REAL -TIME OR NEAR REAL -TIME ? - TOWARDS A REAL -TIME ASSESSMENT MODELSince the advent of information technology, the availability of up-to-date information has been a key goal. Recently the term \u201creal-time\u201d has been discussed in combination with technologies such as in-memory-computing. However, the promoted acceleration of data availability and response times are accompanied by high investment costs to implement such infrastructures. Businesses are faced with the question of whether the increased real-time capability actually translates into benefits beyond pure up-to-date availability. This paper argues that the additional value for the business is essential and proposes a model for assessing and classifying business processes' real-time level. It aims to assess the information requirement of specific processes and determines the suitable level of data availability. It shows that real-time information is not always required and investments in real-time infrastructures may represent an overinvestment. A case study from the automotive industry illustrates the model and presents some early implications for the usability in practice.","Learning of Lateral Interactions for Perceptual Grouping Employing Information GainPerceptual Grouping is an important aspect in the understanding of sensory input. One of the major problems there is, how features can form meaningful groups while segregating from non relevant informations. One solution can be to couple features by attracting and repelling interactions and let neural dynamics decide the assignment of features to groups. In this paper, we present a modification of a learning approach to find these couplings, which explicitly incorporates the information gain of feature pairs, increasing the overall grouping quality of the original technique. The new approach is evaluated with an oscillator network and compared to the original work.","Dynamic Analysis and Optimal Design of High Efficiency Full Bridge LLC Resonant ConverterIn this paper, high efficiency full bridge LLCresonant converter for server power system is introduced. LLCresonant converter was reported in many papers recentlybecause of its simple structure, high efficiency and highswitching frequency ability. However, many SMPS designersand field engineers still encounter technical difficulties of powerstage design and control scheme due to environmentalregulations of power system. This paper clearly presentstheoretical and practical details involved with the dynamicanalysis and design procedures. The accuracy of dynamicanalysis and validity of optimal design are confirmed with bothcomputer simulations and experimental measurement.","Detecting anomalous behaviors using structural properties of social networksIn this paper we discuss the analysis of mobile networks communication patterns in the presence of some anomalous \"real world event\". We argue that given limited analysis resources (namely, limited number of network edges we can analyze), it is best to select edges that are located around 'hubs' in the network, resulting in an improved ability to detect such events. We demonstrate this method using a dataset containing the call log data of 3 years from a major mobile carrier in a developed European nation.","SMT-Based Model Checking for Stabilizing Programs,We focus on the verification of stabilizing programs using SMT solvers. SMT solvers have the potential to convert the verification problem into a satisfiability problem of a Boolean formula and utilize efficient techniques to determine whether it is satisfiable. We focus on utilizing techniques from bounded model checking to determine whether the given program is stabilizing. We illustrate our approach using three case studies. We also identify tradeoffs between verification with SMT solvers and existing approaches.","Erratum: Common Sense Knowledge Based Personality Recognition from Text ","Rhythm Reading Exercises with PWGLThis paper presents rhythm reading, one of the elementary ear training exercises, as a pedagogical software application of PWGL. We use different kinds of stochastic and mathematical models to generate a rhythmic database. The database is divided into several categories, including, binary or ternary, euclidian, afro-cuban, corpus-based, and contemporary. Our musical constraints systems is used to define a rule set, which, in turn, can be used to automatically generate graded rhythm reading exercises. The user is then presented with a musical score, and he or she can perform a reading with any percussive instrument or voice and a microphone connected to a computer. Our novel signal processing system is utilized to analyze the reading. Finally, visual feedback and statistics are displayed directly as a part of the exercise. In this paper we present our rhythm reading application, and discuss the details of its implementation.","Toward Task-Based Mental Models of Human-Robot Teaming: A Bayesian ApproachWe consider a set of team-based information tasks, meaning that the team's goals are to choose behaviors that provide or enhance information avail- able to the team. These information tasks occur across a region of space and must be performed for a period of time. We present a Bayesian model for (a) how infor- mation flows in the world and (b) how information is altered in the world by the location and perceptions of both humans and robots. Building from this model, we specify the requirements for a robot's computational mental model of the task and the human teammate, including the need to understand where and how the human processes information in the world. The robot can use this mental model to select its behaviors to support the team objective, subject to a set of mission constraints.","How to design experiences: macro UX versus micro UX approachUser Experience (UX) can be achieved by a user-related product's purpose (Macro UX) as well as by pleasant embodiment design in detail concerning material, usability and interface (Micro UX). Existing approaches mostly represent the Macro UX approach and therefore demand influencing the whole development process, in particular the early stage of goal setting. Furthermore, they are often psychology-driven. For that reason they are hardly implemented in industrial practice. We observe that most development projects are not triggered by user considerations but by market or technology influences. We show how to achieve an impact on the product's emotional quality and UX by supporting the design phase of those projects incrementally (Micro UX). Based on psychological foundation this approach provides pragmatic short-term support to designers in an adequate language to be applicable.","Tight Bound on the Diameter of the Kn\u00f6del GraphThe Knodel graph W\u0394,n is a regular graph of even order and degree \u0394 where 2 \u2264 \u0394 \u2264\ufffd log 2 n\ufffd . Despite being a highly symmetric and widely studied graph, the diameter of W\u0394,n is known only for n =2 \u0394 . In this paper we present a tight upper bound on the diameter of the Knodel graph for general case. We show that the presented bound differs from the diameter by at most 2 when \u0394&lt;\u03b1 \ufffd log2 nfor some 0 &lt;\u03b1&lt; 1 where \u03b1 \u2192 1w henn \u2192\u221e . The proof is constructive and provides a near optimal diametral path for the Knodel graph W\u0394,n.","Effective hotspot removal system using neural network predictorMonitoring and prediction of resource usage are two major methods to manage distributed computing environments such as cluster, grid computing, and most recent cloud computing. In this paper, we propose a novel hotspot removal system using a neural network predictor. The proposed system detects and removes hotspots with resource specific removal algorithm. The system also improves neural network predictor by introducing prediction confidence. The effectiveness of our proposed system is verified with empirical examples, and evaluation results show that our system outperforms a popular hotspot removal system in hotspot predication and hotspot removal.","An information-centric framework for designing patient-centered medical decision aids and risk communication.Risk communication is a major challenge in productive patient-physician communication. Patient decision making responsibilities come with an implicit assumption that patients are sufficiently educated and confident in their abilities to make decisions about their care based on evidence based treatment recommendations. Attempts to improve health literacy in patients by way of graphical decision aids have met with success. Such decision aids typically have been designed for a general population and evaluated based on whether or not users of the decision aid can accurately report the data points in isolation. To classify decision aids, we present an information-centric framework for assessing the content delivered to patients. We provide examples of our framework from a literature survey and suggest ways improvements can be made by considering all dimensions of our framework.","Articulating an experimental model for the study of game-based learningResearch related to game-based and technology-enhanced learning lacks a focused experimental method. The present paper articulates a well-defined experimental method for studying game-based learning from pre-learning interventions to post-testing assessment of retention and transfer.","Designing iDTV applications from participatory use of patternsInteractive Digital TV (iDTV) is an emerging technology in Brazil, with inherent characteristics that must be addressed and which demand technical resources and references to support the design and development of interactive applications. This paper presents a design activity that reports and discusses the use of specific design patterns combined with prototyping tools and techniques inspired by Participatory Design in the design of applications for iDTV. Results are presented and discussed focusing on: the advantages of using design patterns in a participatory design, the main difficulties the groups had during the design activities, the importance of tools to support the design of iDTV applications.","A Survey: Stereo Based Navigation for Mobile Binocular Robots ","A Corpus-Based Genre and Language Feature Analysis of Chinese and English Linguistics and Literature Article Abstracts ","Media Enrichment on Distributed Displays by Selective Information Presentation: A First PrototypeThe Internet offers a wide range of information and media content. Currently, users who are watching a video and look for related information have to search for it by themselves. In our recent work we focused on how to enrich video content with additional related information. This paper presents an approach to extend media enrichment to support the presentation of additional content on multiple distributed displays. Our approach focuses on real time synchronization between a video on one display and the presentation of related information on the same or any other display with a web browser.","Context-Aware Decision Making for Maze Solving ","Enhancing Textual Data Quality in Data Mining: Case Study and ExperiencesDirty data is recognized as a top challenge for data mining. Textual data is one type of data that should be explored more on the topic of data quality, to ensure the discovered knowledge is of quality. In this paper, we focus on the topic of textual data quality (TDQ) in data mining. Based on our data mining experiences for years, three typical TDQ dimensions and related problems are highlighted, including representation granularity, representation consistency, and completeness. Then, to provide a real-world example on how to enhance TDQ in data mining, a case study is demonstrated in detail in this paper, under the background of data mining in traditional Chinese medicine and covers three typical TDQ problems and corresponding solutions. The case study provided in this paper is expected to help data analysts and miners to attach more importance to TDQ issue, and enhance TDQ for more reliable data mining.","Multidomain Voice Activity Detection during Human-Robot Interaction ","Understanding Application Contentiousness and Sensitivity on Modern Multicores.Runtime systems to mitigate memory resource contention problems on multicore processors have recently attracted much research attention. One critical component of these runtimes is the  indicators  to rank and classify applications based on their contention characteristics. However, although there has been significant research effort, application contention characteristics remain not well understood and indicators have not been thoroughly evaluated.","Runtime Enforcement of First-Order LTL Properties on Data-Aware Business ProcessesThis paper studies the following problem: given a relational data schema, a temporal property over the schema, and a process that modifies the data instances, how can we enforce the property during each step of the process execution? Temporal properties are defined using a first-order future time LTL FO-LTL and they are evaluated under finite and fixed domain assumptions. Under such restrictions, existing techniques for monitoring propositional formulas can be used, but they would require exponential space in the size of the domain. Our approach is based on the construction of a first-order automaton that is able to perform the monitoring incrementally and by using exponential space in the size of the property. Technically, we show that our mechanism captures the semantics of FO-LTL on finite but progressing sequences of instances, and it reports satisfaction or dissatisfaction of the property at the earliest possible time.","Optimal Build-or-Buy Decision for Component Selection of Application Package SoftwareApplication Package Software (APS) is a collection of software programs developed for the purpose of being licensed to third-party organizations. Examples of APS include accounting systems, human resources software, and enterprise resource planning (ERP) software. With the advancement in Information technology, Component Based Software Engineering (CBSE) has emerged for rapid assembly of flexible modular software systems. It promotes software re-use for large software systems by purchasing components in the form of commercial-off the shelf components from the vendor. If the required component is not available in the market, then it has to be developed in-house. This decision of whether to buy the component or build from the scratch is known as build-or-buy decision. Through this paper, we shall discuss a framework that will help the developer to decide whether to buy or to build software components while designing a fault-tolerant modular software system. This paper proposes optimization models for optimal component selection for a fault-tolerant modular software system under the Recovery Block Scheme (RBS).","TWORPUS - An Easy-to-Use Tool for the Creation of Tailored Twitter CorporaIn this paper we present Tworpus, an easy-to-use tool for the creation of tailored Twitter corpora. Tworpus allows scholars to create corpora without having to know about the Twitter Application Programming Interface (API) and related technical aspects. At the same time our tool complies with Twitter\u2019s \u201drules of the road\u201d on how to use tweet data. Corpora may be composed in various sizes and for specific scenarios, as the Tworpus interface provides controls for filtering and gathering customized collections of tweets, which may serve as the basis for subsequent analyses.","Observer-Based adaptive neural networks control of nonlinear pure feedback systems with hysteresisIn this paper, the problem of adaptive neural output feedback control is investigated for a class of uncertain nonlinear pure feedback systems with unknown backlash-like hysteresis. In the design, RBF neural networks are used to approximate the nonlinear functions of systems, and a neural state observer is designed to estimate the unmeasured states. By utilizing the neural state observer, and combining the backstepping technique with adaptive control design, an observer-based adaptive neural output feedback control approach is developed. It is proved that the proposed control approach can guarantee that all the signals in the closed-loop system are semi-globally uniformly ultimately bounded (SUUB), and both observer error and tracking error can converge to a small neighborhood of the origin.","A Preliminary Analysis of Localization in Free Software: How Translations Are Performed ","Queue Automata of Constant LengthWe introduce and study the notion of constant length queue automata, as a formalism for representing regular languages. We show that their descriptional power outperforms that of traditional finite state automata, of constant height pushdown automata, and of straight line programs for regular expressions, by providing optimal exponential and double-exponential size gaps. Moreover, we prove that constant height pushdown automata can be simulated by constant length queue au- tomata paying only by a linear size increase, and that removing non- determinism in constant length queue automata requires an optimal exponential size blow-up, against the optimal double-exponential cost for determinizing constant height pushdown automata.","Modeling Brief Alcohol Intervention Dialogue with MDPs for Delivery by ECAsThis paper describes the design of a multimodal spoken dialogue system using Markov Decision Processes (MDPs) to enable em- bodied conversational virtual health coach agents to deliver brief inter- ventions for lifestyle behavior change - in particular excessive alcohol consumption. Its contribution is two fold. First, it is the first attempt to-date to study stochastic dialogue policy optimization techniques in the health dialogue domain. Second, it provides a model for longer branch- ing dialogues (in terms of number of dialogue turns and number of slots) than the usual slot filling dialogue interactions currently available (e.g. tourist information domain). In addition, the model forms the basis for the generation of a richly annotated dialogue corpus, which is essential for applying optimization methods based on reinforcement learning.","The adoption of mobile internet: industry and users experiencesNowadays Internet and mobile phones are blending into portable devices such as smartphones. At the same time that mobile phones' sales are decreasing worldwide, smartphones, and consequently mobile internet (m-internet), are having an exponential growth. M-internet contributes to the emerging of new practices of mobile social networking and mobile communication, as these devices make it easier to maintain networks of relationships. Resulting from this convergence, contemporary mobile user experience also contributes to the blending of local and global through the permanent dynamic articulation of communication and coordination. This paper deals with the emerging adoption drivers of m-internet and the use patterns that characterize it, highlighting the importance of mobility for online activities and confronting the industry's and users' perspectives on the adoption of this technology, its patterns of use, motivating factors and type of activities performed online. Within a theoretical framework that articulates Maslow's hierarchy of needs theory and the theory of uses and gratification, this paper explores the connection between the nature of social interactions allowed by m-internet and the satisfaction of needs as key adoption drivers. In addition, the paper explores a gap in the expectations of the industry and users regarding m-internet adoption, pointing to social activities as an integrative and relevant part of m-internet service.","An e-payment Architecture Ensuring a High Level of Privacy Protection ","Interactive Visual Analytics for Efficient Maintenance of Model TransformationsMaintaining model transformations remains a demanding task due to the sheer amount of metamodel elements and transformation rules that need to be understood. Several established techniques for software maintenance have been ported to model transformation development. Most available techniques proac- tively help to design and implement maintainable transformations, yet however, a growing number of legacy transformations needs to be maintained. Interactive visualization techniques to support model transformation maintenance still do not exist. We propose an interactive visual analytics process for understanding model transformations for maintenance. Data and control dependencies are statically analyzed and displayed in an interactive graph-based view with cross-view nav- igation and task-oriented filter criteria. We present results of an empirical study, where we asked programmers to carry out typical maintenance tasks on a real- world transformation in QVT-O. Subjects using our view located relevant code spots significantly more efficiently.","Adaptive multi-modal particle filtering for probabilistic white matter tractographyParticle filtering has recently been introduced to perform probabilistic tractography in conjunction with DTI and Q-Ball models to estimate the diffusion information. Particle filters are particularly well adapted to the tractography problem as they offer a way to approximate a probability distribution over all paths originated from a specified voxel, given the diffusion information. In practice however, they often fail at consistently capturing the multi-modality of the target distribution. For brain white matter tractography, this means that multiple fiber pathways are unlikely to be tracked over extended volumes.#R##N##R##N#We propose to remedy this issue by formulating the filtering distribution as an adaptive M-component non-parametric mixture model. Such a formulation preserves all the properties of a classical particle filter while improving multi-modality capture. We apply this multi-modal particle filter to both DTI and Q-Ball models and propose to estimate dynamically the number of modes of the filtering distribution. We show on synthetic and real data how this algorithm outperforms the previous versions proposed in the literature.","Genetic Programming of Augmenting Topologies for Hypercube-Based Indirect Encoding of Artificial Neural Networks ","Guided Skill Practice as an Adaptive Scaffolding Strategy in Open-Ended Learning EnvironmentsWhile open-ended learning environments (OELEs) offer powerful learning opportunities, many students struggle to learn in them. Without proper support, these learners use system tools incorrectly and adopt suboptimal learning strategies. Typically, OELEs support students by providing hints: sug- gestions for how to proceed combined with information relevant to the learner's situation. However, students often ignore or fail to understand such hints. To address this problem, we present an alternative approach to supporting students in OELEs that combines suggestions and assertions with guided skill practice. We demonstrate the feasibility of our approach through an experimental study that compares students who receive suggestions, assertions, and guided skill practice to students who receive no such support. Findings indicate that learners who received the scaffolds approached their tasks more systematically.","A Pairwise Label Ranking Method with Imprecise Scores and Partial PredictionsIn this paper, we are interested in the label ranking problem. We are more specifically interested in the recent trend consisting in predicting partial but more accurate i.e., making less incorrect statements orders rather than complete ones. To do so, we propose a ranking method based on pairwise imprecise scores obtained from likelihood functions. We discuss how such imprecise scores can be aggregated to produce interval orders, which are specific types of partial orders. We then analyse the performances of the method as well as its sensitivity to missing data and parameter values.","Optic disc and cup segmentation from color fundus photograph using graph cut with priors.For automatic segmentation of optic disc and cup from color fundus photograph, we describe a fairly general energy function that can naturally fit into a global optimization framework with graph cut. Distinguished from most previous work, our energy function includes priors on the shape &amp; location of disc &amp; cup, the rim thickness and the geometric interaction of \u201cdisc contains cup\u201d. These priors together with the effective optimization of graph cut enable our algorithm to generate reliable and robust solutions. Our approach is able to outperform several state-of-the-art segmentation methods, as shown by a set of experimental comparisons with manual delineations and a series of results of correlations with the assessments of a merchant-provided software from Optical Coherence Tomography (OCT) regarding several cup and disc parameters.","Argumentative Insights from an Opinion Classification Task on a French Corpus ","A comparative study of social media and traditional polling in the egyptian uprising of 2011Because social network sites such as Twitter are increasingly being used to express opinions and attitudes, the utility of using these sites as legitimate and immediate information sources is of growing interest. This research examines how well information derived from social media aligns with that from more traditional polling methods. Specifically, this research examines tweets from over 40,000 Egyptian users from both before and after the Egyptian uprising on January 25, 2011 and compares that information with polling data collected by The Gallup Organization during the same time period. This analysis ascertains trends in sentiment and identifies the extent to which these methodologies align over time. The results show that trends across the two sources are not consistent. Focusing solely on Twitter data, individuals expressed increasingly negative opinions after the uprising, whereas survey results indicated that individuals were increasingly positive post-uprising. We discuss the implications of these differences for the use of social media as a real-time information source.","Automatic Metadata Generation in an Archaeological Digital Library: Semantic Annotation of Grey Literature ","Development of a Decision Support System to Facilitate Multi-criteria Decision Making during Humanitarian Operation within a Project Life CycleThe use of decision support systems is an important part of supply chain management. Quick and adequate decision making is sometimes difficult to achieve. Three issues arise: how to gather relevant data and use past experiences, how to make the decision when many criteria have to be taken into account and how can we ensure that the decision making process is quick. Those three issues are currently faced by many companies and some solutions have already been proposed in the literature. Yet, in some cases, it is difficult, if not possible to apply those solutions. Humanitarian organizations, for example, have difficulties to build on past experiences. Quick decision making in this sector is vital. The purpose of this paper is to design and develop decision-making tool to support the performance of humanitarian logistics. A case study at the French Red Cross will validate this proposal.","Game-based interactive media in behavioral medicine: creating serious affective-cognitive-environmental-social integration experiencesThe need to refocus health systems more towards prevention is now widely recognized, since most of the major disease conditions in the developed world have significant behavioral determinants. However, most efforts to date have been limited in their impact as they have generally failed to take account of the complex hierarchy of interacting social and environmental influences. The reality of life in a networked society is such there is now an additional set of corresponding influences that arise in the digital world(s) that an individual inhabits. Concurrent with these developments, the rapid emergence of a wide range of digital technologies offers a whole new set of affordances and potential health applications. We therefore argue for the design of digital supportive environments that utilize mobile devices, sensors, social media, game worlds and mechanics, in order to create transformative experiences that can effect large scale positive health behavior change.","Data Collection Capabilities of a New Non-Invasive Monitoring System for Patients with Advanced Multiple SclerosisThis paper reports on a data collection study in a clinical environment to evaluate a new non-invasive monitoring system for people with advanced Multiple Sclerosis (MS) who use powered wheelchairs. The proposed system can acquire respiration and heart activity from ballistocardiogram (BCG) signals, seat and back pressure changes, wheelchair tilt angle, ambient temperature and relative humidity. The data was collected at The Boston Home (TBH), a specialized care residence for adults with advanced MS. The collected data will be used to design algorithms to generate alarms and recommendations for residents and caregivers. These alarms and recommendations will be related to vital signs, low mobility problems and heat exposure. We present different cases where it is possible to illustrate the type of information acquired by our system and the possible alarms we will generate.","Learning Socially Optimal Information Systems from Egoistic UsersMany information systems aim to present results that maximize the collective satisfaction of the user population. The product search of an online store, for example, needs to present an appropriately diverse set of products to best satisfy the different tastes and needs of its user population. To address this problem, we propose two algorithms that can exploit observable user actions e.g. clicks to learn how to compose diverse sets and rankings that optimize expected utility over a distribution of utility functions. A key challenge is that individual users evaluate and act according to their own utility function, but that the system aims to optimize collective satisfaction. We characterize the behavior of our algorithms by providing upper bounds on the social regret for a class of submodular utility functions in the coactive learning model. Furthermore, we empirically demonstrate the efficacy and robustness of the proposed algorithms for the problem of search result diversification.","Business Design Support Method for E-Commerce Companies ","A Semantic Web Approach for Geodata DiscoveryCurrently, vast amounts of geospatial information are offered through OGC's services. However this information has limited formal se- mantics. The most common method to search for a dataset consists in matching keywords to metadata elements. By adding semantics to avail- able descriptions we could use modern inference and reasoning mecha- nisms currently available in the Semantic Web. In this paper we present a novel architecture currently in development in which we use state of the art triplestores as the backend of a CSW service. In our approach, each metadata record is considered an instance of a given class in a domain ontology. Our architecture also adds a spatial dataset of features with toponym values. These additions allow us to provide advance searches based on 1) Instance to class matching, 2) Class to class subsuming rela- tionships, 3) Spatial relationships resulting from comparing the bounding box of a metadata record with our toponym spatial dataset.","Artificial Intelligence Methods in Early Childhood Education ","Probabilistic Neural Network for the Automated Identification of the Harlequin Ladybird Harmonia AxyridisThis paper describes recent work in the UK to automate the identification of Harlequin ladybird species Harmonia axyridis using color images. The automation process involves image processing and the use of probabilistic neural network PNN as classifier, with an aim to reduce the number of color images to be examined by entomologists through pre-sorting the images into correct, questionable and incorrect species. Two major sets of features have been extracted: color and geometrical measurements. Experimental results revealed more than 75% class match for the identification of taxa with similar-colored spots.","Parallel transport with pole ladder: application to deformations of time series of imagesGroup-wise analysis of time series of images requires to compare observed longitudinal evolutions. In medical imaging, longitudinal anatomical changes can be modeled by using deformations resulting from the non-rigid registration of follow-up images. The comparison of longitudinal trajectories is therefore the transport of longitudinal deformations in a common reference frame. We previously showed that the Schild's Ladder is an efficient and simple method for the parallel transport of diffeomorphic deformations parameterized by tangent velocity fields. The Schild's Ladder is based on the construction of a geodesic parallelogram. The base vertices of the parallelogram are the pairs of follow-up images and another vertex is the reference frame. By building the geodesic diagonals of the parallelogram, Schild's Ladder computes the missing vertex which corresponds to the transported follow-up image. However, Schild's Ladder may be inefficient in case of time series of multiple time points, in which the computation of the geodesic diagonals is required several times. In this paper we propose a new algorithm, the Pole Ladder, in which one diagonal of the parallelogram is the baseline-to-reference frame geodesic. This way we have to compute only one diagonal for each time point along the curve. In this work we show that the transport of the Pole ladder and the Schild's Ladder are equivalent. Moreover, we show how the Pole ladder can be succesfully applied to the clinical problem of the measurement of the longitudinal atrophy progression in the brain for a group of patients affected by Alzheimer's disease.","A study of the effect of the shape, the color, and the texture of ikebana on a brain activityA study was performed on the difference between beginners and experts of Ikebana. The brain activity measurement results showed that for beginners, the incidence of \u03b1 wave increased with time both during the planning and the production of the arrangement. However, for experts, the incidence of \u03b1 wave decreased with time during the planning and increased during the production of the arrangement. This result indicated that the experts concentrate the mind more during the planning through the course of the arrangement, and relaxes more during the production of the arrangement. Also, the result of questionnaire survey showed that beginners were unable to recognize the formal beauty of an Ikebana arrangement, while experts were able to evaluate it correctly. It indicates that the experts have the special criteria of the formal beauty of Ikebana cultivated through the long-term training.","Hardware acceleration technologiesAs we reached the end of the microprocessor frequency scaling era, we adopted multi-core programming paradigms to support the need for greater processing speeds. Parallel programming techniques and software optimizations work well for certain classes of problems but not all. More exotic hardware accelerators have taken a place in the arsenal of tools we must use to continue to develop more powerful computing machines. Examples of hardware acceleration in the computing world abound -- Graphical Processing Units (GPU) found in each of our laptops, desktops and smartphones are perhaps the most pervasive and well known example of accelerators. Without the aid of these dedicated computing engines, many of the processing capabilities that we take for granted would either not be possible or not be power efficient enough to meet a user's needs. Field Programmable Gate Arrays (FPGAs), Digital Signal Processors (DSPs) and specialized processors such as Intel's Xeon Phi are all examples of compute accelerators. When speaking about Hardware Accelerators, we must also note that is another category known as I/O acceleration technologies -- Remote Direct Memory Access (RDMA) and TCP/IP Offload Engines (TOE) being prominent examples. There are also acceleration technologies that improve memory architectures -- Hybrid Memory Cube, Non-Volatile DIMMs, FLASH and various new forms of RAM all fall into this category.","Combining recency and topic-dependent temporal variation for microblog searchThe appearance of microblogging services has led to many short documents being issued by crowds of people. To retrieve useful information from among such a huge quantity of messages, query expansion (QE) is usually used to enrich a user query. Some QE methods for microblog search utilize temporal properties (e.g., recency and temporal variation) derived from the real-time characteristic that many messages are posted by users when an interesting event has recently occurred. Our approach leverages temporal properties for QE and combines them according to the temporal variation of a given topic. Experimental results show that this QE method using automatically combined temporal properties is effective at improving retrieval performance.","Enabling access to healthy food alternatives for low-income families: the role of mobile technologyThis research explores the barriers that marginalized citizens face with access to healthy alternatives to the high calorie, highly-processed foods available in most urban areas. Numerous barriers, including technology-related ones, are identified and propositions are offered that might reduce the negative effect of these challenges/encounters. From examining the benefit to citizens on public assistance that results from adequate education about healthy eating, to education on the existence of accessible healthy alternatives, and access to inexpensive accessible food sources this study focuses on offering possible real world solutions, both technology-related and non-technology related, to the barriers to inclusion of economically marginalized citizens.","Utilizing Disease-Specific Organ Shape Components for Disease Discrimination: Application to Discrimination of Chronic Liver Disease from CT Data ","Local Model of the Air Quality on the Basis of Rough Sets Theory ","Trustworthiness Evaluation of Multi-sensor Situation Recognition in Transit Surveillance Scenarios ","WSSL: a fluent calculus-based language for web service specificationsIn order to effectively discover and invoke a Web service, the provider must supply a complete specification of its behavior, with regard to its inputs, outputs, preconditions and effects. Devising such complete specifications comes with many issues that have not been adequately addressed by current service description efforts, such as WSDL, SAWSDL, OWL-S and WSMO. These issues involve the frame, ramification and qualification problems, which deal with the succinct and flexible representation of non-effects, indirect effects and preconditions, respectively. We propose WSSL, a novel specification language for services, based on the fluent calculus, that is expressly designed to address the aforementioned issues. Also, a tool is implemented that translates WSSL specifications to FLUX programs and allows for service validation based on user-defined goals.","Ownership-Based isolation for concurrent actors on multi-core machinesThe deep copy of messages that traditionally ensures the memory isolation of actors severely hinders the performance of actor systems on multi-core machines. Several approaches have been proposed in the state of the art to circumvent this overhead, but they require to choose two properties out of the three desired ones: safety, programmability, and efficiency. In this paper, we introduce a novel runtime ownership model that supports the first memory isolation model of actors with these three properties--it is safe, developer-friendly, and efficient.","Contraction to Matroidal Structure of Rough SetsAs an important technique for granular computing, rough sets deal with vagueness and granularity in information systems. Rough sets are usually used in attribute reduction, however, the corresponding algorithms are often greedy ones. Matroids generalize the linear independence in vector spaces and provide well-established platforms for greedy algorithms. In this paper, we apply contraction to a matroidal structure of rough sets. Firstly, for an equivalence relation on a universe, a matroid is established through the lower approximation operator. Secondly, three characteristics of the dual of the matroid, which are useful for applying a new operation to the dual matroid, are investigated. Finally, the operation named contraction is applied to the dual matroid. We study some relationships between the contractions of the dual matroid to two subsets, which are the complement of a single point set and the complement of the equivalence class of this point. Moreover, these relationships are extended to general cases. In a word, these results show an interesting view to investigate the combination between rough sets and matroids.","Scene Perception and Recognition in Industrial Environments for Human-Robot InteractionIn this paper, a scene perception and recognition module aimed at use in typical industrial scenarios is presented. The major contribution of this work lies in a 3D object detection, recognition and pose estimation module, which can be trained using CAD models and works for noisy data, partial views and in cluttered scenes. This algorithm was qualitatively and quantitatively compared with other state-of-art algorithms. Scene perception and recognition is an important aspect in the design of intelligent robotic systems which can adapt to unstructured and rapidly changing environments. This work has been used and evaluated in several experiments and demonstration scenarios for autonomous process plan execution, human-robot interaction and co-operation.","Boundary Detection of Objects in Digital Images Using Bit-Planes and Threshold Modified Canny MethodTwo novel Canny-based boundary detection techniques are presented in this paper. Canny edge detection has gained popularity over the period due to its potential in edge detection. However, the edges detected by Canny are highly superfluous to extract the boundary of the objects in an image. The Modified Canny methods address this issue by modifying the parameter of Canny. The first method namely Threshold Modified Canny (MC-T) uses the Mean of the input image as threshold. MC-T is found to produce the boundaries even on the high-contrast images. The Second method, Bit-planes and Threshold Modified Canny (MC-BT) performs edge detection on the three intensity significant bit-planes using Mean of the input image as Threshold. This technique has also produced promising results in detecting the image boundary. The second method as it works only on three bit planes information of the input image, it reduces insignificant details and yields significant object boundaries. The result of the two proposed techniques, suitably finds place in object recognition, pattern recognition / matching etc. where boundary detection is an important component. These approaches are much promising in terms of clear boundary detection of an object, as boundary detection by conventional methods is very time consuming.","An Enhanced Mental Model Elicitation Technique to Improve Mental Model Accuracy ","On Distributed Optimization, Convex Relaxations, and Sensor Network Localization Problems ","Evaluating Business Modeling Tools from a Creativity Support System Perspective \u2013 Results from a Focus Group in the Software Development Industry ","Hybrid Standard Platform for E-Journal Usage Statistics Management ","Searching private data in a cloud encrypted domainCloud computing security and reliability are important challenges in the research agenda. For some applications managing sensitive data, cloud security solutions and data-privacy management are the main concerns for organizations that are considering a move to the cloud. The advantages of cloud computing include reduced costs, easy maintenance and re-provisioning of resources, thereby also possibly increasing profits. But the adoption of Cloud Computing solutions applies only if different security concerns are ensured. This article presents a solution for data storage and data management in Internet Storage Clouds, preserving privacy conditions under the control of Cloud users. The proposed solution supports operations over stored encrypted data, including reading, writing and searching based on relevance ranking and multiple keywords. The approach is based on a middleware architecture supported by homomorphic encryption techniques combined with dynamic indexing mechanisms. The solution preserves data-privacy without need to either decipher data during operations in the Cloud or transfer the data during searches. The article further describes an implementation prototype of the solution and its evaluation. The evaluation shows that the solution is viable, offers security and privacy control for the user and does not aggravate conditions of data-access latency and availability.","BotSuer: Suing Stealthy P2P Bots in Network Traffic through Netflow AnalysisA large proportion of modern botnets are currently shifting towards structured overlay topologies, using P2P protocols, for command and control. These topologies provide a better resilience against detection and takedown as they avoid single nodes of failure in the botnet architecture. Yet current state of the art techniques to detect P2P bots mostly rely on swarm effects. They detect bots only when there is multiple infected nodes belonging to the same botnet inside a network perimeter. Indeed, they cannot detect botnets that use public P2P networks such as the TDSS malware using Kad, let alone botnets that encapsulate P2P overlays within HTTP traffic, such as waledac, or even hide behind Tor networks.#R##N##R##N#In this paper, we propose a new and fully behavioral approach to detect P2P bots inside a network perimeter. Our approach observes only high-level malware traffic features with no need of deep packet inspection. We run samples of P2P malware inside a sandbox and we collect statistical features about malware traffic. We further use machine learning techniques in order to first clean the features set by discarding benign-like malware P2P behavior, and second to build an appropriate detection model. Our experimental results prove that we are able to accurately detect single infected P2P bots, while also satisfying a very low false positives rate.","Analysis of Elephant Users in Broadband Network TrafficElephant and mice phenomena of network traffic flows have been an interesting research area in the past decade. Several operational broadband measurement results showed that the majority of the traffic is caused by a small percentage of large flows, called the elephants .I n this paper, we investigate the same phenomenon in regards of users. Our results show that even though the packet level statistics of elephant users and elephant flows show similar characteristics, there is only a small overlap between the two phenomena.","Analyzing Two Participation Strategies in an Undergraduate Course CommunityNowadays, information systems, and more particularly, learning support systems, tend to include social interaction features in their design. These features generally aim to sustain the activities of partially virtual communities and help extend the physical presence of the community in the virtual space. In order to achieve a sustainable community, it is important to understand how the strategies used to promote participation influence the way in which community members interact and relate with each other. This article reports a comparative study on two different student participation strategies mediated by a learning support system. The first strategy stressed the quantity of contributions, and the second one promoted both quantity and quality of contributions. By analyzing the resulting interaction networks, we could better understand the interaction patterns among students in their respective communities and conclude ways to monitor interaction and help maintain the community sustainability in time.","Differences in User Responses to a Wizard-of-Oz versus Automated SystemWizard-of-Oz experimental setup in a dialogue system is commonly used to gather data for informing an automated version of that system. Previous work has exposed dependencies between user behavior towards systems and user belief about whether the system is automated or human-controlled. This work examines whether user behavior changes when user belief is held constant and the system\u2019s operator is varied. We perform a posthoc experiment using generalizable prosodic and lexical features of user responses to a dialogue system backed with and without a human wizard. Our results suggest that user responses are different when communicating with a wizarded and an automated system, indicating that wizard data may be less reliable for informing automated systems than generally assumed.","Design of Lightweight Web Page Tamper-Resistant Mechanism for Linux ","State Space Reduction for Sensor Networks Using Two-Level Partial Order ReductionWireless sensor networks may be used to conduct critical tasks like fire detection or surveillance monitoring. It is thus important to guarantee the correctness of such systems by systematically analyzing their behaviors. Formal verification of wireless sensor networks is an extremely challenging task as the state space of sensor networks is huge, e.g., due to interleaving of sensors and intra-sensor interrupts. In this work, we develop a method to reduce the state space significantly so that state space exploration methods can be applied to a much smaller state space without missing a counterexample. Our method explores the nature of networked NesC programs and uses a novel two-level partial order reduction approach to reduce interleaving among sensors and intra-sensor interrupts. We define systematic rules for identifying dependence at sensor and network levels so that partial order reduction can be applied effectively. We have proved the soundness of the proposed reduction technique, and present experimental results to demonstrate the effectiveness of our approach.","A Personal Document Network Building System for Digital Document Searches ","Adaptive Case Management as a Process of Construction of and Movement in a State SpaceDespite having a number of years of experience, adaptive case management (ACM) still does not have a theory that would differentiate it from other paradigms of business process management and support. The known attempts to formalize Case Management do not seem to help much in creating an approach that could be useful in practice. This paper suggests an approach to building such a theory based on generalization of what is used in practice on one hand and the state-oriented view on business processes on the other. In practice, ACM systems use a number of ready-made templates that are picked up and filled as necessary for the case. State-oriented view considers a process instance/case as a point moving in a specially constructed state space. This paper suggests considering a case template as a definition of a sub-space and piking different template on the fly as constructing the state space along with moving in it when filling the template. The result is similar to what in control-flow based theories are considered as a state space with variable numbers of dimensions. Beside suggestions to building a theory, the paper demonstrates the usage of the theory on an example.","Towards continuous reference architecture conformance analysisReference architectures (RA) are reusable architectures for artifacts in a particular domain. They can serve as a basis for designing new architectures, but also as a means for quality control during system development. Quality control is performed through checking the conformance of systems in development to (company-wide) reference architectures. If performed manually, reference architecture conformance checking is a time- and resource-intensive process. In this paper we outline an approach for reference architecture conformance checking of application architectures in the banking domain. Reference architectures are defined on the basis of reusable rules, consisting of roles and of constraints on roles and role relationships. Conformance checking can be performed semi-automatically and continuously by automating important steps like the extraction of the actual application architecture, the binding of reference architecture roles to the elements of a specific application architecture, and the evaluation of the reference architecture rules for an application architecture.","An Approach Based on Evaluation Particle Swarm Optimization Algorithm for 2D Irregular Cutting Stock ProblemCutting stock problem is an important problem that arises in a variety of industrial applications. An irregular-shaped nesting approach for two- dimensional cutting stock problem is constructed and Evolution Particle Swarm Optimization Algorithm (EPSO) is utilized to search optimal solution in this research. Furthermore, the proposed approach combines a grid approximation method with Bottom-Left-Fill heuristic to allocate irregular items. We evaluate the proposed approach using 15 revised benchmark problems available from the EURO Special Interest Group on Cutting and Packing. The performance illustrates the effectiveness and efficiency of our approach in solving irregular cutting stock problems.","Experimental teaching quality evaluation practice based on AHP-fuzzy comprehensive evaluation modelIn this thesis, we use the integration method of AHP and fuzzy comprehensive evaluation as the evaluation model for the experimental teaching evaluation system. First, we build a hierarchy model and calculate the weigh of evaluation factor by AHP, and then execute hierarchical the evaluation and obtain the total evaluation results by fuzzy comprehensive evaluation. Finally, we compare the evaluation results with the machine test scores of the final grade examination, students' evaluation of classroom teaching evaluation. The result reflects the effectiveness, maneuverability, and fairness of the model.","Linear Support Vector Machines for Error Correction in Optical Data Transmission ","Comparative Analysis of Voting Schemes for Ensemble-based Malware DetectionMalicious software (malware) represents a threat to the security and the privacy of computer users. Traditional signature-based and heuristic-based methods are inadequate for detecting some forms of malware. This paper presents a malware detection method based on supervised learning. The main contributions of the paper are two ensemble learning algorithms, two pre-processing techniques, and an empirical evaluation of the proposed algorithms. Sequences of operational codes are extracted as features from malware and benign files. These sequences are used to create three different data sets with different configurations. A set of learning algorithms is evaluated on the data sets. The predictions from the learning algorithms are combined by an ensemble algorithm. The predicted outcome of the ensemble algorithm is decided on the basis of voting. The experimental results show that the veto approach can accurately detect both novel and known malware instances with the higher recall in comparison to majority voting, however, the precision of the veto voting is lower than the majority voting. The veto voting is further extended as trust-based veto voting. A comparison of the majority voting, the veto voting, and the trust-based veto voting is performed. The experimental results indicate the suitability of each voting scheme for detecting a particular class of software. The experimental results for the composite F1-measure indicate that the majority voting is slightly better than the trusted veto voting while the trusted veto is significantly better than the veto classifier.","A Metrics Model to Measure the Impact of an Agile Transformation in Large Software Development OrganizationsAs the adoption of agile and lean methods continues to grow, measuring the effects of such a transformation can be valuable but chal- lenging due to the many variables influencing the outcome of a software project. In this paper we present a metrics model developed for measuring the effects of an agile and lean transformation on software development organizations. The model was developed iteratively in cooperation with industry partners within the Cloud Software Finland research project. The resulting metrics model is applicable to projects of any size, com- plexity and scope, using metrics that support agile and lean values. The model can be used to measure both past and ongoing projects, regardless of whether the process model used is plan driven or agile. In order to evaluate the metrics model, the proposed model has been piloted in an industry setting.","\"Facebook Distress\": A Model to Investigate Discontinuation of Social Networking Site Use. ","Applicability of the (m,k)-firm Approach for the QoS Enhancement in Distributed RTDBMSMany real-time applications are geographically distributed and have to use large amounts of real-time data. Using DRTDBMS is increasingly needed to better manage the large amount of real-time data. In order to take into account unpredictable workload, Quality of Service (QoS) based approaches are the most appropriate. In the particular case of distributed applications, it is necessary to consider the problems of load balancing for user transactions between different sites. Feedback Scheduling approaches can adapt to unpredictable workload variations. In this paper, we propose to apply a (m,k)-firm approach to schedule user transactions in a distributed feedback scheduling architecture. We also show that our approach can significantly improve the performance of existing approaches by increasing the number of transactions that meet their deadlines while maintaining the DRTDBMS in a stable state.","Dendritic Computations in a Rall Model with Strong Distal StimulationRall's work is the basis for investigating dendritic computations, but only recently the technology became available to study their properties experimentally. Empirical evidence supports the idea that synaptic inputs at distal dendritic locations set the context for recognizing synaptic activation patterns of synapses proximal to the soma. Such a context-dependence is fundamental for action selection and decision making. It is usually assumed that active channels in dendrites are necessary. Here we investigate under which conditions of synaptic drive, a passive dendrite model can realize such a context-dependence, and we find that stronger distal than proximal activation, paired with delayed inhibition, is sufficient to produce so-called up states. Testing the model on a different protocol (selectivity to synaptic activation sequences: distal to proximal vs. proximal to distal) shows that it is more similar to recent experimental findings than Rall's original parameterization, and similar to a model with active dendrites. Our results show that, given stronger distal activation, context-dependent pattern recognition can be implemented in passive dendrites. As a consequence, future experimental studies need to determine on a case-by-case basis the contribution of active channels in dendrites (a single neuron property) vs. synaptic drive (a network property) in context-dependent pattern recognition.","A Methodology to Validate Interactive Storytelling Scenarios in Linear LogicDebugging is one of the main requirements for Interactive Storytelling (IS) authoring tools. During the authoring phase, authors have to specify large numbers of rules and actions as well as consider many possible paths. As a consequence, flaws may happen and finding them \"by hand\" is complex. Therefore the validation of an IS becomes a crucial issue and automatic assistance in this process is needful. Originated from those requirements, we propose, within the framework of this paper, a methodology using Linear Logic, based on analyzing automatically the resource allocation mechanisms, that helps authors derive a valid scenario of an IS. To do this, we model a scenario by a Linear Logic sequent, then prove the received sequent, which allows building and examining automatically all the possible branches in the scenario, thereby authors may guarantee that all the decisions (that may be made while unfolding the IS) lead to satisfactory endings of their goals. The paper ends with an example on an extract of an educational game to illustrate the methodology.","Window Manager Designed for Cloud Services ","Games on prescription! evaluation of the elinor console for home-based stroke rehabilitationThis paper reports the feasibility of Elinor, a game-based system for stroke rehabilitation in the home. The Elinor prototype has been positively evaluated with respect to its usability, user acceptance and motivational factors as well as its rehabilitation effect. This paper reports the findings from the whole project. To summarize the results, we find that game factors can be used to enhance motivation for rehabilitation. We had positive results with respect to many of the rehabilitation measurements employed. For example, the assessment of motor and process skills was positive as were also the self-reported improvements in daily activities. Furthermore, it seems that an increased self-efficacy with respect to the belief that the treatment can have an effect is positive and expected to increase motivation to undergo necessary rehabilitation. The usability and perceived usefulness of the system were also positively evaluated and the subjects expressed a positive attitude towards the system as well as a belief in its usefulness.","Reconstruction and Enumeration of hv-Convex Polyominoes with Given Horizontal ProjectionEnumeration and reconstruction of certain types of polyominoes, according to several parameters, are frequently studied problems in combinatorial image processing. Polyominoes with fixed projections play an important role in discrete tomography. In this paper, we provide a linear-time algorithm for reconstructing hv-convex polyominoes with minimal number of columns satisfying a given horizontal projection. The method can be easily modified to get solutions with any given number of columns. We also describe a direct formula for calculating the number of solutions with any number of columns, and a recursive formula for fixed number of columns.","Social Media and Evolving Marketing Communication Using IT. ","Automated Assistance Robot System for Transferring Model-Free Objects From/To Human Hand Using Vision/Force ControlThis paper will propose an assistance robot system which is able to transfer model-free objects from/to human hand with the help of visual servoing and force control. The proposed robot system is fully automated, i.e. the handing-over task is performed exclusively by the robot and the human will be considered as the weakest party, e.g. elderly, disabled, blind, etc. The proposed system is supported with different real time vision algorithms to detect, to recognize and to track: 1. Any object located on flat surface or conveyor. 2. Any object carried by human hand. 3. The loadfree human hand. Furthermore, the proposed robot system has integrated vision and force feedback in order to: 1. Perform the handing-over task successfully starting from the free space motion until the full physical human-robot integration. 2. Guarantee the safety of the human and react to the motion of the human hand during the handing-over task. The proposed system has shown a great efficiency during the experiments.","Interactive Business Models to Deliver Product-Services to Global MarketsThe main aim of this paper is to propose a collaborative solution platform to design, assess and deploy technology-based business models, supporting the analysis and evaluation of business ecosystems for the manufacturing and delivery of customised product-services in global markets. The proposed platform will guarantee a common thread for the execution of a multi-stage gate reference process for the generation and consolidation of a technology-based business model, providing a consistent path from the idea generation to the production, delivery and commercialisation of a solution.","Virtual Team Effectiveness: Investigating the Moderating Role of Experience with Computer-Mediated Communication on the Impact of Team Cohesion and Openness ","The impact of operations strategies for emergency room in TaiwanFirst aid is a primary part in the medical system; however, large-scale medical centers are facing the dilemma of overcrowding. When the number of emergency patients increases over the allocation of manpower and equipment, emergency is likely to be overloaded. Such a dilemma might crowd out the resources for critical patients, seriously affect the emergency service quality, and reduce the morale of staff before the patients being safe.#R##N##R##N#With system simulation, this study establishes an emergency simulation model aiming at the researched subjects to discuss the authenticity of present emergency room. Furthermore, National Emergency Department Overcrowding Scale (NEDOCS), the emergency compound standard, is utilized for evaluating the overcrowding degree in emergency rooms. Two strategies, proposed for improving the overcrowded emergency rooms receiving emergency patients, are also evaluated the effects on the overcrowding degree with NEDOCS. The outcomes show that the proposed strategies could actually improve the overcrowding in emergency rooms.","The relationship between IT infrastructure leveraging, talent management and operational sustainability, and their effects on the business value of the operations strategy ","A multi-task learning approach for compartmental model parameter estimation in DCE-CT sequencesToday's follow-up of patients presenting abdominal tumors is generally performed through acquisition of dynamic sequences of contrast-enhanced CT. Estimating parameters of appropriate models of contrast intake diffusion through tissues should help characterizing the tumor physiology, but is impeded by the high level of noise inherent to the acquisition conditions. To improve the quality of estimation, we consider parameter estimation in voxels as a multi-task learning problem (one task per voxel) that takes advantage from the similarity between two tasks. We introduce a temporal similarity between tasks based on a robust distance between observed contrast-intake profiles of intensity. Using synthetic images, we compare multi-task learning using this temporal similarity, a spatial similarity and a single-task learning. The similarities based on temporal profiles are shown to bring significant improvements compared to the spatial one. Results on real CT sequences also confirm the relevance of the approach.","Understanding the Effect of Message Content and User Identity on Information Diffusion in Online Social Networks. ","V2V Communication Channels: State of Knowledge, New Results, and What\u2019s NextThis paper surveys the field of vehicle-to-vehicle (V2V) communica- tion channels. Motivated by intelligent transportation systems and vehicular safety, V2V research has proliferated in recent years. We provide a short de- scription of V2V communication systems, and the importance of key channel parameters. This is followed by a discussion of basic channel characteristics\u2014 the channel impulse response and channel transfer function, and their statistical description\u2014and how V2V channels differ from the more familiar cellular ra- dio channel. Modeling of the V2V channel is covered by a review of the litera- ture on V2V channels, addressing path loss, delay spread, and Doppler spread. We describe the two most popular methods for modeling V2V channels, tapped-delay line models and geometry-based models, then briefly discuss mul- tiple-antenna channels and the crucial V2V channel characteristic of non- stationarity. A potential channel classification scheme for V2V channels is giv- en, and some recent results on the channel within parking garages, and on sloped terrain, are provided. We end the paper with a short discussion of what may come next in this vibrant field.","Agent-Based Framework Facilitating Component-Based Implementation of Distributed Computational Intelligence SystemsThe paper presents a framework particularly suitable for the design of a certain class of distributed computational intelligence systems based on the agent paradigm. A starting point constitutes a formalism utilizing the notions of algorithms and dependencies, which allows for the formulation of the system functional integrity conditions. Next, techno- logical assumptions of AgE framework are presented and a direct map- ping between the formalism and the implementation structure of the framework is discussed. The approach assumes that component tech- niques facilitate the realization of the particular system in such a way that algorithm dependencies are represented as contracts. These allow to support the verification of the system's functional integrity. Selected technical aspects of the framework design illustrate the considerations of the paper.","The Finnish Car Rejection Reasons Shown in an Interactive SOM Visualization ToolIn this paper a new SOM visualization tool is introduced. It is shown how Collaborative Filtering can be used as preprocessing before the SOM train- ing. Our goal was to provide for the user a possibility to analyze car differences by component planes which is not possible by original published tables. In ad- dition it is possible to explore how different flaws are related in time or with other variables. The effects of the driver dependent components, such as tires, can be filtered out from rejection probability using the component plane code- books. The interactive SOM visualization is very useful when a large number of labels is present. We developed a function to generate the needed files for a Processing language based tool. Our tool can be used simultaneously with the SOM Toolbox.","Detecting and Preventing Beacon Replay Attacks in Receiver-Initiated MAC Protocols for Energy Efficient WSNsIn receiver-initiated MAC protocols for Wireless Sensor Networks WSNs, communication is initiated by the receiver of the data through beacons containing the receiver's identity. In this paper, we consider the case of a network intruder that captures and replays such beacons towards legitimate nodes, pretending to have a fake identity within the network. To prevent this attack we propose RAP, a challenge-response authentication protocol that is able to detect and prevent the beacon replay attack. The effectiveness of the protocol is formally verified using OFMC and ProVerif. Furthermore, we provide an analysis that highlights the trade-offs between the energy consumption and the level of security, defined as the resilience of the protocol to space exhaustion.","An agent design for repeated negotiation and information revelation with people: Extended AbstractMany negotiations in the real world are characterized by incomplete information, and participants' success depends on their ability to reveal information in a way that facilitates agreement without compromising the individual gains of agents. This paper presents a novel agent design for repeated negotiation in incomplete information settings that learns to reveal information strategically during the negotiation process. The agent used classical machine learning techniques to predict how people make and respond to offers during the negotiation, how they reveal information and their response to potential revelation actions by the agent. The agent was evaluated empirically in an extensive empirical study spanning hundreds of human subjects. Results show that the agent was able (1) to make offers that were beneficial to people while not compromising its own benefit; (2) to incrementally reveal information to people in a way that increased its expected performance. The agent also had a positive effect on people's strategy, in that people playing the agent performed significantly higher than people playing other people. This work demonstrates the efficacy of combining machine learning with opponent modeling techniques towards the design of computer agents for negotiating with people in settings of incomplete information.","Reflections on a virtual experiment addressing human behavior during epidemicsWe report on preliminary results from a pilot study using a virtual experiment to analyse human behavior during epidemics of an infectious disease. The experiment used a two-dimensional computer game representing an epidemic scenario, linked to an agent-based simulation of an epidemic spreading through a large population. 230 participants played the game and completed question-naires about their characteristics in relation to a psychological model of health behaviour, Protection Motivation Theory. The results show that participants responded to increasing infection load in their local neighbourhood by reducing their social contacts, as they would be expected to do in reality. However, there was no correlation between the strength of this response and a number of psychological factors that are known to be associated with health protective behavior in the real world. This suggests that participants might not have responded to the game in the same way they would respond to a real epidemic. We discuss possible explanations for this mismatch, drawing on ideas from experimental behavioral economics, psychology, computer game design, and the study of virtual worlds, and suggest ways in which our experimental methodology could be improved to produce a more realistic response.","A Domain Meta-wrapper Using Seeds for Intelligent Author List Extraction in the Domain of Scholarly Articles ","A Multi-Agent Approach for Modeling Oligarchs' Campaign Donations with Simulated Spatial ElectionsWe present the OLIGO model, a multi-agent simulation of oligarchy. We extend previous multi-agent-based, spatial models of democracy by adding a new class of agents, oligarchs, which represent leaders of firms in a common industry who lobby for beneficial subsidies through campaign donations. We test hypotheses from the literature in political economics on the behavior of oligarchs and political parties as they interact, under conditions of imperfect information and bounded rationality. By verifying that central hypotheses from the economics literature hold for the OLIGO model, we accomplish two goals: (1) We show that the simple rules agents follow in our model are sufficient to capture much of the complex dynamics of this politico-economic system; (2) we validate these results from prior studies that used analytic methods, using an alternative, agent-based modeling method; and (3) we derive support for the claim that the OLIGO model is a useful test environment for novel hypotheses about oligarchs\u2019 campaign donation behavior.","Network Coding Advantage over MDS Codes for Multimedia Transmission via Erasure Satellite Channels ","Evaluation of Low-Level Image Representations for Illumination-Insensitive Recognition of Textureless ObjectsIn this paper the problem of recognizing textureless objects in unconstrained illumination and material conditions is investigated. We evaluate the discriminative power of various low-level image features for a pixelwise representation of the underlying surface characteristics of the object. For this purpose, a new dataset with rendered images of 3D models is used which allows to directly compare the inuences of texture and material properties in an object recognition scenario. The results are further validated on a dataset of real object images and nally reveal that jets of single- and multi-scale even Gabor lter responses outperform other proposed features in scenarios with textureless objects and strong variations of illumination.","Supporting Interaction with Digital Product Memories ","An Overview on the Structure and Applications for Business Intelligence and Data Mining in Cloud ComputingCloud Computing is a new computational paradigm which has attracted a lot of interest within the business and research community. Its objective is to inte- grate a wide amount of heterogeneous resources in an online way to provide services under demand to different types of users, which are liberated from the details of the inner infrastructure, just concentrating on their request of resources over the net. Its main features include an elastic resource configuration and therefore a suitable framework for addressing scalability in an optimal way. From the different scenar- ios in which Cloud Computing could be applied, its use in Business Intelligence and Data Mining in enterprises delivers the highest expectations. The main aim is to extract knowledge of the current working of the business, and therefore to be able to anticipate certain critical operations, such as those based on sales data, fraud detec- tion or the analysis of the clients' behavior. In this work, we give an overview of the current state of the structure of Cloud Computing for applications on Business Intel- ligence and Data Mining. We provide details of the layers that are needed to develop such a system in different levels of abstraction, that is, from the underlying hardware platforms to the software resources available to implement the applications. Finally, we present some examples of approaches from the field of Data Mining that had been migrated to the Cloud Computing paradigm.","An Authenticated Transitive-Closure Scheme for Secure Group Communication in MANETSIt is essential to provide authentication on mobile nodes in group communication to ensure security and privacy. The nodes that are interested in participating in the group communication form Graphs (V, E). In this paper we authenticate the mobile nodes through transitive closure property of the graph in the routing phase of the On Demand Multicast Routing Protocol (ODMRP) that forms Transitive closure graph. We also performed collaborative group key generation with the nodes defined in the transitive closure graph to accomplish secure communication among the group members. Due to the dynamic nature of nodes in the group, we propose the join and leave algorithm. The rekeying is performed at every change that happens in the (Transitive Closure Graph) TCG. The performance analysis is done by simulation with various protocols with respect to the time taken to joining or leaving the group, time taken for group key generation, rekeying the nodes with respect to renewal of nodes in the group. The proposed system shows our protocol reduces the computational and communicational cost of secure group communication.","Eliminating Cache-Based Timing Attacks with Instruction-Based SchedulingInformation \ufb02ow control allows untrusted code to access sensitive and#R##N#trustworthy information without leaking this information. However, the presence#R##N#of covert channels subverts this security mechanism, allowing processes to communicate information in violation of IFC policies. In this paper, we show that#R##N#concurrent deterministic IFC systems that use time-based scheduling are vulnerable to a cache-based internal timing channel. We demonstrate this vulnerability#R##N#with a concrete attack on Hails, one particular IFC web framework. To eliminate#R##N#this internal timing channel, we implement instruction-based scheduling, a new#R##N#kind of scheduler that is indifferent to timing perturbations from underlying hardware components, such as the cache, TLB, and CPU buses. We show this scheduler is secure against cache-based internal timing attacks for applications using a#R##N#single CPU. To show the feasibility of instruction-based scheduling, we have implemented a version of Hails that uses the CPU retired-instruction counters available on commodity Intel and AMD hardware. We show that instruction-based#R##N#scheduling does not impose signi\ufb01cant performance penalties. Additionally, we#R##N#formally prove that our modi\ufb01cations to Hails\u2019 underlying IFC system preserve#R##N#non-interference in the presence of caches.","Implementation of Emergency Medical Text Classifier for syndromic surveillance.Public health officials use syndromic surveillance systems to facilitate early detection and response to infectious disease outbreaks. Emergency department clinical notes are becoming more available for surveillance but present the challenge of accurately extracting concepts from these text data. The purpose of this study was to implement a new system, Emergency Medical Text Classifier (EMT-C), into daily production for syndromic surveillance and evaluate system performance and user satisfaction. The system was designed to meet user preferences for a syndromic classifier that maximized positive predictive value and minimized false positives in order to provide a manageable workload. EMT-C performed better than the baseline system on all metrics and users were slightly more satisfied with it. It is vital to obtain user input and test new systems in the production environment.","Segmentation of Crop Nutrient Deficiency Using Intuitionistic Fuzzy C-Means Color Clustering AlgorithmNowadays, crop nutrient deficiency is common in most of the agricultural fields in India due to inadequate and imbalanced fertilization. The main aim of this work is to segment and calculate the percentage of nutrient deficiency which helps to predict the rate of fertilization needed for that crop. In this paper, a new intuitionistic fuzzy c-means color clustering algorithm (IFCM) is introduced using intuitionistic fuzzy sets (IFSs) with its distance function defined from similarity measure. Initially, all the experimental images are preprocessed. Then the preprocessed images are segmented by using the proposed clustering algorithm. The experimental results obtained by IFCM algorithm are compared with fuzzy c-means algorithm (FCM) to show the effectiveness of the proposed algorithm. Comparison results reveal that the proposed segmentation method is capable of segmenting uncertain crop images with nutrient deficiency.","Implementation of a computerized patient handoff application.For hospitalized patients, handoffs between providers affect continuity of care and increase the risk of medical errors. Most commercial electronic health record (EHR) systems lack dedicated tools to support patient handoff activities. We developed a collaborative application supporting patient handoff that is fully integrated with our commercial EHR. The application creates user-customizable printed reports with automatic inclusion of a variety of EHR data, including: allergies, medications, 24-hour vital signs, recent common laboratory test results, isolation requirements, and code status. It has achieved widespread voluntary use at our institution (6,100 monthly users; 700 daily reports generated), and we have distributed the application to several other institutions using the same EHR. Though originally designed for resident physicians, today about 50% of the application users are nurses, 40% are physicians/physician assistants/nurse practitioners, and 10% are pharmacists, social workers, and other allied health providers.","Solving Modular Model Expansion: Case StudiesModel expansion task is the task of representing the essence of search problems where we are given an instance of a problem and are searching for a solution satisfying certain properties. Such tasks are common in AI planning, scheduling, logistics, supply chain management, etc., and are inherently modular. Recently, the model expansion frame- work was extended to deal with multiple modules to represent e.g. the task of constructing a logistics service provider relying on local service providers. In the current paper, we study existing systems that operate in a modular way in order to obtain general principles of solving mod- ular model expansion tasks. We introduce a general algorithm to solve model expansion tasks for modular systems. We demonstrate, through several case studies, that our algorithm closely corresponds to what is done in practice in different areas such as Satisfiability Modulo Theories (SMT), Integer Linear Programming (ILP), and Answer Set Program- ming (ASP). We make our framework language-independent through a model-theoretic development.","Disparity Map Estimation by Combining Cost Volume Measures Using Genetic Programming ","Design recommendations for the development of a digital storytelling mobile applicationThis paper focuses on the educational benefits of Digital Storytelling (DST) in the context of a primary school and on the importance of a DST application that supports teaching strategies and pedagogical objectives (as defined by the school curriculum). The work presented here is part of a 4-year longitudinal study aimed at understanding how to design an application that supports collaborative DST as educational practice in schools with children aged 6 to 11. In this paper, we describe how a typical case study has been conducted and how we used the Narrative Activity Model (NAM) as a framework to guide the activity analysis and to organize our findings. The result is a set of users' needs and guidelines for the development of an innovative DST application to be used in a formal learning context.","Towards the Intelligent Home: Using Reinforcement-Learning for Optimal Heating Control ","Predictable two-level bus arbitration for heterogeneous task setsIn a multicore processor, arbitrating the shared resources so as to ensure predictable latencies for hard real-time tasks is challenging. In [1], we have introduced a two-level bus arbitration scheme that fits the needs of heterogeneous task sets, when some tasks have a higher demand to memory than others. In this paper, we show how this scheme can be used to optimise the overall utilisation of the cores while enforcing the schedulability of the whole task set. Our approach both configures the bus arbiter and maps the tasks onto the cores. Experimental results show that it reduces the global utilisation of the cores compared to the traditional round-robin scheme.","Experiments on Reducing Footprint of Unit Selection TTS System ","From Ideal Data Synchronization to Hybrid Forms of Interconnections: Architectures, Processes, and Data. ","To Relay or Not to Relay: Learning Relaying Strategies in Cellular Device-to-Device Networks. ","An evaluation of the ipod touch as an alternative low-vision magnifier for people with low visionThis study evaluated the feasibility of using the iPod Touch as an alternative low-vision magnifier by comparing its usability issues, subjective ratings, and preferences with those of two existing low-vision magnifiers (SmartView Pocket and Amigo). Thirty participants (30-91 years) performed magnification adjustment tasks and reading tasks using three devices and rated the devices based on ease of use, ease of understanding, and satisfaction. The results show 60% of the participants preferred the pinch zoom gesture and 66% preferred the scrolling one-finger gesture on the iPod Touch. This high user preference data indicate participants' acceptability of finger gestures, which suggests new opportunities for the adoption of new technology for low-vision video magnifiers. The gesture interfaces may be a promising method for magnification and navigation for low-vision users.","Learning to Classify Short Text with Topic Model and External KnowledgeMany methods have been developed to utilize topic analysis models to deal with the noises and sparseness of the text. However, the use of a topic model solely sometimes unable to achieve the expected high performance, it is very necessary to improve the current topic model to cope with the characteristic of texts and specific requirements. In this paper, we focus on two tasks. One is to make use of different external corpus to identify topics from texts for better categorization. The other is to add the weight of a few features in texts to get some other top- ics from those of topic model. We further evaluate the performance of the two tasks with baseline results. The experiments show that our pro- posed method can achieve a higher accuracy in text classification. The approach can find truly representative words which may contribute to wide acceptance of topic models in micro-blog analysis.","Performance Study of a New Modified Differential Evolution Technique Applied for Optimal Placement and Sizing of Distributed GenerationDetermination of optimal placement and sizing of Distributed Generations (DGs) is one of the important tasks in power system operation. Several conventional as well as heuristics techniques like particle swarm optimization, differential evolution etc. have been applied to solve the problem. But one of the major drawback of these techniques are the improper selection of user defined parameters for optimal solution. Improper selection of the parameters may even lead to premature convergence. A new modified differential evolution technique based algorithm is proposed in this paper for the solution of optimal sizing and location of distributed generation to avoid premature convergence. The proposed algorithm is applied on IEEE 14 and 30 bus systems to verify its effectiveness. The results obtained by the proposed method are compared with other methods. It is found that the results obtained by the proposed algorithm are superior in terms of cost and losses.","Research Prototypes versus Products: Lessons Learned from Software Development Processes in Research ProjectsSoftware and systems development in industry typically focus on con- structing high-quality products by using traditional or agile software processes and applying established tools and methods. Most projects have to handle more or less stable requirements but usually build on a proven architecture. On the other hand, research projects typically aim at investigating new ideas, facing promising research directions, showing feasibility of novel approaches or building proto- types for demonstration purposes. Obviously there seems to be a big gap between industrial projects and research projects. Anyway - after a period of research - there is the need to enable the transition from prototype to real products, compa- rable to industrial developed software products. The main challenge is bridging the gap between research prototypes and industry products, typically out of scope of a research project. As we have to handle these challenges in a long-running re- search project, this paper aims at identifying risks, challenges and candidate solu- tions to identify how to bridge the gap from research to industry. Main result of this paper is an adapted software engineering process that has been initially evaluated in context of our research project.","An Overlapping Domain Decomposition Method for a 3D PEMFC Model ","OpenML: A Collaborative Science PlatformWe present OpenML, a novel open science platform that pro- vides easy access to machine learning data, software and results to encour- age further study and application. It organizes all submitted results online so they can be easily found and reused, and features aw eb API which is being integrated in popular machine learning tools such as Weka, KNIME, RapidMiner and R packages, so that experiments can be shared easily.","Matrix Factorization with Content Relationships for Media PersonalizationContent personalization is identified as a key technology for enabling ubiquitous access to social media. Recommender systems implement media personalization, by suggesting relevant content and helping users in addressing the \"information overload\" problem. In this paper, our aim is to improve per- sonalization by increasing the accuracy of recommendations. We propose a novel method, called Content Relationships Matrix Factorization (CRMF), which exploits additional information in the form of content relationships that express relevance between items. We model content relationships based on af- finity graphs and use them in the context of matrix-factorization, which are cur- rently the state-of-the-art prediction models for recommender systems. In our experimental evaluation with a real data set, we demonstrate the accuracy im- provement of CRMF compared to matrix factorization models that do not take into account content relationships. Our experimental results show that CRMF compares favorably to the baseline method, demonstrating the usefulness of considering content relationships.","Monitoring norm violations in multi-agent systemsThe use of norms is widely accepted as an effective approach to control and regulate the behaviour of agents in multi-agent systems. Existing work on normative multi-agent systems has mainly focussed on how norms can influence the behaviour of agents by assuming that the agents' behaviours are perfectly monitored. In this paper we focus on monitoring mechanisms, propose different types of monitors, provide a logical analysis of monitors, study the relations between monitors and norms to be monitored, and finally explore computational aspects of norm monitoring.","Validation of a Multisensory System for Fruit Harvesting Robots in Lab Conditions. ","Exploring impact of e-marketplace reputation and reference group on trust of e-marketplace ","Guide to Voice and Video over IP: For Fixed and Mobile NetworksThis book presents a review of the latest advances in speech and video compression, computer networking protocols, the assessment and monitoring of VoIP quality, and next generation network architectures for multimedia services. The book also concludes with three case studies, each presenting easy-to-follow step-by-step instructions together with challenging hands-on exercises. Features: provides illustrative worked examples and end-of-chapter problems; examines speech and video compression techniques, together with speech and video compression standards; describes the media transport protocols RTP and RTCP, as well as the VoIP signalling protocols SIP and SDP; discusses the concepts of VoIP quality of service and quality of experience; reviews next-generation networks based on the IP multimedia subsystem and mobile VoIP; presents case studies on building a VoIP system based on Asterisk, setting up a mobile VoIP system based on Open IMS and Android mobile, and analysing VoIP protocols and quality.","Co-training and visualizing sentiment evolvement for tweet eventsSentiment classification on tweet events attracts more interest in recent years. The large tweet stream stops people reading the whole classified list to understand the insights. We employ the co-training framework in the proposed algorithm. Features are split into text view features and non-text view features. Two Random Forest (RF) classifiers are trained with the common labeled data on the two views of features separately. Then for each specific event, they collaboratively and periodically train together to boost the classification performance. At last, we propose a \"river\" graph to visualize the intensity and evolvement of sentiment on an event, which demonstrates the intensity by both color gradient and opinion labels, and the ups and downs of confronting opinions by the river flow. Comparing with the well-known sentiment classifiers, our algorithm achieves consistent increases in accuracy on the tweet events from TREC 2011 Microblogging and our database. The visualization helps people recognize turning and bursting patterns, and predict sentiment trend in an intuitive way.","On QBF Proofs and PreprocessingQBFs (quantified boolean formulas), which are a superset of propositional formulas, provide a canonical representation for PSPACE problems. To overcome the inherent complexity of QBF, significant effort has been invested in developing QBF solvers as well as the underlying proof systems. At the same time, formula preprocessing is crucial for the application of QBF solvers. This paper focuses on a missing link in currently-available technology: How to obtain a certificate (e.g. proof) for a formula that had been preprocessed before it was given to a solver? The paper targets a suite of commonly-used preprocessing techniques and shows how to reconstruct certificates for them. On the negative side, the paper discusses certain limitations of the currently-used proof systems in the light of preprocessing. The presented techniques were implemented and evaluated in the state-of-the-art QBF preprocessor bloqqer.","A Unified Framework for Emotional Elements Extraction Based on Finite State Matching Machine ","Using Automated Indices of Cohesion to Evaluate an Intelligent Tutoring System and an Automated Writing Evaluation SystemWe present an evaluation of the Writing Pal (W-Pal) intelligent tutor- ing system (ITS) and the W-Pal automated writing evaluation (AWE) system through the use of computational indices related to text cohesion. Sixty-four students participated in this study. Each student was assigned to either the W- Pal ITS condition or the W-Pal AWE condition. The W-Pal ITS includes strate- gy instruction, game-based practice, and essay-based practice with automated feedback. In the ITS condition, students received strategy training and wrote and revised one essay in each of the 8 training sessions. In the AWE condition, students only interacted with the essay writing and feedback tools. These stu- dents wrote and revised two essays in each of the 8 sessions. Indices of local and global cohesion reported by the computational tools Coh-Metrix and the Writing Assessment Tool (WAT) were used to investigate pretest and posttest writing gains. For both the ITS and the AWE systems, training led to the increased use of global cohesion features in essay writing. This study demon- strates that automated indices of text cohesion can be used to evaluate the effects of ITSs and AWE systems and further demonstrates how text cohesion develops as a result of instruction, writing, and automated feedback.","Continuous, Online Anomaly Region Detection and Tracking in Networks ","Efficient Online Novelty Detection in News Streams ","Master Slave LMPM Position Control Using Genetic Algorithms ","Signcryption from Randomness Recoverable PKE RevisitedA new generic construction of a signcryption scheme from randomness recoverable public key encryption PKE-RR is proposed. This paper modifies the 'Li &amp; Wong' construction [Information Sciences 180 2010] to achieve better security from weaker building blocks and thereby making it open to a larger class of encryption and signature schemes. The proposed construction achieves multi-user insider security for confidentiality in random oracle model and authenticity in standard model. It is done by incorporating one extra hashing in both signcryption and unsigncryption phases than the original construction.","Combining HCI, Natural Language Processing, and Knowledge Discovery - Potential of IBM Content Analytics as an Assistive Technology in the Biomedical Field ","Determining the conceptual space of metaphoric expressionsWe present a method of constructing the semantic signatures of target concepts expressed in metaphoric expressions as well as a method to determine the conceptual space of a metaphor using the constructed semantic signatures and a semantic expansion. We evaluate our methodology by focusing on metaphors where the target concept is Governance. Using the semantic signature constructed for this concept, we show that the conceptual spaces generated by our method are judged to be highly acceptable by humans.","Towards Connected Filtering Based on Component-GraphsIn recent works, a new notion of component-graph has been intro- duced to extend the data structure of component-tree -and the induced antiex- tensive filtering methodologies- from grey-level images to multivalued ones. In this article, we briefly recall the main structural key-points of component-graphs, and we present the initial algorithmic results that open the way to the actual development of component-graph-based antiextensive filtering procedures.","Evolving the Modular Layered Architecture in Digital Innovation: The Case of the Car's Instrument Cluster. ","A Six-Step Guide to Persuasive LearningBy combining existing methodological approaches from Persuasive Design and Learning, this paper presents the initial version of a general guide for creating persuasive learning designs. The notion of persuasive learning designs is based on the acknowledgement that there must be an appropriate balance between context and learning technology, and that reflections regarding the context must be included throughout the design process. The 6 step guide to persuasive learning springs from research conducted in the EuroPLOT project, however the approach aims to be generally applicable.","Effects of Visual Fidelity on Biometric Cue Detection in Virtual Combat Profiling Training ","The SafeCap Platform for Modelling Railway Safety and CapacityThis paper describes a tooling platform that supports reasoning about railway capacity while ensuring system safety. It uses a Domain Specific Language (DSL) that allows signalling engineers to design stations and junctions, to check their safety and to evaluate the potential improvements of capacity while applying various alteration patterns that change the railway schemas. The platform uses a combination of model checking and SMT solving to verify system safety in the most efficient and user-friendly way. It includes several plug-ins that evaluate various capacity parameters. The tool uses the Eclipse technology, including its EMF and GMF frameworks. It has been developed in close cooperation with the Invensys Rail engineers and applied in a variety of mediumscale projects, which has demonstrated its ability to help understand the effects that changes in the plans and schemas can potentially have on capacity.","Vibrotactile Cues for Motion GuidanceIn this paper, we have developed motion guiding device with utilizing Kinect of Microsoft Inc. for motion capturing sensor and phantom sensation which is famous tactile illusion effect generating space and direction induced vibrational information. The system detects real time motion of arm and its designated path. Then it guides arm motion along with the detected path with directional vibration information. The directional information of upper arm and lower arm was generated in order for the motion guidance by vibrations with the consideration of the pose of the arm. Instead of the discrete vibration in the vicinity of the vibrating motor, we could express continuous vibration for generating locational feedback along the arm with tactile illusion effect which induces the intentional motion. In order to evaluate the vibrational algorithm, the tactile illusion effect was implemented in the motion guidance experiments of the extension and flexion motion of the elbow joint.","Learning fields in vocational IT education: how teachers interpret the conceptVocational schools in Germany are part of the compulsory school system, but they differ from other secondary school types. They combine theory and practice by using learning venue cooperation between schools and vocational training companies. Taking this into account the curricula in the field of computer science (CS) and information and communication technologies (IT) are arranged in so-called \"Lernfelder\" (learning fields). Learning fields are worded openly, so teachers get leeway to select learning content for their purposes. But it seems that teachers interpret the concept of learning fields quite differently. The question is: How do vocational IT school teachers deal with learning fields? The elicitation study described in this paper explores the IT teachers' knowledge of the concept of learning fields. It is part of a project which aims to develop exemplary learning situations and helpful tools for several learning fields, which will support teachers in creating lessons in this context.","Memory Trace in Spiking Neural NetworksSpiking neural networks have a limited memory capacity, such that a stimulus arriving at time t would vanish over a timescale of 200-300 milliseconds [1]. Therefore, only neural computations that require history dependencies within this short range can be accomplished. In this paper, the limited memory capacity of a spiking neural network is extended by coupling it to an delayed-dynamical system. This presents the possibility of information exchange between spiking neurons and continuous delayed systems.","Remotely gauging upstream bufferbloat delays\"Bufferbloat\" is the growth in buffer size that has led Internet delays to occasionally exceed the light propagation delay from the Earth to the Moon. Manufacturers have built in large buffers to prevent losses on Wi-Fi, cable and ADSL links. But the combination of some links' limited bandwidth with TCP's tendency to saturate that bandwidth results in excessive queuing delays. In response, new congestion control protocols such as BitTorrent's uTP/LEDBAT aim at explicitly limiting the delay that they add over the bottleneck link. This work proposes and validate a methodology to monitor the upstream queuing delay experienced by remote hosts, both those using LEDBAT, through LEDBAT's native one-way delay measurements, and those using TCP (via the Timestamp Option).","Service subscription and consumption for personal web applicationsWeb services have played a vital role in our daily life for some time now. A wide spectrum of online applications have been developed in diverse domains such as banking, shopping, gaming, and video streaming. However, the end-user does often not have the means to tune the applications to her personal needs and interests, especially not across services from different providers. Moreover, the end-user can not take full advantage of the myriad of useful resources and services available on the Web, as interoperation among different services is often not given. Hence, the new Web application paradigm called Personal Web has emerged. The key idea behind the Personal Web is to have Web services exploit Web data that is collected and organized automatically according to the end-users' context and preferences. This paper introduces a new concept that enables Personal Web applications, namely, service subscription and consumption. This new concept is driven by events exposed from Semantic Web resources and Web services through Padres, a distributed content-based publish/subscribe messaging substrate, and Polaris, an approach for event exposure at service interfaces. We explain service subscription and consumption based on a comprehensive scenario and design a framework and architecture that realizes the approach.","An Agent Based Framework for Multiple, Heterogeneous Case Based ReasoningThis paper investigates the application of Multiple, Heterogeneous Case Based Reasoning (MHCBR) using agents operating on different structures/views of the problem domain in a transparent and autonomous way to retrieve solutions for a new problem from more than one case-base. An MHCBR framework is proposed. This framework includes sub-processes for subscribing of provider case-bases through agents, creating a dynamic structure, and retrieving solutions by using agents and employing a Blackboard communication architecture. A mechanism based on the competence of a provider case base is introduced to improve MHCBR performance. A negotiation system to support the retrieval process from each source case base of the MHCBR is proposed. ProMHCBR, a MHCBR system employing agents is discussed and an experimental evaluation of this system is presented.","Electronic end-of-life care registry: the Utah ePOLST initiative.As a patient\u2019s end-of-life approaches, it is typical for the disease to be the focus of treatment instead of the dying patient. There is limited congruence between the care preferred by patients and the treatment actually delivered to patients during their end-of-life. The Physician Orders for Life-Sustaining Treatment Paradigm has been endorsed or is in development in all but three states and the District of Columbia in an effort to ensure that patients are provided with adequate opportunities to specify their end-of-life care preferences. However, most states are using paper forms to document these preferences which may be inaccessible when needed. We have developed an electronic end-of-life care registry that allows authorized users to store and retrieve information pertaining to patients\u2019 end-of-life care preferences. In this paper, we describe (a) the requirements identified for the registry from the users\u2019 perspective and (b) the design and development of the electronic registry.","Local-Global Joint Decision Based Clustering for Airport Recognition ","New Selection Schemes in a Memetic Algorithm for the Vehicle Routing Problem with Time Windows ","Frames for Tensor Field MorphologyWe propose to apply our recently developed frame-based framework for group-invariant morphology to the problem of tensor field morphology. Group invariance (and particularly rotation invariance) have been, and are, motivated to be relevant for filtering tensor fields. This leads to the development of a rotation-invariant frame for tensors, which can be used to easily define rotation-invariant morphological operators on tensor fields. We also show how our method can be used to filter structure tensor fields.","An Approximate Execution of Rule-Based Multi-level ModelsIn cell biology, models increasingly capture dynamics at different organizational levels. Therefore, new modeling languages are developed, e.g., like ML-Rules, that allow a compact and concise description of these models. However, the more complex models become the more important is an efficient execution of these models. i\u00be?-leaping algorithms can speed up the execution of biochemical reaction models significantly by introducing acceptable inaccurate results. Whereas those approximate algorithms appear particularly promising to be applied to hierarchically structured models, the dynamic nested structures cause specific challenges. We present a i\u00be?-leaping algorithm for ML-Rules which tackles these specific challenges and evaluate the efficiency and accuracy of this adapted i\u00be?-leaping based on a recently developed visual analysis technique.","Pairwise similarity for cluster ensemble problem: link-based and approximate approachesCluster ensemble methods have emerged as powerful techniques, aggregating several input data clusterings to generate a single output clustering, with improved robustness and stability. In particular, link-based similarity techniques have recently been introduced with superior performance to the conventional co-association method. Their potential and applicability are, however limited due to the underlying time complexity. In light of such shortcoming, this paper presents two approximate approaches that mitigate the problem of time complexity: the approximate algorithm approach (Approximate SimRank Based Similarity matrix) and the approximate data approach (Prototype-based cluster ensemble model). The first approach involves decreasing the computational requirement of the existing link-based technique; the second reduces the size of the problem by finding a smaller, representative, approximate dataset, derived by a density-biased sampling technique. The advantages of both approximate approaches are empirically demonstrated over 22 datasets (both artificial and real data) and statistical comparisons of performance (with 95% confidence level) with three well-known validity criteria. Results obtained from these experiments suggest that approximate techniques can efficiently help scaling up the application of link-based similarity methods to wider range of data sizes.","Supporting a pseudo-TDMA access scheme in mesh wireless networksWireless mesh networks appear a promising solution for providing ubiquitous low-cost wireless access, but cannot rely on simple CSMA access protocols because of the critical inefficiencies that arise in topologies with hidden nodes. To overcome these limitations, some important protocol extensions based on synchronization and reservation mechanisms have been ratified.#R##N##R##N#In this paper we show that an alternative approach to the standardization of new features and signaling messages for mesh networks can be the utilization of programmable nodes able to execute different MAC protocols programmed on the fly. Signaling messages are used only for disseminating the new protocol among the nodes. The scheme, that we call pseudo-TDMA, can be optimized as a function of the node density in the network. Apart from the numerical evaluations, we also run some experiments by exploiting our prototype of wireless programmable node called Wireless MAC Processor.","A multi-objective feature selection approach based on binary PSO and rough set theoryFeature selection has two main objectives of maximising the classification performance and minimising the number of features. However, most existing feature selection algorithms are single objective wrapper approaches. In this work, we propose a multi-objective filter feature selection algorithm based on binary particle swarm optimisation (PSO) and probabilistic rough set theory. The proposed algorithm is compared with other five feature selection methods, including three PSO based single objective methods and two traditional methods. Three classification algorithms (naive bayes, decision trees and k-nearest neighbours) are used to test the generality of the proposed filter algorithm. Experiments have been conducted on six datasets of varying difficulty. Experimental results show that the proposed algorithm can automatically evolve a set of non-dominated feature subsets. In almost all cases, the proposed algorithm outperforms the other five algorithms in terms of both the number of features and the classification performance (evaluated by all the three classification algorithms). This paper presents the first study on using PSO and rough set theory for multi-objective feature selection.","The Study of Style for Kogi Pottery Art in LifeThere are plentiful and diverse culture assets and local sources in Taiwan, and thus the national soft power has been valued gradually, the tradi- tional craft industries also being focused as well. Koji pottery art has essential place in the architectures of Taiwan tempos, and it was considered as the repre- sentation of gods in the local belief which was sacredness in Taiwan. However, the elaborate Kogi pottery art which was applied in tempo architectures is inter- grading in people's life at home due to the constructive promotion to cultural creative industries from the government. Therefore, the study collected and discussed the develop status of Kogi pottery crafts via literature analysis exten- sively, as well as to explore the differences of the traditional implements that introduce to life art and analyze the styles via morphological analysis. The study has three conclusions as follows: 1. New opportunity can be created by introducing cultural creative ideas to Kogi pottery industry which allow it trans- forming to elaborate craft industry from traditional one. (2) Kogi pottery art work still has the unique style by describing abstract implications through con- crete forms. (3) Kogi pottery is trending toward simplification but nonetheless retains its symbolic meaning and achieves its goal of continuing its cultural heritage.","Hybrid Self Organising Migrating \u2013 Scatter Search AlgorithmA hybrid approach combining the unique exploration strategy of Discreet Self Organising Migration Algorithm and the robust and effective memory adaptive programming paradigm of Scatter Search is presented. The new hybrid approach is developed to solve permutative combinatorial optimization problems and it applied to the flow-shop with no-wait scheduling optimization problem. Experimentation is done with the benchmark Taillard sets and the obtained results are favorably com- pared with results in current literature","Business Process Outsourcing in Suriname: Call Center Services ","Repository-based implementation of information pyramid: a study based on an ERP case studyERP case studies have an important impact on the transfer of knowledge between software vendor, lecturer and user. This paper describes to which extent ERP case studies can be used to demonstrate a repository based integrated approach for modeling and implementing the entire information pyramid in the context of the Business Process Management life cycle. The study is based on the Global Bike Inc. enterprise model repository created with ARIS Business Designer for SAP by Software AG. The information models have been exemplarily synchronized with SAP Solution Manager repository and implemented with SAP ERP respectively with SAP Netweaver BI.","System for Estimation of Patient\u2019s State \u2013 Discussion of the Approach ","VIA - Visualizing Individual Actions to Develop a Sustainable Community Culture through CyclingImproving the sustainability of our society requires significant change in our collective behavior. But today, individuals in our society have no regular way of seeing that collective behavior, or how their own behavior compares to it. We are creating a research network that will study how new technologies such as mobiles and visualization can encourage individuals to change their behavior to improve sustainability. In Winston-Salem NC, network members will use new technologies to engage the community about its use of transportation--especially biking--and study how that communication affects sustainability awareness and behavior.","A Flexible Image-Based Access Control Model for Social Networks ","Gaussian Process Covariance Kernels for Pattern Discovery and Extrapolation ","Neural Networks Training Based on Differential Evolution in Radial Basis Function Networks for Classification of Web Logs ","Further Analysis on Stability for a Class of Neural Networks with Variable Delays and Impulses ","AppGuard: enforcing user requirements on android appsThe success of Android phones makes them a prominent target for malicious software, in particular since the Android permission system turned out to be inadequate to protect the user against security and privacy threats. This work presents AppGuard, a powerful and flexible system for the enforcement of user-customizable security policies on untrusted Android applications. AppGuard does not require any changes to a smartphone's firmware or root access. Our system offers complete mediation of security-relevant methods based on callee-site inline reference monitoring. We demonstrate the general applicability of AppGuard by several case studies, e.g., removing permissions from overly curious apps as well as defending against several recent real-world attacks on Android phones. Our technique exhibits very little space and runtime overhead. AppGuard is publicly available, has been invited to the Samsung Apps market, and has had more than 500,000 downloads so far.","Understanding election candidate approval ratings using social media dataThe last few years has seen an exponential increase in the amount of social media data generated daily. Thus, researchers have started exploring the use of social media data in building recommendation systems, prediction models, improving disaster management, discovery trending topics etc. An interesting application of social media is for the prediction of election results. The recently conducted 2012 US Presidential election was the \"most tweeted\" election in history and provides a rich source of social media posts. Previous work on predicting election outcomes from social media has been largely been based on sentiment about candidates, total volumes of tweets expressing electoral polarity and the like. In this paper we use a collection of tweets to predict the daily approval ratings of the two US presidential candidates and also identify topics that were causal to the approval ratings.","Leveraging on social media to support the global building resilient cities campaignThis paper presents a summary of the main points put forward during the presentation delivered at the 2nd International Workshop on Social Web for Disaster Management which was held in conjunction with WWW 2013 on May 14th 2013 in Rio de Janeiro, Brazil.","Discrepancy-Detection in Virtual Learning Environments for Young Children with ASC ","Evaluating community detection using a bi-objective optimizationCommunity detection consists on a partitioning networks technique into clusters (communities) with weak coupling (external connectivity) and high cohesion (internal connectivity). In order to measure the performance of the clustering, the network modularity is largely used, a metric that presents the cohesion and the coupling of communities. In this paper, a global and bi-objective function is proposed to evaluate community detection. This function combines modularity (based on structure and edges weights) and the inter-classes inertia (based on nodes weights). Then, we rely on a computational optimization technique i.e. Particle Swarm Optimization to maximize this bi-objective quality. Finally, a case study evaluates the proposed solution and illustrates practical uses.","Approximation Algorithms for the Maximum Multiple RNA Interaction Problem ","Structural Decomposition Trees: Semantic and Practical Implications ","About Experience and Emergence - A Framework for Decentralized Interactive Play EnvironmentsPlay is an unpredictable and fascinating activity. Its qualities can serve as an inspiration for design. In designing for play, we focus on play environments with players and multiple interactive objects. The current understanding of how to design these objects and interaction opportunities to create meaningful interactions and engaging user experiences is limited. In this paper we introduce a framework focusing on the development of decentralized interactive play environments for emergent play. This framework combines knowledge from different fields including play, user experience, emergent behavior and interactions. Two case studies demonstrate its use as a tool for analysis.","THE ROLE OF INFORMATION TECHNOLOGY AS A FIRM-SPECIFIC ADVANTAGE IN INTERNATIONALIZATION OF FIRMS : THEORY AND EVIDENCEThis study examines how IT influences the extent of internationalization of firms by using firm% level data on the IT investments and international operations of US multinationals for the 1999% 2005 period. We identify managerial/operational complexity, geographic dispersion of subunits, and contextual differences between home and host countries as the main challenges involved in internationalization, and investigate whether IT plays a role in resolving these challenges. Our results suggest that firms\u2019 IT capability plays an important role in their internationalization by resolving the aforementioned challenges. Moreover, a firm\u2019s IT capability (as reflected in its IT investments) and production knowledge (as reflected in its R&amp;D investments) are complementary in their influence on the internationalization of the firm. Given the lack of firm%level empirical evidence on the ro le of IT in the internationalization and global operations of firms, the current study provides a richer understanding of the impact of IT on firms\u2019 international operations.","Temporal Faceted Learning of Concepts Using Web Search EnginesIn this paper, we propose the problem of generating temporal faceted learning of concepts. The goal of the proposed problemisto annotate a concept with semantic, temporal, faceted, concise, andstructured information, which can release the cognitive burden of learning new concepts for users. The temporal faceted annotations can help users to learn and understand the unfamiliar or new emerged concepts. We propose a general method togenerate temporal faceted annotationof a concept by constructing its learning words, learning sentences, learning graph, and learning communities. Empirical experiments on LinkedIn dataset show that the proposed algorithm is effective and accurate. Different from the manually generated annotation repository such as LinkedIn and Wikipedia, the proposed method can automatically generated the annotations and does not need any prior knowledge such as ontology or the hierarchical knowledge base such as WordNet. The proposed method usesWeb search engines as a temporal faceted learning platform, which can add the new meaning and update the old meaning of concepts.","Challenging Learning Myths through Intervention Studies in Formal Higher Education ","From Individual EHR Maintenance to Generalised Findings: Experiments for Application of NLP to Patient-Related Texts ","Is Agile the Answer? The Case of UK Universal CreditIn 2010 the UK government responded to a catalogue of failing large-scale IT projects by cancelling most of them. In 2011 they announced the Universal Credit (UC) project, described as \"the biggest single change to the system of benefits and tax credits since 1945, affecting some 6 million households and 19 million people\". UC will integrate a number of legacy databases with the Real Time Information (RTI) system, administered by Her Majesty's Revenue and Customs (HMRC) and due to complete by October 2013. The coupling of these two large-scale IT projects will affect millions of UK citizens; it is crucial that both complete successfully and on time. Government has responded to criticisms by stating that the use of Agile methods will solve the failures of the past. This paper critically assesses the adoption of Agile methods for software development, project management and procurement in the case of Universal Credit.","Achieving Chosen Ciphertext Security from Detectable Public Key Encryption Efficiently via Hybrid EncryptionIn EUROCRYPT'12, Hohenberger, Lewko, and Waters pro- posed a new paradigm for constructing chosen ciphertext secure public key encryption (PKE) schemes from a new concept of detectable PKE. In this paper, we propose an efficient variant of the Hohenberger-Lewko- Waters (HLW) construction, based on the techniques and results from hybrid encryption. On the technical side, our security proof avoids using the notion of nested-indistinguishability that was used in the original proof by Hohenberger et al., and we believe that what role each build- ing block plays is clearer, leading to better understanding of the HLW paradigm.","Extended KBE: Scenario of an Application Development ","On the Homogeneous Multiprocessor Virtual Machine Partitioning ProblemThis work addresses the partitioning of virtual machines with real-time requirements onto a multi-core platform. The partition- ing is usually done manually through interactions between subsystem vendors and system designers. Such a proceeding is expensive, does not guarantee to find the best solution, and does not scale with regard to the upcoming higher complexity in terms of an increasing number of both virtual machines and processor cores. The partitioning problem is defined in a formal manner by the abstraction of computation time de- mand of virtual machines and computation time supply of a shared pro- cessor. The application of a branch-and-bound partitioning algorithm is proposed. Combined with a generation of a feasible schedule for the vir- tual machines mapped to a processor, it is guaranteed that the demand of a virtual machine is satisfied, even if independently developed vir- tual machines share a processor. The partitioning algorithm offers two optimization goals, required number of processors and the introduced optimization metric criticality distribution, a first step towards a parti- tioning that considers multiple criticality levels. The different outcomes of the two approaches are illustrated exemplarily.","Mining multidimensional frequent patterns from relational databaseMining frequent patterns focus on discover the set of items which were frequently purchased together, which is an important data mining task and has broad applications. However, traditional frequent pattern mining does not consider the characteristics of the customers, such that the frequent patterns for some specific customer groups cannot be found. Multidimensional frequent pattern mining can find the frequent patterns according to the characteristics of the customer. Therefore, we can promote or recommend the products to a customer according to the characteristics of the customer. However, the characteristics of the customers may be the continuous data, but frequent pattern mining only can process categorical data. This paper proposes an efficient approach for mining multidimensional frequent pattern, which combines the clustering algorithm to automatically discretize numerical-type attributes without experts.","Intention Estimation and Recommendation System Based on Attention Sharing ","Evaluation of the Urban Land Intensive Use and It\u2019s Regional Differences in Shaanxi Province Based on GIS ","A Design and Planning Support System for Walkability and Pedestrian Accessibility ","HFST \u2014 A System for Creating NLP ToolsThe paper presents and evaluates various NLP tools that have been created using the open source library HFST - Helsinki Finite-State Technology and outlines the minimal extensions that this has required to a pure finite-state system. In particular, the paper describes an implementation and application of Pmatch presented by Karttunen at SFCM 2011.","Improved Boomerang Attacks on SM3The cryptographic hash function SM3 is designed by X. Wang et al. and published by Chinese Commercial Cryptography Administration Office for the use of electronic certification service system in China. It is based on the Merkle-Damgard design and is very similar to SHA-2 but includes some additional strengthening features. In this paper, we apply the boomerang attack to SM3 compression function, and present such distinguishers on up to 34/35/36/37 steps out of 64 steps, with time complexities 231.4, 233.6, 273.4 and 293 compression function calls respectively. Especially, we are able to obtain the examples of the distinguishers on 34-step and 35-step on a PC due to their practical complexities. In addition, incompatible problems in the recent boomerang attack are pointed out.","Pedestrian Detection in Poor Visibility Conditions: Would SWIR Help?The 2WIDE SENSE (WIDE spectral band &amp; WIDE dynam- ics multifunctional imaging SENSor Enabling safer car transportation) EU funded project is aimed at the development of a low-cost camera sen- sor for Advanced Driver Assistance Systems (ADAS) applications able to acquire the full visible to Short Wave InfraRed (SWIR) spectrum from 400 to 1700 nm. This paper presents the first results obtained by investigating the SWIR contribution to pedestrian detection in difficult visibility conditions as haze and fog employing the wide-bandwidth cam- era developed within the project.","Towards Self-development of Evolutionary Information Systems: An Action Research of Business Architecture Development by Students in Socially Networked Groups ","Learning, Learning Analytics, Activity Visualisation and Open Learner Model: Confusing?This paper draws on visualisation approaches in learning analytics, considering how classroom visualisations can come together in practice. We suggest an open learner model in situations where many tools and activity visualisations produce more visual information than can be readily interpreted.","BioModels Database: a public repository for sharing models of biological processes ","The nature and use of surveillance technologies in residential care ","An adaptive context acquisition framework to support mobile spatial and context-aware applicationsThe increasing number of mobile devices allows users to access applications anytime and anywhere. In such applications, location is a key information to improve the interaction between user and services. Existing applications combine location with other context information, such as weather, user's activity, temperature, among others. However, developing context-aware applications is still a non-trivial task due to the complexity to implement context management. Additionally, existing context management infrastructures are too brittle to handle changes in the underlying execution infrastructure. In this scenario, this work proposes a context acquisition framework, which tries to reduce the development complexity of mobile spatial and context-aware applications. The framework uses tuples space and OSGi to promote uncoupling and to adapt itself according to application requirements. A proof of concept was developed in order to show how spatial and context filters can be easily implemented during the development of a tracking application.","Dark Knowledge and Graph Grammars in Automated Software Design ","Symbiosis: an innovative human-computer interaction environment for alzheimer's supportAlzheimer's disease (AD) is the most common form of dementia diagnosed in people over 65 years of age. There is no cure for the disease, which worsens as it progresses, and eventually leads to death. As the disease advances, symptoms can include confusion, irritability and aggression, mood swings, trouble with language, and long-term memory loss. As the sufferer declines they often withdraw from family and society. Gradually, body functions are lost, ultimately leading to death. Current treatments only help with the symptoms of the disease. Following the vision of WHO and AD International for innovative approaches to AD, the system proposed here, namely Symbiosis, aims at creating a novel human-computer interaction (HCI) environment to facilitate, understand and incorporate the needs of the whole AD community (patients, caregivers and doctors).","Automatic Load Testing of Web Application in SaaS Model ","Estimating risk management in software engineering projectsIndependently from the nature of a project, process management variables like cost, quality, schedule, and scope are critical decision factors for a good and successful execution of a project. In software engineering, project planning and execution are highly influenced by the creative nature of all the individuals involved with the project. Thus, managing the risks of different project stages is a key task with extreme importance for project managers (and sponsors) that should be focused on control and monitoring effectively the referred variables, as well as all the others concerned with their context. In this work, we used a small \"cocktail\" of data mining techniques and methods to explore potential correlations and influences contained in some of the most relevant parameters related to experience, complexity, organization maturity and project innovation in Software Engineering, developing in a model that could be deployed in any project management process, assisting project managers in planning and monitoring the state of one project (or program) under its supervision.","Physical Activity Classification Using Resilient Backpropagation (RPROP) with Multiple OutputsConsiderable research has been conducted into the classification of Physical activity monitoring, an important field in computing research. Using artificial neural networks model, this paper explains novel architecture of neural network that can classify physical activity monitoring, recorded from 9 subjects. This work also presents a continuation of benchmarking on various defined tasks, with a high number of activities and personalization, trying to provide better solutions when it comes to face common classification problems. A brief review of the algorithm employed to train the neural network is presented in the first section. We also present and discuss some preliminary results which illustrate the performance and the usefulness of the proposed approach. The last sections are dedicated to present results of many architectures networks. In particular, the experimental section shows that multiple-output approaches represent a competitive choice for classification tasks both for biological purposes, industrial etc.","Crowdsourced risk factors of influenza-like-illness in MexicoMonitoring of influenza like illnesses (ILI) using the Internet has become more common since its beginnings nearly a decade ago. The initial project of Der Grote Griep Meting was launched in 2003 in the Netherlands and Belgium. It was designed as a means of engaging people in matters of scientific and public health importance, and indeed attracted participation from over 30,000 people in its first year. Its success thus gathered a wealth of potentially valuable epidemiological data complementary to those obtained through the established disease surveillance networks, and linked to rich background information on each participant. Since then, there has been an accelerated increase in the number of countries hosting similar websites, and many of these have generated rather promising results   In this talk, an analysis of the data from the Mexican monitoring website, \"Reporta\" is presented, and the risk factors that are linked to reporting of ILI symptoms among its participants are determined and analyzed. The data base gathered from the launching of Reporta in May 2009 to September 2011 is used for this purpose. The definition of suspect ILI case employed by the Mexican Health Ministry is applied to distinguish a class C of participants; the traits gathered in the background questionnaire are labeled Xi. Risk associated to any given trait Xi is evaluated by considering the difference between the frequency with which C occurs among participants with trait Xi and in the general population. This difference is then normalized to assess its statistical significance   Interestingly, while some of the results confirm the suspected importance of certain traits indicative of enhanced susceptibility or a large contact network, others are unexpected and must be interpreted within an adequate framework. Thus, a taxonomy of background traits is proposed to aid interpretation, and tested through a new assessment of the associated risks. This work illustrates a way in which Internet-based monitoring can contribute to our understanding of disease spread.","Exploring Big Data Challenges: Factors Affecting Individuals\u2019 Intention for Authorizing Their Network Operators the Usage of Their Personal Information ","On the Communication Complexity of Distributed Name-Independent Routing SchemesWe present a distributed asynchronous algorithm that, for every undirected weightedn-node graphG ,c onstructs name-independent routing tables forG .T he size of each table is \u02dc O( ! n) ,w hereas the length of any route is stretched by a factor of at most7w.r.t. the shortest path. At any step, the memory space of each node is \u02dc O( ! n).","Sales strategy mining system with visualization of action historyRecently, sales data of a store is called POS (Point of Sales) data. POS data set of items that each customer purchased is highly expected to be utilized for creating new sales strategies. Though POS data is generally analyzed by data mining techniques, the results do not contain the fact why the customers purchased the items. Therefore, customers moving history in a store is important because such data is directly connected to the reason why they have bought items. However, it was difficult to obtain moving history data. In this paper, Sales Strategy Mining system that supports users to create new sales strategies with customers moving history is proposed. Moving history data is combined with POS data and visualized on the interface effectively. According to the experimental results, the system was effective to create new various sales strategies.","Robust Sparse Regression under Adversarial CorruptionWe consider high dimensional sparse regression with arbitrary - possibly, severe or coordinated - errors in the covariates matrix. We are interested in understanding how many corruptions we can tolerate, while identifying the correct support. To the best of our knowledge, neither standard outlier rejection techniques, nor recently developed robust regression algorithms (that focus only on corrupted response variables), nor recent algorithms for dealing with stochastic noise or erasures, can provide guarantees on support recovery. As we show, neither can the natural brute force algorithm that takes exponential time to find the subset of data and support columns, that yields the smallest regression error.#R##N##R##N#We explore the power of a simple idea: replace the essential linear algebraic calculation - the inner product - with a robust counterpart that cannot be greatly affected by a controlled number of arbitrarily corrupted points: the trimmed inner product. We consider three popular algorithms in the uncorrupted setting: Thresholding Regression, Lasso, and the Dantzig selector, and show that the counterparts obtained using the trimmed inner product are provably robust.","The Parameterized Complexity of Fixpoint Free Elements and Bases in Permutation Groups ","Mass Customization in Supply Chain Level: Development of a Conceptual Framework to Manage and Assess PerformanceRecent market interest on customized offers and intensive competi- tion on attracting market globally, lead companies to implement supply chain management to improve performance and gain competitive advantage. To this aim, Supply chain management in customer-oriented environment is pursuing the transition from traditional supply chain into concurrent flexible and efficient one. This paper aims to understand specifically how supply chain within this environment needs to be configured and managed in order to enable efficient customization for mass market. To reach this goal, a conceptual framework and list of indicators to support the framework have been developed and tested.","A pilot study of cyber security and privacy related behavior and personality traitsRecent research has begun to focus on the factors that cause people to respond to phishing attacks as well as affect user behavior on social networks. This study examines the correlation between the Big Five personality traits and email phishing response. Another aspect examined is how these factors relate to users' tendency to share information and protect their privacy on Facebook (which is one of the most popular social networking sites).   This research shows that when using a prize phishing email, neuroticism is the factor most correlated to responding to this email, in addition to a gender-based difference in the response. This study also found that people who score high on the openness factor tend to both post more information on Facebook as well as have less strict privacy settings, which may cause them to be susceptible to privacy attacks. In addition, this work detected no correlation between the participants estimate of being vulnerable to phishing attacks and actually being phished, which suggests susceptibility to phishing is not due to lack of awareness of the phishing risks and that real-time response to phishing is hard to predict in advance by online users.   The goal of this study is to better understand the traits that contribute to online vulnerability, for the purpose of developing customized user interfaces and secure awareness education, designed to increase users' privacy and security in the future.","Structural Test Data Generation Based on Harmony Search ","Block Device System with Pattern Definition Capability by Visible LightThis paper describes an interactive block device \u0097 LED Tile \u0097 utilizing 8x8 dot-matrix LEDs which obtain pattern drawing capability. It also applies magnet connectors for physical connections and signal transmissions, as well as interacts with accelerometer sensor and audio signal device. The function of the block device can be defined by the drawn pattern on the matrix LED, and this capability extends the block system applications. In this paper, we describe the hardware and software configurations of this block device, as well as several fundamental and high-level functions of alphanumerical character recognition. We also describe two applications of this device, such as magic square and character arrangement.","Geometric Relationships Between Gaussian and Modulo-Lattice Error ExponentsLattice coding and decoding have been shown to achieve the capacity of the additive white Gaussian noise (AWGN) channel. This was accomplished using a minimum mean-square error scaling and randomization to transform the AWGN channel into a modulo-lattice additive noise channel of the same capacity. It has been further shown that when operating at rates below capacity but above the critical rate of the channel, there exists a rate-dependent scaling such that the associated modulo-lattice channel attains the error exponent of the AWGN channel. A geometric explanation for this result is developed. In particular, it is shown how the geometry of typical error events for the modulo-lattice channel coincides with that of a spherical code for the AWGN channel.","A Survey about Faults of Robots Used in RoboCupFaults that occur in an autonomous robot system negatively affect its dependability. The aim of truly dependable and autonomous systems requires that one has to deal with these faults in some way. In order to be able to do this efficiently one has to have information on the nature of these faults. Very few studies on this topic have been conducted so far. In this paper we present results of a survey on faults of autonomous robots we conducted in the context of RoboCup. The major contribution of this paper is twofold. First we present an adapted fault taxonomy suitable for autonomous robots. Second we give information on the nature, the relevance and impact of faults in robot systems that are beneficial for researcher dealing with fault mitigation and management in autonomous systems.","Comparison of kansei information between joyful and happy expressions in danceThis research was designed to investigate the relationships between Kansei information and movement characteristics in dance. The purpose is to specify the parameters contributing to the perception and identification of joy and happiness from dance movements. Professional and expert dancers expressed joy and happiness without using facial expressions. For capturing and recording expressions, we used a 3D motion capture system and digital video cameras. There were 54 observers who rated 50 items of Kansei information in both expressions. The results showed the scores of Kansei information for joyful expressions--happy, dynamic, energetic, strong, accelerated, decelerated, extended, high, asymmetrical, fast, accented, big, down, and sudden--were higher than those for happy expressions. We calculated acceleration for kinematic features, and the results showed that acceleration in joyful expressions was higher than in happy expressions. Our findings demonstrated the differences in strength of movements and emotions between joyful and happy expressions in dance.","The Web of Things - Challenges and Enabling Technologies ","Was braucht man f\u00fcr sichere IKT in Smart GridsSmart Grids sind in aller Munde \u2013 ebenso wie die Diskussion von Sicherheitsaspekten dieser zukunftigen Energienetze. Dieser Artikel spannt den Bogen uber die verschiedenen Themenbereiche, die es bei IKT-Sicherheitsaspekten von Smart Grids zu betrachten gilt, und zeigt existierende Best Practices und Standards auf.","When is a confidence measure good enoughConfidence estimation has recently become a hot topic in image processing and computer vision. Yet, several definitions exist of the term \"confidence\" which are sometimes used interchangeably. This is a position paper, in which we aim to give an overview on existing definitions, thereby clarifying the meaning of the used terms to facilitate further research in this field. Based on these clarifications, we develop a theory to compare confidence measures with respect to their quality.","Modeling and Timing Simulation of Agilla Agents for WSN Applications in Executable UML ","A symbiosis of interval constraint propagation and cylindrical algebraic decompositionWe present a novel decision procedure for non-linear real arithmetic: a combination of iSAT, an incomplete SMT solver based on interval constraint propagation (ICP), and an implementation of the complete cylindrical algebraic decomposition (CAD) method in the library GiNaCRA. While iSAT is efficient in finding unsatisfiability, on satisfiable instances it often terminates with an interval box whose satisfiability status is unknown to iSAT. The CAD method, in turn, always terminates with a satisfiability result. However, it has to traverse a double-exponentially large search space.#R##N##R##N#A symbiosis of iSAT and CAD combines the advantages of both methods resulting in a fast and complete solver. In particular, the interval box determined by iSAT provides precious extra information to guide the CAD-method search routine: We use the interval box to prune the CAD search space in both phases, the projection and the construction phase, forming a search \"tube\" rather than a search tree. This proves to be particularly beneficial for a CAD implementation designed to search a satisfying assignment pointedly, as opposed to search and exclude conflicting regions.","Verification of Models in Agent Based Computational Economics \u2014 Lessons from Software Engineering ","Do Facts Speak Louder than Words? Understanding the Sources of Punishment Perceptions in Software Piracy Behavior. ","Selecting a Representation for Spatial Vagueness: A Decision Making Approach ","Virtual spatiality in agent controllers: encoding compartmentalizationApplying methods of artificial evolution to synthesize robot controllers for complex tasks is still a challenging endeavor. We report an approach which might have the potential to improve the performance of evolutionary algorithms in the context of evolutionary robotics. We apply a controller concept that is inspired by signaling networks found in nature. The implementation of spatial features is based on Voronoi diagrams that describe a compartmentalization of the agent's inner body. These compartments establish a virtual embodiment, including sensors and actuators, and influence the dynamics of virtual hormones. We report results for an exploring task and an object discrimination task. These results indicate that the controller, that determines the principle hormone dynamics, can successfully be evolved in parallel with the compartmentalizations, that determine the spatial features of the sensors, actuators, and hormones.","Using text-based web image search results clustering to minimize mobile devices wasted space-interfaceThe recent shift in human-computer interaction from desktop to mobile computing fosters the needs of new interfaces for web image search results exploration. In order to leverage users' efforts, we present a set of state-of-the-art ephemeral clustering algorithms, which allow to summarize web image search results into meaningful clusters. This way of presenting visual information on mobile devices is exhaustively evaluated based on two main criteria: clustering accuracy, which must be maximized, and wasted space-interface, which must be minimized. For the first case, we use a broad set of metrics to evaluate ephemeral clustering over a public golden standard data set of web images. For the second case, we propose a new metric to evaluate the mismatch of the used space-interface between the ground truth and the cluster distribution obtained by ephemeral clustering. The results evidence that there exist high divergences between clustering accuracy and used space maximization. As a consequence, the trade-off of cluster-based exploration of web image search results on mobile devices is difficult to define, although our study evidences some clear positive results.","Funneling and saltation effects for tactile interaction with \"detached\" out of the body virtual objects ","Role Of Innovation Attributes In Explaining Intention And Adoption: A Case Of The IRCTC Mobile Ticketing Application In The Indian Context ","Multi-dimensional Parametric Mincuts for Constrained MAP InferenceIn this paper, we propose novel algorithms for inferring the Maximum a Posteriori (MAP) solution of discrete pairwise random field models under multiple constraints. We show how this constrained discrete optimization problem can be formulated as a multi-dimensional parametric mincut problem via its Lagrangian dual, and prove that our algorithm isolates all constraint instances for which the problem can be solved exactly. These multiple solutions enable us to even deal with `soft constraints' (higher order penalty functions). Moreover, we propose two practical variants of our algorithm to solve problems with hard constraints. We also show how our method can be applied to solve various constrained discrete optimization problems such as submodular minimization and shortest path computation. Experimental evaluation using the foreground-background image segmentation problem with statistic constraints reveals that our method is faster and its results are closer to the ground truth labellings compared with the popular continuous relaxation based methods.","Simulation der Smart Grid Integration eines modernen B\u00fcrogeb\u00e4udes am Beispiel von IBM-SchweizZusammenfassung Die Entwicklung von Smart Grids ermoglicht die Einfuhrung dynamischer Stromtarife, etwa mit sich stundlich andernden Preisen. Diese konnen der zeitlichen Abhangigkeit von Angebot und Nachfrage nach elektrischer Energie und Netzkapazitat Rechnung tragen, dadurch Lastspitzen vermeiden und die Nutzung fluktuierender erneuer barer Energiequellen begunstigen. Wir stellen ein Simulationsmodell vor, das den hohen Strombedarf fur die Beheizung und Kuhlung moderner Burogebaude im Kontext dynamischer Strompreise untersucht. Das Modell erlaubt die Simulation von Szenarien, in denen vorhandene thermische Energiespeicher (Warm- und Kaltwassertanks) durch eine angepasste Steuerung und Regelung gezielt fur die Smart-Grid-Integration genutzt werden. Das Modell wurde im Rahmen einer Diplomarbeit an der Universitat Zurich in Zusammenarbeit mit IBM-Research entwickelt und am Beispiel des Gebaudes von IBM-Schweiz erprobt. Insbesondere wurden die Einsparpotentiale abgeschatzt, die eine Anpassung der Steuerung der bestehenden Anlage unter der Annahme dynamischer Strompreise bietet. Im Modell konnte unter diesen Annahmen fur den untersuchten Sommermonat Juni eine Einsparung von 31 % der Energiekosten erreicht werden.","Machine Learning Techniques Applied to the Cleavage Site Prediction ProblemThe Genome of the Potyviridae virus family is usually ex- pressed as a polyprotein which can be divided into ten proteins through the action of enzymes or proteases which cut the chain in specific places called cleavage sites. Three different techniques were employed to model each cleavage site: Hidden Markov Models (HMM), grammatical infer- ence OIL algorithm (OIL), and Artificial Neural Networks (ANN). Based on experimentation, the Hidden Markov Model has the best classification performance as well as a high robustness in relation to class imbalance. However, the Order Independent Language (OIL) algorithm is found to exhibit the ability to improve when models are trained using a greater number of samples without regard to their huge imbalance.","Fuzzy Markup Language for Malware Behavioral AnalysisIn recent years, antimalware applications represented one of the most important research topics in the area of network security threat. In addition, malware have become a growing important problem for governments and commercial organizations. The key point of the research on the network security is to judge and validate the similarity metrics among the malicious software. Indeed, most computer network issues are also caused by malware. As a consequence, one enhanced system to analyze the behavior of malwares is needed to try to predict the malicious actions and to minimize the computer damages caused by the malware. However, the conventional data analysis tools lack the ability to deal with the computer safety because the environments malwares operating are with high levels of imprecision and vagueness. For this reason, we have developed Taiwan Malware Analysis Net (TWMAN) to improve the accuracy of malware behavioral analysis. This chapter tries to explorer and deal with these computer security and safety issues by integrating the semantic technologies and computational intelligence methods, such as the fuzzy ontologies and fuzzy markup language (FML). With the proposed approach, the malware identification has achieved a good performance according to the experimental results.","A Real-Time Noise Image Edge Detector Based on FPGA ","Identifying Explicit Discourse Connectives in TextExplicit discourse relations in text are signalled by discourse connectives like since, because, however, etc. Identifying discourse con- nectives is a part of the bigger task called discourse parsing in which discourse coherence relations are extracted from text. In this paper we report improvements to the state-of-the-art for identifying explicit dis- course connectives in the Penn Discourse Treebank and the Biomedical Discourse Relation Bank. These improvements have been achieved with maximum entropy (logistic regression) classifiers by combining machine learning features from previous approaches with new surface level fea- tures that capture information about a connective's surrounding phrases and new syntactic features that add more information from the path in the syntax tree connecting the root to the connective and from the clause following the connective by means of its syntactic head.","Fuzzy decision making based on fuzzy propositional logic with three kinds of negationIn [16], negation of fuzzy information were distinguished as contradictory negation, opposite negation and medium negation, and proposed a fuzzy propositional logic with contradictory negation, opposite negation and medium negation (FLcom). In order to show that FLcom is applicable for handling fuzzy proposition and its different negations, this paper studied the application of FLcom to fuzzy decision making in an example. We presented an approach to formal representation of fuzzy proposition and different negations in decision rules, and the measure of truth value of fuzzy proposition and threshold of truth value. Finally, we discussed reasoning and realization on fuzzy decision making in the example based FLcom and the fuzzy production rule.","The Effects of User Involvement in Online Games, Game-Playing Time and Display Duration on Working MemoryCollege students spending too much time on online games every week tend to suffer from worsened learning ability, concentration problems, poor academic performance, and decreased interactions with other people. This study's author conducted a questionnaire-based survey to examine how many hours college students from central Taiwan spend on online games per week, in order to find out their average daily involvement in such games. Using proportionate stratified sampling, the survey respondents were selected to examine the weekly involvement in online games among college students from central Taiwan, who were divided into low-, medium- and high-involvement groups in a cluster analysis. Results of the survey were tested using a self-developed evaluation system based on working memory and response time. Totally 36 college students, or 12 students from each of the low-, medium- and high-involvement groups, were randomly selected from the population to test how involvement in online games, game-playing time and display duration affected their working memory. Findings from this study include: I. The low, medium and high levels of online game involvements are defined as an average 1.34 hours, 4.84 hours and 10.27 hours spent on online games every day. 30.9% of the survey respondents said they spent more than 4 hours on online games, which suggests that online games may be the reason why college students stay up all night so often. II. This testing discovers that the levels of involvement in video gaming (p&lt;0.05), display duration (p&lt;0.05), and the interaction of the two factors will all have an impact on visual working memory (p&lt;0.05).","Fully Automated Brain Tumor Segmentation Using Two MRI ModalitiesAn algorithm is presented for fully automated brain tumor segmentation from only two magnetic resonance image modalities. The technique is based on three steps: 1 alternating different levels of automatic histogram-based multi-thresholding step, 2 performing an effective and fully automated procedure for skull-stripping by evolving deformable contours, and 3 segmenting both Gross Tumor Volume and edema. The method is tested using 19 hand-segmented real tumors which shows very accurate results in comparison to a very recent method STS in terms of the Dice coefficient. Improvements of 5% and 20% respectively for segmentation of edema and Gross Tumor Volume have been recorded.","Remote Controller for Regression Test in the Robot Framework ","A Novel Community Detection Algorithm for Privacy Preservation in Social Networks ","Smart control of spinal alignment through active adjustment of mechanical bed properties during sleepThis study implements an algorithm for the autonomous control of spinal alignment during sleep by the active adjustment of mechanical bed characteristics according to the adopted sleep posture. Bed systems were used that allow active control of the mechanical stiffness in eight comfort zones by means of separately adjustable actuators. Mattress indentation measurements provide the input to detect body movement, recognize sleep posture, and --by combination with a subject specific human model --estimate spine shape. Comparison between the estimated spine shape and the desired shape results in new target values for the actuators. The control loop is repeated until the desired spine shape is reached. Results of overnight experiments revealed a significant improvement of spinal alignment during nights with active control of bed properties compared to a reference night without control. In addition, a significant improvement on subjectively perceived sleep quality was demonstrated after sleeping on the actively controlled systems.","A simulation analysis to weigh the impact of obesity: corresponding patient need with medical capacityU.S. population data indicate upsurges in obesity that can outpace the medical community's ability to provide care. Identifying that \"outpaced\" tipping point can mitigate shortages in healthcare capacity. A simulation model was developed to determine the burden of patient need vis-a-vis the medical community's ability in two U.S. cities to establish the tipping point. The model captured medical capacity via Primary Care Physician and Emergency Room usage by two patient types: Patient A-endeavoring to maintain good health and Patient B-indifferent. Demographic statistics were drawn from CDC and census data. Outputs indicated significant queue lengths for both cities with queues reached differing tipping points per city, per patient degree of concern, and per patient-to-physician ratio. Additional alarming results showed Patient A becoming obese and Patient B sustaining obese weight. Assessing medical capacity is critical to averting foreseeable deficits in healthcare as the population continues to succumb to the obesity epidemic.","An evolutionary method for associative local distribution rule miningA method for rule mining for continuous value prediction has been proposed using a graph structure based evolutionary computation technique. The method extracts the rules named associative local distribution rule whose consequent part has a narrow distribution of continuous value. A set of associative local distribution rules is applied to the continuous value prediction. The experimental results showed that the method can bring us useful rules for the continuous value prediction. In addition, two cases of contrast rules are defined based on the associative local distribution rules. The performances of the contrast rule extraction were evaluated and the results showed that the proposed method has a potential to realize contrast analysis between two datasets.","Human-Robot Upper Body Gesture Imitation Analysis for Autism Spectrum DisordersIn this paper we combine robot control and data analysis techniques into a system aimed at early detection and treatment of autism. A humanoid robot - Zeno is used to perform interactive upper body gestures which the human subject can imitate or initiate. The result of interaction is recorded using a motion capture system, and the similarity of gestures performed by human and robot is measured using the Dynamic Time Warping algorithm. This measurement is proposed as a quantitative similarity measure to objectively analyze the quality of the imitation interaction between the human and the robot. In turn, the clinical hypothesis is that this will serve as a consistent quantitative measurement, and can be used to obtain information about the condition and possible improvement of children with autism spectrum disorders. Experimental results with a small set of child subjects are presented to illustrate our approach.","Behavior Recognition for Elderly People in Large-Scale DeploymentBehavior recognition through ambient assisted living solutions for elderly people, represents an ambitious challenge for actimetry. Numerous and versatile solutions have been deployed. However, a commercial adoption is still pending, due to scalability and acceptability constraints. Most researches in ambient assisted living appear to have an heavy design, where precise features are first selected, and hardware architecture is designed accordingly. Although it may provide interesting results, such approach leads to a lack of scalability. This is why we experimented a lighter approach for a real deployment. The complexity is shifted from hardware to software, and we aim to make meaningful informations emerge from simple and generic sensor data, in order to recognize abnormal and dangerous situations. In this paper, we will describe how to retrieve consistent informations, so that resident's behavior may be observed, and that a light and generic approach fits in large scale deployments, with acceptable cost and scalability.","Automated Verification of Chapel Programs Using Model Checking and Symbolic Execution ","Tasklettes \u2013 a Fine Grained Parallelism for Ada on MulticoresThe widespread use of multi-CPU computers is challenging pro- gramming languages, which need to adapt to be able to express potential paral- lelism at the language level. In this paper we propose a new model for fine grained parallelism in Ada, putting forward a syntax based on aspects, and the corresponding semantics to integrate this model with the existing Ada tasking capabilities. We also propose a standard interface and show how it can be ex- tended by the user or library writers to implement their own parallelization strategies.","Facilitating the Adoption of Public Services Using High Definition Video: The Case of Primary EducationThe adoption of innovative Information and Communication Technologies (ICTs) in public services in general, and in education in particular has intensified in the last few years. Although electronic services in learning has been used in primary, secondary and higher education for some years, the use of live video technology to facilitate public services has rarely been explored before. In this paper, we focus on the adoption of high definition video-to-video (V2V) communication in the context of public sector primary education. This paper examines how V2V technology can be utilised in encouraging collaborative learning initiatives among different schools. Results of a preliminary case study are presented highlighting some of the technical and users criteria required to ensure a successful adoption of video-to-video communication in the context of education.","Efficient Indexing of the Past, Present and Future Positions of Moving Objects on Road Network ","Robust Image Registration for Improved Clinical Efficiency : Using Local Structure Analysis and Model-Based ProcessingMedical imaging plays an increasingly important role in modern healthcare. In medical imaging, it is often relevant to relate different images to each other, something which can prove challenging,  ...","Swarmic paintings and colour attentionSwarm-based multi-agent systems have been deployed in non-photorealistic rendering for many years. This paper introduces a novel approach in adapting a swarm intelligence algorithm --- Stochastic Diffusion Search --- for producing non-photorealistic images. The swarm-based system is presented with a digital image and the agents move throughout the digital canvas in an attempt to satisfy the dynamic roles --- attention to different colours --- associated to them via their fitness function. Having associated the rendering process with the concepts of 'attention' in general and colour attention in particular, this papers briefly discusses the 'computational creativity' of the work through two prerequisites of creativity (i.e. freedom and constraints) within the swarm intelligence's two infamous phases of exploration and exploitation.","Towards Reduced EEG Based Brain-Computer Interfacing for Mobile Robot Navigation ","What Makes Learning Fun? Exploring the Influence of Choice and Difficulty on Mind Wandering and Engagement during Learning ","The impact of Internet and PC addiction in school performance of Cypriot adolescents. ","Towards Complete Specifications with an Error Calculus ","Which targets to contact first to maximize influence over social networkWe address a new type of influence maximization problem which we call \"target selection problem\". This is different from the traditionally thought influence maximization problem, which can be called \"source selection problem\", where the problem is to find a set of K nodes that together maximizes their influence over a social network. The very basic assumption there is that all these K nodes can be the source nodes, i.e. can be activated. In \"target selection problem\" we maximize the influence of a new user as a source node by selecting K nodes in the network and adding a link to each of them. We show that this is the generalization of \"source selection problem\" and also satisfies the submodularity. The selected nodes are substantially different from those of \"source selection problem\" and use of the solution of \"source selection problem\" results in a very poor performance.","How E-Consumers Integrate Diverse Recommendations from Multiple Sources ","Cloud-Based Platform to Labor Integration of Deaf People ","Transport Protocol with Acknowledgement-Assisted Storage Management for Intermittently Connected Wireless Sensor Networks ","An Optimized Memory Monitoring for Runtime Assertion Checking of C ProgramsRuntime assertion checking provides a powerful, highly au- tomatizable technique to detect violations of specified program proper- ties. However, monitoring of annotations for pointers and memory lo- cations (such as being valid, initialized, in a particular block, with a particular offset, etc.) is not straightforward and requires systematic in- strumentation and monitoring of memory-related operations. This paper describes the runtime memory monitoring library we devel- oped for execution support of e-acsl, executable specification language for C programs offered by the Frama-C platform for analysis of C code. We present the global architecture of our solution as well as various op- timizations we realized to make memory monitoring more efficient. Our experiments confirm the benefits of these optimizations and illustrate the bug detection potential of runtime assertion checking with e-acsl.","Computational Modelling of the Interruptional Activities between Transposable Elements ","Network of Social ListenersPeople in a society in some context lend an ear to their respective world members and so form a network of listening that is passively embedded in the society. This paper defines a model of listen- ing that explains spread of a message creating listen pathways to reach people in the network. A metric listen weight, measures the message relevance perceived by a listener. And accumulation of this weight to a message while traversing a network projects the emergent relevance and intensity of the message spread. We propose a method to engineer listening process to make a society inclusive of listening.","Noninvasive localization of ectopic foci: a new optimization approach for simultaneous reconstruction of transmembrane voltages and epicardial potentialsThe goal of ECG imaging is the reconstruction of cardiac electrical activities from the potentials measured on the thorax surface. The tool can gain prominent clinical value for diagnosis and pre-interventional planning. The problem is however ill-posed, i.e. it is highly sensitive to modelling and measurement errors. In order to overcome this obstacle a regularization technique must be applied. In this paper we propose a new optimization based method for simultaneous reconstruction of transmembrane voltages and epicardial potentials for localizing the origin of ventricular ectopic beats.#R##N##R##N#Compared to second-order Tikhonov regularization, the new approach showed superior performance in marking activated regions and provided meaningful results where Tikhonov method failed.","Properties of Answer Set Programming with Convex Generalized AtomsIn recent years, Answer Set Programming (ASP), logic programming under the stable model or answer set semantics, has seen several extensions by generalizing the notion of an atom in these programs: be it aggregate atoms, HEX atoms, generalized quantifiers, or abstract constraints, the idea is to have more complicated satisfaction patterns in the lattice of Herbrand interpretations than traditional, simple atoms. In this paper we refer to any of these constructs as generalized atoms. Several semantics with differing characteristics have been proposed for these extensions, rendering the big picture somewhat blurry. In this paper, we analyze the class of programs that have convex generalized atoms (originally proposed by Liu and Truszczynski in [10]) in rule bodies and show that for this class many of the proposed semantics coincide. This is an interesting result, since recently it has been shown that this class is the precise complexity boundary for the FLP semantics. We investigate whether similar results also hold for other semantics, and discuss the implications of our findings.","The conceptual model of experience engineering (XE)The conceptual model of XE (experience Engineering) was proposed to cover both of the products and services. It was also proposed to take \"U\" out from \"UX\" so that more adequate description of the people can be possible.","From Process Models to Business Process Architectures: Connecting the Layers ","Blowing Holes in Various Aspects of Computational Problems, with Applications to Constraint SatisfactionWe consider methods for constructing NP-intermediate problems under the assumption that P i\u00be\u017a NP. We generalize Ladner's original method for obtaining NP-intermediate problems by using parameters with various characteristics. In particular, this generalization allows us to obtain new insights concerning the complexity of CSP problems. We begin by fully characterizing the problems that admit NP-intermediate subproblems for a broad and natural class of parameterizations, and extend the result further such that structural CSP restrictions based on parameters that are hard to compute such as tree-width are covered. Hereby we generalize a result by Grohe on width parameters and NP-intermediate problems. For studying certain classes of problems, including CSPs parameterized by constraint languages, we consider more powerful parameterizations. First, we identify a new method for obtaining constraint languages \u0393 such that CSP\u0393 are NP-intermediate. The sets \u0393 can have very different properties compared to previous constructions by, for instance, Bodirsky &amp; Grohe and provides insights into the algebraic approach for studying the complexity of infinite-domain CSPs. Second, we prove that the propositional abduction problem parameterized by constraint languages admits NP-intermediate problems. This settles an open question posed by Nordh &amp; Zanuttini.","A serious game to improve situation awareness in laparoscopic surgerySafety analyses show that errors in surgery are more frequently caused by misperceptions and misjudgments than from technical failure of the surgeons. The adaptive coupling between humans and their environment, based on the perception and comprehension of signs and signals when performing a complex task, is referred to as situation awareness (SA). To date, no off-site training methods are offered to improve SA in surgical trainees. To aid the improvement of SA in minimally invasive surgery (MIS), a serious game was designed for surgical trainees. This serious game teaches surgical trainees to deal with major and minor problems in the minimallyinvasive surgical theatre that originate outside of the direct line of sight. Serious games are instructional methods that allow serious skills training in a challenging environment. This paper discusses insights on design, development and evaluation of a game-based educational program for surgical residents.","Decision path models for patient-specific modeling of patient outcomes.Patient-specific models are constructed to take advantage of the particular features of the patient case of interest compared to commonly used population-wide models that are constructed to perform well on average on all cases. We introduce two patient-specific algorithms that are based on the decision tree paradigm. These algorithms construct a decision path specific for each patient of interest compared to a single population-wide decision tree with many paths that is applicable to all patients of interest that are constructed by standard algorithms. We applied the patient-specific algorithms to predict five different outcomes in clinical datasets. Compared to the population-wide CART decision tree the patient-specific decision path models had superior performance on area under the ROC curve (AUC) and had comparable performance on balanced accuracy. Our results provide support for patient-specific algorithms being a promising approach for predicting clinical outcomes.","An Approach for the Ordering of Evaluation of Objectives in Multiobjective Optimization ","A Hierarchical Approach to Optimal TransportA significant class of variational models in connection with matching general data structures and comparison of metric measure spaces, lead to computationally intensive dense linear assignment and mass transportation problems. To accelerate the computation we present an extension of the auction algorithm that exploits the regularity of the otherwise arbitrary cost function. The algorithm only takes into ac- count a sparse subset of possible assignment pairs while still guarantee- ing global optimality of the solution. These subsets are determined by a multiscale approach together with a hierarchical consistency check in order to solve problems at successively finer scales. While the theoretical worst-case complexity is limited, the average-case complexity observed for a variety of realistic experimental scenarios yields a significant gain in computation time that increases with the problem size.","Efficient Subdomains for Random TestingOpinion is divided over the effectiveness of random testing. It produces test cases cheaply, but struggles with boundary conditions and is labour intensive without an automated oracle. We have created a search-based testing technique that evolves multiple sets of efficient subdomains, from which small but effective test suites can be randomly sampled. The new technique handles boundary conditions by targeting different mutants with each set of subdomains. It achieves an average 230% improvement in mutation score over conventional random testing.","National electronic medical records integration on cloud computing system. ","Computational Social Science: A Bird\u2019s Eye View ","On-time clinical phenotype prediction based on narrative reports.In this paper we describe a natural language processing system which is able to predict whether or not a patient exhibits a specific phenotype using the information extracted from the narrative reports associated with the patient. Furthermore, the phenotypic annotations from our report dataset were performed at the report level which allows us to perform the prediction of the clinical phenotype at any point in time during the patient hospitalization period. Our experiments indicate that an important factor in achieving better results for this problem is to determine how much information to extract from the patient reports in the time interval between the patient admission time and the current prediction time.","A Vocabulary of Topological and Containment Relations for a Practical Biological OntologyWe describe the development of a formal language for expressing qualitative spatial knowledge. The language is intended as a practical tool for knowledge representation and has been designed with the particular aim of encoding the qualitative spatial information found in an introductory college level biology textbook. We have taken a corpus-driven approach in which we first identify the requirements by analysing the sentences in the book, design the vocabulary, and then check its adequacy by applying it to model the sentences containing spatial knowledge. Our technical solution extends the well-known Region Connection Calculus with predicates for referring to surfaces, cavities and different forms of containment. We illustrate the application of this vocabulary in encoding sample sentences from the book, and give empirical results regarding the correspondence between the defined relations of our formal theory and the actual usage of vocabulary pertaining to 'surrounding', 'enclosure' and 'containment' in the textbook.","Personalized news recommendation using ontologies harvested from the webIn this paper, we concentrate on exploiting background knowledge to boost personalized news recommendation by capturing underlying semantic relatedness without expensive human involvement. We propose an Ontology Based Similarity Model (OBSM) to calculate the news-user similarity through collaboratively built ontological structures and compare our approach with other ontology-based baselines on both English and Chinese data sets. Our experimental results show that OBSM outperforms other baselines by a large margin.","Consistency among Domain Analysts in Selecting Domain Documents and Creating VocabulariesA study is reported on the consistency of the domain vocabularies created and the source documents selected by domain analysts for domain analysis using DARE (Domain Analysis and Reuse Environment). Consistency was analyzed by measuring the pairwise overlap scores between the domain analysts. The overlap scores of the vocabularies and the source documents were both found to be significantly greater than zero. The effect sizes were large. A positive correlation was also observed between overlap scores of the vocabularies and overlap scores of the source documents. The variability of domain vocabularies created automatically was compared to the variability of domain vocabularies produced manually by domain engineers. The variability of automatic and manual vocabularies was found to be significantly different. The difference was of medium effect size.","An Efficient Memetic Algorithm for the Flexible Job Shop with Setup TimesThis paper addresses the flexible job shop scheduling problem with sequence-dependent setup times (SDSTFJSP). This is an extension of the classical job shop scheduling problem with many applications in real production environments. We propose an effective neighborhood structure for the problem, including feasibility and non improving conditions, as well as procedures for fast neighbor estimation. This neighborhood is embedded into a genetic algorithm hybridized with tabu search. We conducted an experimental study to compare the proposed algorithm with the state-of-the-art in the SDST-FJSP and also in the standard FJSP. In this study, our algorithm has obtained better results than those from other methods. Moreover, it has established new upper bounds for a number of instances.","A Pattern Language for Teaching Design Patterns ","Sub-channel and Power Allocation for Multiuser OFDM Systems with Proportional Rate Constraints Based on Genetic Algorithms ","eDoctor: automatically diagnosing abnormal battery drain issues on smartphonesThe past few years have witnessed an evolutionary change in the smartphone ecosystem. Smartphones have gone from closed platforms containing only preinstalled applications to open platforms hosting a variety of thirdparty applications. Unfortunately, this change has also led to a rapid increase in Abnormal Battery Drain (ABD) problems that can be caused by software defects or misconfiguration. Such issues can drain a fully-charged battery within a couple of hours, and can potentially affect a significant number of users.#R##N##R##N#This paper presents eDoctor, a practical tool that helps regular users troubleshoot abnormal battery drain issues on smartphones. eDoctor leverages the concept of execution phases to capture an app's time-varying behavior, which can then be used to identify an abnormal app. Based on the result of a diagnosis, eDoctor suggests the most appropriate repair solution to users. To evaluate eDoctor's effectiveness, we conducted both in-lab experiments and a controlled user study with 31 participants and 17 real-world ABD issues together with 4 injected issues in 19 apps. The experimental results show that eDoctor can successfully diagnose 47 out of the 50 use cases while imposing no more than 1.5% of power overhead.","SELF ADAPTIVE HYBRIDIZATION OF QUADRATIC APPROXIMATION WITH REAL CODED GENETIC ALGORITHM2 } Abstract: The real coded Genetic Algorithm (LX-PM) that uses Laplace Crossover and Power mutation became popular to find optimal solution. In recent past, the LX-PM is being hybridized with a local search called Quadratic Approximation (QA) to improve the solution quality. However, there are some instances to improve it further, just by checking the frequency of hybridization. In this paper, a self adaptive strategy of hybridization is incorporated in the cycle of LX-PM. The improved efficiency and efficacy of the adaptive hybridization of QA over the simple hybridization of QA with LX-PM, is being realized through a set of 22 unconstrained benchmark problems. Comparative result is being analyzed through the numerical results, in terms of five different aspects.","NEXIR: A Novel Web Extraction Rule Language toward a Three-Stage Web Data Extraction Model ","Human Action Recognition by Mining Discriminative Segment with Novel Skeleton Joint FeatureIn this paper, we present a \"key segment\" mining approach for human action recognition. Our model is able to locate discriminative segments for action samples via multiple instance learning. Moreover, we propose a dynamic pooling approach to automatically find the optimal length of segment for each action sample. In addition, an effective feature is proposed for action recognition with 3D skeleton joints. It can effectively capture informative motion and shape cues of skeletons, and leads to a compact and discriminative representation. The experimental results validate the effectiveness of the proposed human action recognition method on two benchmark datasets (i.e., MSR Action3D and UCF-Kinect). Moreover, our method demonstrates superior accuracy than previous methods of using only skeleton data on MSR Action3D, and achieves the state-of-the-art performance on UCF-Kinect.","A multi-core memory organization for 3-d DRAM as main memoryThere is a growing interest in using 3-D DRAM structures and non-volatile memories such as Phase Change Memories (PCM) to both improve access latencies and reduce energy consumption in multicore systems. These new memory technologies present both opportunities and challenges to computer systems design.#R##N##R##N#In this paper we address how such memories should be organized to fully benefit from these technologies. We propose to keep 3-D DRAMs as main memory systems, but use non-volatile memories as backing store. In this connection, we view DRAM based main-memory both as a cache memory and as main memory. The cache like addressing allows for fast address translation and better memory allocation among multiple processes. We explore a set of wide-ranging design parameters for page sizes, sub-page sizes, TLB sizes, and sizes of write-buffers.","Parking Lot Occupancy Detection Using Computational Fluid Dynamics ","Automatic GUI Generation for Home Electric Appliances by Remote Controller on Ad-Hoc Wireless Communication ","Improving perfect electronic health records and integrated health information in china: a case on disease management of diabetesTo examine the role of EHRs in disease management diabetes and other favorable factors, explore feasible strategy for improving the developing EHRs by perfecting top-designing and integration.#R##N##R##N#The study adopt literature review method, reviews the research literature on EHRs systems. Data of three provinces come from the China Fourth National Health Survey 2008.#R##N##R##N#Data analysis reveals the gap in diabetes management and the limitation use of data for intervention. Diabetes management has been incorporated into the national package of basic public health service, but not high proportion of EHRs for diabetic patients. It suggest that the effort for establishing links between use of EHRs and disease management is needed for moving forward the integration, due to EHR play unique role for evidence-based on chronic disease management. To accelerate making progress, it not only need to build the implement framework, but the top-designing framework and targeted guidelines.#R##N##R##N#EHRs' standardization and quality is a key to form good practice. Developing of EHRs' is beneficial chronic disease management and intervention, but need to formulate right policy and practice in perfecting EHRs' system itself and integration with disease management system current.","Technical Components and Requirements Model for Supporting Collaboration in the Product Technology Transfer Process ","An adaptive pitch control strategy for a doubly fed wind generation systemA smart pitch control strategy for a variable speed doubly fed wind generation system is presented in this article. Non-linear as well as linearized dynamic models of the wind system pitch controller and the doubly fed induction generator including the drive train are developed. A PI controller is employed to generate the appropriate pitch angle for varying wind speed conditions. An adaptive artificial neural network (ANN) is trained to produce PI gain settings for various wind speed conditions. The training data, on the other hand, was generated through differential evolution (DE). Simulation studies show that the DE based adaptive ANN can generate the appropriate control to deliver the wind power to the generator efficiently with minimum transients. The data used was collected from the wind generator located at the King Fahd University beach front.","Emotions and Norms in Shared SpacesOpen-plan offices are working environments which require people to share a common space. However, violation of conventional rules (norms) can cause instances of incivility which, if untreated, can cause further problems: escalating retaliation, demoralised or demotivated workforce, staff turnover, etc. In this paper, we envision the common space as a common pool resource which we seek to manage according to the institutional design principles of Elinor Ostrom. We describe the design and implementation of an affective conditioning system, which detects a violation of office norms and deterioration of (positive) affective (emotional) state of the office occupants, and seeks to restore a homeostatic equilibrium using self-regulation and forgiveness. We suggest that this convergence of normative, affective and adaptive computing demonstrates the possibilities for self-regulatory platforms for successful collective action in such communal situations.","Assessing the Quality Level of Corn Tortillas with Inductive Characterization and Digital Image AnalysisCharacterization and classification of corn tortillas turns out to be an extremely delicate and difficult process when dealing with regulations for import/export and production process certification. In this paper we present a method for non-invasive feature extraction, based on digital imaging and a series of procedures to characterize different qualities of corn tortillas for their later classification. The novelty in this whole method lies in the extremely reduced set of features required for the characterization with only geometrical and color features. Nonetheless, this set of features can assess diverse quality elements like the homogeneity of the baking process and others alike. Experimental results on a sample batch of 600 tortillas show the presented method to be around 95% effective.","Kernelizing the proportional odds model through the empirical kernel mappingThe classification of patterns into naturally ordered labels is referred to as ordinal regression. This paper explores the notion of kernel trick and empirical feature space in order to reformulate the most widely used linear ordinal classification algorithm (the Proportional Odds Model or POM) to perform nonlinear decision regions. The proposed method seems to be competitive with other state-of-the-art algorithms and significantly improves the original POM algorithm when using 8 ordinal datasets. Specifically, the capability of the methodology to handle nonlinear decision regions has been proven by the use of a non-linearly separable toy dataset.","Joint and coupled bilingual topic model based sentence representations for language model adaptationThis paper is concerned with data selection for adapting language model (LM) in statistical machine translation (SMT), and aims to find the LM training sentences that are topic similar to the translation task. Although the traditional approaches have gained significant performance, they ignore the topic information and the distribution information of words when selecting similar training sentences. In this paper, we present two bilingual topic model (BLTM) (joint and coupled BLTM) based sentence representations for cross-lingual data selection. We map the data selection task into cross-lingual semantic representations that are language independent, then rank and select sentences in the target language LM training corpus for a sentence in the translation task by the semanticsbased likelihood. The semantic representations are learned from the parallel corpus, with the assumption that the bilingual pair shares the same or similar distribution over semantic topics. Large-scale experimental results demonstrate that our approaches significantly outperform the state-of-the-art approaches on both LM perplexity and translation performance, respectively.","Forecasting the TAIEX based on fuzzy time series, PSO techniques and support vector machinesThis paper presents a new method for forecasting the TAIEX based on fuzzy time series, particle swarm optimization techniques and support vector machines. The proposed method to forecast the TAIEX is based on slope of one-day variations of the TAIEX and the slope of two-days average variations of the TAIEX. The particle swarm optimization techniques are used to get optimal intervals in the universe of discourse. The support vector machine is used to classify the training data set. The experimental results show that the proposed method outperforms the existing methods for forecasting the TAIEX.","The Antecedents of E-Grocery Store Continuance.This study presents a respecification of the DeLone and McLean IS success model and empirically assesses it to predict customers\u2019 future purchases in the context of the online grocery store. Survey data were collected from 376 customers of one online grocery store. Structural equation modeling was conducted to validate the research model. The results indicate that service quality, product quality, and perceived ease of use are significant predictors of user satisfaction with the online grocery store. Additionally, user satisfaction, service quality, product quality, and perceived ease of use are significant predictors of customer future intentions to repurchase groceries from the online grocery store. The results may be of importance in explaining factors that measure success of the online grocery store, as well as in providing operators of the online grocery service with a better understanding of how to maintain customer loyalty.","Automatic Equivalence Checking of UF+IA Programs ","Long-Distance Resolution: Proof Generation and Strategy Extraction in Search-Based QBF SolvingStrategies (and certificates) for quantified Boolean formulas (QBFs) are of high practical relevance as they facilitate the verification of results returned by QBF solvers and the generation of solutions to problems formulated as QBFs. State of the art approaches to obtain strategies require traversing a Q-resolution proof of a QBF, which for many real-life instances is too large to handle. In this work, we consider the long-distance Q-resolution (LDQ) calculus, which allows particular tautological resolvents. We show that for a family of QBFs using the LDQ-resolution allows for exponentially shorter proofs compared to Q-resolution. We further show that an approach to strategy extraction originally presented for Q-resolution proofs can also be applied to LDQ-resolution proofs. As a practical application, we consider search-based QBF solvers which are able to learn tauto- logical clauses based on resolution and the conflict-driven clause learning method. We prove that the resolution proofs produced by these solvers correspond to proofs in the LDQ calculus and can therefore be used as input for strategy extraction algorithms. Experimental results illustrate the potential of the LDQ calculus in search-based QBF solving.","Algorithms and Framework for Comparison of Bee-Intelligence Based Peer-to-Peer LookupAbstract. Peer-to-peer has proven to be a scalable technology for retrieval of information that is widely spread among distributed sites and that is subject to dynamic changes. However, selection of a right search algorithm depends on many factors related to actual data content and application problem at hand. A comparison of different algorithms is difficult, especially if many different ap-proaches (intelligent or unintelligent ones) shall be evaluated fairly and possibly also in combinations. In this paper, we describe a generic architectural pattern that serves as an overlay network based on autonomous agents and decentra-lized control. It supports plugging of different algorithms for searching and retrieving data, and thus eases comparison of algorithms in various topology configurations. A further novelty is to use bee intelligence for the lookup prob-lem, spot optimal parameters' settings, and evaluate the bee algorithm by using the architectural pattern to benchmark it with other algorithms.","Efficient Retrieval for Large Scale Metric Learning ","Heuristic methods aiding ergonomic designThe increasing complexity of the world of technology and the technical components surrounding humans increases the need for ergonomic measures. However, these activities often have only a corrective character, and therefore, despite (or perhaps because of) the possibility of computer support, their results are not satisfactory. When solving problems, very often it is difficult to give up the well-worn strategies or hypotheses, even though they turn out to be ineffective. During the design process a specific attitude is formed towards a certain kind of conduct, which certainly makes it difficult to adopt new and effective strategies, which in turn inhibits creativity. Moreover, it appears that in many cases a functional solution is not determined by a systematic evaluation of all possible solutions, and the initially adopted concept's primary reasons often have been removed. Therefore, in this article, it was decided to take on the subject of the possibility of using heuristic methods in ergonomic design. In the article, described is the use of specific methods and design situations requiring a new approach. Also presented are the limitations of heuristic methods for ergonomic design and the possibility of their fusion in typical design processes.","Determination of Cardiac Ejection Fraction by Electrical Impedance Tomography Using an Artificial Neural Network ","On dimension partitions in discrete metric spacesLet (W,d) be a metric space and S={s1 \u2026sk} an ordered list of subsets of W. The distance between p\u2208W and si\u2208S is d(p, si)= min { d(p,q) : q\u2208si }. S is a resolving set for W if d(x, si)=d(y, si) for all si implies x=y. A metric basis is a resolving set of minimal cardinality, named the metric dimension of (W,d). The metric dimension has been extensively studied in the literature when W is a graph and S is a subset of points (classical case) or when S is a partition of W ; the latter is known as the partition dimension problem. We have recently studied the case where W is the discrete space \u2124n for a subset of points; in this paper, we tackle the partition dimension problem for classical Minkowski distances as well as polyhedral gauges and chamfer norms in \u2124n.","A User Privacy Protection Technique for Executing SQL over Encrypted Data in Database Outsourcing Service ","Correlated Trends: A New Representation for Imperfect and Large DataseriesThe computational representation of dataseries is a task of growing interest in our days. However, as these data are often imperfect, new representation models are required to effectively handle them. This work presents Frequent Correlated Trends, our proposal for representing uncertain and imprecise multivariate dataseries. Such a model can be applied to any domain where dataseries contain patterns that recur in similar --but not identical-- shape. We describe here the model representation and an associated learning algorithm.","An Approach for Sponsored Search Auctions Based on the Coalitional Game TheorySponsored search auctions play a crucial role in the Internet advertising. By considering the mutual interactions among advertisers in sponsored search auctions, we propose a game-theory based method for advertisers cooperating with each other in a sponsored search auction. First, we propose a cooperation bid strategy for advertisers' coalition, which could make the utility of the coalition increased and be obtained in linear time. Then, we prove the coalitional game of advertisers has a non-empty core containing the Shapley value. Following, we use an approximate Shapley value to distribute the coalition's utility among advertisers in the coalition. Experiments results verify the efficiency and effectiveness of our method.","Trees in Graphs with Conflict Edges or Forbidden Transitions ","Practical Applications of Virtual Organizations and Agent TechnologyComputation as interaction paradigm can be considered the most promising technological evolution in the areas of Computer Science and Communication in the last few years. Recent tendencies have conducted to the use of Virtual Organizations (VOs), which can be considered as a set of individuals and institutions that need to coordinate resources and services across institutional boundaries. Multi-agent systems (MAS) technology, which allows forming dynamic agent organizations, is particularly well suited as a support for the development of these open systems. PANGEA is an agent platform to develop open multi-agent systems, specifically those including organizational aspects such as virtual agent organizations. The platform allows the integral management of organizations and offers tools to the end user. Additionally, it includes a communication protocol based on the IRC standard, which facilitates implementation and remains robust even with a large number of connections.","Re-engaging with Cultural Engagement: Innovative Product Design of Cultural Field Experience ","Integration of Various Health Record Systems ","Improved inapproximability results for the shortest superstring and related problemsWe develop a new method for proving explicit approximation lower bounds for the Shortest Superstring problem, the Maximum Compression problem, the Maximum Asymmetric TSP problem, the (1, 2)--ATSP problem and the (1, 2)--TSP problem improving on the best known approximation lower bounds for those problems.","From packets to people: quality of experience as a new measurement challengeOver the course of the last decade, the concept of Quality of Experience (QoE) has gained strong momentum, both from an academic research and an industry perspective. Being linked very closely to the subjective perception of the end user, QoE is supposed to enable a broader, more holistic understanding of the qualitative performance of networked communication systems and thus to complement the traditional, more technology-centric Quality of Service (QoS) perspective.#R##N##R##N#The purpose of this chapter is twofold: firstly, it introduces the reader to QoE by discussing the origins and the evolution of the concept. Secondly, it provides an overview of the current state of the art of QoE research, with focus on work that particularly addresses QoE as a measurement challenge on the technology as well as on the end-user level. This is achieved by surveying the different streams of QoE research that have emerged in the context of Video, Voice and Web services with respect to the following aspects: fundamental relationships and perceptual principles, QoE assessment, modeling and monitoring.","3D Mesh Decomposition Using Protrusion and Boundary Part Detection ","Technical Section: Automatic urban modeling using volumetric reconstruction with surface graph cutsThe demand for 3D city-scale models has been significantly increased due to the proliferation of urban planning, city navigation, and virtual reality applications. We present an approach to automatically reconstruct buildings densely spanning a large urban area. Our method takes as input calibrated aerial images and available GIS meta-data. Our computational pipeline computes a per-building 2.5D volumetric reconstruction by exploiting photo-consistency where it is highly sampled amongst the aerial images. Our building surface graph cut method overcomes errors of occlusion, geometry, and calibration in order to stitch together aerial images and yield a visually coherent texture-mapped result. Our comparisons show similar quality to the manually modeled buildings of Google Earth, and show improvements over naive texture mapping and over space-carving methods. We have tested our algorithms with a 12sqkm area of Boston, MA (USA), using 4667 images (i.e., 280GB of raw image data) and producing 1785 buildings.","Hybrid multiobjective artificial bee colony with differential evolution applied to motif findingThe Multiobjective Artificial Bee Colony with Differential Evolution (MO-ABC/DE) is a new hybrid multiobjective evolutionary algorithm proposed for solving optimization problems. One important optimization problem in Bioinformatics is the Motif Discovery Problem (MDP), applied to the specific task of discovering DNA patterns (motifs) with biological significance, such as DNA-protein binding sites, replication origins or transcriptional DNA sequences. In this work, we apply the MO-ABC/DE algorithm for solving the MDP using as benchmark genomic data belonging to four organisms: drosophila melanogaster, homo sapiens, mus musculus, and saccharomyces cerevisiae. To demonstrate the good performance of our algorithm we have compared its results with those obtained by four multiobjective evolutionary algorithms, and their predictions with those made by thirteen well-known biological tools. As we will see, the proposed algorithm achieves good results from both computer science and biology point of views.","ATTENTO: ATTENTion Observed for Automated Spectator Crowd AnalysisWe propose a new type of crowd analysis, focused on the spectator crowd, that is, people \"interested in watching something specific that they came to see\" [1]. This scenario applies on stadiums, amphitheaters etc., and shares some aspects with classical crowd monitoring: actually, many people are simultaneously observed, so that per-person analysis is hard; however, here the dynamics of humans is more constrained, due to the architectural environment in which they are situated; specifically, people are expected to stay in a fixed location most of the time, limiting their activities to applaud, support/heckle the players or discuss with the neighbors. In this paper, we start facing this challenge by considering hockey matches, locating a videocamera 25-30 meters far from the bleachers, pointing at the crowd: in this scenario, aggregations of spectators that exhibit similar behavior are detected, and the behavior is classified into a set of predefined classes, highlighting the overall excitement. To these aims, in a first step we focus on individual frames, clustering local flow measures into spatial regions. The clustering is then extended by adding the temporal axis into the analysis, looking for non-randomic spatio-temporal clusters; for this purpose, the Lempel-Ziv complexity is considered. This way, choral activities can emerge, indicating for example fan groups belonging to different teams. After this, with the adoption of entropic measures, the degree of excitement of such groups can be quantified.","Understanding Big Picture and Its Challenges: Experts and Decision Makers PerspectivesThe big picture of an organization plays an important role in providing insight into the decision making process. Thus, the objectives of this paper are to investigate how experts and decision makers obtain the features of the big picture, and then identify related challenges (problems and issues). Data analysis and interpretation show that experts and decision makers gain the big picture through a process of collaboration. Basically there are four main sequences in the collaboration process of constructing the big picture. These are: (i) understanding the big picture requirements, (ii) extracting content from the tools, (iii) collaborating on pieces of information and (iv) using the collaborative information for decision making. In addition, the challenges of attaining the big picture were identified and then clustered into the 3 main components from the perspective of knowledge visualization (KV) on user perception, namely cognition, perception and communication. Data was collected using semi structured interviews following qualitative methods. The sketching technique was used in the one-to-one interviews to represent mental models which are important for later use in the design stage.","Characterization of Failure Effects on AADL ModelsPrior works on model-based Failure Modes and Effects Analysis (FMEA) automatically generate a FMEA table given the system model, a set of failure modes, and a set of possible effects. The last requirement is critical as bias may occur: since the considered failure effects are restricted to the anticipated ones, unexpected effects - the most interesting ones - are disregarded in the FMEA.#R##N##R##N#In this paper, we propose and investigate formal concepts that aim to overcome this bias. They support the construction of FMEA tables solely based on the system model and the failure modes, i.e., without requiring the set of effects as input. More concretely, given a system specification in the Architecture Analysis and Design Language (AADL), we show how to derive relations that characterize the effects of failures based on the state transition system of that specification. We also demonstrate the benefits and limitations of these concepts on a satellite case study.","Minimal Vertex Unique Labelled Subgraph MiningThis paper introduces the concept of Vertex Unique Labelled Subgraph Mining VULSM, a specialised form of subgraph mining. A VULS is a subgraph defined by a set of edge labels that has a unique vertex labelling associated with it. A minimal VULS is then a VULS which is not a supergraph of any other VULS. The application considered in this paper, for evaluation purposes, is error prediction with respect to sheet metal forming. The minimum BFS Right-most Extension Unique Subgraph Mining Min-BFS-REUSM algorithm is introduced for identifying minimal VULS using a Breadth First SearchBFS strategy.","Technical Section: Adaptive cloth simulation using corotational finite elementsIn this article we introduce an efficient adaptive cloth simulation method which is based on a reversible 3-refinement of corotational finite elements. Our novel approach can handle arbitrary triangle meshes and is not restricted to regular grid meshes which are required by other adaptive methods. Most previous works in the area of adaptive cloth simulation use discrete cloth models like mass-spring systems in combination with a specific subdivision scheme. However, if discrete models are used, the simulation does not converge to the correct solution as the mesh is refined. Therefore, we introduce a cloth model which is based on continuum mechanics since continuous models do not have this problem. We use a linear elasticity model in combination with a corotational formulation to achieve a high performance. Furthermore, we present an efficient method to update the sparse matrix structure after a refinement or coarsening step. The advantage of the 3-subdivision scheme is that it generates high quality meshes while the number of triangles increases only by a factor of 3 in each refinement step. However, the original scheme was not intended for the use in an interactive simulation and only defines a mesh refinement. In this article we introduce a combination of the original refinement scheme with a novel coarsening method to realize an adaptive cloth simulation with high quality meshes. The proposed approach allows an efficient mesh adaption and therefore does not cause much overhead. We demonstrate the significant performance gain which can be achieved with our adaptive simulation method in several experiments including a complex garment simulation.","Specifying a Semantic Wiki Ontology through a Collaborative Reconceptualisation Process ","Modeling and Simulation of the EV Charging in a Residential Distribution Power GridThere are numerous advantages of using Electric Vehicles (EVs) as an alternative method of transportation. However, an increase in EV usage in the existing residential distribution grid poses problems such as overloading the existing infrastructure. In this paper, we have modeled and simulated a residential distribution grid in GridLAB-D (an open-source software tool used to model, simulate, and analyze power distribution systems) to illustrate the problems associated with a higher EV market penetration rates in the residential domain. Power grid upgrades or control algorithms at the transformer level are required to overcome issues such as transformer overloading. We demonstrate the method of coordinating EV charging in a residential distribution grid so as to overcome the overloading problem without any upgrades in the distribution grid.","A Content Recommendation Framework Using Ontological User Profiles ","GALS-CMP: chip-multiprocessor for GALS embedded systemsIn this paper we present a novel multi-processor architecture for concurrent execution of programs that follow the Globally Asynchronous Locally Synchronous (GALS) formal model of computation. Programs are specified using the SystemJ concurrent programming language, suitable for modeling heterogeneous embedded applications that contain reactive and control driven parts and interact with the external environment. The proposed architecture is based on separating the control-driven and data-driven operations and executing them on distinct cores that support both types of operations, implemented as two modes within the single processor core. Each core can switch between two modes without any overhead. The core as the basic building block of the multiprocessor extends Java Optimized Processor (JOP), suitable for data-driven transformational operations, with control-oriented constructs that implement concurrency, reactivity, and control flow in SystemJ. Experimental evaluation over a range of benchmarks shows significant performance improvements over the existing platforms developed for the execution of the SystemJ program.","Toward secure clustered multi-party computation: a privacy-preserving clustering protocolDespite a large amount of research work has been done and a large number of results produced, the deployment of Secure Multi-party Computation (SMC) protocols for solving practical problems in real world scenarios is still an issue. This is mainly due to the complexity of the SMC-based solutions and to the needed assumptions that are not easy to fit to the considered problem. In this paper we propose an innovative approach for the deployment of SMC, providing a tradeoff between efficiency and privacy. In the Secure Clustered Multi-Party Computation (SCMC) approach, a function is more efficiently computed through reducing the number of participants to the SMC protocol by clustering, such that a reasonable privacy leakage inside the cluster is allowed. Toward this direction, this paper verifies the impact and the feasibility of applying different clustering techniques over the participants to a SMC protocol and proposes an effective specifically-tailored clustering protocol.","Hardness and Algorithms for Variants of Line Graphs of Directed Graphs ","SRAD with Weighted Diffusion FunctionSpeckle Reducing Anisotropic Diffusion, SRAD, is a multiplicative noise reduction method. In highly speckled environment, SRAD occasionally produces over-smoothed, dislocated/broadened edge lines and inadequate de- noising on homogeneous image regions where the speckles are well developed. To overcome these weaknesses, we propose a modification to SRAD with a weighted diffusion function. The proposed diffusion function is a weighted sum of two components - (1) a global ratio-based edge detection inspired compo- nent and (2) the original diffusion function of SRAD. The proposed filter shows significant improvement in de-noising and edge preservation. Speckle is a form of locally correlated multiplicative noise. Synthetic Aperture Radar (SAR), Synthetic Aperture Sonar (SAS) and ultrasound images are usually laden with such noise. Several filters have been proposed to reduce speckle noise. Roughly, they can be grouped into two families: homomorphic and adaptive. Homomorphic filtering refers to a technique of preprocessing the observed image to transform non-additive noise into additive noise using some nonlinear memoryless operator. Then standard additive noise filtering is applied for noise reduction. The enhanced image is formed by applying the inverse nonlinear operator. For speckle-like multiplicative noise, logarithmic and exponential operators are required for forward and inverse transfor- mation, respectively. In many cases, a speckled image represents the observed data as being multiplicative noise operated on by a linear system. Hence, a logarithmic opera- tor cannot separate the signal from the noise in this case. As a result, homomorphic filters are not efficient in speckle reduction. Adaptive filters account for the local correlation of speckle model and exploit local statistics. Among the earlier speckle reducing adaptive filters, Lee (3) and Kuan (4) filters were quite successful. Both Lee and Kuan filters have the same formation though the signal model assumptions and derivations are different. They are based on a linear speckle noise model and the Minimum Mean Square Error (MMSE) design approach. These filters are designed to reduce speckle noise while preserving edges and point features in radar imagery. Both Lee and Kuan filters produce the enhanced data by","Structure in Optimization: Factorable Programming and Functions ","Using Network Sciences to Evaluate the Brazilian Airline NetworkIn the next few years, Brazil will host international events such as the 2014 FIFA World Cup and the 2016 Olympics Games. Given the worldwide appeal of these events, local authorities in Brazil expect the country will have around 1.6 million visitors arriving at its airports (1 million for the Olympics and 600 thousand for the World Cup). There- fore, these events will put to test the robustness of the Brazilian airline transportation system. As of today, Brazil concentrates most of its flights in and out a single hub city: Sao Paulo Airport in Guarulhos (GRU). Is this concentration a problem? Aiming to analyze the hub choices of this network we collected data from the five biggest companies that operate in Brazil with domestic and international flights; together these companies are responsible for more than 94% of the total flight traffic in Brazil. In this paper analyzed the impact of moving today's main hub, Guarulhos Airport in Sao Paulo (GRU), to other airports around the country\u2014the idea is to understand what is the best configuration for single-hub model in Brazil. We also investigated the robustness of the network having a single hub by analyzing the impact of the removal of this hub from the network. We believe this work may help us understand how the airport infrastructure in Brazil has to be developed in the near future.","Assessing The Assessors - An Overview And Evaluation Of IT Project Success Reports ","Community Based User Behavior Analysis on Daily Mobile Internet UsageLaptops, handhelds and smart phones are becoming ubiqui- tous providing (almost) continuous Internet access and ever-increasing demand and load on supporting networks. Daily mobile user behavior analysis can facilitate personalized Web interactive systems and Internet services in the mobile environment. Though some research have already been done, there are still some problems need to be investigated. In this paper, we study the community based user behavior analysis on the daily Mobile Internet usage. What we focus on in this paper is to propose a framework which can calculate the proper number of the clusters in mo- bile user network. Given a mobile user Internet access dataset of one week which contains thousand of users, we firstly calculate the hourly traffic variation for the whole week. Then, we propose to use cluster coefficient and network community profile to confirm the presence of communities in mobile user network. Principal Component Analysis (PCA) is employed to capture the dominant behavioral patterns and uncover the several communities in the network. At last, we use communities/clusters to work out the various interests of the users on the timeline of the day.","A Smart Problem Solving EnvironmentResearchers of constructivist learning suggest that students should ra- ther learn to solve real-world problems than artificial problems. This paper pro- poses a smart constructivist learning environment which provides real-world problems collected from crowd-sourcing problem-solution exchange platforms. In addition, this learning environment helps students solve real-world problems by retrieving relevant information on the Internet and by generating appropriate questions automatically. This learning environment is smart from three points of view. First, the problems to be solved by students are real-world problems. Second, the learning environment extracts relevant information available on the Internet to support problem solving. Third, the environment generates questions which help students to think about the problem to be solved.","A Fast Poisson Solver for Hybrid Reconfigurable SystemThis paper presents the design and implementation of a fast Poisson solver on a reconfigurable hybrid system. Our hybrid solver in- tegrates a FPGA-based FFT coprocessor to collaborate in the solution of a numerical meteorological model involving one-dimensional shallow water equations. The Poisson equation is solved using a singular value decomposition associated with the Moore-Penrose inverse. The hybrid fast Poisson solver is evaluated under different amount of data entry and shows performance gains compared to the reference application.","Building a Common Framework for IIR EvaluationCranfield-style evaluations standardised Information Retrieval IR evaluation practices, enabling the creation of programmes such as TREC, CLEF, and INEX, and long-term comparability of IR systems. However, the methodology does not translate well into the Interactive IR IIR domain, where the inclusion of the user into the search process and the repeated interaction between user and system creates more variability than the Cranfield-style evaluations can support. As a result, IIR evaluations of various systems have tended to be non-comparable, not because the systems vary, but because the methodologies used are non-comparable. In this paper we describe a standardised IIR evaluation framework, that ensures that IIR evaluations can share a standardised baseline methodology in much the same way that TREC, CLEF, and INEX imposed a process on IR evaluation. The framework provides a common baseline, derived by integrating existing, validated evaluation measures, that enables inter-study comparison, but is also flexible enough to support most kinds of IIR studies. This is achieved through the use of a \"pluggable\" system, into which any web-based IIR interface can be embedded. The framework has been implemented and the software will be made available to reduce the resource commitment required for IIR studies.","Weighting Query Terms towards Multi-faceted Information Fusion of Market DataThis paper presents a framework that uses information fusion to capture similar contexts, and then apply these to learn similar instances from a knowledge base in an unsupervised way. These experiments are part of an initiative to build an intelligent business information system with capabilities for multi-faceted repeatable data analysis and decision making. The proposed framework consists of three components: Query Understanding, Information Fusion and Reasoning &amp; Learning. As part of the proposed framework, we present a new approach to performing the weighting of query terms which is aimed at improving our understanding of a user's query intent. The proposed query terms weighting method captures the key contexts of the user's query intent using evidence from corpus statistics. By way of example, the datasets used in our experiments consist of the information retrieved from different sources pertaining to Mobile Payments, a rapidly evolving sector of the Financial Services industry. We illustrate the performance of the proposed information retrieval system using the new query terms weighting approach on three different datasets. Our experiments illustrate that the proposed query terms weighting approach significantly improves the retrieval of texts with a greater variety of contextual information.","A Decision Framework for Broker Selection in Smart GridsTrust and reputation are critical factors for successful cooperative re- lationships between broker agents and producers/consumers in \"SmartGrids\" electricity markets. In this paper, we present SmartRate, a trust and reputation- based decision framework for Smart Grids, based on the available ratings pro- vided by other customers. This model considers multiple trust factors associated with the broker and the preferences of customers for each of these factors. Our previous work has shown the importance of learning the behavior of the agent who is providing reports or rates in selecting trustworthy partners. SmartRate uses direct interactions with brokers to learn the rating behavior of customers. We define a multi-attribute utility function for broker selection and show how learning customers' rating behaviors helps to increase a decision maker's utility, which leads to an increase in customer satisfaction. We evaluate this framework by simulating a market based on real-world data. Our results show that learning the characteristics of a rating population helps to interpret and personalize the rates, which results in better decision making and an increase in customer satis- faction.","Implementing Mobility Service Based on Japanese Linked DataThis study aims at developing a web service with Japanese Linked Data and evaluating the service. In Japan, government sets Open Data as a new strategy in Information Technology field and focuses on \"Linked Open Data LOD\" [ 1 ] as a means to publish. However, the number of dataset as Japanese Linked Data is small, and the effect by introducing Japanese Linked Data has not been shown yet. Therefore, we created Linked Data in Japanese focused on geographical or positional data, and implemented a mobility service to reduce user's cognitive load. Moreover, we conducted verification experiment for using the service and compared with conventional services. As a result, the possibilities of Linked Data to respond to various queries easily and to apply for information services by crossing some domains were explored.","Experimenting with BitTorrent on a Cluster: A Good or a Bad Idea?Evaluation of large-scale network systems and applications is usually done in one of three ways: simulations, real deployment on Internet, or on an emulated network testbed such as a cluster. Simulations can study very large systems but often abstract out many practical details, whereas real world tests are often quite small, on the order of a few hundred nodes at most, but have very realistic conditions. Clusters and other dedicated testbeds offer a middle ground between the two: large systems with real application code. They also typically allow configuring the testbed to enable repeatable experiments. In this paper we explore how to run large BitTorrent experiments in a cluster setup. We have chosen BitTorrent because the source code is available and it has been a popular target for research. Our contribution is twofold. First, we show how to tweak and configure the BitTorrent client to allow for a maximum number of clients to be run on a single machine, without running into any physical limits of the machine. Second, our results show that the behavior of BitTorrent can be very sensitive to the configuration and we revisit some existing BitTorrent research and consider the implications of our findings on previously published results. As we show in this paper, BitTorrent can change its behavior in subtle ways which are sometimes ignored in published works.","Mobile App versus Web App: a Comparison Using 2008\u20132012 \u201cPubMed for Handhelds\u201d Server DataRecent surveys show that mobile apps are more popular than Web apps. Apple\u2019s iTunes Store, now has about 800,000 apps and reported to have about 40 billion downloads. Android apps, although fewer, is available to the most number of smartphones today. About 40,000 apps are medical or health related. We developed a PubMed4Hh mobile app for iPhone/iPad users to search MEDLINE/PubMed with same features as our Web-based search tools, in use since 2002. Five-year (2008\u20132012) server data for PubMed4Hh and Web app were analyzed. Searches using the mobile app significantly increased compared to the same five-year time period. Month-by-month comparison showed a 3 to 5-fold increase in queries. The six-month total accesses comparison increased 280% from the previous four-year average. A review of 500 randomly selected queries revealed that the majority of queries were clinical questions ((97.8%) and 61% of these queries are searches related to therapy.","Authoring Support for Post-WIMP ApplicationsEmploying post-WIMP interfaces, i.e. user interfaces going beyond the traditional WIMP (Windows, Icons, Menu, Pointer) paradigm, often implies a more complex authoring process for applications. We present a novel authoring method and a corresponding tool that aims to enable developers to cope with the added level of complexity. Regarding the development as a process conducted on different layers, we introduce a specific layer for post-WIMP in addition to layers addressing implementation or traditional GUI elements. We discuss the concept of cross layer authoring that supports different author groups in the collaborative creation of post-WIMP applications permitting them working independently on their respective layer and contributing their specific skills. The concept comprises interactive visualization techniques that highlight connections between code, GUI and post-WIMP functionality. It allows for graphical inspection while transitioning smoothly between layers. A cross layer authoring tool has been implemented and was well received by UI developers during evaluation.","Disambiguating Authors in Academic Search Engines ","Skyline Queries over Incomplete Data - Error Models for Focused Crowd-SourcingSkyline queries are a well-known technique for explorative retrieval, multi-objective optimization problems, and personalization tasks in databases. They are widely acclaimed for their intuitive query formulation mechanisms. However, when operating on incomplete datasets, skyline query processing is severely hampered and often has to resort to error-prone heuristics. Unfortunately, incomplete datasets are a frequent phenomenon due to widespread use of automated information extraction and aggregation. In this paper, we evaluate and compare various established heuristics for adapting skylines to incomplete datasets, focusing specifically on the error they impose on the skyline result. Building upon these results, we argue for improving the skyline result quality by employing crowd-enabled databases. This allows dynamic outsourcing of some database operators to human workers, therefore enabling the elicitation of missing values during runtime. Unfortunately, each crowd-sourcing operation will result in monetary and query runtime costs. Therefore, our main contribution is introducing a sophisticated error model, allowing us to specifically concentrate on those tuples that are highly likely to be error-prone, while relying on established heuristics for safer tuples. This technique of focused crowd-sourcing allows us to strike a perfect balance between costs and result's quality.","Rapid multi-organ segmentation using context integration and discriminative modelsWe propose a novel framework for rapid and accurate segmentation of a cohort of organs. First, it integrates local and global image context through a product rule to simultaneously detect multiple landmarks on the target organs. The global posterior integrates evidence over all volume patches, while the local image context is modeled with a local discriminative classifier. Through non-parametric modeling of the global posterior, it exploits sparsity in the global context for efficient detection. The complete surface of the target organs is then inferred by robust alignment of a shape model to the resulting landmarks and finally deformed using discriminative boundary detectors. Using our approach, we demonstrate efficient detection and accurate segmentation of liver, kidneys, heart, and lungs in challenging low-resolution MR data in less than one second, and of prostate, bladder, rectum, and femoral heads in CT scans, in roughly one to three seconds and in both cases with accuracy fairly close to inter-user variability.","Composite Event Indicator Processing in Event Extraction for Non-configurational Language ","Development of Recognition System of Japanese Sign Language Using 3D Image Sensor ","Robustness evaluation of incentive mechanismsA general assumption for incentive mechanisms is that all agents are rational and seek to maximize their utility. When some agents are irrational and launch various attacks, these mechanisms may fail to work. To address the issue of evaluating the robustness of incentive mechanisms, we propose a robustness metric in this paper. It is inspired by the studies of the evolutionary game theory and defined as the maximum percentage of irrational agents existing in the system while it is still better off for rational agents to perform desired strategies. Then a simulation framework is designed to measure the robustness of incentive mechanisms, and is verified to be able to produce the same results as those by theoretical analysis. Finally, we demonstrate the usage of our simulation framework in evaluating and comparing the robustness of two incentive mechanisms where irrational agents adopt different attacking strategics.","Accessibility of Public Web Services: A Distant Dream?Today, many public services are available online through Web sites. The accessibility of the sites, also to people with disabilities, is important be- cause the accessibility concerns equality of citizens, a cornerstone of democracy. In the current study we carried out a meta-analysis of 17 studies concerning the accessibility of the Web sites of public administration. Furthermore, we assessed the accessibility of Web pages of 12 ministries of the Finnish government. The assessments were based on the Web Content Accessibility Guidelines (WCAG). The results showed that in terms of the WCAG guidelines, the average accessi- bility of public Web sites is poor. Moreover, there was no improvement in the accessibility in the 2000's and many of the accessibility failures were so simple that they could have been easily avoided. This may indicate that the building of information society is driven by technology, rather than principles of democracy and well-being.","Environmental evaluation of a rehabilitation aid interaction under the framework of the ideal model of assistive technology assessment processRecently Federici and Scherer [1] proposed an ideal model of an Assistive Technology Assessment (ATA) process that provides reference guidelines for professionals of a multidisciplinary team of assistive technology (AT) service delivery centers to compare, evaluate, and improve their own matching models. The ATA process borrows a user-driven working methodology from the Matching Person and Technology Model [2] and it embraces the biopsychosocial model [3] aiming at the best combination of AT to promote customers' personal well-being. As Federici and Scherer [1] suggest, the multidisciplinary team, by applying the ATA process, may provide for users not only a device, but much more an assistive solution, which is the real outcome of a match process. An assistive solution is provided for the user only when the interaction dialogue between user, device, and environments of use improves the users' performances in participating in their everyday contexts. In this theoretical framework, the evaluation of the users' interaction with the AT in different kinds of environments is a key factor for the success of the ATA process, because, as Mirza, Gossett Zakrajsek, and Borsci [4] claim, the environment is antecedent to the AT and crucial for identifying how the AT works in relation to the users' needs. In the ATA process a specific Environmental Assessment (EA) model for testing the interaction of the user with the environments of use, through the AT, has been defined. The aim of this paper is to describe the EA model steps and discuss the dimensions that a practitioner has to consider for this assessment. Accessibility, universal design, and sustainability are used in the EA model as the dimensions for measuring the relationship between the AT and the environment [4]. The EA model steps and the trade-off among these dimensions are presented through a case example in which practitioners analyze the relationship between a communication aid used by a child and her classroom and home environments.","Integrating the anchoring process with preference stability for interactive movie recommendationsMany e-commerce sites employ collaborative filtering techniques to provide recommendations to customers based on the preferences of similar users. However, as the number of customers and products increases, the prediction accuracy of collaborative filtering algorithms declines because of sparse ratings. In addition, the traditional recommendation approaches just consider the item's attributes and the preference similarities between users; however, they are not concerned that users' preferences may be developed as their familiarity with or experiences during choice or preference elicitation grows. In this work, we propose an anchor-based hybrid filtering approach to capture the user's preferences of movie genres interactively and then achieve precise recommendations. To conduct this experiment, we recruited 30 users with different types of preference stabilities for movie genres. The experimental results show that the proposed anchor-based hybrid filtering approach can effectively filter out the users' undesired movie genres, especially for the user who has unstable movie genre preferences. The results suggest that the factor of the stability of users' preferences can be considered for developing effective recommendation strategies.","Security Games for Virtual Machine Allocation in Cloud ComputingWhile cloud computing provides many advantages in accessibility, scalability and cost efficiency, it also introduces a number of new security risks. This paper concentrates on the co-resident attack, where malicious users aim to co-locate their virtual machines (VMs) with target VMs on the same physical server, and then exploit side channels to extract private information from the victim.Most of the previous work has discussed how to eliminate or mitigate the threat of side channels. However, the presented solutions are impractical for the current commercial cloud platforms. We approach the problem from a different perspective, and study how to minimise the attacker's possibility of co-locating their VMs with the targets, while maintaining a satisfactory workload balance and low power consumption for the system. Specifically, we introduce a security game model to compare different VM allocation policies. Our analysis shows that rather than deploying one single policy, the cloud provider decreases the attacker's possibility of achieving co-location by having a policy pool, where each policy is selected with a certain probability. Our solution does not require any changes to the underlying infrastructure. Hence, it can be easily implemented in existing cloud computing platforms.","Organizational Learning, Agility and Social Technologies in Contemporary Workplaces ","GNMF with Newton-Based MethodsSeveral variants of Nonnegative Matrix Factorization (NMF) have been proposed for supervised classification of various objects. Graph regularized NMF (GNMF) incorporates the information on the data geometric structure to the training process, which considerably improves the classification results. However, the multiplicative algorithms used for updating the underlying factors may result in a slow convergence of the training process. To tackle this problem, we propose to use the Spectral Projected Gradient (SPG) method that is based on quasi-Newton methods. The results are presented for image classification problems.","Situational Awareness for Improving Network Resilience ManagementComputer networks, widely used by enterprises and individuals nowadays, are still vulnerable when facing traffic injection, human mistakes, malicious attacks and other failures though we spend much more time and cost on security, dependability, performability, survivability, and risk assessment to make the network provide resilient services. This is because these measures are commonly viewed as closely related but a practical means of linking them is often not achieved. Network resilience research brings together all the planning that the network can be managed at a holistic view of resilience management. This paper focuses on network resilience management from \"reactive\" paradigm to a \"proactive\" one through Situational Awareness (SA) of internal factors of network and external ones of complex, dynamic and heterogeneous network environment. After surveying the research of network resilience and resilience assessment in the network, we give a model to discuss how to construct awareness of resilience issues which includes four stages. The first step is to get the situational elements about what we are interested in. Second, to understand what happened and what is going on in the networks, pattern learning and pattern matching are exploited to identify challenge. Then, to make proactive resilience management, we need to predict challenges and look for potential ones at this stage. At the fourth stage, resilience management can help take actions of remediation and recovery according to the policy of defender and attacker. After that, the two players' behaviors of defender and attacker are modeled in the same model by using Extended Generalized Stochastic Game Nets (EGSGN) which combines Game theory into Stochastic Petri Nets. Finally, we give a case study to show how to use EGSGN to depict the network resilience situation in the same model.","Novel Method to Generate Tests for VHDL ","A SVM-based system for predicting protein-protein interactions using a novel representation of protein sequencesProtein-protein interactions (PPIs) are crucial for almost all cellular processes, including metabolic cycles, DNA transcription and replication, and signaling cascades. However, the experimental methods for identifying PPIs are both time-consuming and expensive. Therefore, it is important to develop computational approaches for predicting PPIs. In this article, a sequence-based method is developed by combining a novel feature representation using binary coding and Support Vector Machine (SVM). The binary-coding-based descriptors account for the interactions between residues a certain distance apart in the protein sequence, thus this method adequately takes the neighboring effect into account and mine interaction information from the continuous and discontinuous amino acids segments at the same time. When performed on the PPI data of Saccharomyces cerevisiae, the proposed method achieved 86.93% prediction accuracy with 86.99% sensitivity at the precision of 86.90%. Extensive experiments are performed to compare our method with the existing sequence-based method. Achieved results show that the proposed approach is very promising for predicting PPI, so it can be a useful supplementary tool for future proteomics studies.","Image segmentation on GPGPUs: a cellular automata-based approachImage segmentation is one of the most difficult tasks in image processing and plays a critical role in the analysis of medical images used for diagnosis and treatment. With the decreased hardware costs and improvements in computing power of many-core architectures, there is an opportunity to both improve upon image segmentation algorithms and to make this technology more accessible. This paper describes our on-going research efforts to implement efficient image segmentation algorithms on graphical processing units (GPUs). A focused case study was performed with a suitable algorithm based on Cellular Automata, a parallel computational technique. Preliminary segmentation results are shown to validate our approach. Plans to improve the algorithm by making it more robust to noise and more efficient on GPU architectures are discussed. Our use of graph theoretic techniques and their implementation on GPUs will have broad application to other areas requiring computationally intensive calculations, as found in many problems involving modeling and simulation.","Agile Behavior Of Business Intelligence Systems: An Empirical Study On The Impact Of In-Memory Technology ","An Evaluation Measure for Learning from Imbalanced Data Based on Asymmetric Beta Distribution ","Communication and Social Network Requirements of Chinese Elderly People for Mobile Services ","Temporal Video Segmentation to Scene Based on Conditional Random FiledsIn this paper, we propose a novel approach of video segmen- tation into scenes based on the technique of conditional random fields (CRFs). This approach is built upon the design in which scene segmen- tation is transformed into a label identification problem by defining three types of shots. To implement our algorithm, three middle-level features including shot difference signal, scene transition graph and audio type are extracted to depict the label properties of each shot, and then CRFs model is employed to identify the labels sequence. The advantage of CRFs model lies in its facility in integrating context information of neigh- boring shots, which produces accurate results in scene segmentation. The proposed approach is verified by seven types of data covering the most major genres of TV program. Experiments on testing data set yield av- erage 0.88 F-measure, which illustrates that the proposed method can accurately detect most scenes in different genres of programs.","Using graphical representations to support the calculation of infusion parametersA variety of medical procedures require arithmetic calculations to be performed. These calculations can be complex and induce errors that can have serious consequences on the ward. In this paper, we consider whether a graphical representation might make these calculations easier. The results of a laboratory experiment are reported in which participants were asked to solve a number of infusion parameter problems that were represented either graphically or textually. Results show that participants were faster but no more accurate in solving graphical problems than they were textual problems. We discuss the need for situated work to be conducted that builds on these initial findings to determine whether the advantages of graphical representations transfer to actual workplace settings. \u00a9 2013 Springer-Verlag.","Illumination Variation Dictionary Designing for Single-Sample Face Recognition via Sparse RepresentationThis paper focuses on enhancing Sparse Representation based Classifier (SRC) in single-sample face recognition tasks under vary- ing illumination conditions. The major contribution is two-fold: firstly, we present an interesting observation based on Lambertian reflectance model: the identity information will be canceled out by the pair-wise difference images from the same subject in logarithmic domain, and only the subject-independent illumination variation retains. Secondly, inspired from this observation, we propose to \"borrow\" illumination vari- ations from any generic subject by constructing an illumination variation dictionary composed of pair-wise difference images of generic subjects in logarithmic domain to cover the possible illumination variations between test and gallery samples. Experimental results on Extended Yale B and FERET face databases demonstrate the superiority of our method.","A Consensus Approach for Combining Multiple Classifiers in Cost-Sensitive Bankruptcy Prediction ","Second-Generation Product Line Engineering: A Case Study at General Motors ","Modeling Multimodal Behaviors from Speech ProsodyHead and eyebrow movements are an important communi- cation mean. They are highly synchronized with speech prosody. En- dowing virtual agent with synchronized verbal and nonverbal behavior enhances their communicative performance. In this paper, we propose an animation model for the virtual agent based on a statistical model link- ing speech prosody and facial movement. A fully parameterized Hidden Markov Model is proposed first to capture the tight relationship between speech and facial movement of a human face extracted from a video corpus and then to drive automatically virtual agent's behaviors from speech signals. The correlation between head and eyebrow movements is also taken into account during the building of the model. Subjective and objective evaluations were conducted to validate this model.","Fuzzy logic optimized wireless sensor network routing protocolWireless sensor networks WSNs are used in health monitoring, tracking and security applications. Such networks transfer data from specific areas to a nominated destination. In the network, each sensor node acts as a routing element for other sensor nodes during the transmission of data. This can increase energy consumption of the sensor node. In this paper, we propose a routing protocol for improving network lifetime and performance. The proposed protocol uses type-2 fuzzy logic to minimize the effects of uncertainty produced by the environmental noise. Simulation results show that the proposed protocol performs better than a recently developed routing protocol in terms of extending network lifetime and saving energy and also reducing data packet lost.","Enhancing privacy protection in distributed environments through identification and authentication-based secure data-level access controlSystem-level access control methodologies depending on Perimeter Protection proofed their efficiency in the past, but the appearance of many new significant developments in digital communications highlighted the limitations of this approach. Increased concerns about the compatibility of system-level access control mechanism with new distributed and ubiquitous environments are turning aspirations towards de-perimeterisation protection and data level access control as solutions. This research does therefore try to make a contribution to privacy protection based on already advanced data-level access control work, such as the SPIDER project. The solution developed in this research suggests an X.509 certification extension to fit the data-level access control requirements, and proposes a new design for application structure in order to improve the identification and authentication-based secure data-level access control process.","ELEXR: Automatic Evaluation of Machine Translation Using Lexical RelationshipsThis paper proposes ELEXR 1 , a novel metric to evaluate ma- chine translation (MT). In our proposed method, we extract lexical co-occurrence relationships of a given reference translation (Ref) and its corresponding hypothesis sentence using hyperspace analogue to language space matrix. Then, for each term appearing in these two sentences, we convert the co-occurrence information into a conditional probability dis- tribution. Finally, by comparing the conditional probability distributions of the words held in common by Ref and the candidate sentence (Cand) us- ing Kullback-Leibler divergence, we can score the hypothesis. ELEXR can evaluate MT by using only one Ref assigned to each Cand without incorpo- rating any semantic annotated resources like WordNet. Our experiments on eight language pairs of WMT 2011 submissions 2 show that ELEXR outperforms baselines, TER and BLEU, on average at system-level corre- lation with human judgments. It achieves average Spearman's rho corre- lation of about 0.78, Kendall's tau correlation of about 0.66 and Pearson's correlation of about 0.84, corresponding to improvements of about 0.04, 0.07 and 0.06 respectively over BLEU, the best baseline.","AntSM: Efficient Debugging for Shared Memory Parallel Programs ","Simultaneous sample and gene selection using t-score and approximate support vectorsT-score, based on t-statistics between samples and disease classes, is a widely used filter criterion for gene selection from microarray data. However, classical T-score uses all the training samples but for both biological and computational reasons, selection of relevant samples for training is an important step in classification. Using a modified logistic regression approach, we propose a sample selection criterion based on T-score and develop a backward elimination approach for gene selection. The method is more stable and computationally less costly compared to support vector machine recursive feature elimination (SVM-RFE) methods.","Alignment of DNA Mass-Spectral Profiles Using Network Flows ","Combining Topic Model and Relevance Filtering to Localize Relevant Frames in Web VideosNumerous web videos associated with rich metadata are avail- able on the Internet today. While such metadata like video tags bring us facilitations and opportunities for video search and multimedia content un- derstanding, some challenges also arise due to the fact that those video tags are usually annotated at the video level while many tags actually only de- scribe parts of the video content. Thus how to localize the relevant parts or frames of web video for given tags is the key to many applications and research tasks. In this paper we propose to combine topic model and rele- vance filtering to localize relevant frames. Our method is designed in three steps. First we apply relevance filtering to assign relevance scores to video frames and a raw relevant frame set is obtained by selecting the top ranked frames. Then we separate the frames into topics by mining the underlying semantics using Latent Dirichlet Allocation and use the raw relevance set as validation set to select relevant topics. Finally, the topical relevances are used to refine the raw relevant frame set and the final results are obtained. Experiment results on real web videos validate the effectiveness of the pro- posed approach.","Large deformation image classification using generalized locality-constrained linear coding.Magnetic resonance (MR) imaging has been demonstrated to be very useful for clinical diagnosis of Alzheimer's disease (AD). A common approach to using MR images for AD detection is to spatially normalize the images by non-rigid image registration, and then perform statistical analysis on the resulting deformation fields. Due to the high nonlinearity of the deformation field, recent studies suggest to use initial momentum instead as it lies in a linear space and fully encodes the deformation field. In this paper we explore the use of initial momentum for image classification by focusing on the problem of AD detection. Experiments on the public ADNI dataset show that the initial momentum, to- gether with a simple sparse coding technique\u2014locality-constrained linear coding (LLC)\u2014can achieve a classification accuracy that is comparable to or even better than the state of the art. We also show that the performance of LLC can be greatly improved by introducing proper weights to the codebook.","Open Challenges in the Resilience Evaluation of Ad Hoc NetworksWireless ad hoc networks are spontaneous, self-healing and self-managing systems strongly raising in the last decade. However, their deployment in privacy- or life-critical scenarios still requires a deeper analysis to determine their robustness to faults/attacks and their ability to recover from situations degrading performance and dependability. Un- fortunately, several challenges limit the development of practical assess- ment approaches for ad hoc networks. This paper focuses on identifying these challenges to provide potential evaluators with a guide of the sen- sitive points that require an especial attention to improve the credibility of results when addressing the resilience evaluation of ad hoc networks.","Security in Critical Infrastructures \u2013 Future Precondition for Operating License? ","Block Programming Technique in Traffic ControlIn the paper there are discussed benefits of using the block-oriented approach in programming the PLC controller. As an example there is taken a model of traffic junction with multiple traffic flow (including the railway cross- ing). The model is described and control system structure is presented. There are discussed principles of block-oriented programming approach in Ladder Diagram (LAD) language. Benefits of using this technique are shown and example is discussed.","Facility Location and Social Choice via Microaggregation ","A Non-temporal Approach for Gesture Recognition Using Microsoft KinectGesture recognition has become a very active research area with the advent of the Kinect sensor. The most common approaches for gesture recognition use temporal information and are based on meth- ods such as Hidden Markov Models (HMM) and Dynamic Time Warp- ing (DTW). In this paper, we present a novel non-temporal alternative for gesture recognition using the Microsoft Kinect device. The proposed approach, Recognition by Characteristic Window (RCW), identifies, us- ing clustering techniques and a sliding window, distinctive portions of individual gestures which have low overlapping information with other gestures. Once a distinctive portion has been identified for each gesture, all these sub-sequences are used to recognize a new instance. The pro- posed method was compared against HMM and DTW on a benchmark gesture's dataset showing very competitive performance.","Empirical Evaluation of the Quality of Conceptual Models Based on User Perceptions: A Case Study in the Transport DomainToday, many companies design and maintain a vast amount of conceptual models. It has been also observed that such large model collections exhibit serious quality issues in industry practice. A number of quality frameworks have been proposed in the literature, but the practice is that practitioners continue to evaluate conceptual models in an ad-hoc and subjective way, based on common sense and experience. Therefore, there is a lack of empirical works in the evaluation of conceptual frameworks. This paper reports an empirical qualitative study on the evaluation of the quality of a conceptual framework in the domain of transport logistics, using existent quality evaluation frameworks. The results show how the users perceive the ease of understanding, the usefulness, the perceived semantic quality and satisfaction with the models included in the conceptual framework. The results also provided their view on advantages, challenges and improvements to be performed in the framework.","Why Are Users of Social Media Inclined to Word-of-Mouth? ","Massive Query Expansion by Exploiting Graph Knowledge BasesKeyword based search engines have problems with term ambiguity and vocabulary mismatch. In this paper, we propose a query expansion technique that enriches queries expressed as keywords and short natural language descriptions. We present a new massive query expansion strategy that enriches queries using a knowledge base by identifying the query concepts, and adding relevant synonyms and semantically related terms. We propose two approaches: (i) lexical expansion that locates the relevant concepts in the knowledge base; and, (ii) topological expansion that analyzes the network of relations among the concepts, and suggests semantically related terms by path and community analysis of the knowledge graph. We perform our expansions by using two versions of the Wikipedia as knowledge base, concluding that the combination of both lexical and topological expansion provides improvements of the system's precision up to more than 27%.","A Model of Commercial Open Source Software Product FeaturesCommercial open source software has become an important part of the packaged software product industry. This paper provides a model of individual product features, rather than full-fledged business models, and their perceived value to customers. The model is the result of a three-iteration study, including interview analysis, literature review and the implementation of an empirical survey. Companies can use the feature model to determine their products and business model..","A Granulometry Based Descriptor for Object CategorizationThe progress in the area of object recognition in the last decade is impressive. The literature reports new descriptors, new strate- gies, new ways to combine descriptors and classifiers and new problems in a so fast pace that it is hard to follow the whole area. A recent problem in the area is the fine-grained categorization. In this work, to address this problem, we propose a descriptor based on the application of morpho- logical granulometries in the map of edges of an image. This descriptor is used to characterize the distribution of lengths and orientations of edges and to build a model for generic objects. We also propose a new spatial quantization with an arbitrary number of levels and divisions in each level. This quantization is so flexible that adjacent regions may have overlapping areas to avoid breakages in the structures that are near the border of the regions as it happens in the traditional spatial pyramids. Both approaches are used in a challenging and recent object recognition problem, the categorization of very similar classes. The proposed descrip- tor was used along with other descriptors and the overall performance of our solution to this problem was about 8% better than other work using the bag-of-words approach reported in the literature. Our descrip- tor showed a result 12% better when compared to the results of other edge-related descriptor in the categorization of very similar classes.","Cloud Extraction and Removal in Aerial and Satellite Images ","Information and Information Systems Project for a Strategic Digital City: A Brazilian Case ","Automatic Verification of Parent-Child Pairs from Face ImagesThe automatic identification of kinship relations from pairs of facial images is an emerging research area in pattern analysis with possible applications in image retrieval and annotation, forensics and his- torical studies. This work explores the computer identification of pairs of kins using different facial features, based on geometric and textural data, and state-of-the-art classifiers. We first analyzed different facial at- tributes individually, selecting the most effective feature variables with a two stage feature selection algorithm. Then, these features were combined together, selecting again the most relevant ones. Experiments shows that the proposed approach provides a valuable solution to the kinship verifi- cation problem, as suggested by the comparison with a different method on the same data and on the same experimental protocol.","Assessing liability with argumentation maps : an application in aviation lawIn this paper we present an application of argument maps for assessing liability in the field of Air Traffic Management (ATM), developed within the ALIAS (Addressing the Liability Impact of Automated Systems) project. Such maps are used for presenting legal concepts and norms to lawyers and non lawyers (engineers, software developers and other technical personnel), within the cooperative design and assessment of new technologies for ATM.","A Better Time Approximation Scheme for e-PassportsE-passports are the new means of identification documents in border control points, where special reader devices named inspection terminals are installed to authenticate travelers. The authentication of e-passports to inspection terminals is based on biometric data stored in the formers, while the authentication of inspection terminals to e-passports is based on digital certificates. To check the expiration date of certificates, e-passports maintain an internal variable named effective date, which provides only an estimation of the current time. This introduces a serious threat on e-passports' privacy. Specifically, e-passports may accept expired certificates, considering them as non-expired, due to the time difference between the effective dates of e-passports and the current time. Thus, in case an adversary obtains an expired certificate, he/she may impersonate a fake inspection terminal and compromise sensitive personal information e.g., biometric data from e-passports. This paper proposes a scheme that enables e-passports to update their effective dates based on the effective dates of other, more recently updated e-passports, in a secure and effective manner. In this way, more e-passports have a better estimation of the current time, reducing the time window in which an attacker can use an expired certificate. The proposed scheme minimizes the deployment complexity, since it does not require extensive modifications to the existing infrastructure, while at the same time maintains compatibility with the legacy system.","Managing the Access Grid - A Process View to Minimize Insider Misuse RisksIt is generally agreed upon the fact that the quality of Identity- and Access Management (IAM) data such as user accounts, access privileges or consistent user representation among different security domains is low. Grow- ing user populations in medium- and large-sized organizations lead to a so called \"identity chaos\" in which over-privileged employees increase the risk of insider misuse. Recent governance and compliance mandates have amplified the importance of minimizing these risks. In order to fulfill these requirements, organizations focus on implementing role-based user management. To set up a role-based access control system, they face the challenge of modeling suitable roles for their employees. In this paper we show how the role modeling process can be improved by utilizing the so called access grid, a visualization technique to incorporate human interaction into the process of role creation.","PRINSYS: on a quest for probabilistic loop invariantsPrinsys (pronounced \"princess\") is a new software-tool for  pr  obabilistic  in  variant  sy  nthesi s  . In this paper we discuss its implementation and improvements of the methodology which was set out in previous work. In particular we have substantially simplified the method and generalised it to non-linear programs and invariants. Prinsys follows a constraint-based approach. A given parameterised loop annotation is speculatively placed in the program. The tool returns a formula that captures precisely the invariant instances of the given candidate. Our approach is sound and complete. Prinsys's applicability is evaluated on several examples. We believe the tool contributes to the successful analysis of sequential probabilistic programs with infinite-domain variables and parameters.","Evaluation of ILP-Based Approaches for Partitioning into Colorful ComponentsThe NP-hard Colorful Components problem is a graph partitioning problem on vertex-colored graphs. We identify a new appli- cation of Colorful Components in the correction of Wikipedia inter- language links, and describe and compare three exact and two heuristic approaches. In particular, we devise two ILP formulations, one based on Hitting Set and one based on Clique Partition .F urthermore, we use the recently proposed implicit hitting set framework (Karp, JCSS 2011; Chandrasekaran et al., SODA 2011) to solve Colorful Components. Finally, we study a move-based and a merge-based heuristic for Col- orful Components. We can optimally solve Colorful Components for Wikipedia link correction data; while the Clique Partition-based ILP outperforms the other two exact approaches, the implicit hitting set is a simple and competitive alternative. The merge-based heuristic is very accurate and outperforms the move-based one. The above results for Wikipedia data are confirmed by experiments with synthetic instances.","\u2018It don\u2019t matter if you\u2019re Black or White\u2019? Effects of robot appearance and user prejudice on evaluations of a newly developed robot companion. ","An Efficient High-Speed Traffic Control Scheme for Real-Time Multimedia Applications in Wireless Networks ","Slid pairs in the initialisation of the A5/1 stream cipherA5/1 is a shift register based stream cipher which uses a majority clocking rule to update its registers. It is designed to provide privacy for the GSM system. In this paper, we analyse the initialisation process of A5/1. We demonstrate a sliding property of the A5/1 cipher, where every valid internal state is also a legitimate loaded state and multiple key-IV pairs produce phase shifted keystream sequences. We describe a possible ciphertext only attack based on this property.","Analysis of Gait Recognition on Constrained Scenarios with Limited Data InformationThis paper is focused on the assessment of gait recognition on a constrained scenario, where limited information can be extracted from the gait image sequences. In particular we are interested in assessing the performance of gait images when only the lower part of the body is acquired by the camera and just half of a gait cycle is available (SFootBD database). Thus, various state-of-the-art feature approaches have been followed and applied to the data. Results show that good recognition performance can be achieved using such limited data information for gait biometric. A comparative analysis of the influence of the quantity of data used in the training models has been carried out obtaining results of 8.6% EER for the case of using 10 data samples to train the mod- els, and 5.7% of EER for the case of using 40 data for training. Also, a comparison with a standard and ideal gait database (USF database) is also carried out using similar experimental protocols. In this case 10 data samples are used for training achieving results of 3.6% EER. The comparison with a standard database shows that different feature ap- proaches perform differently for each database, achieving best individual results with MPCA and EGEI methods for the SFootBD and the USF databases respectively.","Logic-Oriented Confidentiality Policies for Controlled Interaction Execution ","Thermal Feedback Identification in a Mobile EnvironmentAudio and vibrotactile feedback are not always suitable or desirable, as noise and/or movement may mask them, and so thermal feedback may provide a salient alternative. In this paper, the identification of 'thermal icons' structured thermal feedback was tested as a means of conveying information when users were sitting and walking in an outdoor location. Overall identification rate for thermal icons was 64.6%, but identification of individual parameters was promising, at 94% accuracy for direction of thermal change warming/cooling and 73.1% accuracy for subjective intensity moderate/strong. Results showed that walking outdoors did not significantly worsen icon identification compared to sitting outdoors, but the environmental temperature had a strong influence. Recommendations are given on how better to design and adapt thermal feedback for use in outdoor mobile scenarios.","On Data, Information, and Knowledge Representation in Business Process Models ","Governing and Managing Customer-Initiated Engineering Change: An In-Depth Case Study of a Global Industrial Supplier ","Take or wait? learning turn-taking from multiparty dataWe build turn-taking models for autonomous characters in language-based interactions with small groups of children. Two models explore the use of support vector machines given the same multimodal features, but different methods for collecting turn-taking labels.","Reachability-based impact as a measure for insidernessInsider threats pose a difficult problem for many organisations. While organisations in principle would like to judge the risk posed by a specific insider threat, this is in general not possible. This limitation is caused partly by the lack of models for human behaviour, partly by restrictions on how much and what may be monitored, and by our inability to identify relevant features in large amounts of logged data. To overcome this, the notion of insiderness has been proposed, which measures the degree of access an actor has to a certain resource. We extend this notion with the concept of impact of an insider, and present different realisations of impact. The suggested approach results in readily usable techniques that allow to get a quick overview of potential insider threats based on locations and assets reachable by employees. We present several variations ranging from pure reachability to potential damage to assets causable by an insider.","Investigation of an agent-based modeling on crowd evacuation and its application to real buildingsAn agent-based modeling and the simulator for evacuation from multistory buildings at the time of outbreak of an earthquake and the fire are presented. The basic theory is that individual agents move in each floor and stair, unless it is filled to capacity per unit area. The simulator can reflect the situation when some destruction occurred in a passage and the stairs in the middle of refuge, because the capacity can be changed dynamically every place. Each agent moves in principle based on local information around oneself. However, as for the cases that the inside of stairs has been clogged up, wide area information equivalent to the broadcast in the hall is conveyed to agents after pre-determined time. Comparative study with the real measurement and simulation was carried out about the refuge time of the fire drill that was performed in a university building of 12 stories.","Point Cloud Segmentation and Denoising via Constrained Nonlinear Least Squares Normal EstimatesWe first introduce a surface normal estimation procedure for point clouds capable of handling geometric singularities in the data, such as edges and corners. Our formulation is based on recasting the popular Principal Component Analysis (PCA) method as a constrained nonlinear least squares (NLSQ) problem. In contrast to traditional PCA, the new formulation assigns appropriate weights to neighboring points automatically during the optimization process in order to minimize the contributions of points located across singularities. We extend this strategy to point cloud denoising by combining normal estimation, point projection, and declustering into one NLSQ formulation. Finally, we propose a point cloud segmentation technique based on surface normal estimates and local point connectivity. In addition to producing consistently oriented surface normals, the process segments the point cloud into disconnected components that can each be segmented further into piecewise smooth components as needed.","Kernel Fuzzy Similarity Measure-Based Spectral Clustering for Image SegmentationSpectral clustering has been successfully used in the field of pattern recognition and image processing. The efficiency of spectral clustering, however, depends heavily on the similarity measure adopted. A widely used similarity mea- sure is the Gaussian kernel function where Euclidean distance is used. Unfor- tunately, the Gaussian kernel function is parameter sensitive and the Euclidean distance is usually not suitable to the complex distribution data. In this paper, a novel similarity measure called kernel fuzzy similarity measure is proposed first, Then this novel measure is integrated into spectral clustering to get a new cluster- ing method: kernel fuzzy similarity based spectral clustering (KFSC). To alleviate the computational complexity of KFSC on image segmentation, Nystrm method is used in KFSC. At last, the experiments on three synthetic texture images are made, and the results demonstrate the effectiveness of the proposed algorithm.","Achieving Flexible Process Interoperability in the Homecare Domain through Aspect-Oriented Service CompositionIn elderly care the shortage of available financial and human resources for coping with an increasing number of elderly people becomes critical. Current solutions to this problem focus on efficiency gains through the usage of information systems and include homecare services provided by IT systems. However, the current IT systems that integrate homecare services have difficulties in handling the user-context dynamicity and the diversity of needs and preferences of care-receivers. This makes the available homecare services hardly interoperable at the process level, particularly due to the lack of support for process flexibility. In this paper, we present an approach capable of dealing with such interoperability issues based on aspect-oriented service composition. We demonstrate the feasibility of our approach and of the proposed architecture by implementing a prototype for a reminder service scenario.","Particle Swarm Optimization-Based Distributed Control Scheme for Flocking Robots ","An Approach to Test Set Generation for Pair-Wise Testing Using Genetic AlgorithmsInstead of performing exhaustive testing that tests all possible combinations of input parameter values of a system, it is better to switch to a more efficient and effective testing technique i.e., pair wise testing. In pair wise testing, test cases are designed to cover all possible combinations of each pair of input parameter values. It has been shown that the problem of finding the minimum set of test cases for pair-wise testing is an NP complete problem. In this paper we apply genetic algorithm, a meta heuristic search algorithm, to find an optimal solution to the pair-wise test set generation problem. We present a method to generate initial population using hamming distance and an algorithm to find crossover points for combining individuals selected for reproduction. We describe the implementation of the proposed approach by extending an open source tool PWiseGen and evaluate the effectiveness of the proposed approach. Empirical results indicate that our approach can generate test sets with higher fitness level by covering more pairs of input parameter values.","Linking and visualizing television heritage: the EUscreen virtual exhibitions and the linked open data pilotThe EUscreen initiative represents the European television archives and acts as a domain aggregator for Europeana, Europe's digital library, which provides access to over 20 million digitized cultural objects. The main motivation for the initiative is to provide unified access to a representative collection of television programs, secondary sources and articles, and in this way to allow students, scholars and the general public to study the history of television in its wider context. This paper explores the EUscreen activities related to novel ways to present curated content and publishing EUscreen metadata as Linked Open Data.","Gamification: when it works, when it doesn'tThe concept of using game mechanics to attract and retain customers in the consumer space is now well accepted. However, the use of gamification in the enterprise space is still catching on. There are a number of reasons to believe that acceptance of gamification will grow in the enterprise space. The most likely reason is that companies are increasingly concerned about the effect of employee engagement on productivity. But, there are circumstances where gamification can be successful and circumstances where gamification can fail.","Situating Asynchronous Voice in Rural AfricaDesigning for oral users in economically poor places has intensified efforts to develop platforms for asynchronous voice. Often these aim to assist users in rural areas where literacy is lowest, but there are few empirical studies and design tends to be oriented by theory that contrasts the mental functions of oral and literate users, rather than by local practices in social situations. We de- scribe designing an Audio Repository (AR) based on practices, priorities and phone-use in rural Africa. The AR enables users to record, store and share voice files on a shared tablet and via their own cell-phones. We deployed the AR for 10 months in rural Africa and illiterate elders, who have few ways to use free or low-cost phone services, used it to record meetings. Use of, and interactions with, the AR informed the design of a new prototype. They also sensitized us to qualities of collective sense-making that can inspire new interactions but that guidelines for oral users overlook; such as the fusion of meaning and sound and the tuning of speech and bodily movement. Thus, we claim that situating design in local ways of saying enriches the potential for asynchronous voice.","Moneyball for nanoHUB: theory-driven and data-driven approaches to understand the formation and success of software development teamsThe same principle that transformed baseball may hold the key to building more innovative scientific teams. In 2002, Billy Beane changed baseball when he fielded a $41 million baseball team for the Oakland Athletics that successfully competed with the $125 million New York Yankees. We increasingly turn to teams to solve wicked scientific problems from sequencing the human genome to curing cancer. Building scientific dream teams who produce breakthrough innovations at minimal cost is not unlike choosing the players who will go on to win the World Series. Like pre-Beane baseball, much of the selection of scientific dream teams currently rests on an assessment of the caliber of the individual scientists, with far less attention paid to the relationships that gel the team together, and the factors that determine how those pivotal relationships come about.","Towards live synthetic populations for large-scale realistic multiagent simulationsSynthetic populations attempt to capture population dynamics of a geographic region and hence are widely used in large-scale multiagent applications simulating real-world phenomena. However, current synthetic populations are mostly static - individuals are assumed to perform same daily routine every day. My thesis aims at taking the first step towards making it a \"live\" synthetic population that would update automatically to reflect changes in the real population, by incorporating information from social media and other online data resources. As an initial step, I have extended synthetic population model for Washington DC metro area to include transient (tourists and business travelers) population. This is done by combining data from various online and offline data resources by hand. This subpopulation which keeps changing with time, has also shown to have an important effect on disease dynamics of the city. Next, I propose to use information from social media to improve activity patterns of individuals using hidden semi-Markov model.","Norms in Distributed OrganizationsDue to external requirements we cannot always construct a centralized organization, but have to construct one that is distributed. A distributed organization is a network of organizations which can locally observe and control the environment. In this paper we analyze how norms can be enforced through the joint effort of the individual local organizations. Norm violations are detected by monitoring. Sanctioning compensates the violations of norms. The main problem is to map the required data for monitoring, and the required control capabilities for sanctioning, to the local observe/control capabilities of organizations. Our investigation focuses on exploring the solution space of this problem, the properties of proper solutions and practical considerations when developing a solution.","Patterns for Business Process Improvement: A First Approach ","The Learning Effect of Students\u2019 Cognitive Styles in Using Cloud Technology ","AOF-Based Algorithm for Dynamic Multi-Objective Distributed Constraint OptimizationMany real world problems involve multiple criteria that should be considered separately and optimized simultaneously. A Multi-Objective Distributed Constraint Optimization Problem MO-DCOP is the extension of a mono-objective Distributed Constraint Optimization Problem DCOP. A DCOP is a fundamental problem that can formalize various applications related to multi-agent cooperation. This problem consists of a set of agents, each of which needs to decide the value assignment of its variables so that the sum of the resulting rewards is maximized. An MO-DCOP is a DCOP which involves multiple criteria. Most researches have focused on developing algorithms for solving static problems. However, many real world problems are dynamic. In this paper, we focus on a change of criteria/objectives and model a Dynamic MO-DCOP DMO-DCOP which is defined by a sequence of static MO-DCOPs. Furthermore, we develop a novel algorithm for DMO-DCOPs. The characteristics of this algorithm are as follows: i it is a reused algorithm which finds Pareto optimal solutions for all MO-DCOPs in a sequence using the information of previous solutions, ii it utilizes the Aggregate Objective Function AOF technique which is the widely used classical method to find Pareto optimal solutions, and iii the complexity of this algorithm is determined by the induced width of problem instances.","Dynamic Scheduling for Usable Service in Network RobotNetwork robots can provide a variety of services to users of network. Existing service robots not only have been developed for specific purpose with constraint capabilities, but have only focused on how to perform their service efficiently. In order to improve the usefulness of the networked service robot, however, it is necessary to provide services considering the user's needs and service context change. This paper proposes a dynamic service scheduling scheme to provide effective services to multiple users for network robots. The proposed scheme is adaptable to dynamic changes of service type, environment and users by customizing the scheduling policy with both system-centric and user-centric properties in real time. The experimental results show that the proposed scheme enhances the user satisfaction and performance of the robot service compared to other scheduling schemes.","Many weak keys for PRINTCIPHER: fast key recovery and countermeasuresIn this paper we investigate the invariant property of PRINTcipher first discovered by Leander et al. in their CRYPTO 2011 paper. We provide a complete study and show that there exist 64 families of weak keys for PRINTcipher---48 and as many as 115,669 for PRINTcipher---96. Moreover, we show that searching the weak key space may be substantially sped up by splitting the search into two consecutive steps. We show that for many classes of weak keys, key recovery can be done with very small time complexity in the chosen/known plaintext scenario. This shows that the cipher is actually much more vulnerable to this type of attacks than was even thought previously. Still, effective countermeasures exist against the attack. The method of finding all weak key families has value on its own. It is based on Mixed Linear Integer Programming and can be adapted to solving other interesting problems on similar ciphers.","Efficiently solving joint activity based security gamesDespite recent successful real-world deployments of Stackelberg Security Games (SSGs), scale-up remains a fundamental challenge in this field. The latest techniques do not scale-up to domains where multiple defenders must coordinate time-dependent joint activities. To address this challenge, this paper presents two branch-and-price algorithms for solving SSGs, SMARTO and SMARTH, with three novel features: (i) a column-generation approach that uses an ordered network of nodes (determined by solving the traveling salesman problem) to generate individual defender strategies; (ii) exploitation of iterative reward shaping of multiple coordinating defender units to generate coordinated strategies; (iii) generation of tighter upper-bounds for pruning by solving security games that only abide by key scheduling constraints. We provide extensive experimental results and formal analyses.","Socially Enabled Preference Learning from Implicit Feedback DataIn the age of information overload, collaborative filtering and recommender systems have become essential tools for content discovery. The advent of online social networks has added another approach to recommendation whereby the social network itself is used as a source for recommendations i.e. users are recommended items that are preferred by their friends.#R##N##R##N#In this paper we develop a new model-based recommendation method that merges collaborative and social approaches and utilizes implicit feedback and the social graph data. Employing factor models, we represent each user profile as a mixture of his own and his friends' profiles. This assumes and exploits \"homophily\" in the social network, a phenomenon that has been studied in the social sciences. We test our model on the Epinions data and on the Tuenti Places Recommendation data, a large-scale industry dataset, where it outperforms several state-of-the-art methods.","What Do You See in the Cloud? Understanding the Cloud-Based User Experience through Practices ","Mining User Interests from Information Sharing Behaviors in Social Media ","A constructive neural network to predict pitting corrosion status of stainless steelThe main consequences of corrosion are the costs derived from both the maintenance tasks as from the public safety protection. In this sense, artificial intelligence models are used to determine pitting corrosion behaviour of stainless steel. This work presents the C-MANTEC constructive neural network algorithm as an automatic system to determine the status pitting corrosion of that alloy. Several classification techniques are compared with our proposal: Linear Discriminant Analysis, k-Nearest Neighbor, Multilayer Perceptron, Support Vector Machines and Naive Bayes. The results obtained show the robustness and higher performance of the C-MANTEC algorithm in comparison to the other artificial intelligence models, corroborating the utility of the constructive neural networks paradigm in the modelling pitting corrosion problem.","Annotating real-world objects using semantic entitiesDue to protocols such as 6LoWPAN and CoAP, wireless sensor nodes have become an integral part of the Internet. While this makes their data available on the Internet, it still remains a strictly devicecentric approach. However, one is usually interested in the phenomena observed by one or more devices and not in the sensors themselves. To bridge this gap, we introduce and evaluate the concept of Service-Level Semantic Entities (SLSE). They support the automatic semantic annotation of real-world objects based on networked sensor devices. SLSE continuously collect observations of sensors attached to some objects, and aggregates them to descriptions of the objects themselves. It then makes this augmented object data available as (semantic) linked data. This removes several layers of indirection in the semantic data, and allows to directly access properties of real-world objects.","Combined Bayesian Classifiers Applied to Spam Filtering ProblemThis paper focuses on the problem of designing effective spam filters using combined Naive Bayes classifiers. Firstly, we describe different tokenization methods which allow us for extracting valuable features from the e-mails. The methods are used to create training sets for individual Bayesian classifiers, because different methods of feature extraction ensure the desirable diversity of classifier ensemble. Because of the lack of an adequate analytical methods of ensemble evaluation the most valuable and diverse committees are chosen on the basis of com- puter experiments which are carried out on the basis of our own spam dataset. Then the number of well known fusion methods using class labels and class supports are compared to establish the final proposition.","Blending Evidence and Users for TEL: An OvertureTERENCE is an adaptive learning system for reasoning about stories with children having deep text comprehension problems. It develops reading interventions in the form of smart games for stimulating the text comprehension of such children. In order to ensure the pedagogical effectiveness and the usability of the smart games, and of the system in general, TERENCE was designed combining the user centred and the evidence based design. In this paper, we illustrate how such methodologies were used in the design of the TERENCE smart games.","L2 syntax acquisition: the effect of oral and written computer assisted practice ","A Nonconforming Characteristic Finite Element Method for Nonlinear Advection-Dominated Diffusion Equation with Memory TermA nonconforming characteristic finite element method is considered for nonlinear convection-dominated diffusion equation with memory term. By the use of some special properties of the finite element interpolation operator, and without Rietz-Volterra projection operator which is an indispensable tool in the conver- gence analysis of finite element methods for integro-differential evolution equa- tions in the previous literature, the optimal error estimate on L 2 -norm and the superconvergence result on H 1 -norm are obtained.","A Conditional Superpolynomial Lower Bound for Extended Resolution ","Stochastic Simultaneous Optimistic OptimizationWe study the problem of global maximization of a function f given a finite number of evaluations perturbed by noise. We consider a very weak assumption on the function, namely that it is locally smooth (in some precise sense) with respect to some semi-metric, around one of its global maxima. Compared to previous works on bandits in general spaces (Kleinberg et al., 2008; Bubeck et al., 2011a) our algorithm does not require the knowledge of this semi-metric. Our algorithm, StoSOO, follows an optimistic strategy to iteratively construct upper confidence bounds over the hierarchical partitions of the function domain to decide which point to sample next. A finite-time analysis of StoSOO shows that it performs almost as well as the best specifically-tuned algorithms even though the local smoothness of the function is not known.","(2q+1)-arcs in PG(3, q 3 ) stabilized by a Sylow p-subgroup of PSL(2, p).Abstract   We construct arcs   K   of cardinality   2  q  +  1   in the projective space   P  G  (  3  ,    q    3    )  ,   q  =    p    h    ,   p  &gt;  3   prime, from a cubic curve   C  . By construction,   K   is stabilized by a Sylow  p -subgroup of the projectivities preserving   C   and it is contained in no twisted cubic of   P  G  (  3  ,    q    3    )  .","Using Range and Bearing Observation in Stereo-Based EKF SLAMIn this work, we have developed a new observation model for a stereo-based simultaneous localization and mapping (SLAM) system within the standard Extended-Kalman filter (EKF) framework. The observation model was derived by using the inverse depth parameterization as the landmark model, and contributes to both bearing and range information into the EKF estimation. In this way the inherently non-linear problem cause by the camera projection equations is resolved and real depth uncertainty distribution of landmarks features can be accurately estimated. The system was tested by real- world large-scale outdoor data. Analysis results show that the landmark feature depth estimation is more stable and the uncertainty noise converges faster than the binocular stereo-based approach. We also found minor drift in the vehicle pose estimation even after extended periods demonstrating the effectiveness of the new model.","Adverse Driving Conditions Alert: Investigations on the SWIR Bandwidth for Road Status MonitoringThe 2WIDE SENSE (WIDE spectral band &amp; WIDE dynamics multi- functional imaging SENSor Enabling safer car transportation) EU funded project is aimed at the development of a low-cost camera sensor for automotive applica- tions able to acquire the full visible to Short Wave InfraRed (SWIR) spectrum, from 400 to 1700 nm. This paper presents the results obtained using this extended spectral respon- sivity sensor for a Road Status Monitoring application to inspect the vehicle's frontal area and detect layers of ice or water on the road surface.","Vector Generation and Operations in Neural Networks Computations ","Extending the Groovy Language Using AST Transformations to Monitor Variables and Methods ","Physician's Perceived EMR-Communication Fit: Towards Developing A Measurement Instrument ","Architecture and Implementation of a Decision Support System for Software Industry Business Models ","Visual Novels: An Methodology Guideline for Pervasive Educational Games that Favors Discernment ","Narratives in the History of Computing: Constructing the Information Age Gallery at the Science MuseumOne of the challenges of exhibiting the complex, and mostly intangible, world of computing in a museum context is how you bring together the technology with the people involved and the information shared. The history of computing is not just a neat history of devices. Analogue, digital, mini, personal and supercomputers all reflect the material culture of information and communication technologies, but the story of information machines is a much more complex story of the interrelationship between networks of people, societal and cultural influences. This paper reflects on approaches to the display of the history of computing and suggests that a shift to narrative and users, rather than chronology and technological progress, invites a more engaging experience for the majority of visitors. It also suggests that there is an inherent value in the display of computing artefacts that goes far beyond that of working machines. Some machines can work on a profound level, not just a utilitarian one. The paper discusses the approach taken in the Science Museum\u2019s Information Age gallery, opening in September 2014.","Real Time Object Tracking: Simulation and Implementation on FPGA Based Soft Processor ","A Collaborative Document Ranking Model for a Multi-faceted SearchThis paper presents a novel collaborative document ranking model which aims at solving a complex information retrieval task involving a multi-faceted information need. For this purpose, we consider a group of users, viewed as experts, who collaborate by addressing the different query facets. We propose a two-step algorithm based on a relevance feedback process which first performs a document scoring towards each expert and then allocates documents to the most suitable experts using the Expectation-Maximisation learning-method. The performance improvement is demonstrated through experiments using TREC interactive benchmark.","Robo-Teacher: A Computational Simulation Based Educational System to Improve Cyber Security ","Event Relationship Analysis for Temporal Event SearchThere are many news articles about events reported on the Web daily, and people are getting more and more used to reading news articles online to know and understand what events happened. For an event, (which may consist of several component events, i.e., episodes), people are often interested in the whole picture of its evolution and development along a time line. This calls for model- ing the dependent relationships between component events. Further, people may also be interested in component events which play important roles in the event evolution or development. To satisfy the user needs in finding and understand- ing the whole picture of an event effectively and efficiently, we formalize in this paper the problem of temporal event search and propose a framework of event relationship analysis for search events based on user queries. We define three kinds of event relationships which are temporal relationship, content dependence relationship, and event reference relationship for identifying to what an extent a component event is dependent on another component event in the evolution of a target event (i.e., query event). Experiments conducted on a real data set show that our method outperforms a number of baseline methods.","Elastic Remote MethodsFor distributed applications to take full advantage of cloud computing systems, we need middleware systems that allow developers to build elasticity management components right into the applications. This paper describes the design and implementation of ElasticRMI, a middleware system that (1) enables application developers to dynam- ically change the number of (server) objects available to handle remote method invocations with respect to the application's workload, without requiring major changes to clients (invokers) of remote methods, (2) en- ables flexible elastic scaling by allowing developers to use a combination of resource utilization metrics and fine-grained application-specific in- formation like the properties of internal data structures to drive scaling decisions, (3) provides a high-level programming framework that handles elasticity at the level of classes and objects, masking low-level platform specific tasks (like provisioning VM images) from the developer, and (4) increases the portability of ElasticRMI applications across different pri- vate data centers/IaaS clouds through Apache Mesos (5).","The Chinese Word-Form Transformation Related to the Development of Visual Behavior CategoriesThe cognitive development of visual behavior categories has been proceeding from the simple to the complex and from the concrete to the ab- stract. Reflected on the language level, it has caused the word form transfor- mations of visual verbs in Chinese. The transformation includes the creation of compound characters and compound words. In Old Chinese, producing new compound characters based on (mu)(eye) is the best way to reflect the complication of visual behavior categories. The rich visual characters and their explanations in Shuo Wen Jie Zi show that the ancient ancestors' cogni- tive maturity of visual behavior categories is high. The main way to record the development of visual behavior categories is generating new compound words. Through studying the internal structures, semantic relationships be- tween morphemes and significant features of 153 compound verbs related (kan)(look), we found that the word-formation abilities of those core mor- phemes are unequal because they have different stylistic features. And the compound verbs sharing one visual morpheme have the same significant fea- tures which could be used to distinguish the synonyms in the visual verb group.","Systematic Integration of Solution Elements: How Does Digital Creativity Support Change Group Dynamics? ","Error Annotation of the Arabic Learner Corpus - A New Error Tagset.This paper introduces a new two-level error tagset, AALETA (Alfaifi Atwell Leeds Error Tagset for Arabic), to be used for annotating the Arabic Learner Corpora (ALC). The new tagset includes six broad classes, subdivided into 37 more specific error types or subcategories. It is easily understood by Arabic corpus error annotators. AALEETA is based on an existing error tagset for Arabic corpora, ARIDA, created by Abuhakema et al. [1], and a number of other error-analysis studies. It was used to annotate texts of the Arabic Learner Corpus [2]. The paper shows the tagset broad classes and types or subcategories and an example of annotation. The understandability of AALETA was measured against that of ARIDA, and the preliminary results showed that AALETA achieved a slightly higher score. Annotators reported that they preferred using AALETA over ARIDA.","IT Project Management Practices in Very Small Software Companies : A Case of Pakistan. ","Associative Model for the Forecasting of Time Series Based on the Gamma ClassifierInstitutoPolit\u00b4ecnicoNacional,CentrodeInvestigaci\u00b4onenComputaci\u00b4on(CIC-IPN),Av.JuandeDiosB\u00b4atizs/nEdi\ufb01cioCIC,MexicoCity,Mexicocyanez@cic.ipn.mxAbstract. The paperdescribes a novel associative model for the fore-casting of time series in petroleum engineering. The model is based onthe Gamma classi\ufb01er, which is inspired on the Alpha-Beta associativememories, taking thealphaand betaoperators as basis for thegammaoperator.Theobjectiveistoreproduceandpredictfutureoilproductionindi\ufb00erentscenariosinanadjustabletimewindow.Thedistinctivefea-turesoftheexperimentaldatasetarespikes,abruptchangesandfrequentdiscontinuities, which considerably decrease theprecision of traditionalforecasting methods. Asexperimentalresults show, thisclassi\ufb01er-basedpredictorexhibitscompetitiveperformance.Theadvantagesandlimita-tionsofthemodel,aswellaslinesofimprovement,arediscussed.Keywords: Time series forcasting, associative models, oil productiontimeseries,Gammaclassi\ufb01er.","Tower of babel: a crowdsourcing game building sentiment lexicons for resource-scarce languagesWith the growing amount of textual data produced by online social media today, the demands for sentiment analysis are also rapidly increasing; and, this is true for worldwide. However, non-English languages often lack sentiment lexicons, a core resource in performing sentiment analysis. Our solution,  Tower of Babel (ToB) , is a language-independent sentiment-lexicon-generating crowdsourcing game. We conducted an experiment with 135 participants to explore the difference between our solution and a conventional manual annotation method. We evaluated ToB in terms of effectiveness, efficiency, and satisfactions. Based on the result of the evaluation, we conclude that sentiment classification via ToB is accurate, productive and enjoyable.","Preorders on monads and coalgebraic simulationsWe study the construction of preorders on Set-monads by the semantic \u22a4\u22a4-lifting. We show the universal property of this construction, and characterise the class of preorders on a monad as a limit of a Cardop-chain. We apply these theoretical results to identifying preorders on some concrete monads, including the powerset monad, maybe monad, and their composite monad. We also relate the construction of preorders and coalgebraic formulation of simulations.","Accelerating Topic Model Training on a Single Machine ","AnonyFacebook - Liking Facebook Posts AnonymouslyIn several countries the simple act of liking (on Facebook) an anti-government article or video can be (and has already been) used to pursue and detain activists. Given such a scenario, it is of great relevance to allow anyone to anonymously \"like\" any post. In this paper we present anonyFacebook, a system that allows Face- book users to \"like\" a post (e.g., news, photo, video) without revealing their identity (even to the social network administrators). Obviously, such anonymous \"likes\" count to the total number of \"likes\". Anony- mous \"likes\" are ensured by means of cryptographic techniques such as homomorphic encryption and shared threshold key pairs.","Increasing Students\u2019 Vocabulary Size Through the Use of Latent Semantic Analysis in a Mobile Learning Environment ","Testing M2T/T2M TransformationsTesting model-to-model M2M transformations is becoming a prominent topic in the current Model-driven Engineering landscape. Current approaches for transformation testing, however, assume having explicit model representations for the input domain and for the output domain of the transformation. This excludes other important transformation kinds, such as model-to-text M2T and text-to-model T2M transformations, from being properly tested since adequate model representations are missing either for the input domain or for the output domain. The contribution of this paper to overcome this gap is extending Tracts, a M2M transformation testing approach, for M2T/T2M transformation testing. The main mechanism we employ for reusing Tracts is to represent text within a generic metamodel. By this, we transform the M2T/T2M transformation specification problems into equivalent M2M transformation specification problems. We demonstrate the applicability of the approach by two examples and present how the approach is implemented for the Eclipse Modeling Framework EMF. Finally, we apply the approach to evaluate code generation capabilities of several existing UML tools.","Holistic Processing Is Not Always a Property of Right Hemisphere Processing- Evidence from Computational Modeling of Face Recognition ","Scheme for Assigning Security Automatically for Real-Time Wireless Nodes via ARSASecurity and ease of use are two fundamental requirements of wireless network users. But they conflict with each other. The strongly secure network will put a lot of load on the server for security related work which may hamper the packet delivery ratio. But strong security is indispensable for maintaining the confidentiality of information in current real-time wireless communication networks. This research work combines both, the concepts of network security and the packet scheduling issues of the wireless data packets. Most of the users using wireless network are unaware about what level of security is needed for them. We present a new Automated Security-Aware Packet Scheduling Strategy or ASPS for real-time wireless network. This ASPS algorithm assigns the desirable level of security automatically to the respective data packets with guarantee of deadlines for the packets. Our simulation result proves that our proposal is performing better than existing algorithms in terms of the quality of security, guarantee ratio and reducing the load on the network switch.","Editorial: Transport scheduling: Meeting the challenges of scale, complexity and uncertainty ","Transfer Learning Using Twitter Data for Improving Sentiment Classification of Turkish Political News ","Assisting Lifestyles: \u201cLaughing, Living and Learning\u201dThis paper reports on practices of a senior community based on the findings from three participatory observation sessions, a short survey and wrap-up interviews. Our findings suggest that both the lifestyle of individuals and the constraints of the specific community settings play a role for designing for senior communities. We introduce our insights from our studies on the setting, the artifacts used in the sessions and on senior individuals. Further we introduce our initial design ideas and discuss their relations to the presented design space.","On the Relationship between the Different Methods to Address Privacy Issues in the CloudIn conjunction with regulation, information security technology is expected to play a critical role in enforcing the right for privacy and data pro- tection. The role of security in privacy by design is discussed in this paper, as well as the relationship of these to accountability. The focus within these dis- cussions is on technological methods to support privacy and data protection in cloud scenarios.","Aged people's emotion elicited by touching materials of armrestsA chair with armrests is an important object required by aged people for sitting, when their physical strength decline gradually. Users' emotions can be evoked by touching material of the armrest. This study attempts to explore aged people's emotional responses as evoked by interaction with materials on armrests. An experiment was conducted to explore emotional responses evoked by touching six different materials of a armrest between aged people and young adults. The results indicate that a chair's armrests made from fabric can enhance users' pleasure senses better, as compared with the other five materials. The result also showed that aged people were willing to give a higher mean score on pleasure than young adults were.","Border-sensitive learning in kernelized learning vector quantizationPrototype based classification approaches are powerful classifiers for class discrimination of vectorial data. Famous examples are learning vector quantization models (LVQ) and support vector machines (SVMs). In this paper we propose the application of kernel distances in LVQ such that the LVQ-algorithm can handle the data in a topologically equivalent data space compared to the feature mapping space in SVMs. Further, we provide strategies to force the LVQ-prototypes to be class border sensitive. In this way an alternative to SVMs based on Hebbian learning is established. After presenting the theoretical background, we demonstrate the abilities of the model for an illustrative toy example and for the more challenging task of classification of Wilson's disease patients according to their neurophysiological impairments.","A Heuristic Approach to Handling Sequential Information in Incremental ILPWhen using Horn Clause Logic as a representation formalism, the use of uninterpreted predicates cannot fully account for the complexity of some domains. In particular, in Machine Learning frameworks based on Horn Clause Logic, purely syntactic generalization cannot be applied to these kinds of predicates, requiring specific problems to be addressed and tailored strategies and techniques to be introduced. Among others, outstanding examples are those of numeric, taxonomic or sequential information. This paper deals with the case of (multidimensional) sequential information.Coverage and generalization techniques are devised and presented, and their integration in an incremental ILP system is used to run experiments showing its performance.","Dynamic Attitudes, Fixed Points and Minimal ChangeAccording to the principle of minimal change, an agent should not change her belief state more than is strictly required to accomodate new information. We propose a novel approach to the issue by considering a notion of optimality of belief revision policies that is sensitive to the target of revision.","A sparse coding based transfer learning framework for pedestrian detectionPedestrian detection is a fundamental problem in video surveillance and has achieved great progress in recent years. However, training a generic de- tector performing well in a great variety of scenes has been approved to be very difficult. On the other hand, exhausting manual labeling effort for each specific scene to achieve high accuracy of detection is not acceptable especially for vid- eo surveillance applications. In order to alleviate the manual labeling effort without scarifying accuracy of detection, we propose a transfer learning frame- work to automatically train a scene-specific pedestrian detector starting from a pre-trained generic detector. In our framework, sparse coding is proposed to calculate similarities between source samples and a small set of selected target samples by using the former as dictionary. The similarities are later used to cal- culate weights of source samples. The weights of initially detected target samples are calculated in a similar way but using the selected target dataset as dictionary. By using these weighted samples during re-training process, our framework can efficiently get a scene-specific pedestrian detector. Our experi- ments on VIRAT dataset show that our trained scene-specific pedestrian detec- tor performs well and it is comparable with the detector trained on a large number of training samples manually labeled from the target scene.","On Popular Random AssignmentsOne of the most fundamental and ubiquitous problems in mi- croeconomics and operations research is how to assign objects to agents based on their individual preferences. An assignment is called popular if there is no other assignment that is preferred by a majority of the agents. Popular assignments need not exist, but the minimax theorem implies the existence of a popular random assignment. In this paper, we study the compatibility of popularity with other properties that have been con- sidered in the literature on random assignments, namely efficiency, equal treatment of equals, envy-freeness, and strategyproofness.","Active Credential Leakage for Observing Web-Based Attack CycleA user who accesses a compromised website is usually redirected to an adversary's website and forced to download malware. Additionally, the adversary steals the user's credentials by using information-stealing malware. Furthermore, the adversary may try to compromise public websites owned by individual users by impersonating the website administrator using the stolen credential. These compromised websites then become landing sites for drive-by download malware infection. Identifying malicious websites using crawling techniques requires large resources and takes a lot of time. To observe web-based attack cycles to achieve effective detection and prevention, we propose a novel observation system based on a honeytoken that actively leaks credentials and lures adversaries to a decoy that behaves like a compromised web content management system. The proposed procedure involves collecting malware, leaking credentials, observing access by an adversary, and inspecting the compromised web content. It can instantly discover malicious entities without conducting large-scale web crawling because of the direct observation on the compromised web content management system. Our system enables continuous and stable observation for about one year. In addition, almost all the malicious websites we discovered had not been previously registered in public blacklists.","Fault Tolerant Range Grouping Routing in Dynamic NetworksA characteristic feature of dynamic networks is the notion of failure. A failure can be a partial failure (as in distributed systems) or total failure. A partial failure may happen when one component in a system fails. This failure may affect the proper operation of other components, while at the same time leaving yet other components totally unaffected. In contrast, a failure in any system is often total in the sense that it affects all components, and may easily bring down the entire system. Hence, it becomes important to design a system which can work even if (partial) failures occur. This paper proposes various approaches which help in making the designed system fault tolerant. Mainly the routing mechanism is focused upon with the help of the concept of acknowledgment and negative acknowledgment.","Corporate Sponsorship of Academic Research: The Trend, Its Drivers, and Its Implications ","A Framework for the Pre-clinical Validation of LBM-EP for the Planning and Guidance of Ventricular Tachycardia AblationThis manuscript presents a framework for the pre-clinical validation of LBM-EP, a fast cardiac electrophysiology model based on the lattice-Boltzmann method LBM. The overarching goal is to assess whether the model is able to predict ventricular tachycardia VT induction given lead location and stimulation protocol. First, the random-walk algorithm is used to interactively segment the heart ventricles from delayed-enhancement magnetic resonance images DE-MRI. Scar and border zone are visually delineated using image thresholding. Then, a detailed anatomical model is generated, comprising fiber architecture and spatial distribution of action potential duration. That information is rasterized to a Cartesian grid, and the cardiac potentials are computed. The framework is illustrated on one swine data, for which two different pacing protocols at four different sites were tested. Each of the protocols were then virtually tested by computing seven seconds of heart beat. Model predictions in terms of VT induction were compared with what was observed in the animal. Our parallel implementation on graphics processing units required a total computation time of about two minutes at an isotropic grid resolution of 0.8 mm 21s at a resolution of 1.5 mm, thus enabling interactive VT testing.","Learning Throttle Valve Control Using Policy SearchThe throttle valve is a technical device used for regulating a fluid or a gas flow. Throttle valve control is a challenging task, due to its complex dynamics and demanding constraints for the controller. Using state-of-the-art throttle valve control, such as model-free PID controllers, time-consuming and manual adjusting of the controller is necessary. In this paper, we investigate how reinforcement learning (RL) can help to alleviate the effort of manual controller design by automatically learning a control policy from experiences. In order to obtain a valid control policy for the throttle valve, several constraints need to be addressed, such as no-overshoot. Furthermore, the learned controller must be able to follow given desired trajectories, while moving the valve from any start to any goal position and, thus, multi-targets policy learning needs to be considered for RL. In this study, we employ a policy search RL approach, Pilco [2], to learn a throttle valve control policy. We adapt the Pilco algorithm, while taking into account the practical requirements and constraints for the controller. For evaluation, we employ the resulting algorithm to solve several control tasks in simulation, as well as on a physical throttle valve system. The results show that policy search RL is able to learn a consistent control policy for complex, real-world systems.","Improving User Performance in Conditional Probability Problems with Computer-Generated DiagramsMany disciplines in everyday life depend on improved performance in probability problems. Most adults struggle with conditional probability problems and prior studies have shown user accuracy is less than 50%. This study examined user performance when aided with computer-generated Venn and Euler-type diagrams in a non-learning context. Following relational complexity, working memory and mental model theories, this study manipulated problem complexity in diagrams and text-only displays. Partially consistent with the study hypotheses, complex visuals outperformed complex text-only displays and simple text-only displays outperformed complex text only displays. However, a significant interaction between users' spatial ability and the use of diagram displays led to a reversal of performance for low-spatial users in one of the diagram displays. Participants with less spatial ability were significantly impaired in their ability to solve problems with less relational complexity when aided by a diagram.","Measurement of lens accommodation and convergence during the viewing of 3d imagesThree-dimensional display technology has developed rapidly in recent years. This has been accompanied by increasing problems of visual complaints such as eye strain. There are also various types of digital signage, in which text information moves on a screen. In this paper, we conducted two experiments for the purpose of easy to read, dynamic characters that pop out when viewing 3D images, and safe and comfortable 3D viewing. We conducted a survey of accommodation and convergence of viewers when they watched a movie with a television opaque projector for large outward projection of characters. We also compared the results of a survey on the readability of characters that pop out and the proportion and the perception of the amount of protrusion. We examined the maximum distance in which subjects' eyes could recognize the 3D character representations without any difficulty or discomfort. The distance of the images as they popped out from the screen as a theoretical virtual target was compared with what the subjects recognized according to each age group. There was no significant difference between the theoretical and observed values in any age groups. In a second experiment, we performed objective measurements of accommodation and convergence for 3D character representation using original instruments. We then compared the values of the measurements of the subjects with the theoretical positions of emergence. When a subject recognized a 3D character representation, the position of his or her accommodative and convergent focus was closer to the theoretical position of the virtual object that projected out from the screen. Nearly all of the subjects recognized the 3D representation at even 3.8 degrees, which was the largest parallax condition. Cognitively, almost all of the subjects viewed the positions of the objects correctly without much difficulty.","Sustainable Supply Chain Management: Improved Prioritization of Auditing Social Factors, Leveraging Up-to-Date Information Technology ","Understanding Team Dynamics with Agent-Based SimulationAgent-based simulation is increasingly used in industry to model sys- tems of interest allowing the evaluation of alternative scenarios. By this means, business managers can estimate the consequences of policy changes at low cost before implementing them in the business. However, in order to apply such models with confidence, it is necessary to validate them continuously against changing business patterns. Typically, models contain key parameters which significantly affect the overall behaviour of the system. The process of selecting such parameters is an inverse problem known as 'tuning' In this chapter, we describe the application of computational intelligence to tune the parameters of a workforce dynamics simulator. We show that the best algorithm achieves reduced tuning times as well as more accurate field workforce simulations. Since implementation, this algorithm has facilitated the use of simulation to assess the effect of changes in different business scenarios and transformation initiatives.","Constructs Replacing and Complexity Downgrading via a Generic OWL Ontology Transformation Framework ","An Adversarial Risk Analysis Model for an Autonomous Imperfect Decision AgentMachines that perform intelligent tasks interacting with humans in aseamless manner are becoming a reality. A key element in their design is their abilityto make decisions based on a reasonable val ...","HCI education in brazil: challenges and opportunitiesHCI Education in Brazil has come a long way. Since 1999, the Brazilian Computer Society (SBC) included HCI in its reference curriculum for its Computing courses. Since then, the community has discussed the perspective of the area in our country. From 2010 to this day, we have held a series of workshops on HCI Education, called WEIHC, as a permanent discussion forum within the Brazilian HCI conference, IHC. We report here the results of the WEIHC discussions and of two surveys, conducted in 2009 and in 2012, to help us assess the status of HCI Education in Brazil. Despite the advances of the Brazilian HCI community, our surveys show that we still face some important challenges. We should curate existing teaching material to further enhance collaboration among professors, to increase the quality of our courses, and to broaden HCI awareness across all related departments.","Model Checking General Linear Temporal Logic ","Supplier Value of Customer-Initiated Product Development: An In-Depth Case Study of a European Industrial Mass-Producer ","Shrinking l1 instruction caches to improve energy: delay in SMT embedded processorsInstruction caches are responsible for a high percentage of the chip energy consumption, becoming a critical issue for battery-powered embedded devices. We can potentially reduce the energy consumption of the first level instruction cache (L1-I) by decreasing its size and associativity. However, demanding applications may suffer a dramatic performance degradation, specially in superscalar multi-threaded processors, where, in each cycle, multiple threads access the L1-I to fetch instructions.#R##N##R##N#We introduce iLP-NUCA (Instruction Light Power NUCA), a new instruction cache that substitutes the conventional L2, improving the Energy-Delay of the system. iLP-NUCA adds a new tree-based transport network topology that reduces latency and energy consumption, regarding former LP-NUCA implementations.#R##N##R##N#With iLP-NUCA we reduce the size of the L1-I outperforming conventional cache hierarchies, and reducing the overall consumption, independently of the number of threads.","Drafting a Composite Indicator of Validity for Regulatory Models and Legal SystemsThe aim of this paper is to lay the groundwork for the creation of a composite indicator of the validity of regulatory systems. The composite nature of the indicator implies a that its construction is embedded in the long-standing theoretical debate and framework of legal validity; b that it formally contains other sub-indicators whose occurrence is essential to the determination of validity. The paper suggests, in other words, that validity is a second-degree property, i.e., one that occurs only once the justice, efficiency, effectiveness, and enforceability of the system have been checked.","Speed Control of A.C. Drive with Induction Motor Using Genetic Algorithm ","Learning Halfspaces Under Log-Concave Densities: Polynomial Approximations and Moment MatchingWe give the first polynomial-time algorithm for agnostically learning any function of a constant number of halfspaces with respect to any log-concave distribution (for any constant accuracy parameter). This result was not known even for the case of PAC learning the intersection of two halfspaces. We give two very different proofs of this result. The first develops a theory of polynomial approximation for log-concave measures and constructs a low-degree\u20181 polynomial approximator for sufficiently smooth functions. The second uses techniques related to the classical moment problem to obtain sandwiching polynomials. Both approaches deviate significantly from known Fourier-based methods, where essentially all previous work required the underlying distribution to have some product structure. Additionally, we show that in the smoothed-analysis setting, the above results hold with respect to distributions that have sub-exponential tails, a property satisfied by many natural and well-studied distributions in machine learning.","Gamification of Community Policing: SpamCombatThe purpose of this paper is two-fold. First, it seeks to introduce the conceptual prototype of SpamCombat, a Web application that helps combat spam through gamification of community policing. Second, it attempts to evaluate SpamCombat by identifying factors that can potentially drive users' behavioral intention to adopt. A questionnaire seeking quantitative and qualitative responses was administered to 120 participants. The results indicate that behavioral intention to adopt SpamCombat is generally promising. Most participants appreciated the novelty of SpamCombat in supporting community policing to promote a spam-free cyber space. However, participants felt that using SpamCombat could be time-consuming.","Cloud ERP Adoption-A Process View Approach ","DIGTOBI: a recommendation system for Digg articles using probabilistic modelingDigg is a social news website that lets people submit articles to share their favorite web pages (e.g. blog postings or news articles) and vote the articles posted by others. Digg service currently lists the articles in the front page by popularity without considering each user's preference to the topics in the articles. Helping users to find the most interesting Digg articles tailored to each user's own interests will be very useful, but it is not an easy task to classify the articles according to their topics in order to recommend the articles differently to each user.   In this paper, we propose DIGTOBI, a personalized recommendation system for Digg articles using a novel probabilistic modeling. Our model considers the relevant articles with low Digg scores important as well. We show that our model can handle both warm-start and cold-start scenarios seamlessly through a single model. We next propose an EM algorithm to learn the parameters of our probabilistic model. Our performance study with Digg data confirms the effectiveness of DIGTOBI compared to the traditional recommendations algorithms.","Using a Reputation Framework to Identify Community Leaders in Ontology Engineering ","Improving Scalability of an Hybrid Infrastructure for E-Science Applications ","Comparison and Evaluation of Human Locomotion Traits with Different Prosthetic Feet Using Graphical Methods from Control AreaThis study investigates joint kinematics, joint angular posi- tions, and orbital dynamic stability of human walking with different pros- thetic feet by using graphical methods of phase plane portraits, Poincare maps and Floquet multipliers, respectively. The Flex foot, SACH foot, Seattle foot and one non-specific optimized foot are taken as the research objects. Numerical experiments are performed to compare and evaluate human locomotion traits on several aspects by focusing on the concerned four kinds of prosthetic feet.","Using nonlinear dimensionality reduction to visualize classifiersNonlinear dimensionality reduction (DR) techniques offer the possibility to visually inspect a given finite high-dimensional data set in two dimensions. In this contribution, we address the problem to visualize a trained classifier on top of these projections. We investigate the suitability of popular DR techniques for this purpose and we point out the benefit of integrating auxiliary information as provided by the classifier into the pipeline based on the Fisher information.","The Influence of Information-Processing Needs on the Continuous Use of Business IntelligenceIntroduction: Many organisations implement business intelligence systems, but their long-term impact on the quality of decision making and consequently performance varies a lot. An analysis of the factors influencing the continued use of those systems is called for. We focus on the role of information processing needs on and the factors that influence those needs.Method: A longitudinal mixed method case study of a North American company was conducted. Several data collection methods were used. The researchers collaborated on developing the company\u2019s business intelligence capabilities over three years and made direct observations during this period. Internal documentation was reviewed and the current business processes were analysed. Process maps were constructed and studied and over 50 end-users were interviewed. Interviews with the company\u2019s managers, outside contractors, lodge managers and individual workers were also conducted. In addition, an online web-based survey and on-site interviews were used to gather information about room availability and guest satisfaction at the 15 lodges. In our case, room overbookings, no shows and \u201cdays to arrival\u201d were used as the main evaluation measures for success or failure of business intelligence.Analysis: Implementation of business intelligence tools leads to a high level of initial use. However, after a decrease in processing needs following changes in leadership, the levels of use significantly dropped. This also eventually led to the erosion of processing capabilities in both IT systems and organisational capabilities.Results: Business intelligence oriented needs are different than transactional or workflow needs. The latter are built into the process and system and are not optional. Business intelligence oriented needs are often optional, driven by management and personal work methods. Thus a deliberate effort is needed to ensure a permanent increase in processing needs in order to secure the long-term use and impact of business intelligence.Conclusion: While IT-enabled business intelligence can drastically enhance information-processing capabilities, they do not necessarily have the same effect on information-processing needs. We need to better understand how information processing needs will form and press the individual towards information-seeking behaviour. This will enable to not only better implement business intelligence but also to improve the likelihood of their proper use in the long run, leading to better decision-making and consequently better performance.","Learning Multicriteria Utility Functions with Random Utility ModelsIn traditional multicriteria decision analysis, decision maker evaluations or comparisons are considered to be error-free. In particular, algorithms like UTA*, ACUTA or UTA-GMS for learning utility functions to rank a set of alternatives assume that decision makers are able to provide fully reliable training data in the form of e.g. pairwise preferences. In this paper we relax this assumption by attaching a likelihood degree to each ordered pair in the training set; this likelihood degree can be interpreted as a choice probability group decision making perspective or, alternatively, as a degree of confidence about pairwise preferences single decision maker perspective. Since binary choice probabilities reflect order relations, the former can be used to train algorithms for learning utility functions. We specifically address the learning of piecewise linear additive utility functions through a logistic distribution; we conclude with examples and use-cases to illustrate the validity and relevance of our proposal.","TAIEX Forecasting Based on Fuzzy Time Series and Technical Indices Analysis of the Stock Market ","Process Aware Ultra-High-Speed Hybrid Sensing Technique for Low Power Near-Threshold SRAM ","Graph-Based Regularization of Binary Classifiers for Texture SegmentationIn this paper, we propose to improve a recent texture-based graph regularization model used to perform image segmentation by including a binary classifier in the process. Built upon two non-local image processing techniques, the addition of a classifier brings to our model the ability to weight texture features according to their relevance. The graph regularization process is then applied on the initial segmentation provided by the classifier in order to clear it from most imperfections. Results are presented on artificial and medical images, and compared to an active contour driven by classifiers segmentation algorithm, highlighting the increased generality and accuracy of our model.","Linear Time Distributed Swap Edge AlgorithmsIn this paper, we consider the all best swap edges problem in a distributed environment. We are given a 2-edge connected positively weighted network X, where all communication is routed through a rooted spanning tree T of X. If one tree edge e = {x, y} fails, the communica- tion network will be disconnected. However, since X is 2-edge connected, communication can be restored by replacing e by non-tree edge e \ufffd , called a swap edge of e, whose ends lie in different components of T \u2212 e .O f all possible swap edges of e, we would like to choose the best, as defined by the application. The all best swap edges problem is to identify the best swap edge for every tree edge, so that in case of any edge failure, the best swap edge can be activated quickly. There are solutions to this problem for a number of cases in the literature. A major concern for all these solutions is to minimize the number of messages. However, es- pecially in fault-transient environments, time is a crucial factor. In this paper we present a novel technique that addresses this problem from a time perspective; in fact, we present a distributed solution that works in linear time with respect to the height h of T for a number of different criteria, while retaining the optimal number of messages. To the best of our knowledge, all previous solutions solve the problem in O(h 2 )t ime in the cases we consider.","Data mining with ant colony algorithmsThe Ant-Miner algorithm, Ant-Miner2, Ant-Miner3 and Taco-Miner have an excellent performance in classification tasks, what can be seen in literature. These algorithms are inspired on the behavior of real ant colonies and some data mining concepts as well as principles. This paper presents a new algorithm based on Ant Colony whose experiments comparing with the others suggest superiority.","A Context-Driven Gene Prioritization Method for Web-Based Functional GenomicsFunctional genomics experiments often result in large sets of gene centered results associated with biological concepts such as dis- eases. Prioritization and interpretation of these results involves eval- uation of the relevance of genes to various annotations or associated terms and is often executed through the use of prior information in bi- ological databases. These diverse databases are frequently disconnected, or loosely federated data stores. Consequently, assessing the relations among biological entities and constructs, including genes, gene products, diseases, and model organism phenotypes is a challenging task typically requiring manual intervention, and as such only limited information is considered. Extracting and quantifying relations among genes and dis- ease related concepts can be improved through the quantification of the entire contextual similarity of gene representations among the landscape of biological data. We have devised a suitable metric for this analysis which, unlike most similar methods requires no user-defined input pa- rameters. We have demonstrated improved gene prioritization relative to existing metrics and commonly used software systems for gene prioriti- zation. Our approach is implemented as an enhancement to the flexible integrative genomics platform, GeneWeaver.org.","Knowledge Sharing, Absortive Capacity And Organizational Performance. ","Stationary Equilibrium Strategies for Bandwidth ScanningIn this paper we investigate the problem of designing a spectrum multi-step scanning strategy to detect an intelligent Invader who wants to utilize spectrum undetected for his/her unapproved purposes. To deal with this problem, we model it as a two stage game, along with specifying an algorithm of scanning the spectrum and evaluating the stationary bandwidth of spectrum to scan. The game is solved explicitly and reveal interesting properties. In particular, we have found a discontinuous dependence of the equilibrium strategies on the network parameters, fine and the Invader's intention for illegal activity, which can lead even to multi-equilibrium situation. To select a proper equilibrium strategy the best response strategy algorithm can be applied which in the multi-equilibria case always converges for a finite number of iteration, meanwhile for mono-equilibria situation it does not converge, circling around the equilibrium. Also, we have shown that the detection probability and payoffs in some situation can be very sensible to fine and the Invader's intention to intrude into the network longer, what yields that the network provider has to carefully make a value judgement of fine and estimation of the Intruder's intentions.","Ideal mode selection of a cardiac pacing systemMode transition in any inappropriate mode can be a common cause of any mishap in a complex health-care system. This paper presents an approach for formalizing and reasoning about optimal mode transition in a health-care system that uses several operating modes in various operating states. Modes are formalized and their relation to a state-based formalism is established through a refinement approach. The efficiency of this approach is presented by formalizing an ideal operating mode transition of a cardiac pacemaker case study. An incremental approach is used to develop the system and its detailed design is verified through a series of refinements. The consequence of this approach is to improve system structuring, elicitation of system assumptions and expected functionality, as well as requirement traceability using modes in state-based modeling. Models are expressed in Event B modeling language and validated by a model checker tool: ProB.","Understanding user experience and artifact development through qualitative investigation: ethnographic approach for human-centered designIn this paper, we introduce a method for utilizing qualitative investigation in the development of artifacts. In particular, we discuss ethnography principles that developers and designers need to learn in order to improve artifact quality and user experience in accordance with the principles of human-centered design (HCD). The objective of ethnographic interview in the development of artifacts is to understand users in their real environment and to build personas and scenarios based on this understanding. This objective applies to the first two steps in the HCD process, which are \"Understand and specify the context of use\" and \"Specify the user requirements.\" Furthermore, the investigative process of ethnographic research for development is outlined. While it is difficult to understand users through objective observation alone, and the fact that the knowledge that comes from interaction is also vital, the application of contextual inquiry through ethnography is a valuable tool for efficient understanding of the user in a short timeframe and with a limited number of observations.","A Fast and Low-Distortion Capacity Adaptive Synchronized Acoustic-to-Acoustic Steganography Scheme ","An associative memory based on the immune networks: perspectives on internal image with antibody dynamicsImmune memory can be regarded as an equilibrium state of immune network system with nonlinear dynamical behavior. The rapid response of immune systems to the second-time antigen is owing to the stable structure of memory state forming by a closed idiotypic immune network. Internal image of an antigen is defined while memory state is formed via such network. A dynamical system of cell population based on antibody chains and tree structure is proposed which explains how the memory state is formed in the immune network. We also propose a network dynamics model of idiotypic immune network based on cross-reactive correlation matrix to fill the gap of weaker assumption for artificial immune memory. Mathematical theory of associative memory is also explored, particularly, combining network structure and dynamical systems are some breakthrough in this paper. We realize that cyclic idiotypic immune network and dynamical systems can be a cooperative description for immune memory.","Kalman Filter and SVR Combinations in Forecasting US UnemploymentThe motivation for this paper is to investigate the efficiency of a Neural Network (NN) architecture, the Psi Sigma Network (PSN), in forecast- ing US unemployment and compare the utility of Kalman Filter and Support Vector Regression (SVR) in combining NN forecasts. An Autoregressive Mov- ing Average model (ARMA) and two different NN architectures, a Multi-Layer Perceptron (MLP) and a Recurrent Network (RNN), are used as benchmarks. The statistical performance of our models is estimated throughout the period of 1972-2012, using the last seven years for out-of-sample testing. The results show that the PSN statistically outperforms all models' individual perfor- mances. Both forecast combination approaches improve the statistical accuracy, but SVR outperforms substantially the Kalman Filter.","Product and User Dependent Social Network Models for Recommender Systems ","Best Practices for Privacy and Data Protection for the Processing of Biometric Data ","Business Model for Analysis of the University Research and Scientific Collaboration: A Case Study ","A Harmonized Process Model for Digital Forensic Investigation ReadinessDigital forensic readiness enables an organization to prepare itself to perform digital forensic investigations in an efficient and effective man- ner. The benefits include enhancing the admissibility of digital evidence, better utilization of resources and greater incident awareness. However, a harmonized process model for digital forensic readiness does not cur- rently exist and, thus, there is a lack of effective and standardized im- plementations of digital forensic readiness within organizations. This paper presents a harmonized process model for digital forensic investi- gation readiness. The proposed model is holistic in nature and properly considers readiness and investigative activities along with the interface between the two types of activities. We are living in an information society where we depend heavily on information systems and information technology. Therefore, we also depend on information systems security, specifically the confidentiality, integrity and availability of data, services and systems. These facts, com- bined with the increasing rate of information security incidents, make the field of digital forensics even more important. Methods and process models for the digital forensic investigation pro- cess (DFIP) have been developed mostly by practitioners and forensic investigators based on their expertise and experience. The initial goal was to increase the effectiveness and efficiency of investigations, not nec- essarily to achieve harmonization or standardization. The same is true for the digital forensic investigation readiness process (DFIRP). There is","Real time mono-vision based customizable virtual keyboard using finger tip speed analysisUser interfaces are a growing field of research around the world specifically for PDA's, mobile phones, tablets and other such gadgets. One of the many challenges involved are their adaptability, size, cost and ease of use. This paper presents a novel mono-vision based touch and type method on customizable keyboard drawn, printed or projected on a surface. The idea is to let the user decide the size, orientation, language as well as the position of the keys, a fully user customized keyboard. Proposed system also takes care of keyboard on uneven surfaces. Accurate results are found by the implementation of the proposed real time mono-vision based customizable virtual keyboard system. This paper uses a phenomenal idea that the finger tip intended to type must be moving fastest relative to other fingers until it does a hit on a surface.","Voting Advice Applications: Missing Value Estimation Using Matrix Factorization and Collaborative FilteringA Voting Advice Application (VAA) is a web application that recommends to a voter the party or the candidate, who replied like him/her in an online questionnaire. Every question is responding to the political positions of each party. If the voter fails to answer some ques- tions, it is likely the VAA to offer him/her the wrong candidate. There- fore, it is necessary to inspect the missing data (not answered questions) and try to estimate them. In this paper we formulate the VAA missing value problem and investigate several different approaches of collabora- tive filtering to tackle it. The evaluation of the proposed approaches was done by using the data obtained from the Cypriot presidential elections of February 2013 and the parliamentary elections in Greece in May, 2012. The corresponding datasets are made freely available to other researchers working in the areas of VAA and recommender systems through the Web.","You are who you hang out with: agents with dynamic identityThe presence of others as well as several other social context's factors have an affect on the way someone is going to perceive oneself. Whether as unique and distinctive individual, or as part of a group with shared interests among its members, the perception of group membership is going to determine if one's behaviour is going to be influenced by one's personal identity or social identity. When a social identity is salient, people tend to cooperate more with members of their group, even when the group's goals differ from their own personal goals. In this paper, we introduce Dynamic Identity Model for Agents that provides agents with an adaptive identity and behaviour that is adjustable to the social context.","A Practical Security Infrastructure for Distributed Agent Applications ","Evaluation of Intravenous Medication Errors with Smart Infusion Pumps in an Academic Medical CenterWhile some published research indicates a fairly high frequency of Intravenous (IV) medication errors associated with the use of smart infusion pumps, the generalizability of these results are uncertain. Additionally, the lack of a standardized methodology for measuring these errors is an issue. In this study we iteratively developed a web-based data collection tool to capture IV medication errors using a participatory design approach with interdisciplinary experts. Using the developed tool, a prevalence study was then conducted in an academic medical center. The results showed that the tool was easy to use and effectively captured all IV medication errors. Through the prevalence study, violation errors of hospital policy were found that could potentially place patients at risk, but no critical errors known to contribute to patient harm were noted.","STRONG: a trajectory-based verification toolbox for hybrid systemsWe present STRONG, a MATLAB toolbox for hybrid system verification. The toolbox addresses the problem of reachability/safety verification for bounded time. It simulates a finite number of trajectories and computes robust neighborhoods around their initial states such that any trajectory starting from these robust neighborhoods follows the same sequence of locations as the simulated trajectory does and avoids the unsafe set if the simulated trajectory does. Numerical simulation and computation of robust neighborhoods for linear dynamics scale well with the size of the problem. Moreover, the computation can be readily parallelized because the nominal trajectories can be simulated independently of each other. This paper showcases key features and functionalities of the toolbox using some examples.","Monitoring Networks through Multiparty Session TypesIn large-scale distributed infrastructures, applications are realised through communications among distributed components. The need for methods for assuring safe interactions in such environments is recognized, however the existing frameworks, relying on centralised verification or restricted specification methods, have limited applicability. This paper proposes a new theory of monitored \u03c0-calculus with dynamic usage of multiparty session types (MPST), offering a rigorous foundation for safety assurance of distributed components which asynchronously communicate through multiparty sessions. Our theory establishes a framework for semantically precise decentralised run-time enforcement and provides reasoning principles over monitored distributed applications, which complement existing static analysis techniques. We introduce asynchrony through the means of explicit routers and global queues, and propose novel equivalences between networks, that capture the notion of interface equivalence, i.e. equating networks offering the same services to a user. We illustrate our static-dynamic analysis system with an ATM protocol as a running example and justify our theory with results: satisfaction equivalence, local/global safety and transparency, and session fidelity.","An Open Source Monitoring Framework for Enterprise SOAWeb services monitoring is currently emerging as an effective way to trace faults in services at runtime. The lack of testing information provided by web services specifications was an indication that other methods need to be used to assess the quality of web services. This is mainly due to the fact that it is difficult to simulate the client infrastructure during testing of web services. Monitoring consists of inspecting services at runtime and taking adequate actions when unacceptable events occur. Monitoring could be performed by different stakeholders and could target different properties of services. Predominantly, monitoring is performed by service providers to manage their internal resources and balance their requests load. In our effort to improve the monitoring infrastructures, we propose a monitoring framework in which all the participants (services providers, services requestors) can contribute to monitoring and at the same time have direct access to the monitoring data. This paper describes a monitoring framework developed as part of NEXOF-RA 1 project. The framework offers a set of capabilities for a collaborative monitoring of web services. The paper presents motivations, system design, implementation and usage of the framework.","Interactive Self-Diagnostic System Using Anatomical 3D Human Body ","A Secure DS-CDMA Technique with Capacity Enhancement for Ad Hoc Wireless Networks ","Cluster Analysis Based on Pre-specified Multiple Layer Structure ","Voting with partial information: what questions to ask?Voting is a way to aggregate individual voters' preferences. Traditionally a voter's preference is represented by a total order on the set of candidates. However, sometimes one may not have complete information about a voter's preference, and in this case, can only model a voter's preference as a partial order. Given this framework, there has been work on computing the possible and necessary winners of a (partial) profile. In this paper, we take a step further, look at sets of questions to ask in order to determine the outcome of such a partial profile. Specifically, we call a set of questions a deciding set for a candidate if the outcome of the vote for the candidate is determined no matter how the questions are answered by the voters, and a possible winning (losing) set if there is a way to answer these questions to make the candidate a winner (loser) of the vote. We discuss some interesting properties about these sets of queries, prove some complexity results about them under some well-known voting rules such as plurality and Borda, and consider their application in vote elicitation.","An Investigation of Business and Management Cluster\u2019s Students\u2019 Motivation of Taking Technician Certification at Vocational High Schools in Central Taiwan ","To PLS or Not to PLS: That is the QuestionPLS is used quite widely in the MIS field, but some evidence questioning its efficacy is mounting, at least in the eyes of the \"nays\". In this panel we bring together advocates of multiple perspectives of the debate, to lay the evidence on the table and to vigorously explore the various points of view.","OFDM Transmission with Non-binary LDPC Coding in Wireless NetworksHigh-quality information exchange between upper layers of the communication network (e.g. TCP, IP layers) requires reliable connection of communicating devices on the physical layer. Any non- corrected errors at this level force the upper layers to perform proper ac- tion to recover transmitted information. It reduces data throughput and increases delay to unacceptable level for some services. Among physical media, wireless one is the most hostile environment, due to its unpre- dictable behavior. In that case, OFDM (Orthogonal Frequency Division Multiplex) modulation and LDPC (Low Density Parity Check) error cor- rection codes appear the best choice to provide high transmission qual- ity on the physical layer. This paper presents the results of the authors' simulation of a LDPC-coded OFDM system with particular emphasis on codes over high order Galois fields (non-binary) which are not commer- cialized yet.","Boosting Lexical Resources for the Semantic Web: Generative Lexicon and Lexicon Interoperability ","Time-Point specific weighting improves coexpression networks from time-course experimentsIntegrative systems biology approaches build, evaluate, and combine data from thousands of diverse experiments. These strategies rely on methods that effectively identify and summarize gene-gene relationships within individual experiments. For gene-expression datasets, the Pearson correlation is often applied to build coexpression networks because it is both easily interpretable and quick to calculate. Here we develop and evaluate weighted Pearson correlation approaches that better summarize gene expression data into coexpression networks for synchronized cell cycle time-course experiments. These methods use experimental measurements of cell cycle synchrony to estimate appropriate weights through either sliding window or linear regression approaches. We show that these weights improve our ability to build coexpression networks capable of identifying phase-specific functional relationships between genes. We evaluate our method on diverse experiments and find that both weighted strategies outperform the traditional method. This weighted correlation approach is implemented in the Sleipnir library, an open source library used for integrative systems biology. Integrative approaches using properly weighted time-course experiments will provide a more detailed understanding of the processes studied in such experiments.","Dynamics of Relative Agreement in Multiple Social ContextsIn real world scenarios, the formation of consensus is an self-organisation process by which actors have to make a joint assessment about a target subject being it a decision making problem or the formation of a collective opinion. In social simulation, models of opinion dynamics tackle the opinion formation phenomena. These models try to make an assessment, for instance, of the ideal conditions that lead an interacting group of agents to opinion consensus, polarisation or fragmentation. In this paper, we investigate the role of social relation structure in opinion dynamics using an interaction model of relative agreement. We present an agent-based model that defines social relations as multiple concomitant social networks and apply our model to an opinion dynamics model with bounded confidence. We discuss the influence of complex social network topologies where actors interact in multiple relations simultaneously. The paper builds on previous work about social space design with multiple contexts and context switching, to determine the influence of such complex social structures in a process such as opinion formation.","Spatial Anisotropic Interpolation Approach for Text Removal from an ImageWe propose a Spatial Anisotropic Interpolation SAI based, Design and Analysis of Computer Experiment DACE model for inpainting the gaps that are induced by the removal of text from images. The spatial correlation among the design data points is exploited, leading to a model which produces estimates with zero variance at all design points. Incorporating such a feature turns the model to serve as a surrogate for predicting the response at desired points where experiment is not carried out. This property has been tuned for the purpose of gap filling in images also called as Image Inpainting, while treating the pixel values as responses. The proposed methodology restores the structural as well as textural characteristics of input image. Experiments are carried out with this methodology and results are demonstrated using quality metrics such as SSIM and PSNR.","Digital Curator Vocational Education Europe: Overview of the DigCurV Project.This paper provides an overview of the EC-funded#R##N#DigCurV project, its context, methods, main finding#R##N#s, and the#R##N#project\u2019s initial framework for a digital curation#R##N#curriculum and#R##N#the Curate! game.","A Probabilistic Approach for Events Identification from Social Media RSS FeedsSocial Media RSS feeds are the most up-to-date and inclusive releases of information on current events used by the new social media sites such as Twitter and Flickr. Indeed, RSS feeds are considered as a powerful realtime means for real-world events sharing within the social Web. By identifying these events and their associated social media resources, we can greatly improve event browsing and searching. However, a thriving challenge of events identification from such releases is owed to an efficient as well as a timely identification of events. In this paper, we are mainly dealing with event identification from heterogenous social media RSS feeds. In this respect, we introduce a new approach in order to get out these events. The main thrust of the introduced approach stands in achieving a better tradeoff between event identification accuracy and swiftness. Specifically, we adopted the probabilistic Naive Bayes model within the exploitation of stemming and feature selection techniques. Carried out experiments over two real-world datasets emphasize the relevance of our proposal and open many issues.","Offers Discovery and Identifying User Requirements for Multi-commodity Trade in Open MarketsThe paper desribes a novel approach to discovery of offers in multi- commodity trade on open markets. Methods for gathering user requirements and for offer search are described. The process utilizes semantic technologies and multi- agent architecture. Examplex are shown in the domain of trading electric energy with the use of M 3 ontology.","Potential norms detection in social agent societies ","Um ambiente colaborativo para suporte ao com\u00e9rcio na universidadeEm um ambiente colaborativo, pessoas de diferentes areas e diferentes experiencias trabalham juntas para alcancar um objetivo em comum. O uso das redes sociais para divulgacao de bens e servicos tem se tornado uma ferramenta comum para usuarios compartilharem seus produtos e servicos entre sua rede de amigos e conhecidos, que divulgam as publicacoes a outros amigos, criando assim uma ampla rede de divulgacao e conhecimento. A venda de produtos em universidades e utilizada como forma de complementacao de renda, mas ocorre de forma descentralizada e dispersa entre o campus das universidades e grupos em redes sociais. Este artigo propoe o desenvolvimento de um mecanismo colaborativo, baseado nos principios de redes sociais e do desenvolvimento centrado no usuario para fornecer uma interface que garanta maior produtividade e seja acessivel a um grande numero de usuarios. Para validacao da proposta foram realizados testes com usuarios do dominio que reportaram favoravelmente a utilizacao do ambiente.","Digital Circlism as Algorithmic ArtWe present here an algorithmic solution to digital circlism, which is a contemporary rendition style in the media of digital art. The algorithmic artwork is processed within a few minutes by our algorithm, which makes it computationally attractive in comparison with its manual counterpart that requires tremendous diligence and apt craftsmanship throughout its hour-long processing. We show how the problem is mapped to circle packing in discrete space, once the segmentation is done. A greedy technique similar to the dynamic programming approach for solving the coin denomination problem is used to achieve the packing result. To aid the greedy technique, progressive Euclidean distance transform is resortedi\u00be\u017ato. Variability of the denomination set and color rendition based on mapping the original color range to Macbeth color chart add to its further appeal. Results on different kinds of images speak about further possibilities of this new style of algorithmic art.","A Game Theoretic Approach for Reliable Power Supply in Islanded DG GridsGame theory applies mathematical models in deciding interactions among people and their outcome. Mixed strategy Nash equilibrium in general exists in every game with a finite set of actions. Correlated equilibrium is a new solution concept in game theory that is more general than Nash Equilibrium and can be formulated with more accuracy on solutions. In this paper a Correlated Equilibrium based control has been extended to an Islanded Microgrid structure which depicts that scenario in smart-grids when it is isolated from the main power supply during power scarcity. The game theory based control has been shown to perform exceedingly well for the islanded scenario considering multi-agent structure. The individual agents are segregated by a superagent as potential buyers and sellers.A novel problem formulation is proposed and a Constrained variant of a newly proposed Differential Evolution Algorithm, ADE-LbX has been used for solving the non linear optimization problem. The final outcome has shown that the overall utility or satisfaction of agents is maximized extensively after energy trading besides maintaining trade advantage for each agent.","Discovering different types of topics: factored topic modelsIn traditional topic models such as LDA, a word is generated by choosing a topic from a collection. However, existing topic models do not identify different types of topics in a document, such as topics that represent the content and topics that represent the sentiment. In this paper, our goal is to discover such different types of topics, if they exist. We represent our model as several parallel topic models (called topic factors), where each word is generated from topics from these factors jointly. Since the latent membership of the word is now a vector, the learning algorithms become challenging. We show that using a variational approximation still allows us to keep the algorithm tractable. Our experiments over several datasets show that our approach consistently outperforms many classic topic models while also discovering fewer, more meaningful, topics.","Fast Implementations of Markov Clustering for Protein Sequence Grouping ","Structural Entities of an Ontology-Driven Unifying Metamodel for UML, EER, and ORM2Software interoperability may be achieved by using their respective conceptual data models. However, each model may be represented in a different conceptual data modelling language for the tool's purpose or due to legacy issues. Several translations between small subsets of language features are known, but no unified model exists that includes all their language features. Aiming toward filling this gap, we designed a common and unified, ontology-driven, metamodel covering and unifying EER, UML Class Diagrams v2.4.1, and ORM2. This paper presents the static, structural, components of the metamodel, highlighting the common entities and summarizing some modelling motivations.","Revisiting the Term Frequency in Concept-Based IR ModelsIndexing documents and queries using concepts, instead of word-based indexing, is an alternative approach, and it supposes to give a more meaningful indexing. However, this way of indexing needs to revisit some hypotheses of classical Information Retrieval. Therefore, we propose a new concept weighting approach, namely Relative Weight, which weights concepts with respect to their corresponding text in the documents or queries. In other words, it assigns to each concept a relative weight with respect to the other concepts in the same context. We explore interesting experimental results of our new weighting approach, compared to the classical approaches, through studying the retrieval performance of some classical IR models.","MoHex 2.0: A Pattern-Based MCTS Hex PlayerIn recent years the Monte Carlo tree search revolution has spread from computer Go to many areas, including computer Hex. MCTS- based Hex players now outperform traditional knowledge-based alpha- beta search players, and the reigning Computer Olympiad Hex gold medallist is the MCTS player MoHex. In this paper we show how to strengthen MoHex, and observe that\u2014as in computer Go\u2014using learned patterns in priors and replacing a hand-crafted simulation pol- icy by a softmax policy that uses learned patterns significantly increases playing strength. The result is MoHex 2.0, about 250 Elo points stronger than MoHex on the 11\u00d711 board, and 300 Elo points stronger on the 13\u00d713 board.","Expert Webest Tool: A Web Based Application, Estimate the Cost and Risk of Software Project Using Function Points ","Alternative Assessment: Developing e-Portfolio for Final Year Project ","Class-Based language models for chinese-english parallel corpusThis paper addresses using novel class-based language models on parallel corpora, focusing specifically on English and Chinese languages. We find that the perplexity of Chinese is generally much higher than English and discuss the possible reasons. We demonstrate the relative effectiveness of using class-based models over the modified Kneser-Ney trigram model for our task. We also introduce a rare events clustering and a polynomial discounting mechanism, which is shown to improve results. Our experimental results on parallel corpora indicate that the improvement due to classes are similar for English and Chinese. This suggests that class-based language models should be used for both languages.","Aggregating evidence from hospital departments to improve medical records searchSearching medical records is challenging due to their inherent implicit knowledge --- such knowledge may be known by medical practitioners, but it is hidden from an information retrieval (IR) system. For example, it is intuitive for a medical practitioner to assert that patients with heart disease are likely to have records from the hospital's cardiology department. Hence, we hypothesise that this implicit knowledge can be used to enhance a medical records search system that ranks patients based on the relevance of their medical records to a query. In this paper, we propose to group aggregates of medical records from individual hospital departments, which we refer to as department-level evidence, to capture some of the implicit knowledge. In particular, each department-level aggregate consists of all of the medical records created by a particular hospital department, which is then exploited to enhance retrieval effectiveness. Specifically, we propose two approaches to build the department-level evidence based on a federated search and a voting paradigm, respectively. In addition, we introduce an extended voting technique that could leverage this department-level evidence while ranking. We evaluate the retrieval effectiveness of our approaches in the context of the TREC 2011 Medical Records track. Our results show that modelling department-level evidence of records in medical records search improves retrieval effectiveness. In particular, our proposed approach to leverage department-level evidence built using a voting technique obtains results comparable to the best submitted TREC 2011 Medical Records track systems without requiring any external resources that are exploited in those systems.","Reflections on a Multimethodology Approach to Business Process AutomationBusiness Process Management Systems (BPMS) have the potential to reduce the effort required to provide technology support for business processes in an organization. Despite their relatively long history, however, there is currently no single development methodology recommended for their use in creating and maintaining Process-Aware Information Systems (PAIS). Instead, developers cur-rently take a multimethodology approach, drawing from a range of available paradigms, methodologies, techniques, and tools. The purpose of this paper is to consider whether an end-to-end methodology is needed for PAIS development or if multimethodology is sufficient. The discussion is informed by the specific experience of designing and building a PAIS for a telecommunications company in Ireland. The paper describes the study and the lessons learned from it, concluding that while an integrated methodology has benefits, a multimethodogy approach seems necessary until there is greater maturity in the BPMS field.","Characteristics of Elderly User Behavior on Mobile Multi-touch Devices ","AQUEDUC: Improving Quality and Efficiency of Care for Elders in Real HomesElderly care is facing the challenge of the disequilibrium between the increased number of old people and the low number of personnel in the elderly care. The emerging pervasive technology has revolutionised the way of assistance in elderly care. Current solutions usually focus too much on technology, and fail to address the usability issues. In this paper, we offer a comprehensive system for both elderly care providers and elders. The system enables coordinators to manage care-givers and elders in an efficient way to improve service quality. For instance, care-givers can be scheduled in a real-time manner with mo- bile phones. We also deploy several sensors in their homes to monitor daily routines to ensure their safety. Alerts will be sent and accessible by coordinators immediately once detected, then elderly care services can be provided accordingly. We test our system in a real home for over 2 months. Finally, we offer a statistical study about the collected data and the reported alerts.","A Hoare Logic for SIMT ProgramsWe study a Hoare Logic to reason about GPU kernels, which are parallel programs executed on GPUs. We consider the SIMT (Single Instruction Multiple Threads) execution model, in which multiple threads execute in lockstep (that is, execute the same instruction at a time). When control branches both branches are executed sequentially but during the execution of each branch only those threads that take it are enabled; after the control converges, all threads are enabled and execute in lockstep again. In this paper we adapt Hoare Logic to the SIMT setting, by adding an extra component representing the set of enabled threads to the usual Hoare triples. It turns out that soundness and relative completeness do not hold for all programs; a difficulty arises from the fact that one thread can invalidate the loop termination condition of another thread through shared memory. We overcome this difficulty by identifying an appropriate class of programs for which soundness and relative completeness hold.","Towards the protection of industrial control systems: conclusions of a vulnerability analysis of profinet IOThe trend of introducing common information and communication technologies into automation control systems induces besides many benefits new security risks to industrial plants and critical infrastructures. The increasing use of Internet protocols in industrial control systems combined with the introduction of Industrial Ethernet on the field level facilitate malicious intrusions into automation systems. The detection of such intrusions requires a detailed vulnerability analysis of the deployed protocols to find possible attacks. Profinet IO is one of the emerging protocols for decentralized control in the European automation industry which has found wide application. In this paper, we describe as results of a vulnerability analysis of the Profinet IO protocol several possible attacks on this protocol. Thereafter we discuss an appropriate protection of automation networks using anomaly-based intrusion detection as an effective countermeasure to address these attacks.","Complexity Theoretic Lower Bounds for Sparse Principal Component DetectionIn the context of sparse principal component detection, we bring evidence towards the existence of a statistical price to pay for computational efficiency. We measure the performance of a test by the smallest signal strength that it can detect and we propose a computationally efficient method based on semidefinite programming.We also prove that the statistical performance of this test cannot be strictly improved by any computationally efficient method. Our results can be viewed as complexity theoretic lower bounds conditionally on the assumptions that some instances of the planted clique problem cannot be solved in randomized polynomial time.","Ricochet Robots: A Transverse ASP BenchmarkA distinguishing feature of Answer Set Programming is its versatility. In addition to satisfiability testing, it offers various forms of model enumeration, intersection or unioning, as well as optimization. Moreover, there is an increasing interest in incremental and reactive solving due to their applicability to dynamic domains. However, so far no comparative studies have been conducted, contrasting the respective modeling capacities and their computational impact. To assess the variety of different forms of ASP solving, we propose Alex Randolph's board game Ricochet Robots as a transverse benchmark problem that allows us to compare various approaches in a uniform setting. To begin with, we consider alternative ways of encoding ASP planning problems and discuss the underlying modeling techniques. In turn, we conduct an empirical analysis contrasting traditional solving, optimization, incremental, and reactive approaches. In addition, we study the impact of some boosting techniques in the realm of our case study.","Does Accurate Scoring of Ligands against Protein Targets Mean Accurate Ranking ","A Transformation Approach for Multiform Time RequirementsMany of the timing constraints expressed in physical prescriptions of distributed systems and multi-clock electronic systems can be expressed in logical concepts. A logical time model has been developed as a part of the official OMG UML profile MARTE, in order to enrich the formalism of this profile and also to facilitate the description and analysis of temporal constraints.#R##N##R##N#This time model is associated with CCSL Clock Constraint Specification Language. Once the software is modeled, the difficulty lies in both expressing the relevant properties and in verifying them formally. We present an automatic transformation technique related to a method for verifying properties by model checking, thus exploiting both the CDL language Context Description Language and the OBP tool Observer-based Prover. The technique is based on a translation of MARTE models and the CCSL constraints into Fiacre code. CDL can express predicates and observers. These are verified during the exhaustive exploration of the complete model by OBP. We illustrate our contribution by an illustrative case.","A Performance Study of Concentrating Photovoltaic Modules Using Neural Networks: An Application with CO2RBFN ","Apply Agile Method for Improving the Efficiency of Software Development Project at VNG Company ","Towards Product Avatars Representing Middle-of-Life Information for Improving Design, Development and Manufacturing Processes ","Conceptual Modeling and Natural Language AnalysisThe CAiSE'92 paper presented a tool called OICSI that used Natural Language Processing (NLP) techniques to support both the generation of an Information System (IS) conceptual schema from textual requirements and in the reverse way, schema paraphrasing to ease schema understanding and evaluation by stakeholders. Both topics have been of interest during the next 20 years among other new usages of NLP techniques in the context IS development. For sake of space, this paper concentrates on an overview of NLP techniques used as elicitation techniques.","Boundary Spanning through Enterprise Social Software: An External Stakeholder PerspectiveRecent boundary spanning literature has recommended a shift toward assessing the role of virtual tools\u2014such as social media. Simultaneously the proliferation of Enterprise Social Software (ESS) points to the need to theorize and investigate the supra-individual usage of these tools. This exploratory study responds to both mandates through a longitudinal, multi-method investigation of ESS\u2019 effects on boundary spanning by virtual research teams within a worldwide provider of workplace solutions. Combining survey, ESS log, and content data, this study complements the dominant internal focus of the boundary spanning literature with an external stakeholder perspective to analyze the types of boundary spanning activities enacted through ESS, the perceptions of these activities by external parties, as well as the effect of ESS hereon. Disentangling ESS\u2019 effects on boundary spanning not only extends our current understanding of the potential role of social media, but can further inform the design of supportive tools.","Granddaughter Beware! An Intergenerational Case Study of Managing Trust Issues in the Use of FacebookWe offer a qualitative analysis of on-line safety practices and expectations in a community setting to look at trust practices that contribute to the complexity of information behaviors in the use of social media. Staging an encounter between local families by bringing together grandmothers and granddaughters at a workshop, we interrogate resulting discussions to understand how information practices are deployed to perform and interpret social identity. The analysis reveals the importance of trust practices and in particular, shows the tension between inward-looking and outward-looking behavior and how different perspectives on trust influence the manner in which communities work to protect members and police alternative uses of Facebook. In doing so, we add to knowledge about on-line safety and trust practices and the roles that families and tools play in supporting, enforcing and augmenting these practices.","Reduced Complexity Pseudo-fractional Adaptive Algorithm with Variable Tap-Length SelectionThe structural complexity and overall performance of the adaptive filter depend on its structure. The number of taps is one of the most important structural parameters of the liner adaptive filter. In practice the system length is not known a-priori and has to be estimated from the knowledge of the input and output signals. In a system identification framework the tap length estimation algorithm automatically adapts the filter order to the desired optimum value which makes the variable order adaptive filter a best identifier of the unknown plant. In this paper an improved pseudo-fractional tap-length selection algorithm has been proposed to find out the optimum tap-length which best balances the complexity and steady state performance. Simulation results reveal that the proposed algorithm results in reduced complexity and faster convergence in comparison to existing tap-length learning methods.","Instrument to assess the need of disabled persons for rehabilitation measures based on the international classification of functioning, disability and healthThis paper introduces a special software product to assess the need of disabled persons for rehabilitation. It is based on a codifier of disability categories which are differentiated according to the primary type of assistance. Depending on impairments severity of body functions and structures and using the International Classification of Functioning, Disability and Health it allows to choose rehabilitation services and technical aids for rehabilitation when making the Individual Rehabilitation Program. The obtained condition codes of a disabled person can be used to electronically record measures on a social card of a citizen, to control the implementation of rehabilitation measures, to analyze the needs in various kinds of assistance and accordingly to plan a budget for different levels etc.#R##N##R##N#The software product has been developed in DBMS Cache in programming environment qWord by SP.ARM Company (St.Petersburg, Russia). The software is multilingual and can be adapted for almost any national language.","Applying Case Based Reasoning in Cuckoo Search for the Expedition of Groundwater Exploration ","Proposal of intellectual productivity model based on work state transitionAiming to reveal the mechanism of intellectual productivity variation of office workers, the authors analyzed the behavior of subjective experiment assuming office work, and proposed an intellectual productivity model. The model is a three state transit model assuming \"working state\", \"short-term rest state\" and \"long-term rest state\". A subject experiment was conducted where illuminance on the desk and work motivation were controlled to vary their productivity. The result was analyzed with this model and it is confirmed that the model can explain the productivity variation.","Study of the Influence of Prototype Aesthetic Fidelity (A Realism Factor) in Usability TestsTools (virtual and physical) currently available for product interactive design are becoming better and more affordable. Thus, it is now easier for designers to apply high degrees of appearance refinement to a prototype at early stages of design. This paper presents the findings of a study investigating the effect of aesthetic fidelity of digital and physical prototypes of a musical metronome device on user's perception of usability, in a series of experimental trials. The study examined user behavior and subjective user evaluation and emotion. Four groups of users were created and assigned different kind of prototypes (physical or digital with low and high aesthetic fidelity). This paper presents results indicating that there is an effect of aesthetic fidelity on user's perception of attractiveness and usability in both digital and physical prototypes and that user's assessment becomes more critical as the prototype gets closer to the real product.","A Diversity-Dependent Measure for Discovering Influencers in Social Networks ","Robustness Analysis of Networked SystemsMany software systems are naturally modeled as networks of interacting elements such as computing nodes, input devices, and output devices. In this paper, we present a notion of robustness for a networked system when the underlying network is prone to errors. We model such a system $\\mathcal{N}$ as a set of processes that communicate with each other over a set of internal channels, and interact with the outside world through a fixed set of input and output channels. We focus on network errors that arise from channel perturbations, and assume that we are given a worst-case bound i\u00be? on the number of errors that can occur in the internal channels of $\\mathcal{N}$. We say that the system $\\mathcal{N}$ is i\u00be?, e-robust if the deviation of the output of the perturbed system from the output of the unperturbed system is bounded by e.#R##N##R##N#We study a specific instance of this problem when each process is a Mealy machine, and the distance metric used to quantify the deviation from the desired output is either the L1-norm or the Levenshtein distance also known as the edit distance. For the former, we present a decision procedure for i\u00be?, e-robustness that is polynomial in the size of the network. For the latter, we present a decision procedure that is polynomial in the size of the network and exponential in the error bound on the output channel. Our solution draws upon techniques from automata theory, essentially reducing the problem of checking i\u00be?,e-robustness to the problem of checking emptiness for a certain class of reversal-bounded counter automata.","The Combined Median Rank-Based Gini Index for Customer Satisfaction Analysis ","Highly Accurate Key Extraction Method for Access-Driven Cache Attacks Using Correlation Coefficient ","Interface design for minimizing loss of context in in-situ remote robot controlWhen controlling robot in-situ, the operator's attention is often divided between the scene and the interface. This often causes inefficiency in the control performance. One possible solution to address this attention switch is to employ a camera (or sensor) view (despite being at the site) in which critical parts of the operating environment can be shown side-by-side with the control interface so that the user is not distracted from the either. In addition, when the user switches one's attention away unavoidably and then back to the control interface, the interface can be configured so that user can easily continue the task at hand without momentary the loss of context. In this paper, we describe the design of such an interface and investigate in the possible user attentive behaviors based on it. In particular, we present an experiment that compares three variant forms of interactions: (1) Nominal (no camera view), (2) Fixed (using a camera view and user not allowed to overlook into the scene), and (3) Free (using a camera view but user is free to overlook into the scene). The three approaches represent different balances between information availability, interface accessibility and the amount of attentional shift. Experiment results have shown that all three interaction models exhibited similar task performance even though the Fixed type induced much less attentional shift. However, the users much preferred the Nominal and Free type. Users mostly ignored the camera view, shifting one's attention excessively into the operating scene, due to the lack of visual quality, realistic scale and depth information of the camera view.","RKA Secure PKE Based on the DDH and HR AssumptionsIn this paper, we prove the security against related key attacks of two public key encryption schemes in the standard model. The first scheme is a variation of the scheme (KYPS09) presented by Kiltz, Pietrzak et al. in Eurocrypt 2009. While KYPS09 has been proved CCA secure under the DDH assumption, we show that it is not secure against related key attacks when the class of related key functions includes affine functions. We make a modification on KYPS09 and prove that the resulted scheme is secure against related key attacks in which the related key functions could be affine functions. We also prove the security against related key attacks of the scheme presented by Hofheinz and Kiltz in Crypto 2009 based on the HR assumption. The security proofs rely heavily on a randomness extractor called 4-wise independent hash functions.","Modeling Energy Performance of Manufacturing Systems Using Gi/M/1 Queues ","On the Implementation of a Multiple Output Algorithm for Defeasible ArgumentationThe authors acknowledge the Spanish projects ARINF (TIN2009-14704-C03-01),  TASSAT  (TIN2010-20967-C04-03)  and  EdeTRI  (TIN2012-39348-C02-01).","Iterated Contraction Based on IndistinguishabilityWe introduce a class of set-theoretic operators on a toler- ance space that models the process of minimal belief contraction, and therefore a natural process of iterated contraction can be defined. We characterize the class of contraction operators and study the properties of the associated iterated belief contraction.","Boosting the Detection of Transposable Elements Using Machine Learning ","On Conservative Learning of Recursively Enumerable LanguagesConservative partial learning is a variant of partial learning whereby the learner, on a text for a target language L, outputs one index e with L = We infinitely often and every further hypothesis d is output only finitely often and satisfies LWd. The present paper studies the learning strength of this notion, comparing it with other learnability cri- teria such as confident partial learning, explanatory learning, as well as behaviourally correct learning. It is further established that for classes comprising infinite sets, conservative partial learnability is in fact equiv- alent to explanatory learnability relative to the halting problem.","A Broadly Applicable and Flexible Conceptual Metagrammar as a Basic Tool for Developing a Multilingual Semantic WebThe paper formulates the problem of constructing a broadly applicable and flexible Conceptual Metagrammar (CM). It is to be a collection of the rules enabling us to construct step by step a semantic representation (or text meaning representation) of practically arbitrary sentence or discourse pertaining to mass spheres of human's professional activity. The opinion is grounded that the first version of broadly applicable and flexible CM is already available in the scientific literature. It is conjectured that the definition of the class of SK-languages (standard knowledge languages) provided by the theory of K-representations (knowledge representations) can be interpreted as the first version of broadly applicable and flexible CM. The current version of the latter theory is stated in the author's monograph published by Springer in 2010. The final part of the paper describes the connections with the related approaches, in particular, with the studies on developing a Multilingual Semantic Web.","A Hybrid Algorithm Combining an Evolutionary Algorithm and a Simulated Annealing Algorithm to Solve a Collaborative Learning Team Building Problem ","DTD based costs for tree-edit distance in structured information retrievalIn this paper we present a Structured Information Retrieval (SIR) model based on graph matching. Our approach combines content propagation, which handles sibling relationships, with a document-query structure matching process. The latter is based on Tree-Edit Distance (TED) which is the minimum set of insert, delete, and replace operations to turn one tree to another. To our knowledge this algorithm has never been used in ad-hoc SIR. As the effectiveness of TED relies both on the input tree and the edit costs, we first present a focused subtree extraction technique which selects the most representative elements of the document w.r.t the query. We then describe our TED costs setting based on the Document Type Definition (DTD). Finally we discuss our results according to the type of the collection (data-oriented or text-oriented). Experiments are conducted on two INEX test sets: the 2010 Datacentric collection and the 2005 Ad-hoc one.","On the Local Approximations of Node Centrality in Internet Router-Level TopologiesIn many networks with distributed operation and self-organization features, acquiring their global topological information is impractical, if feasible at all. Internet protocols drawing on node centrality indices may instead approximate them with their egocentric counterparts, computed out over the nodes' ego-networks. Surprisingly, however, in router-level topologies the approximative power of localized ego-centered measurements has not been systematically evaluated. More importantly, it is unclear how to practically interpret any positive correlation found between the two centrality metric variants.#R##N##R##N#The paper addresses both issues using different datasets of ISP network topologies. We first assess how well the egocentric metrics approximate the original sociocentric ones, determined under perfect network-wide information. To this end we use two measures: their rank-correlation and the overlap in the top-k node lists the two centrality metrics induce. Overall, the rank-correlation is high, in the order of 0.8-0.9, and, intuitively, becomes higher as we relax the ego-network definition to include the ego's r-hop neighborhood. On the other hand, the top-k node overlap is low, suggesting that the high rank-correlation is mainly due to nodes of lower rank. We then let the node centrality metrics drive elementary network operations, such as local search strategies. Our results suggest that, even under high rank-correlation, the locally-determined metrics can hardly be effective aliases for the global ones. The implication for protocol designers is that rank-correlation is a poor indicator for the approximability of centrality metrics.","From 3D Content Models to HBIM for Conservation and Management of Built Heritage ","Human Dimension in Cyber Operations Research and Development PrioritiesWithin cyber security, the human element represents one of the greatest untapped opportunities for increasing the effectiveness of network defenses. However, there has been little research to understand the human dimension in cyber operations. To better understand the needs and priorities for research and development to address these issues, a workshop was conducted August 28-29, 2012 in Washington DC. A synthesis was developed that captured the key issues and associated research questions. Research and development needs were identified that fell into three parallel paths: (1) human factors analysis and scientific studies to establish foundational knowledge concerning factors underlying the performance of cyber defenders; (2) development of models that capture key processes that mediate interactions between defenders, users, adversaries and the public; and (3) development of a multi-purpose test environment for conducting controlled experiments that enables systems and human performance measurement. These research and development investments would transform cyber operations from an art to a science, enabling systems solutions to be engineered to address a range of situations. Organizations would be able to move beyond the current state where key decisions (e.g. personnel assignment) are made on a largely ad hoc basis to a state in which there exist institutionalized processesmore\u00a0\u00bb for assuring the right people are doing the right jobs in the right way. These developments lay the groundwork for emergence of a professional class of cyber defenders with defined roles and career progressions, with higher levels of personnel commitment and retention. Finally, the operational impact would be evident in improved performance, accompanied by a shift to a more proactive response in which defenders have the capacity to exert greater control over the cyber battlespace.\u00ab\u00a0less","Mini smart grid @ copenhagen business school: prototype demonstrationProject Smart Grid:#R##N##R##N#The Intelligent Electrical System Is the Way Forward#R##N##R##N#In 2012 Peter Mollgaard from Department of Economics and Rasmus Pedersen from Department of IT Management initiated a new project supported by CBS Sustainability Platform. The purpose of the project is to establish an understanding of micro-economic and IT challenges related to Smart Grid technology.#R##N##R##N#The mini-smart-grid project at Copenhagen Business School (MSC@CBS) project seeks to investigate the business opportunities and issues that arise from this new technology. The project revolves around the concepts of Smart Grids, Smart Meters and prosumers. Smart Grids are a new method of managing electricity and power supply. It has not reached its full potential yet, but it offers a more interactive platform for both the consumer and the main supplier e.g. Dong Energy. The Smart Grid will collect and control the behavior of consumers and suppliers in order to make the system more effective and sustainable. The consumers or suppliers will be able to control certain appliances in their homes so that they become a resource for the system. For example, the customer or supplier can choose to switch off the freezer for 30 minutes during the night to save energy.","Validating constraint driven design techniques in spatial augmented realityWe describe new techniques to allow constraint driven design using spatial augmented reality (SAR), using projectors to animate a physical prop. The goal is to bring the designer into the visual working space, interacting directly with a dynamic design, allowing for intuitive interactions, while gaining access to affordance through the use of physical objects. We address the current industrial design process, expressing our intended area of improvement with the use of SAR. To corroborate our hypothesis, we have created a prototype system, which we have called SARventor. Within this paper, we describe the constraint theory we have applied, the interaction techniques devised to help illustrate our ideas and goals, and finally the combination of all input and output tasks provided by SARventor.#R##N##R##N#To validate the new techniques, an evaluation of the prototype system was conducted. The results of this evaluation indicated promises for a system allowing a dynamic design solution within SAR. Design experts see potential in leveraging SAR to assist in the collaborative process during industrial design sessions, offering a high fidelity, transparent application, presenting an enhanced insight into critical design decisions to the projects stakeholders. Through the rich availability of affordance in SAR, designers and stakeholders have the opportunity to see first-hand the effects of the proposed design while considering both the ergonomic and safety requirements.","Exponential Synchronization of a Class of RNNs with Discrete and Distributed DelaysThis paper studies the exponential synchronization of RNNs. The investigations are carried out by means of Lyapunov stability method and the Halanay inequality lemma. Finally, a numerical example with graphical illustrations is given to illuminate the presented synchronization scheme.","Supervised Learning and Distributional Semantic Models for Super-Sense TaggingSuper-sense tagging is the task of annotating each word in a text with a super-sense, i.e. a general concept such as animal, food or person, coming from the general semantic taxonomy defined by the WordNet lexicographer classes. Due to the small set of involved concepts, the task is simpler than Word Sense Disambiguation, which identifies a specific meaning for each word. The small set of concepts allows machine learning algorithms to achieve good performance when coping with the problem of tagging. However, machine learning algorithms suffer from data-sparseness. This problem becomes more evident when lexical features are involved, because test data can contain words with low frequency (or completely absent) in training data. To overcome the sparseness problem, this paper proposes a supervised method for super-sense tagging which incorporates information coming from a distributional space of words built on a large corpus. Results obtained on two standard datasets, SemCor and SensEval-3, show the effectiveness of our approach.","Enhancing czech parsing with verb valency framesIn this paper an exploitation of the verb valency lexicons for the Czech parsing system Syntis presented and an effective implementation is described that uses the syntactic information in the complex valency frames to resolve some of the standard parsing ambiguities, thereby improving the analysis results. We discuss the implementation in detail and provide evaluation showing improvements in parsing accuracy on the Brno Phrasal Treebank.","Algebraic Laws for Process SubtypingThis work presents a conservative extension of OhCircus, a concurrent specification language, which integrates CSP, Z, object- orientation and embeds a refinement calculus. This extension supports the definition of process inheritance, where control flow, operations and state components are eligible for reuse. We present the extended OhCircus grammar and, based on Hoare and He's Unifying Theories of Program- ming, we give the formal semantics of process inheritance and its sup- porting constructs. The main contribution of this work is a set of sound algebraic laws for process inheritance. The proposed laws are exercised in the development of a case study.","Semantic web and ontology engineering for the colorectal cancer follow-up clinical practice guidelinesFollow-up care for Cancer patients is provided by the oncologist at the cancer center. There are administrative and cost advantages in providing the follow-up care by family physicians or nurses. This paper presents a Semantic Web approach to develop a decision support system for the Colorectal Cancer Follow-up care that can be used to provide the follow-up care by the physicians. The decision support system requires the development of Ontology for the follow-up care suggested by the Clinical Practice Guidelines (CPG). We present the ontology for the Colorectal Cancer based on the follow-up CPG. This formalized and structured CPGs ontology can then be used by the semantic web framework to provide patient specific recommendation. In this paper, we present the details on the design and implementation of this ontology and querying the ontology to generate knowledge and recommendations for the patients.","HOW SOON IS NOW? THEORIZING TEMPORALITY IN INFORMATION SYSTEMS RESEARCHTime is an inherent quality of human life and the temporal nature of our being in this world has fundamentally shaped our knowledge and understanding of it: the concept of time pervades everyday language: \u201ctime is of the essence\u201d; \u201ctiming is everything\u201d; and \u201ca stitch in time saves nine\u201d. Thus, many disciplines are concerned with Time \u2010 physics of course, and also history, philosophy, psychology, computer science, communication studies and media. Nevertheless, our understanding of it is fundamentally limited because our consciousness moves along it . The goal of this paper is to develop a conceptualization of time that can be used to investigate the impact of temporality on the design, development, adoption and use of Information Systems and to trace the societal and business impact of that association.","Answering Questions by Means of Causal SentencesThe aim of this paper is to introduce a set of algorithms able to configure an automatic answer from a proposed question. This procedure has two main steps. The first one is focused in the extraction, filtering and selection of those causal sentences that could have relevant information for the answer. The second one is focused in the composition of a suitable answer with the obtained information in the previous step.","On efficient processing of complicated cloaked region for location privacy aware nearest-neighbor queries ","Integrating Modeling Tools in the Development Lifecycle with OSLC: A Case StudyModels play a central role in a model driven development process. They realize requirements, specify system design, abstract source code, drive test cases, etc. However, for a modeling tool to be most effective, it needs to integrate its data and workflows with other tools in the development lifecycle. This is often problematic as these tools are usually disparate. OSLC is an emerging specification for integrating lifecycle tools using the principles of linked data. In this paper, we describe how OSLC can be used to integrate MOF-based modeling tools with other lifecycle tools. We demonstrate this in a case study involving an EMF-based modeling tool. We show how we made the tool conform to the OSLC specification and discuss how this enabled it to integrate seamlessly with other lifecycle tools to support some key end-to-end development lifecycle workflows.","Controllability of Time-Aware Processes at Run TimeCompanies increasingly adopt process-aware information systems (PAISs) to analyze, coordinate and monitor their business processes. Although the proper handling of temporal constraints (e.g., deadlines, minimum time lags between activities) is crucial for many applications, contemporary PAISs lack a sophisticated support of the temporal perspective of business processes. In previous work, we introduced Conditional Simple Temporal Networks with Uncertainty (CSTNU) for checking controllability of time constraint networks with decision points. In particular, controllability refers to the ability of executing a time constraint network independent of the actual duration of its activities, while satisfying all temporal constraints. In this paper, we demonstrate how CSTNUs can be applied to time-aware business processes in order verify their controllability at design as well as at run time. In particular, we present an algorithm for ensuring the controllability of time-aware process instances during run time. Overall, proper run-time support of time-aware business processes will broaden the use of PAIS significantly.","Integrative analysis of two cell lines derived from a non-small-lung cancer patient--a panomics approach.Cancer cells derived from different stages of tumor progression may exhibit distinct biological properties, as exemplified by the paired lung cancer cell lines H1993 and H2073. While H1993 was derived from chemo-naive metastasized tumor, H2073 originated from the chemo-resistant primary tumor from the same patient and exhibits strikingly different drug response profile. To understand the underlying genetic and epigenetic bases for their biological properties, we investigated these cells using a wide range of large-scale methods including whole genome sequencing, RNA sequencing, SNP array, DNA methylation array, and de novo genome assembly. We conducted an integrative analysis of both cell lines to distinguish between potential driver and passenger alterations. Although many genes are mutated in these cell lines, the combination of DNA- and RNA-based variant information strongly implicates a small number of genes including TP53 and STK11 as likely drivers. Likewise, we found a diverse set of genes differentially expressed between these cell lines, but only a fraction can be attributed to changes in DNA copy number or methylation. This set included the ABC transporter ABCC4, implicated in drug resistance, and the metastasis associated MET oncogene. While the rich data content allowed us to reduce the space of hypotheses that could explain most of the observed biological properties, we also caution there is a lack of statistical power and inherent limitations in such single patient case studies.","Studying a Head Tracking Technique for First-Person-Shooter Games in a Home Setting ","Top- K aggregate queries on continuous probabilistic datasetsTop-K aggregate query, which ranks groups of tuples by their aggregate values and returns the K groups with the highest aggregates, is a crucial requirement in many domains such as information extraction, data integration, and sensor data processing. In this paper, we formulate the top-K aggregate queries when the tuple scores are presented as continuous probability distributions. Algorithms for top-K aggregate queries are presented. To further improve the performance, we develop pruning techniques and adaptive strategy that avoid computing the exact aggregate values of some groups that are guaranteed not to be in top-K. Our experimental study shows the efficiency of our techniques over several datasets with continuous attribute uncertainty.","Fully Decentralized Cooperative Localization of a Robot Team: An Efficient and Centralized Equivalent SolutionThis paper presents an efficient, centralized equivalent and fully decentralized solution to the cooperative localization of mobile robot teams. Formulating the cooperative localization problem in the framework of Bayesian estimation, the decentralized solution is designed by interlacing the calculation steps of prediction and update in a proper sequence. In the proposed solution, each robot fuses only the sensor data relevant to itself; information is shared among the robots by a chain communication topology. The solution yields linear minimum mean-square error estimates, equivalent to a centralized extended Kalman filter. There is no information redundancy and computation duplication among the robots. The solution can also be viewed from the perspective of implementing inference on a specific junction tree. The performance of the proposed algorithm is evaluated with simulation experiments.","Navigation for indoor mobile robot based on wireless sensor networkA practical system is proposed to solve the navigation problem for indoor mobile robot based on wireless sensor network (WSN). The discrete data acquired by WSN is processed to form a three-dimen- sional global topographic map, which is then converted into a 0-1 grid map through binarization. The grids where obstacles locate are expanded according to specific criteria to construct the robot route network. Then, the route-network-grid map is converted to directional weighted graph, with which the D*Lite algorithm can be used to solve the problem of shortest path between two fixed nodes and acquire the optimal node set to construct the optimal path. Simulation result shows that the indoor environment can be well expressed by the proposed modeling method, from which we can accomplish the navigation to lead the mobile robot arrive to destination with the shortest distance in a dynamic environment.","Sparse Representation for Machine Learning ","Simple yet effective methods for cross-lingual link discovery (CLLD) - KMI @ NTCIR-10 CrossLink-2Cross-Lingual Link Discovery (CLLD) aims to automatically find links between documents written in different languages. In this paper, we first present a relatively simple yet effective methods for CLLD in Wiki collections, explaining the fndings that motivated their design. Our methods (team KMI) achieved in the NTCIR-10 CrossLink-2 evaluation the best overall results in the English to Chinese, Japanese and Korean (E2CJK) task and were the top performers in the Chinese, Japanese, Korean to English task (CJK2E)1 [Tang et al.,2013]. Though tested on these language combinations, the methods are language agnostic and can be easily applied to any other language combination with sufficient corpora and available pre-processing tools. In the second part of the paper, we provide an in depth analysis of the nature of the task, the evaluation metrics and the impact of the system components on the overall CLLD performance. We believe a good understanding of these aspects is the key to improving CLLD systems in the future.","Localization of Submerged Sensors Using Radio and Acoustic Signals with Single BeaconThis paper proposes a simple mechanism to accurately determine the distance between nodes using radio and acoustic signals in underwater wireless sensor networks (UWSN). It also delineates a new method of determining the coordinates of sensors with a single beacon. As the knowledge of precise coor- dinates of the sensors is as important as the collected data in UWSN, the accu- rate distance measurement between the nodes is the prime factor for better accuracy. Mostly, in range free method, received signal strength indicator (RSSI) is used to determine the propagation loss from which the inter nodes dis- tances are calculated. However, in underwater, RSSI of acoustic signal is heavi- ly affected by multipath fading that eventually leads to erroneous coordinates. The proposed mathematical model of coordinate-determination has better immunity from multipath fading as well as synchronization in distance determi- nation resulting precise location of the sensors. Moreover, a single beacon is used to determine the coordinates of the sensor nodes where none of them has a priori knowledge about its location.","Toward Efficient Packet Buffering and Congestion Control Approaches for Reliable Data Delivery in Mobile Ad Hoc NetworkIn this paper, we address two important problems of mobile ad hoc network MANET- route failure and congestion, which reduce the data delivery performance of the network. We propose an efficient and reliable data delivery mechanism that introduces the concept of local packet buffering and multilevel congestion detection and control approaches for improving the reliable delivery of data packets. The nodes on an active route buffer incoming packets at their local transport layer queues, and on finding a new path, resume their transmissions. As a result, packet dropping rate of the network decreases. In addition, we employ a multi-level congestion detection and control mechanism at the source and intermediate nodes that can judiciously take the most appropriate decision for congestion control in the network proactively. Various simulations were carried out based on different traffic loads and route failure rates using NS2 simulator to evaluate the performance of the proposed approaches. The results demonstrate that our approaches outperform a number of state-of-the-art approaches in terms of packet delivery ratio and average end-to-end packet delay.","Logical Inference Framework for Security Management in Geographical Information Systems. ","Incremental Possibilistic K-ModesThis paper proposes an incremental version of a soft clustering approach under uncertainty. The possibility theory and the k-modes algorithm are combined together in an incremental way to deal with two aspects of uncertainty. On one hand, the possibility theory deals with uncertain values of attributes of instances using possibility distributions and handles the belonging of objects to different clusters based on possibilistic membership degrees. On the other hand, the incremental aspect is studied in this new method by adding clusters without re-clustering initial instances. Experimental results clearly demonstrate the advantages of our proposal in a variety of databases using different evaluation criteria.","Parallel Seed-Based Approach to Protein Structure Similarity Detection ","Performances of Invariant Feature Detectors in Real-Time Video ApplicationsThis paper reviews and compares the performance of five well-known detectors, SIFT, SURF, ORB, MSER and STAR, when combined in combination of with using three common descriptors, SIFT, SURF and ORB. To validate the results, these descriptors' performances are verified using three scenarios that differ with respect to changes in scale, light variation and rotation. The results show that the SIFT and SURF detectors possess the most stable features, with an overall accuracy of 80% under various conditions. Among the tested descriptors, SURF provides the best description of each keypoint.","Graph k-Anonymity through k-Means and as Modular DecompositionIn this paper we discuss k-anonymous graphs in terms of modular decomposition and we present two algorithms for the k-anonym-ization of graphs with respect to neighborhoods. This is the strictest definition of k-anonymity for graphs. The first algorithm is an adaptation of the k-means algorithm to neighborhood clustering in graphs. The second algorithm is distributed of message passing type, and therefore enables user-privacy: the individuals behind the vertices can jointly protect their own privacy. Although these algorithms are not optimal in terms of information loss, they are a first example of algorithms that provide k-anonymization of graphs with respect to the strictest definition, and they are simple to implement.","Webpage Mining for Inflation Emergency Early WarningSerious inflation turbulence is a signal of potential financial crisis and social economic emergencies. Macroeconomic early warning of inflation and other major economic indicators is critical to discover po- tential crisis in advance. Traditional early warning methods are based on official economic statistics which are usually either released at least one month later than the economic activities actually occur or lack of flexibility to cope with fast business changes. With proper extraction and aggregation, huge amount of Internet data can serve as a new comple- mentarity source to facilitate more timely and accurate emergency early warning. This research innovatively adopts web data processing tech- niques and text mining methods to extract useful information from huge amount of Internet news reports. Based on the extracted information, a price sentiment index is proposed to detect turning points of inflation efficiently. Empirical evaluation proved that the price sentiment index is efficient in inflation emergency early warning.","Variational Foundations of Online BackpropagationOn-line Backpropagation has become very popular and it has been the subject of in-depth theoretical analyses and massive experimentation. Yet, after almost three decades from its publication, it is still surprisingly the source of tough theoretical questions and of experimental results that are somewhat shrouded in mystery. Although seriously plagued by local minima, the batch-mode version of the algorithm is clearly posed as an optimization problem while, in spite of its effectiveness, in many real-world problems the on-line mode version has not been given a clean formulation, yet. Using variational arguments, in this paper, the on-line formulation is proposed as the minimization of a classic functional that is inspired by the principle of minimal action in analytic mechanics. The proposed approach clashes sharply with common interpretations of on-line learning as an approximation of batch-mode, and it suggests that processing data all at once might be just an artificial formulation of learning that is hopeless in difficult real-world problems.","A Fuzzy Cognitive Map Model for Estimating the Repercussions of Greek PSI on Cypriot Bank Branches in Greece ","Online change detection in exponential families with unknown parametersThis paper studies online change detection in exponential families when both the parameters before and after change are unknown. We follow a standard statistical approach to sequential change detection with generalized likelihood ratio test statistics. We interpret these statistics within the framework of information geometry, hence providing a unified view of change detection for many common statistical models and corresponding distance functions. Using results from convex duality, we also derive an efficient scheme to compute the exact statistics sequentially, which allows their use in online settings where they are usually approximated for the sake of tractability. This is applied to real-world datasets of various natures, including onset detection in audio signals.","Towards a Unified Modeling and Verification of Network and System Security Configurations ","Activity Recognition and Activity Level Estimation for Context-Based Prompting System of Mild Cognitive Impairment Patients ","A measurement of mobile traffic offloadingA promising way to use limited 3G mobile resources efficiently is 3G mobile traffic offloading through WiFi by the user side. However, we currently do not know enough about how effective the mobile traffic offloading is in the wild. In this paper, we report the results of a two-day-long user-based measurement of mobile traffic offloading by over 400 android smartphone users in Japan. We first explain that the variation of aggregated traffic volume via WiFi is much greater than that via 3G in our dataset. Next, we show that the traffic volume offloading through WiFi is common over whole weekend and weekday night, though weekday rush hours have less chance of traffic offloading. Our results emphasize that a small fraction of users contribute to a large fraction of offload traffic volume. In fact, our per-user level analysis reveals that the top 30% of users downloaded over 90% of their total traffic volume via WiFi. However, bottom 20% of users stuck to 3G only and over 50% of users turned off the WiFi interface in business hours. Also, 17.4% of the total traffic volume was generated by users whose WiFi traffic volume was less than 1MB. We observed that some hybrid users downloaded most of their traffic volume via WiFi in shorter durations. In this sense, there is more room to improve the current traffic offloading by promoting users to use WiFi more effectively. Furthermore, we demonstrate that WiFi offloading is mainly performed by access points (APs) in homes while the use of public WiFi APs is still uncommon in our dataset.","Particle Swarm Optimization in Regression Analysis: A Case Study ","Online Game Performance EngineeringInteractive, massive online games are widely popular appli- cations requiring specific solutions to ensure interactivity, consistency, network fairness, and scalability. The wireless revolution has further com- plicated this scenario by adding mobile players competing for network resources with other users. It is hence crucial to provide holistic solutions that enable a top quality online gaming experience regardless whether the player is wired, wireless, or even mobile. To this aim, we analyze how a high level of performance can be ensured through specific engineering of the game architecture, synchronization scheme, and game gateway.","Evolution of Cheating DNA-based Agents Playing the Game of Rock-Paper-ScissorsIn models of games, the indirect interactions between players, such as body language or knowledge about the other\u2019s playstyle, are often omitted. They are, however, a rich source of information in real life, and increase the complexity of possible strategies. In the game of rock-paper-scissors, the simple monitoring of the opponent\u2019s move before it was played is a sufficient condition to trigger an arms race of detection and misinformation among evolved individuals. The most interesting aspect of those results is that they were obtained by evolving purely chemical reaction networks thanks to an adapted version of the famous NEAT algorithm. More specifically, those individuals were represented as biochemical systems built on the DNA toolbox, a paradigm that allows both easy in-vitro implementation and predictive in-silico simulation. This guarantees that the specific motives that emerged in this competition would behave identically in a test tube, and thus can be used in a more generic context than the current game.","Human Heart Segmentation Based on Differential Evolution and Active Contours with Shape PriorActive contour model is an image segmentation technique that uses the evaluation of internal and external forces to be attracted towards the edge of a target object. In this paper a novel image segmen- tation method based on differential evolution and active contours with shape prior is introduced. In the proposed method, the initial active contours have been generated through an alignment process of reference shape priors, and differential evolution is used to perform the segmen- tation task over a polar coordinate system. This method is applied in the segmentation of the human heart from datasets of Computed To- mography images. To assess the segmentation results compared to those outlined by experts and by different segmentation techniques, a set of similarity measures has been adopted. The experimental results suggest that by using differential evolution, the proposed method outperforms the classical active contour model and the interactive Tseng method in terms of efficiency and segmentation accuracy.","On the Power of the Adversary to Solve the Node Sampling ProblemWe study the problem of achieving uniform and fresh peer sampling in large scale dynamic systems under adversarial behaviors. Briefly, uniform and fresh peer sampling guarantees that any node in the system is equally likely to appear as a sample at any non malicious node in the system and that infinitely often any node has a non-null probability to appear as a sample of honest nodes. This sample is built locally out of a stream of node identifiers received at each node. An important issue that seriously hampers the feasibility of node sampling in open and large scale systems is the unavoidable presence of malicious nodes. The objective of malicious nodes mainly consists in continuously and largely biasing the input data stream out of which samples are obtained, to prevent (honest) nodes from being selected as samples. First, we demonstrate that restricting the number of requests that malicious nodes can issue and providing a full knowledge of the composition of the system is a necessary and sufficient condition to guarantee uniform and fresh sampling. We also define and study two types of adversary models: (1) an omniscient adversary that has the capacity to eavesdrop on all the messages that are exchanged within the system, and (2) a blind adversary that can only observe messages that have been sent or received by nodes it controls. The former model allows us to derive lower bounds on the impact that the adversary has on the sampling functionality while the latter one corresponds to a more realistic setting. Given any sampling strategy, we quantify the minimum effort exerted by both types of adversary on any input stream to prevent this sampling strategy from outputting a uniform and fresh sample.","Expressing DOACROSS Loop Dependences in OpenMPOpenMP is a widely used programming standard for a broad range of parallel systems. In the OpenMP programming model, syn- chronization points are specified by implicit or explicit barrier opera- tions within a parallel region. However, certain classes of computations, such as stencil algorithms, can be supported with better synchronization efficiency and data locality when using doacross parallelism with point- to-point synchronization than wavefront parallelism with barrier syn- chronization. In this paper, we propose new synchronization constructs to enable doacross parallelism in the context of the OpenMP program- ming model. Experimental results on a 32-core IBM Power7 system using four benchmark programs show performance improvements of the pro- posed doacross approach over OpenMP barriers by factors of 1.4\u00d7 to 5.2\u00d7 when using all 32 cores.","Near-Duplicate detection for online-shops owners: an FCA-Based approachWe proposed a prototype of near-duplicate detection system for web-shop owners. It's a typical situation for this online businesses to buy description of their goods from so-called copyrighters. Copyrighter can cheat from time to time and provide the owner with some almost identical descriptions for different items. In this paper we demonstrated how we can use FCA for fast clustering and revealing such duplicates in real online perfume shop's datasets.","Controlling for population variances in health and exposure risk using randomized matrix based mathematical modelingIn a previous work, we analyzed the co-occurrence of HPV types in 6 large studies with cervicovaginal samples, representing &gt;32,000 women, to ascertain if associations exist among HPV types and to guide policies on HPV vaccination and vaccine development. The data showed that more women either were uninfected by HPV or had multiple concurrent infections than could be explained by independent assortment, which could result from variance in health and exposure risk factors. Modeling exposure and immune competence proved unstable, so we used a randomized matrix based approach that obviated the need to understand the underlying risk factors. We randomized our source data while preserving increasing levels of fidelity to the original data structures to discover the type associations for HPV infection. We offer that this could be a generally useful technique for studying any type of association in biosocial science, e.g. between demographic, socioeconomic, or other variables.","Semi-supervised constituent grammar induction based on text chunking informationThere is a growing interest in unsupervised grammar induction, which does not require syntactic annotations, but provides less accurate results than the supervised approach. Aiming at improving the accuracy of the unsupervised approach, we have resorted to additional information, which can be obtained more easily. Shallow parsing or chunking identifies the sentence constituents (noun phrases, verb phrases, etc.), but without specifying their internal structure. There exist highly accurate systems to perform this task, and thus this information is available even for languages for which large syntactically annotated corpora are lacking. In this work we have investigated how the results of a pattern-based unsupervised grammar induction system improve as data on new kind of phrases are added, leading to a significant improvement in performance. We have analyzed the results for three different languages. We have also shown that the system is able to significantly improve the results of the unsupervised system using the chunks provided by automatic chunkers.","I know the shortened URLs you clicked on Twitter: inference attack using public click analytics and Twitter metadataTwitter is a popular social network service for sharing messages among friends. Because Twitter restricts the length of messages, many Twitter users use URL shortening services, such as bit.ly and goo.gl, to share long URLs with friends. Some URL shortening services also provide click analytics of the shortened URLs, including the number of clicks, countries, platforms, browsers and referrers. To protect visitors' privacy, they do not reveal identifying information about individual visitors. In this paper, we propose a practical attack technique that can infer who clicks what shortened URLs on Twitter. Unlike the conventional browser history stealing attacks, our attack methods only need publicly available information provided by URL shortening services and Twitter. Evaluation results show that our attack technique can compromise Twitter users' privacy with high accuracy.","Contextual Graphs Platform as a Basis for Designing a Context-Based Intelligent Assistant SystemThe complexity of tasks and problems in the management of databases requires the development of tools for supporting database experts. For instance, in the database administration area, when problems occur, the database administrator DBA is frequently the first person blamed. Most DBAs work in a fire-fighting mode and have little opportunity to plan ahead or be proactive. They must be constantly ready to analyze and correct failures based on a large set of procedures. In addition, they are continually readjusting these procedures and developing practices to manage a multitude of specific situations that differ from the generic situation by some few contextual elements. These practices have to deal with these contextual elements in order to solve the problem at hand. This paper proposes to use \"Contextual Graphs\" formalism to improve existing procedures used in database administration. Up to now, this improvement is achieved by a DBA through practices that adapt procedures to the context in which tasks should be performed and the incidents appear. This work present a new version of the contextual graph platform as a basis for designing and implementing a context-based intelligent assistant system for supporting database administrators.","Coopetitive data warehouse: a case studyIn this paper we discuss the experience of the development of a real system for integrating data about turnover, price and selling volume of AOP UnoLombardia, the biggest association of fruit and vegetable growers in the Lombardia region (Italy), that includes primary Italian and European brands such as Bonduelle and Dimmidisi. The system represents an adaptation and transformation of traditional data warehouse repository oriented development to comply the requirements of a coopetitive environment, where multiple organizations are willing to cooperate over some topics but, at the same time, they compete in the market. Readers may found useful insights and lessons learned from the following contributions of the present work: (i) a methodology to design data warehouse applications in a coopetitive environment and (ii) an architecture based on the combination of virtual data integration and traditional ETL enforcing protection of sensible data.","The New Enterprise Mobility: Seizing the Opportunities and Challenges in Corporate Mobile ITA new generation of mobile IT is driving new thinking and innovation in most areas of organizations and is challenging corporate IT. From a \"computing\" perspective, this second-generation enterprise mobility (SGEM), such as smartphones and media tablets, enables pervasiveness, much more intuitive computing, and contextual intelligence. This changes what can be done with IT in enterprises and creates new challenges for IT departments. Based on three group interviews and twelve individual interviews including data from 31 corporations, we explore how corporations are responding to SGEM. Based on this data, we derive three opportunities and four challenges. The synthesis of the results reveals that SGEM has changed employee expectations for professional IT and led to fundamental issues concerning the role and objectives of corporate IT departments. The results contribute to a more holistic picture of corporate usage of SGEM and illustrate how the new perception of IT is challenging common practice.","Hyperspectral Images as Function-Valued Mappings, Their Self-similarity and a Class of Fractal TransformsA formulation of hyperspectral images as function-valued mappings is introduced, along with a set of simple models of affine self- similarity for digital hyperspectral images. As in the case of greyscale images, these models examine how well vector-valued image subblocks are approximated by other subblocks, as measured by the distribution of approximation errors. This set of models includes both same-scale and cross-scale modes of approximation, the latter of which provides the basis of a method of fractal transforms over hyperspectral images.","Endogenous Metamodeling Semantics for Structural UML 2 ConceptsA lot of work has been done in order to put the Unified Modeling Language UML on a formal basis by translating concepts into various formal languages, e.g., set theory or graph transformation. While the abstract UML syntax is defined by using an endogenous approach, i. e., UML describes its abstract syntax using UML, this approach is rarely used for its semantics. This paper shows how to apply an endogenous approach called metamodeling semantics for central parts of the UML standard. To this end, we enrich existing UML language elements with constraints specified in the Object Constraint Language OCL in order to describe a semantic domain model. The UML specification explicitly states that complete runtime semantics is not included in the standard because it would be a major amount of work. However, we believe that certain central concepts, like the ones used in the UML standard and in particular property features as subsets, union and derived, need to be explicitly modeled to enforce a common understanding. Using such an endogenous approach enables the validation and verification of the UML standard by using off-the-shelf UML and OCL tools.","The effect of haptic degrees of freedom on task performance in virtual surgical environmentsWith a spatial haptic interface device and a suitable haptic rendering algorithm, users can explore and modify virtual geometries in three dimensions with the aid of their haptic (touch) sense. Designers of surgery simulators, anatomy exploration tools and applications that involve assembly of complex objects should consider employing this technology. However, in order to know how the technology behaves as a design material, the designer needs to become well acquainted with its material properties. This presents a significant challenge today, since the haptic devices are presented as black boxes, and implementation of advanced rendering algorithms represent highly specialized and time consuming development activities. In addition, it is difficult to imagine what an interface will feel like until it has been fully implemented, and important design trade-offs such as the virtual object's size and stability gets neglected.Traditional user-centered design can be interpreted as that the purpose of the field study phase is to generate a set of specifications for an interface, and only solutions that cover these specifications will be considered in the design phase. The designer might miss opportunities to create solutions that uses e.g. lower cost devices since that might require reinterpretation of the overarching goal of the situation with starting point in the technical possibilities, which is unlikely without significant material knowledge. As an example, a surgery simulator designed in this thesis required a high cost haptic device to render adequate forces on the scale of human teeth, but if the design goal is reinterpreted as creating a tool for learning anatomical differences and surgical steps, an application more suitable for the lower cost haptic devices could be crafted. This solution is as much informed by the haptic material \"speaking back to\" the designer as by field studies.This licentiate thesis will approach a perspective of spatial haptic interface design that is grounded in contemporary design theory. These theories emphasizes the role of the designer, who is not seen as an objective actor but as someone who has a desire to transform a situation into a preferred one as a service to a client or greater society. It also emphasizes the need for crafting skills in order to innovate, i.e. make designed objects real. Further, it considers aesthetic aspects of a design, which includes the subtle differences in friction as you move the device handle, and overall attractiveness of the device and system.The thesis will cover a number of design cases which will be related to design theory and reflected upon. Particular focus will be placed on the most common class of haptic devices which can give force feedback in three dimensions and give input in six (position and orientation). Forces will be computed and objects deformed by an volume sampling algorithm which will be discussed. Important design properties such as stiffness, have been identified and exposed as a material for design. A tool for tuning these properties interactively has been developed to assist designers to become acquainted with the spatial haptic material and to craft the material for a particular user experience.Looking forward, the thesis suggests the future work of making spatial haptic interfaces more design ready, both in software and hardware. This is proposed to be accomplished through development of toolkits for innovation which encapsulate complexities and exposes design parameters. A particular focus will be placed on enabling crafting with the haptic material whose natural limitations should be seen as suggestions rather than hinders for creating valuable solutions.","Challenges for Search Engine Retrieval Effectiveness Evaluations: Universal Search, User Intents, and Results Presentation ","Technical Section: Interactive high fidelity visualization of complex materials on the GPUHigh fidelity interactive rendering is of major importance for footwear designers, since it allows experimenting with virtual prototypes of new products, rather than producing expensive physical mock-ups. This requires capturing the appearance of complex materials using image based approaches, such as the Bidirectional Texture Function (BTF), to allow subsequent interactive visualization, while still maintaining the capability to edit the materials' appearance. However, interactive global illumination rendering of compressed editable BTFs with ordinary computing resources remains to be demonstrated. In this paper we demonstrate interactive global illumination by using a GPU ray tracing engine and the Sparse Parametric Mixture Model representation of BTFs, which is particularly well suited for BTF editing. We propose a rendering pipeline and data layout which allow for interactive frame rates and provide a scalability analysis with respect to the scene's complexity. We also include soft shadows from area light sources and approximate global illumination with ambient occlusion by resorting to progressive refinement, which quickly converges to a high quality image while maintaining interactive frame rates by limiting the number of rays shot per frame. Acceptable performance is also demonstrated under dynamic settings, including camera movements, changing lighting conditions and dynamic geometry.","Handling structural models composed of objects and their mutual relations in the spatial cognition experimentsIt is one of the basic approaches to use the graphical representation of problem spaces for the spatial cognition experiments of the hard of hearing students. Virtual items and the virtual space are thought to be used practical both to build up questions and to assemble answers between experimenters and subjects. Objects and their mutual relations are the basic components of structural model that have to be managed for forming problems. The object oriented processing is the significant and useful framework for modern programming languages. An object is theoretically the functional abstract closure. However, the idea of closure can be easily extended to the practical items. In this article, object oriented representation and its applying to constraint relation problem for interactive experiments are discussed.","Variational Bayesian PCA versus k-NN on a Very Sparse Reddit Voting DatasetWe present vote estimation results on the largely unexplored Reddit voting dataset that contains 23M votes from 43k users on 3.4M links. This problem is approached using Variational Bayesian Principal Component Analysis VBPCA and a novel algorithm for k-Nearest Neighbors k-NN optimized for high dimensional sparse datasets without using any approximations. We also explore the scalability of the algorithms for extremely sparse problems with up to 99.99% missing values. Our experiments show that k-NN works well for the standard Reddit vote prediction. The performance of VBPCA with the full preprocessed Reddit data was not as good as k-NN's, but it was more resilient to further sparsification of the problem.","Integration of Energy Information for Product Assembly and Logistics Processes ","Robust Scheduling of Dynamic Real-Time Tasks with Low Overhead for Multi-Core SystemsReal-time embedded systems often require the ability of adaptiveness and robustness, because their interactions with physical environments dynamically change workloads. Multi-core chips are becoming an ideal candidate hardware component for such environments, since each of them carries two or more cores on a single die, and has potential for providing execution parallelism as well as better performance at low cost. Parallelism, on the other hand, necessitates complex analysis of computation problems, such as task scheduling, while improving the realization of adaptive controls. Pfair is an optimal scheduling algorithm that can fully utilize all cores in the system, but it incurs excessive scheduling overheads which, in turn, diminishes its practicality in embedded systems. To mitigate this problem, the hybrid partitioned\u0097global Pfair (HPGP) scheduler was proposed in previous work, which significantly reduces the number of task migrations and global scheduling points by performing global scheduling only when absolutely necessary, while still achieving full processor utilization. In this paper, the HPGP scheduler is further extended to support the adaptive controls to dynamic real-time task systems. Experimental evaluation results have shown that the extended HPGP can successfully handle dynamic task systems, thus making it suitable for embedded real-time systems.","Beeinflussen Auswahlkriterien den Erfolg eines CRM- Systems? - eine Strukturgleichungsmodellierung basierend auf dem DeLone und McLean IS- ErfolgsmodellDie strukturierte Auswahl von Customer Relationship Management (CRM) Systemen gilt als eine kritische Voraussetzung fur den Implementie- rungserfolg. Ein indirekter Zusammenhang zwischen Auswahlkriterien und dem Systemerfolg lasst sich u.a. basierend auf dem Modell zur Erfolgsmessung von Informationssystemen nach DeLone und McLean darstellen. Im vorliegen- den Beitrag wird das Modell modifiziert, um Auswahlkriterien fur CRM- Systeme erweitert und empirisch uberpruft. Fur die Datensammlung werden Experten aus dem Umfeld von CRM-Systemen identifiziert und mittels eines standardisierten Fragebogens befragt. Aus einer Stichprobe von 105 Datensat- zen wird ein Strukturgleichungsmodell generiert. Die Auswertung des Struktur- gleichungsmodells unterstutzt die Annahme, dass die Berucksichtigung und Priorisierung bestimmter CRM-Auswahlkriterien einen positiven Einfluss auf die drei Dimensionen System-, Informations- und Servicequalitat sowie den Nettonutzen eines CRM-Systems haben. Die Zusammenhange zwischen den Auswahlkriterien und den einzelnen Komponenten des DeLone und McLean IS-Erfolgsmodells sind dabei unterschiedlich stark ausgepragt.","Exploring Artificial Intelligence Utilizing BioArt ","Developing tools for the team orienteering problem: a simple genetic algorithmThis study is partially supported by FEDER Funds through the COMPETE - Programa Operacional Fatores de Competitividade and by national funds by FCT \u2013 Fundacao para a Ciencia e Tecnologiain the scope of the Project: FCOMP-01-0124-FEDER-022674, and GATOP - Genetic Algorithms for Team Orienteering Problem (Ref PTDC/EME-GIN/120761/2010), financed by national funds by FCT / MCTES, and co-funded by the European Social Development Fund (FEDER) through the COMPETE - Programa Operacional Fatores de Competitividade (POFC) Ref FCOMP-01-0124-FEDER-020609.","Data Handling in the Smart Grid: Do We Know Enough?Data privacy in the smart grid is an important requirement for con- sumers. Central to the data privacy issue is the handling of energy- usage data, in particular, data retention, aggregation and anonymiza- tion. Government and industry groups have formulated various policies in this area, mostly based on fair information practice principles. This paper argues that the current policy-level work is insufficient - scientific work is needed to fully develop and implement privacy policies. A re- search agenda is proposed that balances the advantages of fine-grained energy-usage data with the associated privacy risks. For comparison purposes, the paper describes analogous policies and implementations related to telecommunications, web search and medical data.","Efficient Approximate Indexing in High-Dimensional Feature SpacesIn this paper we present a fast approximate indexing method for high dimensional feature space that uses the error probability as an independent variable.#R##N##R##N#The idea of the algorithm is to define a low-dimensional feature space in which a significant portion of the inter-distance variance is concentrated, to search for the nearest neighborhood of the query in this space, and then to extend the search by a factor i\u00be? to include a number of objects \"near\" this nearest neighborhood. We shall show that, under reasonable hypotheses on the distribution of items in the feature space, it is possible to derive a relation between the value i\u00be? and the error probability.#R##N##R##N#We study the error probability and the complexity of the algorithm, validate the model using a data set of images, and show how the results can be used to design indexing schemes.","Application of an Extended SysML Requirements Diagram to Model Real-Time Control Systems ","Intersecting singularities for multi-structured estimationWe address the problem of designing a convex nonsmooth regularizer encouraging multiple structural effects simultaneously. Focusing on the inference of sparse and low-rank matrices we suggest a new complexity index and a convex penalty approximating it. The new penalty term can be written as the trace norm of a linear function of the matrix. By analyzing theoretical properties of this family of regularizers we come up with oracle inequalities and compressed sensing results ensuring the quality of our regularized estimator. We also provide algorithms and supporting numerical experiments.","Defining Cross-Culture Theoretical Framework of User Interface ","Optimization of the Batch Reactor by Means of Chaos Driven Differential Evolution ","Running to Behavior ChangeLevels of overweight and obese individuals have been seen as rising across the globe. This has caused concerns with regard to how active individu- als are and realization that a high percentage of the population do not meet the weekly requirement of physical activity. Current focus has been on the capabili- ties that new technologies can offer as an intervention technique. This paper of- fers an initial investigation into one such technology, namely the iPod Nike+ kit, which acts as a tracker for running behaviors. This scoping study was con- ducted via a questionnaire and analysis of customer reviews. Participants were assessed on their stage of change for physical activity behavior, based on the Transtheoretical Model of Change (TTM), before and after using the technolo- gy. The results from this study showed that the technology was received posi- tively from those who used it and the predominant outcome was that individuals were more enthusiastic about running.","MetaSymploit: day-one defense against script-based attacks with security-enhanced symbolic analysisA script-based attack framework is a new type of cyber-attack tool written in scripting languages. It carries various attack scripts targeting vulnerabilities across different systems. It also supports fast development of new attack scripts that can even exploit zero-day vulnerabilities. Such mechanisms pose a big challenge to the defense side since traditional malware analysis cannot catch up with the emerging speed of new attack scripts. In this paper, we propose MetaSymploit, the first system of fast attack script analysis and automatic signature generation for a network Intrusion Detection System (IDS). As soon as a new attack script is developed and distributed, Meta-Symploit uses security-enhanced symbolic execution to quickly analyze the script and automatically generate specific IDS signatures to defend against all possible attacks launched by this new script from Day One. We implement a prototype of MetaSymploit targeting Metasploit, the most popular penetration framework. In the experiments on 45 real attack scripts, MetaSymploit automatically generates Snort IDS rules as signatures that effectively detect the attacks launched by the 45 scripts. Furthermore, the results show that MetaSymploit substantially complements and improves existing Snort rules that are manually written by the official Snort team.","Finding, Extracting, and Building Academic Linked Data ","Real-Time Simulation of Vehicle Tracks on Soft TerrainIn this paper, we present algorithms for simulating tracks created by vehicles running on soft terrain. In most 3D graphics applications, vehicle tracks are either not simulated or simply simulated as a texture decal. In applications that involve many vehicle maneuvers, the lack of realistic tracks reduces visual realism. Our method simulates vehicle-terrain interaction based on modified terramechanics models. This method can simulate both wheeled and tracked vehicles on common types of soft terrains such as clay, sand, and snow. Our method can simulate terrain deformations, lateral displacement, tread patterns, and debris.","Discovering math APIs by mining unit testsIn today's API-rich world, programmer productivity depends heavily on the programmer's ability to discover the required APIs. In this paper, we present a technique and tool, called MathFinder, to discover APIs for mathematical computations by mining unit tests of API methods. Given a math expression, MathFinder synthesizes pseudo-code to compute the expression by mapping its subexpressions to API method calls. For each subexpression, MathFinder searches for a method such that there is a mapping between method inputs and variables of the subexpression. The subexpression, when evaluated on the test inputs of the method under this mapping, should produce results that match the method output on a large number of tests. We implemented MathFinder as an Eclipse plugin for discovery of third-party Java APIs and performed a user study to evaluate its effectiveness. In the study, the use of MathFinder resulted in a 2x improvement in programmer productivity. In 96% of the subexpressions queried for in the study, MathFinder retrieved the desired API methods as the top-most result. The top-most pseudo-code snippet to implement the entire expression was correct in 93% of the cases. Since the number of methods and unit tests to mine could be large in practice, we also implement MathFinder in a MapReduce framework and evaluate its scalability and response time.","Functional Dependencies on Symbol Strings Generated by Extended Context Free Languages ","Information Security Behavior: Towards Multi-Stage Models ","Designing a Control Application by Using a Specialized Multi-Core Soft MicroprocessorAbstract   Computationally intensive algorithms for closed loop control and similar systems today can be implemented using reconfigurable FPGA devices. One approach is using soft microprocessor designs and implementing the algorithms as programs. This paper reports about a case study within an ongoing project that investigates a multi-core soft microprocessor solution for a closed-loop control application. Requirements within the project lead to a specialized processor design. Some results from experimental work are presented, demonstrating feasibility and efficiency of the approach.","Automated Model Selection and Parameter Estimation of Log-Normal Mixtures via BYY Harmony Learning ","A Multi-agent Approach to Professional Software EngineeringThe community of agent researchers and engineers has produced a number of interesting and mature results. However, agent technology is still not widely adopted by industrial software developers or software companies--possibly because existing frameworks are infused with academic premises that rarely apply to industrial settings. In this paper, we analyse the requirements of current industry-driven software projects and show how we are able to cope with these requirements in the Java Intelligent Agent Componentware agent framework, JIACi\u00be\u017aV. We argue that the lack of industry-grade requirements and features in other agent frameworks is one of the reasons for the slow acceptance of agent technology in the software industry. The JIACi\u00be\u017aV framework tries to bridge that gap--not as a final solution, but as a stepping stone towards industrial acceptance.","Comparison of GPU and FPGA implementation of SVM algorithm for fast image segmentationThis paper presents preliminary implementation results of the SVM (Support Vector Machine) algorithm. SVM is a dedicated mathematical formula which allows us to extract selective objects from a picture and assign them to an appropriate class. Consequently, a black and white images reflecting an occurrence of the desired feature is derived from an original picture fed into the classifier. This work is primarily focused on the FPGA and GPU implementations aspects of the algorithm as well as on comparison of the hardware and software performance. A human skin classifier was used as an example and implemented both on Intel Xeon E5645.40 GHz, Xilinx Virtex-5 LX220 and Nvidia Tesla m2090. It is worth emphasizing that in case of FPGA implementation the critical hardware components were designed using HDL (Hardware Description Language), whereas the less demanding or standard ones such as communication interfaces, FIFO, FSMs were implemented in Impulse C. Such an approach allowed us both to cut a design time and preserve a high performance of the hardware classification module. In case of GPU implementation whole algorithm is implemented in CUDA.","A Secure RBAC Mobile Agent Model for Healthcare Institutions - Preliminary StudyEfficient healthcare is thus highly dependent on doctors be- ing provided with access to patients medical information at the right time and place. However it frequently happens that critical pieces of pertinent information end up not being used because they are located in information systems that do not interoperate in a timely manner. There are many reasons that contribute to this grim state of affairs, but what interests us the most is the lack of enforceable security policies for systems interoperability and data exchange and the existence of many heterogeneous legacy systems that are almost impossible to directly in- clude into any reasonable secure interoperable workflow. The objective of this paper is to establish a mobile agent access control model based on RBAC model that allows the exchange of clinical information between different health institutions that fall within the same circle of trust.","Robust Online Motion Planning with Regions of Finite Time Invariance ","Comparison of PCA, LDA and Gabor Features for Face Recognition Using Fuzzy Neural Network ","Understanding Privacy and Trust Issues in a Classroom Affective Computing System DeploymentOur research group is in the midst of working with teachers to co-design an affective computing system that uses physiological measures, gathered via wrist worn sensors, to understand how students are engaging with classroom instruction. Optimally, our goal is to find new ways of supporting empathetic practices in the classroom by providing teachers real-time or reflective feedback on student engagement. In parallel, with our work with teachers, we are working to pinpoint the privacy and trust issues that might be associated with this type of system. The objective of this paper is to present the results of a series of studies conducted to understand the challenges associated with introducing a pervasive affective computing system into classroom environments. While we focus on physiological sensors, the implications apply to other pervasive technologies as well.","ISim: A Novel Power Aware Discrete Event Simulation Framework for Dynamic Workload Consolidation and Scheduling in Infrastructure Clouds ","NEST: The Neural Simulation Tool ","Characteristics of touch panel operation with non-dominant hand in car driving contextThe aim of this study is to examine the differences of operability between dominant hand and non-dominant hand in car driving context, especially in operating of touch screen of car navigation system. For the operation of touch screen of car navigation system during car driving, the primary task is of course car driving, and the secondary task is the operation of the touch screen for a car navigation system. In this study, we drove 2 kinds of experiments; the 1st experiment was to investigate the basic usage for touch screen, and the 2nd experiment was to examine the characteristics under dual tasks; the primary and the secondary tasks. As a result, in case of single task, we could find significant differences between with dominant hand and with non-dominant hand. On the other hand, in case of dual task, we could not find significant differences so much, but only when the secondary task was not so complicated we could find statistical difference between dominant hand and non-dominant hand.","Information theoretic pairwise clusteringIn this paper we develop an information-theoretic approach for pairwise clustering. The Laplacian of the pairwise similarity matrix can be used to define a Markov random walk on the data points. This view forms a probabilistic interpretation of spectral clustering methods. We utilize this probabilistic model to define a novel clustering cost function that is based on maximizing the mutual information between consecutively visited clusters of states of the Markov chain defined by the graph Laplacian matrix. The algorithm complexity is linear on sparse graphs. The improved performance and the reduced computational complexity of the proposed algorithm are demonstrated on several standard datasets.","Extractive Text Summarization: Can We Use the Same Techniques for Any Text?This research work has been partially funded by the European Commission under the Seventh (FP7 - 2007-2013) Framework Programme for Research and Technological Development through the FIRST project (FP7-287607); the Spanish Government through the project TEXTMESS 2.0 (TIN2009-13391-C04), \u201dAnalisis de Tendencias Mediante Tecnicas de Opinion Semantica\u201d (TIN2012-38536-C03-03 ) and \u201cTecnicas de Deconstruccion en la Tecnologias del Lenguaje Humano\u201d (TIN2012-31224); and by the Valencian Government through the project PROMETEO (PROMETEO/2009/199).","Cluster-By: An Efficient Clustering Operator in Emergency Management Database SystemsDatabase management systems (DBMS) have been widely used to ef- ficiently store, manage and analysis large emergency management data. Despite the popularity of clustering as a general data mining method, current emergency management database systems lacked a unified and convenient way to support in-database clustering. In this paper we promote the advantages of integrating clustering into databases and propose a new Cluster-by SQL extension. We formally define the syntax and semantics of the Cluster-by clause, illustrate its query plan node in database engine and present two data preprocessing rules. Then we explore the query optimization opportunities, present a novel frame- work for multiquery optimization and define the cost model for multi-query scheduling. We also introduce DBSCAN-based Shrink and Expand algorithms to utilize the historical clustering results and present a heuristic cost model. To demonstrate the integration of the extension with existing DBMSs, we imple- mented the Cluster-by extension in PostgreSQL. We performed experiments on real data sets in PostgreSQL. Results show that Cluster-by extension is useful, the multiquery optimization techniques proposed are efficient.","A Novel Iris Image Quality Evaluation Based on Coarse-to-Fine Method ","Practical Non-blocking Unordered ListsThis paper introduces new lock-free and wait-free unordered linked list algorithms. The composition of these algorithms according to the fast-path-slow-path methodology, a recently devised approach to creating fast wait-free data structures, is nontrivial, suggesting limitations to the applicability of the fast-path-slow-path methodology. The list algorithms introduced in this paper are shown to scale well across a variety of benchmarks, making them suitable for use both as standalone lists, and as the foundation for wait-free stacks and non-resizable hash tables.","Tilt-Based support for multimodal text entry on touchscreen smartphones: using pitch and rollIn this paper we proposea multimodal text entry method for touchscreen smartphones, where standard Tap modality can be used in combination with Pitch and Roll movements that change the orientation of the mobile device. Data from the built-in orientation sensors are used as a basis for commands that support character layout changing. Tilting the device in the appropriate direction will cause visual enlargement of the corresponding half of the current keyboard layout, thus enabling easier character selection, and solely sensor-based text entry. The prototype implementation of the proposed interaction method is analyzed and evaluated via usability testing experiments, with special focus on efficiency of text entry. As the proposed method is also applicable on touchscreen tablets, the form factor of mobile devices is reviewed with respect to text entry performance both of supported interaction modalities (tilt-only and tilt-and-tap) and of possible device orientations (portrait and landscape).","Learning influence and susceptibility from information cascadeFor information propagation on social networks, one key problem is inferring propagation probability, i.e., the probability that one piece of information is propagated from one individual to the other. Existing methods mainly address this problem in a pair-wise manner, determining the propagation probability among pairs of individuals. This over-represented manner makes them suffer severe overfitting problem for pair of individuals without observed interactions, and thus limits their prediction accuracy. In this paper, instead of inferring the pair-wise propagation probability, we learn two low-rank vectors for each individual, representing its influence and susceptibility respectively. Based on this concise representation, we propose a probabilistic model to effectively learn individuals' influence and susceptibility from the log of information cascades. We evaluate the performance of our method on the dataset from the largest social media in China, and show that our method outperforms existing methods at inferring propagation probability.","Computational Analysis of Collective Behaviors via Agent-Based Modeling ","Web 3D Service Implementation ","Multi-touch Based Standard UI Design of Car Navigation System for Providing Information of Surrounding AreasRecognizing current location and surrounding areas is one of the default tasks to utilize car navigation systems. Due to the information and com- munication technologies, features in in-vehicle navigation systems are getting complicated and require more drivers' visual attention. This research aims to de- velop UI design for enhancing drivers' performance in the situation of recogniz- ing and exploring surrounding areas with car navigation systems. In order to make drivers' eyes on the road, a standard feature definition and efficient opera- tion methods are required. First of all, standard features are defined by analyzing top-selling navigation systems in Korean market. Drivers' can get route guidance from their in-vehicle system and personal handheld devices. However, the differences amongst the systems make drivers confused and waste time. The de- velopment of standard features of car navigation systems can reduce drivers' cognition load. Secondly, multi-touch interaction methods and drivers' behaviors are investigated in order to develop basic rationale to introduce multi-touch op- eration to a car navigation system. Current systems in market except smart appli- cations adopt tactile and single-touch based interaction methods. These methods require more visual workload than multi-touch based methods in certain cases. User research has been conducted in tandem with researches of standard features and multi-touch interaction to figure out problems and their needs regarding to exploring surrounding areas in relation to current location. As results of this re- search, TF (Task Flows) of a multi-touch based standard UI design is suggested. The UI design can offer more values to drivers in terms of the amount of infor- mation with efficient and less eyes-on-the-system operations.","K-Induction Based Verification of Real-Time Safety Critical Systems ","Deep Learning Approaches for Link Prediction in Social Network ServicesWith the fast development of online Social Network ServicesSNS, social members get large amounts of interactions which can be presented as links with values. The link prediction problem is to estimate the values of unknown links by the known links' information. In this paper, based on deep learning approaches, methods for link prediction are proposed. Firstly, an unsupervised method that can works well with little samples is introduced. Secondly, we propose a feature representation method, and the represented features perform better than original ones for link prediction. Thirdly, based on Restricted Boltzmann Machine RBM that present the joint distribution of link samples and their values, we propose a method for link prediction. By the experiments' results, our method can predict links' values with high accuracy for data from SNS websites.","A web mining tool for assistance with creative writingWe develop a web mining tool for assistance with creative writing. The relevance of web mining is achieved via computing similarities of parse trees for queries and found snippets. To assure the plausible flow of mental states of involved agents, a multi-agent behavior simulator is included in content generation algorithm.","Design of a Fully Differential Power Output Stage for a Class D Audio Amplifier Using a Single-Ended Power SupplyThis paper presents a full-bridge discrete power output stage for a Class D audio amplifier using a single-ended power supply. The circuit receives a digital control signal with 5 V of amplitude and it generates a floating differential output voltage up to 20 V of amplitude from a single 20 V power supply voltage. Using as control signal a pulse density modulation (PDM) wave generated by an optimized 3rd order continuous-time (CT) sigma delta modulator (\u03a3\u0394M), the system achieves a signal-to-noise-plus-distortion ratio (SNDR) of 83.1 dB, total harmonic distortion (THD) of -89 dB and a power efficiency of 92 %, while delivering 11 W over an 8-\u2126 load with a signal bandwidth of 20 kHz and a sampling frequency of 1.28 MHz.","Long-Reach PONs Employing Directly Modulated Lasers for Provisioning of OFDM-UWB Radio Signals in Sparse Geographical Areas ","A Web-based Adaptive and Intelligent Tutor by Expert SystemsTodays, Intelligent and web-based E-learning is one of regarded topics. So researchers are trying to optimize and expand its application in the field of education. The aim of this paper is developing of E-learning software which is customizable, dynamic, intelligent and adaptive with Pedagogy view for learners in intelligent schools. This system is an integration of adaptive web-based E-learning with expert systems as well. Learning process in this system is as follows. First intelligent tutor determines learning style and characteristics of learner by a questionnaire and then makes his model. After that the expert system simulator plans a pre-test and then calculates his score. If the learner gets the required score, the concept will be trained. Finally the learner will be evaluated by a post-test. The proposed system can improves the education efficiency highly as well as de-creases the costs and problems of an expert tutor. As a result, every time and eve-rywhere (ETEW) learning would be provided via web in this system. Moreover the learners can enjoy a cheap remote learning even at home in a virtual simulated physical class. So they can learn thousands courses very simple and fast.","Computer-Supported Work in Partially Distributed and Co-located Teams: The Influence of Mood Feedback ","State based encapsulation for modular reasoning about behavior-preserving refactoringsA properly encapsulated data representation can be revised for refactoring or other purposes without affecting the correctness of client programs and extensions of a class. But encapsulation is difficult to achieve in object-oriented programs owing to heap based structures and reentrant callbacks. This chapter shows that it is achieved by a discipline using assertions and auxiliary fields to manage invariants and transferrable ownership. The main result is representation independence: a rule for modular proof of equivalence of class implementations.","Hold, Touch and Read It: Border Interactions in Mobile Reading EnvironmentWith the popularity of mobile devices, more and more people read on their phones or tablets in fragmented time. Screen sizes, handedness and other habit factors make the user interface (UI) and interactions far from satisfying every reader. In this study, we present a capacitive sensor based prototype and some novel interactions. The palm grasp style and finger touch gestures are used to infer user reading intent. The user study shows our system can provide efficient recognition and good usability.","An Application of Enhanced Knowledge Models to Fuzzy Time Series ","Towards an Architectural Design Framework for Automotive Systems Development ","Threshold ML-KNN: Statistical Evaluation on Multiple BenchmarksThis paper concerns the performance of a recently proposed multi- label classification algorithm called Threshold ML-KNN. It is a modification of the established ML-KNN algorithm. The performance of both algorithms is com- pared on several publicly available benchmarks. Based on the results, the conclu- sion is drawn that Threshold ML-KNN is statistically significantly better in terms of accuracy, f-measure and hamming loss.","A case-based analysis of the effect of offline media on online conversion actionsIn this paper, we investigate how offline advertising, by means of TV and radio, influences online search engine advertisement. Our research is based on the search engine-driven conversion actions of a 2012 marketing campaign of the potato chips manufacturer Lays. In our analysis we use several models, including linear regression (linear model) and Support Vector Regression (non-linear model). Our results confirm that offline commercials have a positive effect on the number of conversion actions from online marketing campaigns. This effect is especially visible in the first 50 minutes after the advertisement broadcasting.","R2RML by Assertion: A Semi-automatic Tool for Generating Customised R2RML Mappings ","Development of a general internet attitude scaleThis paper presents findings on the recently developed General Internet Attitude Scale (GIAS). Fundamental aspects of attitude in Social Psychological literature outlining appropriate definitions and theoretical frameworks are first presented. Previous issues in Internet attitude research are then reviewed with a focus on the validity of such proposed scales as measurement of attitude. The consideration of such issues in the development of the new attitude scale is then outlined, and the development process of the GIAS is summarized. Although studies with GIAS found difference between age groups, the effect sizes for differences between the genders were extremely small.","An Efficient DRAM Converter for Non-Volatile Based Main Memory ","Electromagnetic Glitch on the AES Round CounterThis article presents a Round Addition Analysis on a software implementation of the Advanced Encryption Standard (AES) algorithm. The round keys are computed on-the-fly during each encryption. A non-invasive transient fault injection is achieved on the AES round counter. The attack is performed by injecting a very short electromagnetic glitch on a 32-bit microcontroller based on the arm Cortex-M3 processor. Using this experimental setup, we are able to disrupt the round counter increment at the end of the penultimate round and execute one additional round. This faulty execution enables us to recover the encryption key with only two pairs of corresponding correct and faulty ciphertexts.","Estimating Shapley Values for Fair Profit Distribution in Power Planning Smart Grid CoalitionsIn future, highly dynamic energy grids a likely scenario is to have dynamically founded groups of distributed energy resources that are in charge of jointly delivering a demanded load schedule for a certain time horizon. In market based scenarios, such a demanded load schedule would be a (day ahead) product that is to be delivered by a coalition of energy resources. Computational aspects of the underlying optimization problem or of proper coalition formation are already subject to many research efforts. In this paper, we focus on the question of fairly shar- ing the profit among the members of such a coalition. Distributing the surplus merely based on the absolute (load) contribution does not take into account that smaller units maybe provide the means for fine grained control as they are able to modify their load on a smaller scale. Shap- ley values provide a concept for the decision on how the generated total surplus of an agent coalition should be spread. In this paper, we propose a scheme for efficiently estimating computationally intractable Shapley values as a prospective base for future surplus distribution schemes for smart grid coalitions and discuss some first ideas on how to use them for smart grid active power product coalitions.","Low-Rank and Sparse Matrix Decomposition for Compressed Sensing Reconstruction of Magnetic Resonance 4D Phase Contrast Blood Flow Imaging (LoSDeCoS 4D-PCI)Blood flow measurements using 4D Phase Contrast blood flow imaging (PCI) provide an excellent fully non-invasive technique to assess the hemodynamics clinically in-vivo. Iterative reconstruction techniques combined with parallel MRI have been proposed to reduce the data acquisition time, which is the biggest drawback of 4D PCI. The novel LoSDeCoS technique combines these ideas with the separation into a low-rank and a sparse component. The high-dimensionality of the PC data renders it ideally suited for this approach. The proposed method is not limited to a single body region, but can be applied to any 4D flow measurement. The benefits of the new method are twofold: It al- lows to significantly accelerate the acquisition; and generates additional images highlighting temporal and directional flow changes. Reduction in acquisition time improves patient comfort and can be used to achieve better temporal or spatial resolution, which in turn allows more precise calculations of clinically important quantitative numbers such as flow rates or the wall shear stress. With LoSDeCoS, acceleration factors of 6-8 were achieved for 16 in-vivo datasets of both the carotid artery (6 datasets) and the aorta (10 datasets), while decreasing the Normalized Root Mean Square Error by over 10 % compared to a standard iterative reconstruction and by achieving similarity values of over 0.93. Inflow- Outflow phantom experiments showed good parabolic profiles and an excellent mass conservation.","Synthesizing Controllers for Automation Tasks with Performance GuaranteesWe present an extension of the MGSyn toolbox that allows synthesiz- ing parallelized controller programs for industrial automation with performance guarantees. We explain the underlying design, outline its algorithmic optimiza- tions, and exemplify its usage with examples for controlling production systems.","Comprehension of vibrotactile route guidance cuesTwo experiments with 24 participants each evaluated comprehension of vibrotactile route guidance instructions via a tactile seat in a driving simulator. Vibrotactile patterns were presented from an array of 8 tactors arranged in two rows of 4 tactors located in the seat pan. A faster pulse rate and a slower pulse rate as well as four distinct locations on the tactile seat (Front-Left, Front-Right, Back-Left, Back-Right) created 8 different combinations of stimuli. Across all participants, the most consistent interpretation was that the faster pulse rate played from the back two tactors was perceived as an instruction to make the next most immediate turn while a slow pulse rate from the front two tactors was interpreted as a cue directing the user to the direction of the next eventual turn. Results have direct implications for design of effective vibrotactile and multimodal route guidance systems.","Teaching Logic through Web-Based and Gamified Quizzing of Formal ArgumentsIn this paper the focus is on the construction, use, pedagogical potential, and long-term sustainability of certain web-based tools designed for teaching logic. A series of web-based tools have been implemented as a two-part system, and the tools have been tested and evaluated in a number of practical experiments. The first part of the system is a student-facing Java-Applet running in the student's browser, implemented using the Prolog programming language as embodied in a Java implementation called Prolog+CG. The second part is a teacher-oriented, server-based backend for logging the progress of students. In the paper, we provide a presentation of the pedagogical and technical ideas of construction that underpin the tools which have been made so far. It is explained how the tools can be developed as web applications using gamified quizzing. We then provide an evaluation of the potential of log data as learning analytics offered by these tools in the context of university courses introducing basic logic and formal aspects of argumentation. We also describe how we have used and evaluated the tools in a real learning context, using both quantitative, log-based data and qualitative interview. The evaluation also includes a discussion of the ethical aspects concerning the logging of student data. We also provide some insights on how the tools can and have been made sustainable.","Differential Impact of Learning Activities Designed to Support Robust Learning in the Genetics Cognitive TutorThis paper describes two types of Conceptually Grounded Learning Activities designed to foster more robust learning in the Genetics Cognitive Tu- tor: interleaved worked examples and genetic-process reasoning scaffolds. We report three empirical studies that evaluate the impact of these learning activi- ties on three diverse genetics problem-solving topics in the tutor. We found that interleaved worked examples yielded less basic-skill learning than conventional problem solving, unlike many prior ITS studies of worked examples. We also found preliminary evidence that scaffolded reasoning tasks in conjunction with conventional problem solving leads to more robust understanding than conven- tional problem solving alone. Implications for the use of contextually grounded learning activities are discussed.","Combining Conditional Random Fields and Background Knowledge for Improved Cyber Security ","Enhanced Differential Evolution Entirely Parallel Method for Biomedical ApplicationsA considerable enhancement is proposed for the Differential Evolution Entirely Parallel DEEP method developed recently. A new selection rule was implemented in order to increase the robustness of DEEP. To simplify the approach a population is not divided now into branches, instead of it, several oldest individuals are substituted with the same number of the best ones after the predefined number of iterations. The individuals are selected on the basis of the number of generations, in which they survived without any change. We demonstrate how the enhanced DEEP provides new solutions to problems with several objective functions.","Complementarity of lexical cohesion and speaker role information for story segmentation of french TV broadcast newsTopic boundary detection in French TV Broadcast News is addressed in this paper with an approach based on the combination of two views: lexical cohesion and speaker role analysis. We propose an improved selection strategy from the classical lexical cohesion curve as well as an integrated supervised classification approach that jointly exploits the two views. The combination of these methods leads to significant improvements on a rich French database composed of shows from 7 different channels.","Classifier Evaluation with Missing Negative Class LabelsThe concept of a negative class does not apply to many problems for which classification is increasingly utilized. In this study we investigate the reliability of evaluation metrics when the negative class contains an unknown proportion of mislabeled positive class instances. We examine how evaluation metrics can inform us about potential systematic biases in the data. We provide a motivating case study and a general framework for approaching evaluation when the negative class contains mislabeled positive class instances. We show that the behavior of evaluation metrics is unstable in the presence of uncertainty in class labels and that the stability of evaluation metrics depends on the kind of bias in the data. Finally, we show that the type and amount of bias present in data can have a significant effect on the ranking of evaluation metrics and the degree to which they over- or underestimate the true performance of classifiers.","A language modeling approach for extracting translation knowledge from comparable corporaA main challenge in Cross-Language information retrieval is to estimate a translation language model, as its quality directly affects the retrieval performance. The translation language model is built using translation resources such as bilingual dictionaries, parallel corpora, or comparable corpora. In general, high quality resources may not be available for scarce-resource languages. For these languages, efficient exploitation of commonly available resources such as comparable corpora is considered more crucial. In this paper, we focus on using only comparable corpora to extract translation information more efficiently. We propose a language modeling approach for estimating the translation language model. The proposed method is based on probability distribution estimation, and can be tuned easier in comparison with heuristically adjusted previous work. Experiment results show a significant improvement in the translation quality and CLIR performance compared to the previous approaches.","Economic Sentiment: Text-Based Prediction of Stock Price Movements with Machine Learning and WordNetThis paper explores the use of machine learning techniques in classifying financial news for the purpose of predicting stock price movements. The current body of literature on the subject is small, and the reported results are mixed. During the course of this paper we attempt to identify some causes for the divergent results, and devise experiments that account for weaknesses in existing research. A corpus of Thomson Reuter newswires was collected from Dow Jones' Factiva for seven large stocks. Each article was then linked with the associated price gap of the trading day following the article's publish date. Utilizing a sequential minimal optimization based support vector machine along with a WordNet-transformed bag-of-words representation, predictions were made in the form of long and short signals. Another variant of the system was also evaluated, wherein Latent Semantic Analysis was employed to process the input data. The signals were conditioned on a set of thresholds, meaning that trade signals were only generated when the predicted values exceeded certain threshold values. Higher thresholds were associated with higher accuracy but a lower number of trading signals. Overall the results were promising.","Network Flow Based Collective Behavior Analysis ","Relevant Subsequence Detection with Sparse Dictionary LearningSparse Dictionary Learning has recently become popular for discovering latent components that can be used to reconstruct elements in a dataset. Analysis of sequence data could also benefit from this type of decomposition, but sequence datasets are not natively accepted by the Sparse Dictionary Learning model. A strategy for making sequence data more manageable is to extract all subsequences of a fixed length from the original sequence dataset. This subsequence representation can then be input to a Sparse Dictionary Learner. This strategy can be problematic because self-similar patterns within sequences are over-represented. In this work, we propose an alternative for applying Sparse Dictionary Learning to sequence datasets. We call this alternative Relevant Subsequence Dictionary Learning (RS-DL). Our method involves constructing separate dictionaries for each sequence in a dataset from shared sets of relevant subsequence patterns. Through experiments, we show that decompositions of sequence data induced by our RS-DL model can be effective both for discovering repeated patterns meaningful to humans and for extracting features useful for sequence classification.","SmartAssist: Open Infrastructure and Platform for AAL ServicesIn this paper we present the open health monitoring platform SmartAssist, which combines flexible in-home and mobile sensing features with a comprehensive social network that is designed to enhance communication between caretakers, caregivers and the community. SmartAssist supports the integration of new sensor types, algorithms, and mobile components through an integrated platform, which consists of an in-home sensor network; a web based service portal; and an extensible infrastructure for mobile devices. Through the adoption of open standards Android, OSGi, OpenSocial, etc., the system addresses issues of data protection and privacy, while simultaneously providing support for third-party extensions and context-aware services. In this paper, we will present the individual building blocks of the SmartAssist Platform as well as some illustrative example services.","An Improved Adaptive Approach for Elitist Nondominated Sorting Genetic Algorithm for Many-Objective Optimization ","A Joint Inference Architecture for Global Coreference Clustering with AnaphoricityWe present an architecture for coreference resolution based on joint inference over anaphoricity and coreference, using Markov Logic Networks. Mentions are discriminatively clustered with discourse enti- ties established by an anaphoricity classier. Our entity-based corefer- ence architecture is realized in a joint inference setting to compensate for erroneous anaphoricity classications and avoids local coreference mis- classications through global consistency constraints. Dening pairwise coreference features in a global setting achieves an ecient entity-based perspective. With a small feature set we obtain a performance of 63.56% (gold mentions) on the ocial CoNLL 2012 data set.","Security Analysis of an Efficient Smart Card-Based Remote User Authentication Scheme Using Hash Function ","A New Intelligent Approach for Mobile Robot Navigation ","Mastering System Analysis and Design through Abstraction and RefinementThe complexity of requirements and complexity of operating environments make error detection in early stages of software system development difficult.  This paper makes an argument for the use of formal modelling and verification in early stages of system development to identify and eliminate errors in a timely fashion.#R##N#Precision is key to eliminating errors in requirements while abstraction is key to mastering requirements complexity. The paper outlines the way in which precision and abstraction may be achieved through modelling and how refinement allows the complexity to be managed through layering.   The role of model validation and model verification in improving the quality of formal models and in improving the quality of the requirements is also outlined. The formalism used throughout is Event-B supported by the Rodin toolset.#R##N##R##N#Based on lectures given at 2012 Marktoberdorf International Summer School on Engineering Dependable Software Systems","Solving Graph Isomorphism Using Parameterized MatchingWe propose a new approach to solve graph isomorphism using parameterized matching. To find isomorphism between two graphs, one graph is linearized,  i.e. , represented as a graph walk that covers all nodes and edges such that each element is represented by a parameter. Next, we match the graph linearization on the second graph, searching for a bijective function that maps each element of the first graph to an element of the second graph. We develop an efficient linearization algorithm that generates short linearization with an approximation guarantee, and develop a graph matching algorithm. We evaluate our approach experimentally on graphs of different types and sizes, and compare to the performance of VF2, which is a prominent algorithm for graph isomorphism. Our empirical measurements show that graph linearization finds a matching graph faster than VF2 in many cases because of better pruning of the search space.","Structured Output Learning with Candidate Labels for Local PartsThis paper introduces a special setting of weakly supervised structured output learning, where the training data is a set of structured instances and supervision involves candidate labels for some local parts of the structure. We show that the learning problem with this weak supervision setting can be efficiently handled and then propose a large margin formulation. To solve the non-convex optimization problem, we propose a proper approximation of the objective to utilize the Constraint Concave Convex Procedure CCCP. To accelerate each iteration of CCCP, a 2-slack cutting plane algorithm is proposed. Experiments on some sequence labeling tasks show the effectiveness of the proposed method.","Design and Control of 3-DOF Robotic Fish 'ICHTHUS V5.5'Recently, many kinds of biomimetic fish-like robots are being actively researched worldwide for practical use of them. However, there are still diverse problems about using of the robotic fish in the real environment such as in the river for monitoring water pollution. Therefore, this study mainly describes development of a robotic fish 'Ichthus V5.5' which can be used for water quality sensing system. The robotic fish 'Ichthus V5.5' has a 3-DOF serial link-mechanism for its propulsion, which is developed in KITECH. We added several sensors to navigate autonomously in the real environment like river. To measure the performance of the robotic fish, an experimental setup is developed for measuring the propulsion force of the robot. Also, we installed two kinds of sensor to detect temperature, electric conductivity, pH (hydrogen ion concentration) of water. Therefore, the developed robotic system can be applied to environmental monitoring system for detect pollution or quality of river.","Extending the information of activity diagrams with a user input classificationThis paper presents an extended notation of actions in activity diagrams. The suggested method combines activity diagrams with a user input classification in order to support interdisciplinary teams, particularly in the early phases of development. In this way, the user input classification serves as a communication basis for user requirements, which is adapted to the needs of software engineers. The method is evaluated within a case study in a nationwide research project for public transport.","Comparison of Enhanced Visual and Haptic Features in a Virtual Reality-Based Haptic SimulationAn experiment was conducted to compare the learning effects following motor skill training using three types of virtual reality simulations. Training and testing were presented using virtual reality (VR) and standardized forms of existing psychomotor tests, respectively. The VR training simulations included haptic, visual and a combination of haptic and visual assistance designed to accelerate training. A comparison of performance test results prior to and following training revealed conditions providing haptic assistance to yield lower scores related to fine motor skill training than the visual-only aiding condition. Similarly, training in the visual condition resulted in comparatively lower cognitive skill scores. The present investigation incorporating healthy subjects was designed as part of an ongoing research effort to provide insight on the design of VR simulations for rehabilitation of motor skills in patients with a history of mTBI.","Participatory Data Gathering for Public Sector Reuse: Lessons Learned from Traditional InitiativesLocal governments are increasingly looking for new ways to involve citizens in policy and decision-making, for example by combining public sector data sources with data gathered by citizens. Several examples exist of data gathering where personal mobile devices act as data collectors. While these efforts illustrate the technical capability of data sourcing, they neglect the value of local knowledge where people use their senses to capture and interpret data. Traditional data gathering initiatives, however, exploit this local knowledge to inform policy makers, e.g., neighborhood policing. To understand data gathering processes of these traditional data gathering initiatives, three cases are examined. We analyze these cases, focusing on the various elements they contain, concluding how digital data gathering can be informed by these traditional variants, concerning what the benefits of using digital means can be for data gathering and how traditional initiatives ensure data re-use by the public sector.","A spatial proximity based compression method for GML documentsGeography Markup Language (GML) has become a standard for encoding and exchanging geographic data in various geographic information systems (GIS) applications. Whereas, high-precision spatial data in GML documents often causes high cost in GML storage and transmission as well as parsing. In this paper, we propose a spatial proximity based GML compression method for GML document compression, which transforms spatial data (coordinates in GML documents) into blocks of coordinates and compress coordinates effectively. Concretely, ordered coordinate dictionaries are constructed firstly, and coordinates are encoded as their ordinal numbers in the coordinate dictionaries. Then, delta encoding and LZW encoding are employed to compress the coordinate dictionaries and coordinate ordinal numbers respectively. Finally, the output of the delta encoder and LZW encoder is streamed to a spatial data container. Extensive experiments over real GML documents show that the proposed method outperforms the existing major XML and GML compression methods in compression ratio, while maintaining an acceptable compression efficiency.","Full length article: Tur\u00e1n type inequalities for q-hypergeometric functionsIn this paper our aim is to deduce some Turan type inequalities for q-hypergeometric and q-confluent hypergeometric functions. In order to obtain the main results we apply the methods developed in the case of classical Kummer and Gauss hypergeometric functions.","Toward \"Third Wave\" Information Systems Research: Linking Sociomaterial Practice with Broader Institutional LogicsThe sociomaterial movement has done much to strengthen the theorizing of IT artifacts in practice. This \u201csecond wave\u201d information systems research, which focuses on theorizing of the interpenetration of IT artifacts and human activity, is a response to the positivistic, reductive accounts that overly simplified human activity around the development and adoption of IT in the name of generalizability. However, with their focus on local ideographic interpretation, sociomaterial views have abandoned the search for regularities across contexts and across time. In this paper, we take a step toward a \u201cthird wave\u201d approach as we look to theoretically account for both idiosyncrasies in sociomaterial practice in situ, and the regularities across these practices. Drawing on institutional logics and the concept of sociomaterial practice, we develop a conceptualization that highlights how technologies afford the enactment of different practice scripts as users draw on different institutional logics.","Trustworthiness Attributes and Metrics for Engineering Trusted Internet-Based Software Systems ","A biological and real-time framework for hand gestures and head posesHuman-robot interaction is an interdisciplinary research area that aims at the development of social robots. Since social robots are expected to interact with humans and understand their behavior through gestures and body movements, cognitive psychology and robot technology must be integrated. In this paper we present a biological and real-time framework for detecting and tracking hands and heads. This framework is based on keypoints extracted by means of cortical V1 end-stopped cells. Detected keypoints and the cells' responses are used to classify the junction type. Through the combination of annotated keypoints in a hierarchical, multi-scale tree structure, moving and deformable hands can be segregated and tracked over time. By using hand templates with lines and edges at only a few scales, a hand's gestures can be recognized. Head tracking and pose detection are also implemented, which can be integrated with detection of facial expressions in the future. Through the combinations of head poses and hand gestures a large number of commands can be given to a robot.","A Framework for Conflict Resolution in Multi-Agent SystemsIn this paper, we analyze the effects of agents' confidence in conflict resolution of a multi-agent system and propose a resolution technique to possible conflicts in the environment. It establishes a framework on agents' confidence and conflict strength and shows the possible limits of agents which provide uncertain information. This paper offers a confidence model that depends on some factors, which suggest that agents' opinions do not have equal confidence level. We exploit such circumstance in selecting appropriate strategy to resolve conflicts between agents. Consequently, we propose a multi-agent framework which examines agents' confidence using specific factors and exploiting the level of confidence for detecting the best strategy to conflict resolution.","Stream-Mode FPGA acceleration of complex pattern trajectory queryingThe wide and increasing availability of collected data in the form of trajectory has lead to research advances in behavioral aspects of the monitored subjects (e.g., wild animals, people, vehicles). Using trajectory data harvested by devices, such as GPS, RFID and mobile devices, complex pattern queries can be posed to select trajectories based on specific events of interest. In this paper, we present a study on FPGA-based architectures processing complex patterns on streams of spatio-temporal data. Complex patterns are described as regular expressions over a spatial alphabet that can be implicitly or explicitly anchored to the time domain. More importantly, variables can be used to substantially enhance the flexibility and expressive power of pattern queries. Here we explore the challenges in handling several constructs of the assumed pattern query language, with a study on the trade-offs between expressiveness, scalability and matching accuracy. We show an extensive performance evaluation where FPGA setups outperform the current state-of-the-art CPU-based approaches by over three orders of magnitude. Unlike software-based approaches, the performance of the proposed FPGA solution is only minimally affected by the increased pattern complexity.","Architecture of a parallel MOSFET parameter extraction systemThe paper first describes an existing parameter estimation approach used to estimate MOSFET mathematical model parameters. Next, all of the presented algorithms are analyzed with respect to the current multiple core processor architecture design. The parallel equivalents of the presented algorithms are given, including their computational complexities. The presented approach is specific that is uses the multiple-modulus arithmetic of the Residue Number System for solution of sets of linear equations. Finally, the paper shows the scalability of the presented approach and compares the obtained results to the original approach.","The UML Diagram to VHDL Code Transformation Based on MDA MethodologyThe Model Driven Architecture (MDA) methodology requires several intelligent operation stages, such as the computation independent model transformation (CIMT), the platform independent model transformation (PIMT), and the platform specific model transformation (PSMT), to progressively transform an abstract model to a physical system. The special Unified Modeling Language (UML) or StarUML is the core tool of CIMT that models a digital system in a diagram paradigm. PIMT uses the Python language with minidom object to perform a series translation from UML diagram to VHSIC Hardware Description Language (VHDL) code. Finally, the PSMT imports an os object to Python for running a series of synthesis command script to get bit stream that is finally downloaded into FPGA device to complete the realization of the digital logic circuit.","DiVinE 3.0: an explicit-state model checker for multithreaded c &amp; c++ programsWe present a new release of the parallel and distributed LTL model checker DiVinE. The major improvement in this new release is an extension of the class of systems that may be verified with the model checker, while preserving the unique DiVinE feature, namely parallel and distributed-memory processing. Version 3.0 comes with support for direct model checking of (closed) multithreaded C/C++ programs, full untimed-LTL model checking of timed automata, and a general-purpose framework for interfacing with arbitrary system modelling tools.","Solving Towers of Hanoi and Related PuzzlesStarting with the well-known Towers of Hanoi, we create a new sequence of puzzles which can essentially be solved in the same way. Since graphs and puzzles are intimately connected, we define a sequence of graphs, the iterated complete graphs, for our puzzles. To create puzzles for all these graphs, we need to generalize another puzzle, Spin-Out, and cross the generalized Towers puzzles with the the generalized Spin-Out puzzles. We show how to solve these combined puzzles. We also show how to compute distances between puzzle configurations. We show that our graphs have Hamiltonian paths and perfect one-error-correcting codes. (Properties that are    $\\mathcal{NP}$   -complete for general graphs.) We also discuss computational complexity and show that many properties of our graphs and puzzles can be calculated by finite state machines.","Fast Computation of the Multi-Points Expected Improvement with Applications in Batch SelectionThe Multi-points Expected Improvement criterion or    $$q$$   -EI has recently been studied in batch-sequential Bayesian Optimization. This paper deals with a new way of computing    $$q$$   -EI, without using Monte-Carlo simulations, through a closed-form formula. The latter allows a very fast computation of    $$q$$   -EI for reasonably low values of    $$q$$    typically, less than 10. New parallel kriging-based optimization strategies, tested on different toy examples, show promising results.","GuideMe: A Mobile Augmented Reality System to Display User Manuals for Home AppliancesIn this paper we present GuideMe, a mobile augmented reality application that provides assistance in using appliances. In order to explore how users perceive GuideMe, as a design of an interactive and digital manual, we conducted two user studies. We compared GuideMe first with paper-based manuals and then with video-based manuals. Our results indicate that the paper-based manuals were superior regarding typical usability measures (i.e. error rates and completion times). However, participants reported a significantly higher perceived task load when using paper-based manuals. Due to a better user experience, GuideMe was preferred by 9 of 10 participants over paper-based manuals. We present our design in detail and discuss broader implications of designing digital manuals. Furthermore, we introduce a custom format to define manual structures for mobile augmented reality enabled manuals.","Supporting Energy Efficiency Decisions with IT: Initial Experiences from the EnRiMa ProjectIT solutions can aid decision makers in making informed decisions that lower the energy consumption in buildings. However, in order to design and implement an IT solution there are a number of issues that need to be resolved, for example, adequately handling sometimes contradicting goals of the decision makers and integrating the Decision Support System with the existing building IT infrastructure in the form of building management systems. In this paper we report on our initial experiences from implementing a decision support system for the management of energy consumption in public buildings. The experiences are based on our work with the EnRiMa project that aims to develop a state-of art decision support system for lowering the energy consumption and CO2 emissions of public buildings. We divide our experiences into two areas, namely, business concerns and software architectural, and provide our initial solutions and lessons learned with respect to these areas. Furthermore, we discuss a number of challenges for future work in the area of IT support for energy efficiency.","Unsupervised learning of functional network dynamics in resting state fMRIResearch in recent years has provided some evidence of temporal non-stationarity of functional connectivity in resting state fMRI. In this paper, we present a novel methodology that can decode connectivity dynamics into a temporal sequence of hidden network \"states\" for each subject, using a Hidden Markov Modeling (HMM) framework. Each state is characterized by a unique covariance matrix or whole-brain network. Our model generates these covariance matrices from a common but unknown set of sparse basis networks, which capture the range of functional activity co-variations of regions of interest (ROIs). Distinct hidden states arise due to a variation in the strengths of these basis networks. Thus, our generative model combines a HMM framework with sparse basis learning of positive definite matrices. Results on simulated fMRI data show that our method can effectively recover underlying basis networks as well as hidden states. We apply this method on a normative dataset of resting state fMRI scans. Results indicate that the functional activity of a subject at any point during the scan is composed of combinations of overlapping task-positive/negative pairs of networks as revealed by our basis. Distinct hidden temporal states are produced due to a different set of basis networks dominating the covariance pattern in each state.","User experience of interRAI assessment tools in New Zealand. ","Modeling Service Migration and Relocation in Mission-Critical SystemsMission-critical information systems are commonly used in critical in- frastructure assets such as the electric power grid, telecommunications networks, healthcare systems, water management systems and national defense. Damage or disruption of these systems could result in the loss of services and potentially serious societal consequences. Therefore, it is important to ensure that the essential services provided by these systems are reliable and dependable. This paper presents a modeling framework for service migration and relocation, which can dynamically transfer critical services from a compromised platform to other healthy platforms. The mechanism guarantees that vital services are continu- ously available despite malicious attacks and system failures. When the compromised platform has recovered, the services can be moved back to the platform. The modeling framework provides a means for study- ing the important factors that impact service migration and relocation, and how an assured service migration mechanism can be designed to increase confidence about the reliability of mission-critical information systems.","Identifying Smart Solutions for Fighting Illegal Logging and Timber TradeWe investigate how smart Information and Communication Technologies (ICT) solutions can be used for combating illegal logging and timber trade. We put together techniques from agile requirements engineering to propose a methodology for identifying user stories and as- sociated risks and priorities and via a collaborative, participatory, single day workshop, named inception workshop. We present our findings from the first application of the method, with the active involvement of the relevant stakeholders, i.e technical and domain experts, which concluded in seven user stories.","A Simple Yet Fast Algorithm for the Closest-Pair Problem Using Sorted Projections on Multi-Dimensions ","Wifigrams: Design of Hierarchical Wi-Fi Indoor Localization Systems Guided by Social Network Analysis ","Type-Based Analysis of Protected Storage in the TPMThe Trusted Platform Module (TPM) is designed to enable trustworthy computation and communication over open networks. The TPM provides a way to store cryptographic keys and other sensitive values in its shielded memory and act as Root of Trust for Storage (RTS). The TPM interacts with applications via a predefined set of commands (an API). In this paper, we give an abstraction model for the TPM 2.0 specification concentrating on Protected Storage part. With identification and formalization of their secrecy properties, we devise a type system with asymmetric cryptographic primitives to statically enforce and prove their security.","Using the Variation Coefficient for Adaptive Discrete Beta Kernel Graduation ","Image Classification Based on 2D Feature MotifsThe classification of raw data often involves the problem of selecting the appropriate set of features to represent the input data. In general, various features can be extracted from the input dataset, but only some of them are actually relevant for the classification process. Since relevant features are often unknown in real-world problems, many candidate features are usually introduced. This degrades both the speed and the predictive accuracy of the classifier due to the presence of redundancy in the candidate feature set.#R##N##R##N#In this paper, we study the capability of a special class of motifs previously introduced in the literature, i.e. 2D irredundant motifs, when they are exploited as features for image classification. In particular, such a class of motifs showed to be powerful in capturing the relevant information of digital images, also achieving good performances for image compression. We embed such 2D feature motifs in a bag-of-words model, and then exploit K-nearest neighbour for the classification step. Preliminary results obtained on both a benchmark image dataset and a video frames dataset are promising.","Augmentation of paramedian 3D ultrasound images of the spineThe blind placement of an epidural needle is among the most difficult regional anesthetic techniques. The challenge is to insert the needle in the mid-sagittal plane and to avoid overshooting the needle into the spinal cord. Prepuncture 2D ultrasound scanning has been introduced as a reliable tool to localize the target and facilitate epidural needle placement. Ideally, real-time ultrasound should be used during needle insertion. However, several issues inhibit the use of standard 2D ultrasound, including the obstruction of the puncture site by the ultrasound probe, low visibility of the target in ultrasound images, and increased pain due to longer needle trajectory. An alternative is to use 3D ultrasound imaging, where the needle and target could be visible within the same reslice of a 3D volume; however, novice ultrasound users (i.e., many anesthesiologists) still have difficulty interpreting ultrasound images of the spine and identifying the target epidural space. In this paper, we propose to augment 3D ultrasound images by registering a multi-vertebrae statistical shape+pose model. We use such augmentation for enhanced interpretation of the ultrasound and identification of the mid-sagittal plane for the needle insertion. Validation is performed on synthetic data derived from the CT images, and 64 in vivo ultrasound volumes.","Viscosity Measurement Monitoring by Means of Functional Approximation and Rule Based Techniques ","Random Access NDMA MAC Protocols for Satellite Networks ","Semantic Video Segmentation from Occlusion Relations within a Convex Optimization FrameworkWe describe an approach to incorporate scene topology and semantics into pixel-level object detection and localization. Our method requires video to determine occlusion regions and thence local depth ordering, and any visual recognition scheme that provides a score at local image regions, for instance object detection probabilities. We set up a cost functional that incorporates occlusion cues induced by object boundaries, label consistency and recognition priors, and solve it using a convex optimization scheme. We show that our method improves localization accuracy of existing recognition approaches, or equivalently provides semantic labels to pixel-level localization and segmentation.","Towards Distributed Software Model-Checking Using Decision DiagramsSymbolic data structures such as Decision Diagrams have proved successful for model-checking. For high-level specifications such as those used in programming languages, especially when manipulating pointers or arrays, building and evaluating the transition is a challenging problem that limits wider applicability of symbolic methods.#R##N##R##N#We propose a new symbolic algorithm, EquivSplit, allowing an efficient and fully symbolic manipulation of transition relations on Data Decision Diagrams. It allows to work with equivalence classes of states rather than individual states. Experimental evidence on the concurrent software oriented benchmark BEEM shows that this approach is competitive.","Seamless Mobility: Individual Mobility Profiles for a Better Usability of Shared Vehicles ","Robust Boundary Layer Mesh GenerationIn this paper, we introduce a 3D local operator that automatically combines typical simpler operators as removal of vertices, collapse of edges or swap of faces and edges. This operator is inherited from incremental methods where the mesh \ue234k is modified iteratively through sequences of insertion of a point P: Hk+1=Hk\u2212CP+BP, where CP is the cavity of P and BP the ball of P. We derive two algorithms to compute Cp . The first algorithm is tuned to be a fast point reprojection to the geometry even in the presence of a boundary layer mesh. The second one is tuned to generate boundary layer meshes for complex geometries. We show how quasi-structured elements can be enforced. In addition, enhancements as multi-normals can be incorporated in the process. Both operators can be used with surface and volume point while preserving a given geometry. They rely on the use on an existing initial volume mesh and always produce a valid 3D mesh on output.","An empirical study on word segmentation for chinese machine translationWord segmentation has been shown helpful for Chinese-to-English machine translation (MT), yet the way different segmentation strategies affect MT is poorly understood. In this paper, we focus on comparing different segmentation strategies in terms of machine translation quality. Our empirical study covers both English-to-Chinese and Chinese-to-English translation for the first time. Our results show the necessity of word segmentation depends on the translation direction. After comparing two types of segmentation strategies with associated linguistic resources, we demonstrate that optimizing segmentation itself does not guarantee better MT performance, and segmentation strategy choice is not the key to improve MT. Instead, we discover that linguistical resources such as segmented corpora or the dictionaries that segmentation tools rely on actually determine how word segmentation affects machine translation. Based on these findings, we propose an empirical approach that directly optimize dictionary with respect to the MT task for word segmenter, providing a BLEU score improvement of 1.30.","Challenges of Applying Adaptive Processes to Enable Variability in Sustainability Data Collection.Nowadays, demanding legal regulations as well as sophisticated customer needs force companies in electronics and automotive industries to provide a multitude of different sustainability indicators. Since their products usually contain numerous components and sub-components, companies must deal with complex, intransparent data collection processes along their supply chains in order to finally deliver valuable data. A myriad of different automatic and manual tasks, potentially long-running processes, and quickly changing situations result in great variability that is hard to handle. In the SustainHub project, a dedicated information system for supporting data collection processes is developed. Thereby, core challenges as well as state-of-the-art were systematically gathered, consolidated as well as assessed. The condensed results are presented in this paper.","Tamper-Resistant LikeJacking ProtectionThe ClickJacking variant LikeJacking specifically targetsWeb widgets that offer seamless integration of third party services, such as social sharing facilities. The standard defense against ClickJacking is preventing framing completely or allowing framing only in trusted contexts. These measures cannot be taken in the case of LikeJacking, due to the widgets' inherent requirement to be available to arbitrary Web applications. In this paper, we report on advances in implementing LikeJacking protection that takes the specific needs of such widgets into account and is compatible with current browsers. Our technique is based on three pillars: A JavaScript-driven visibility check, a secure in-browser communication protocol, and a reliable method to validate the integrity of essential DOM properties and APIs. To study our protection mechanism's performance characteristics and interoperability with productive Web code, we applied it to 635 real-world Web pages. The evaluation's results show that our method performs well even for large, non-trivial DOM structures and is applicable without requiring changes for the majority of the social sharing widgets used by the tested Web applications.","How Much Does Storage Really Cost? Towards a Full Cost Accounting Model for Data StorageIn our everyday lives, we create massive amounts of data. But how much does it really cost to store data? With ever decreasing cost of storage media, a popular misconception is that the cost of storage has become cheaper than ever. However, we argue that the cost of storing data is not equal to the cost of storage media alone \u0097 rather, many often ignored factors including human, infrastructure, and environmental costs contribute to the total cost to store data. Unfortunately, very little research has been done to determine the full cost of cloud based storage systems. Most existing studies do not account for indirect factors and determinants of storage cost. To fully determine the true cost of data storage, we need to perform full cost accounting \u0097 a well known accounting technique. In this paper, we present a full cost accounting model for cloud storage systems. We include all the hidden and environmental costs as well as regular costs to develop a comprehensive model for storage system costs. To the best of our knowledge, this is the first work on creating a full cost accounting model for cloud based storage systems.","On the dissimilarity representation and prototype selection for signature-based bio-cryptographic systemsRobust bio-cryptographic schemes employ encoding methods where a short message is extracted from biometric samples to encode cryptographic keys. This approach implies design limitations: 1) the encoding message should be concise and discriminative, and 2) a dissimilarity threshold must provide a good compromise between false rejection and acceptance rates. In this paper, the dissimilarity representation approach is employed to tackle these limitations, with the offline signature images are employed as biometrics. The signature images are represented as vectors in a high dimensional feature space, and is projected on an intermediate space, where pairwise feature distances are computed. Boosting feature selection is employed to provide a compact space where intra-personal distances are minimized and the inter-personal distances are maximized. Finally, the resulting representation is projected on the dissimilarity space to select the most discriminative prototypes for encoding, and to optimize the dissimilarity threshold. Simulation results on the Brazilian signature DB show the viability of the proposed approach. Employing the dissimilarity representation approach increases the encoding message discriminative power (the area under the ROC curve grows by about 47%). Prototype selection with threshold optimization increases the decoding accuracy (the Average Error Rate AER grows by about 34%).","Intuitionistic Fuzzy Logic as a Tool for Quality Assessment of Genetic Algorithms PerformancesIntuitionistic fuzzy logic (IFL) has been implemented in this investigation aiming to derive intuitionistic fuzzy estimations of S. cere- visiae fed-batch cultivation model parameters obtained using standard simple (SGA) and multi-population (MpGA) genetic algorithms. Perfor- mances of MpGA have been tested before and after the application of the procedure for purposeful model parameters genesis at three different values of generation gap, proven as the most sensitive genetic algorithms parameter toward convergence time. Results obtained after the imple- mentation of intuitionistic fuzzy logic for MpGA performances assess- ment have been compared and MpGA at GGAP = 0.1 after the purposeful model parameters genesis procedure application has been dis- tinguished as the fastest and the most reliable one. Further, the promi- nent MpGA at GGAP = 0.1 has been compared to SGA at GGAP = 0.1. Obtained results have been assessed applying IFL and the most reliable algorithm has been distinguished. Among a number of searching tools, genetic algorithms (GA) are one of the methods based on biological evolution, inspired by Darwins theory of survival of the fittest. GA (1) are directed random search techniques, based on the mechan- ics of natural selection and genetics, and seek for the global optimal solution in complex multidimensional search space by simultaneously evaluating many points in the parameter space. Some properties such as hard problems solving, noise tolerance, easiness to interface and hybridize, make GA a suitable and quite workable tool especially for tasks which are not completely determined. Such an intractable problem and a real challenge for researchers is the parameter iden- tification of fermentation processes models (2,3,4,5,6). Modeling of fermentation processes, known as complex, dynamic systems with interdependent and time- varying process variables, is a specific task, rather difficult to be solved. Failure of conventional optimization methods to reach to a satisfactory solution for pa- rameters identification of fermentation process model (2,5) provokes idea genetic algorithms to be tested as an alternative technique.","D(4)-pair {k\u22122,k+2} and its extensionWe prove that if k\u2a7e3, c and d are positive integers with c&lt;d and the set {k\u22122,k+2,c,d} has the property that the product of any of its distinct elements increased by 4 is a perfect square, then d is uniquely determined. In the proof we use the standard methods used in solving similar problems. Namely, we firstly transform our problem into solving the system of simultaneous pellian equations which furthermore leads to finding intersection of binary recurrence sequences. We get the lower bound for solutions using mostly the congruence method. Combining it with hypergeometric method in which we give an improvement of known results in our special case we get the desired result for \u201clarge\u201d values of parameter k. The remaining values of k are solved using Baker\u02bcs theory of linear form in logarithms.","Influence Structure and Inter-group LearningInter-group learning is an important phenomenon in the modern business world of virtual organizations, distributed knowledge processing, and supply chain systems. Here, we examine how alternative influence structures within groups may affect the learning that happens through inter-group interactions. This study uses a simulation methodology with measures related to influence structure, knowledge matrices, and learning-task completion. The results indicate that the level of centrality in a group\u2019s own influence structure tends to negatively relate to its learning performance. The presence of an influential individual in a group will slow down the learning (require more rounds of interaction to get agreement), impede the spread of knowledge (learn less of the truth), and increase the chance of group conflict (increasing frequency of learning impasses). Furthermore when two groups both have highly centered influence structures, they are detrimental to each other\u2019s learning performance.","Carried object detection and tracking using geometric shape models and spatio-temporal consistencyThis paper proposes a novel approach that detects and tracks carried objects by modelling the person-carried object relationship that is characteristic of the carry event. In order to detect a generic class of carried objects, we propose the use of geometric shape models, instead of using pre-trained object class models or solely relying on protrusions. In order to track the carried objects, we propose a novel optimization procedure that combines spatio-temporal consistency characteristic of the carry event, with conventional properties such as appearance and motion smoothness respectively. The proposed approach substantially outperforms a state-of-the-art approach on two challenging datasets PETS2006 and MINDSEYE2012.","Multi-level Decompositions of Electronic Wave Functions ","Modeling and Simulation of Hadoop Distributed File System in a Cluster of WorkstationsConsidering the increased hard disk capacity on desktop PCs, we examine, by the modeling and simulation technique, the feasibility of exploiting the idle computational storage in a large Cluster of Workstations COW. The model built is architecturally based on the Hadoop Distributed File System HDFS and was implemented in the CPN Tools using the Coloured Petri Nets combined with the CPN ML programming language. To characterize the workstations' availability in the model, a statistical study was realized by collecting data from computer laboratories in our academic institution over a period of 40 days. From the simulation results, we propose a small modification in the source code of HDFS and a specific number of replicas in order to achieve a reliable service for writing and reading files despite the random failures due to the turning on and off of the computers in a COW with hundreds of machines.","How CIO Position Influences IT Investments and Firm Performance ","The Intelligent Room for Elderly CareDaily life assistance for elderly is one of the most promising and interesting scenarios for advanced technologies in the near future. Improving the quality of life of elderly is also some of the first priorities in modern countries and societies where the percentage of elder people is rapidly increasing due mainly to great improvements in medicine during the last decades. In this paper, we present an overview of our informa- tionally structured room that supports daily life activities of elderly with the aim of improving their quality of life. Our environment contains dif- ferent distributed sensors including a floor sensing system and several intelligent cabinets. Sensor information is sent to a centralized manage- ment system which processes the data and makes it available to a service robot which assists the people in the room. One important restriction in our intelligent environment is to maintain a small number of sensors to avoid interfering with the daily activities of people and to reduce as much as possible the invasion of their privacy. In addition we discuss some experiments using our real environment and robot.","Enforcing Privacy in Secondary User Information Sharing and Usage ","Complexity of Checking Bisimilarity between Sequential and Parallel Processes ","A Cluster-Based Incremental Recommendation Algorithm on Stream Processing ArchitectureBy helping users discover books they may be interested in, recommender systems fully exploit the resources of digital libraries and better facilitate users' reading demands. Traditional memory-based collaborative filtering (CF) methods are effective and easy to interpret. However, when datasets become larger, the traditional way turns to be infeasible in both time and space. In order to address this challenge, we propose an incremental, cluster-based algorithm on Stream Processing Architecture, which is scalable and suitable to real-time environment. Our experimental results on MovieLens datasets and CADAL user-chapter logs show our algorithm is efficient, while still maintains comparable accuracy and interpretability.","Virtual Multiple Errands Test: reliability, usability and possible applications ","Using Various Types of Multimedia Resources to Train System for Automatic Transcription of Czech Historical Oral ArchivesHistorical spoken documents represent a unique segment of national cultural heritage. In order to disclose the large Czech Radio audio archive to research community and to public, we have been developing a system whose aim is to transcribe automatically the archive files, index them and make them searchable. The transcription of contemporary (1 or 2 decades old) documents is based on the lexicon and statistical language model (LM) built from a large amount of recent texts available in electronic form. From the older periods (before 1990), however, digital texts do not exist. Therefore, we needed a) to find resources that represent language of those times, b) to convert them from their original form to text, c) to utilize this text for creating epoch specific lexicons and LMs, and eventually, d) to apply them in the developed speech recognition system. In our case, the main resources included: scanned historical newspapers, shorthand notes from the national parliament and subtitles from retro TV programs. When converted into text, they allowed us to built a more appropriate lexicon and to produce a preliminary version of the transcriptions. These were reused for unsupervised retraining of the final LM. In this way, we significantly improved the accuracy of the automatically transcribed radio news broadcast in 1969-1989 era, from initial 83 % to 88 %.","Using bees hill flux balance analysis (BHFBA) for in silico microbial strain optimizationMicrobial strains can be manipulated to improve product yield and improve growth characteristics. Optimization algorithms are developed to identify the effects of gene knockout on the results. However, this process is often faced the problem of being trapped in local minima and slow convergence due to repetitive iterations of algorithm. In this paper, we proposed Bees Hill Flux Balance Analysis (BHFBA) which is a hybrid of Bees Algorithm, Hill Climbing Algorithm and Flux Balance Analysis to solve the problems and improve the performance in predicting optimal sets of gene deletion for maximizing the growth rate and production yield of desired metabolite. Escherichia coli is the model organism in this paper. The list of knockout genes, growth rate and production yield after the deletion are the results from the experiments. BHFBA performed better in term of computational time, stability and production yield.","Human detection algorithm based on bispectrum analysis for IR-UWB radarImpulse-radio Ultra-wide band (IR-UWB) radar plays an important role in searching and detecting human target in particular situations, such as counterterrorism, post-disaster search and rescue and so on. It mainly takes the advantages of its good penetrability through obstacles and high range resolution. It detects human target mainly by detecting the respiratory signal. As the higher order spectrum is immune to the Gaussian noise, a new algorithm based on the bispectrum analysis for human detection behind the wall is proposed. The results of the through-wall experiments show the algorithm has a better performance than the conventional PSD-based algorithm.","Adaptive consoles for supervisory control of multiple unmanned aerial vehiclesWith the prevailing increase of complex operational scenarios, involving multiple unmanned aerial vehicles (UAV), the concerns with the natural increase of operator workload and reduction of situational awareness have become paramount in order to safeguard operational security and objective completion. These challenges can be tackled through alterations of the autonomy levels of the vehicles, however this paper explores how these issues can also be mitigated by changing the way information is presented to the human operator. Relying upon an established framework, that supports operational scenarios with multiple UAVs, a series of display alterations were performed to existing operation consoles. After test sessions, in a simulated environment, with human participants of different levels of operational certification, feedback and results are distilled and analysed. Operator feedback demonstrated an overwhelming preference for the developed consoles and results showed an improvement of situation awareness, as well as reduction of workload.","Self-organized neural learning of statistical inference from high-dimensional dataWith information about the world implicitly embedded in complex, high-dimensional neural population responses, the brain must perform some sort of statistical inference on a large scale to form hypotheses about the state of the environment. This ability is, in part, acquired after birth and often with very little feedback to guide learning. This is a very difficult learning problem considering the little information about the meaning of neural responses available at birth. In this paper, we address the question of how the brain might solve this problem: We present an unsupervised artificial neural network algorithm which takes from the self-organizing map (SOM) algorithm the ability to learn a latent variable model from its input. We extend the SOM algorithm so it learns about the distribution of noise in the input and computes probability density functions over the latent variables. The algorithm represents these probability density functions using population codes. This is done with very few assumptions about the distribution of noise. Our simulations indicate that our algorithm can learn to perform similar to a maximum likelihood estimator with the added benefit of requiring no a-priori knowledge about the input and computing not only best hypotheses, but also probabilities for alternatives.","AcceSciTech: A Global Approach to Make Scientific and Technical Literature Accessible ","FESA: fold- and expand-based shape analysisA static shape analysis is presented that can prove the absence of NULL- and dangling pointer dereferences in standard algorithms on lists, trees and graphs. It is conceptually simpler than other analyses that use symbolically represented logic to describe the heap. Instead, it represents the heap as a single graph and a Boolean formula. The key idea is to summarize two nodes by calculating their common points-to information, which is done using the recently proposed fold and expand operations. The force of this approach is that both, fold and expand, retain relational information between points-to edges, thereby essentially inferring new shape invariants. We show that highly precise shape invariants can be inferred using off-the-shelf SAT-solvers. Cheaper approximations may augment standard points-to analysis used in compiler optimisations.","Spectral rotation versus K-means in spectral clusteringSpectral clustering has been a popular data clustering algorithm. This category of approaches often resort to other clustering methods, such as K-Means, to get the final cluster. The potential flaw of such common practice is that the obtained relaxed continuous spectral solution could severely deviate from the true discrete solution. In this paper, we propose to impose an additional orthonormal constraint to better approximate the optimal continuous solution to the graph cut objective functions. Such a method, called spectral rotation in literature, optimizes the spectral clustering objective functions better than K-Means, and improves the clustering accuracy. We would provide efficient algorithm to solve the new problem rigorously, which is not significantly more costly than K-Means. We also establish the connection between our method and K-Means to provide theoretical motivation of our method. Experimental results show that our algorithm consistently reaches better cut and meanwhile outperforms in clustering metrics than classic spectral clustering methods.","How do Infomediaries affect firms\u2019 information strategies, and how do they impact buyer and social welfare?Product information websites have become ubiquitous. This article explores their impact on firm profitability, consumer surplus, and social welfare. Using an analytical model, we show that firms take advantage of such infomediaries and cut down on their own information investments, increasing their profitability. Surprisingly, we find that the existence of these websites may be reducing social welfare, even if we ignore their cost of operation. In addition, and contrary to the common belief that product information websites are good for buyers, we show that they may be hurting consumers, even when their goal is to maximize consumer surplus. These findings lead us to recommend that product information websites should focus on roles that complement, rather than substitute, the information disclosure investments that firms freely choose on their own accord.","Fuzzy Linguistic Preference Relations Approach: Evaluation in Quality of HealthcareThis study proposes a linguistic preference relations approach to evaluate the quality of healthcare under a fuzzy environment. Pairwise comparisons are utilized to derive the importance weights of evaluation criteria and to obtain the performance rating of feasible healthcare organizations. The subjectivity and vagueness in the evaluation processes are dealt with linguistic variables parameterized by triangular fuzzy numbers. By calculating the distance of each feasible healthcare organization to the fuzzy positive ideal reference point (FPIRP) and the fuzzy negative ideal reference point (FNIRP) respectively, a closeness coefficient is obtained and utilized to rank the order of all feasible healthcare organizations. A case is simultaneously shown to demonstrate the computational procedures of this proposed approach.","Exploring Offline Browsing Patterns to Enhance the Online Environment ","A maximum K-min approach for classificationIn this paper, a general Maximum K-Min approach for classification is proposed. With the physical meaning of optimizing the classification confidence of the K worst instances, Maximum K-Min Gain/Minimum K-Max Loss (MKM) criterion is introduced. To make the original optimization problem with combinational number of constraints computationally tractable, the optimization techniques are adopted and a general compact representation lemma for MKM Criterion is summarized. Based on the lemma, a Nonlinear Maximum K-Min (NMKM) classifier and a Semi-supervised Maximum K-Min (SMKM) classifier are presented for traditional classification task and semi-supervised classification task respectively. Based on the experiment results of publicly available datasets, our Maximum K-Min methods have achieved competitive performance when comparing against Hinge Loss classifiers.","A Study About Security Awareness Program Based on RFID Access Control System ","Simulated annealing for real-time vertical-handoff in wireless networksWhen a mobile terminal is moving across heterogeneous wireless networks acting as access points, it must decide the best network to connect to, taking into account the values of the quality of service parameters of the networks. Selecting an optimal set of weights for these values in the terminal is an optimization problem that must be solved in real time for embedded microprocessors that manage the Vertical Handoff decision phase in highly dynamic environments. For this purpose, we have developed an adaptive heuristic inspired on the Simulated Annealing algorithm that improves the performance of a former algorithm designed to solve this optimization problem.","GA for JSP with Delivery TimeThis paper describes a job-shop scheduling problem (JSP) of processing product subject to no delay time job. It is one objective model of the minimum delivery delay time.In this paper, the effectiveness we the numerical experiments using a benchmark problem to improve the solution accuracy and decrease execution time by adding a method to generate gene and new approach, we introduce a search method for the algorithm shorter delivery times and further there to verify.","MaSh: machine learning for sledgehammerSledgehammer integrates automatic theorem provers in the proof assistant Isabelle/HOL. A key component, the relevance filter, heuristically ranks the thousands of facts available and selects a subset, based on syntactic similarity to the current goal. We introduce MaSh, an alternative that learns from successful proofs. New challenges arose from our \"zero-click\" vision: MaSh should integrate seamlessly with the users' workflow, so that they benefit from machine learning without having to install software, set up servers, or guide the learning. The underlying machinery draws on recent research in the context of Mizar and HOL Light, with a number of enhancements. MaSh outperforms the old relevance filter on large formalizations, and a particularly strong filter is obtained by combining the two filters.","Short Communication: IF-TODIM: An intuitionistic fuzzy TODIM to multi-criteria decision makingThe recently developed fuzzy TODIM (an acronym in Portuguese for iterative multi-criteria decision making) method using fuzzy numbers has been applied to uncertain MCDM problems with promising results. In this paper, a more general approach to the fuzzy TODIM, which takes into account the membership and the non-membership of the fuzzy information is considered. So, the fuzzy TODIM method has been extended to handle intuitionistic fuzzy information. This way, it is possible to tackle more challenging MCDM problems. Two case studies are used to illustrate and show the suitability of the developed method.","Gesture-Based Human-Machine Interface: A Case Study Comparing the Realism of Furniture Products in E-Commerce ","Multi-step classification approaches to cumulative citation recommendationKnowledge bases have become indispensable sources of information. It is therefore critical that they rely on the latest information available and get updated every time new facts surface. Knowledge base acceleration (KBA) systems seek to help humans expand knowledge bases like Wikipedia by automatically recommending edits based on incoming content streams. A core step in this process is that of identifying relevant content, i.e., filtering documents that would imply modifications to the attributes or relations of a given target entity. We propose two multi-step classification approaches for this task that consist of two and three binary classification steps, respectively. Both methods share the same initial component, which is concerned with the identification of entity mentions in documents, while subsequent steps involve identification of documents being relevant and/or central to a given entity. Using the evaluation platform of the TREC 2012 KBA track and a rich feature set developed for this particular task, we show that both approaches deliver state-of-the-art performance.","Applying Psychology to Facilitate Participation in Conceptual Modelling ","Construction of multi-scale common brain networks based on DICCCOLModeling the human brain as a network has been widely considered as a powerful approach to investigating the brain's structural and functional systems. However, many previous approaches focused on a single scale of brain network and the multi-scale nature of brain networks has been rarely explored yet. This paper put forward a novel framework to construct multi-scale common networks of brains via multi-scale spectral clustering of fiber connections among DICCCOLs. Specifically, the recently developed and publicly released DICCCOLs provide the nodal structural and functional correspondence across individuals, and thus the employed multi-scale spectral clustering algorithm divided the DICCCOL landmarks and their connections into sub-networks with correspondences on multiple scales. Experimental results showed the promise of the constructed multi-scale networks in applications of structural and functional connectivity mapping. As an application example, these multi-scale networks are used to guide the identification of multi-scale common fiber bundles across individuals and to facilitate the bundle's functional role analysis, which could enable other tract-based and network-based analyses in the future.","Multi-view maximum entropy discriminationMaximum entropy discrimination (MED) is a general framework for discriminative estimation based on the well known maximum entropy principle, which embodies the Bayesian integration of prior information with large margin constraints on observations. It is a successful combination of maximum entropy learning and maximum margin learning, and can subsume support vector machines (SVMs) as a special case. In this paper, we present a multi-view maximum entropy discrimination framework that is an extension of MED to the scenario of learning with multiple feature sets. Different from existing approaches to exploiting multiple views, such as co-training style algorithms and co-regularization style algorithms, we propose a new method to make use of the distinct views where classification margins from these views are required to be identical. We give the general form of the solution to the multi-view maximum entropy discrimination, and provide an instantiation under a specific prior formulation which is analogical to a multi-view version of SVMs. Experimental results on real-world data sets show the effectiveness of the proposed multi-view maximum entropy discrimination approach.","ODE parameter inference using adaptive gradient matching with Gaussian processesParameter inference in mechanistic models based on systems of coupled differential equa- tions is a topical yet computationally chal- lenging problem, due to the need to fol- low each parameter adaptation with a nu- merical integration of the differential equa- tions. Techniques based on gradient match- ing, which aim to minimize the discrepancy between the slope of a data interpolant and the derivatives predicted from the differen- tial equations, offer a computationally ap- pealing shortcut to the inference problem. The present paper discusses a method based on nonparametric Bayesian statistics with Gaussian processes due to Calderhead et al. (2008), and shows how inference in this model can be substantially improved by consistently inferring all parameters from the joint dis- tribution. We demonstrate the efficiency of our adaptive gradient matching technique on three benchmark systems, and perform a de- tailed comparison with the method in Calder- head et al. (2008) and the explicit ODE inte- gration approach, both in terms of parameter inference accuracy and in terms of computa- tional efficiency.","Supervising random forest using attribute interaction networksGenome-wide association studies (GWAS) have become a powerful and affordable tool to study the genetic variations associated with common human diseases. However, only few of the loci found are associated with a moderate or large increase in disease risk and therefore using GWAS findings to study the underlying biological mechanisms remains a challenge. One possible cause for the \"missing heritability\" is the gene-gene interactions or epistasis. Several methods have been developed and among them Random Forest (RF) is a popular one. RF has been successfully applied in many studies. However, it is also known to rely on marginal main effects. Meanwhile, networks have become a popular approach for characterizing the space of pairwise interactions systematically, which can be informative for classification problems. In this study, we compared the findings of Mutual Information Network (MIN) to that of RF and observed that the variables identified by the two methods overlap with differences. To integrate advantages of MIN into RF, we proposed a hybrid algorithm, MIN-guided RF (MINGRF), which overlays the neighborhood structure of MIN onto the growth of trees. After comparing MINGRF to the standard RF on a bladder cancer dataset, we conclude that MINGRF produces trees with a better accuracy at a smaller computational cost.","Spectral Decomposition for Optimal Graph Index Prediction ","Healthcare System Focusing on Emotional Aspect Using Augmented Reality: Control Breathing Application in Relaxation Service ","Power Aware Cluster Based Routing (PACBR) Protocol for Wireless Sensor Network ","Yet Another Fault-Based Leakage in Non-uniform Faulty CiphertextsThis paper discusses the information leakage that comes from the non-uniform distribution of the faulty calculation results for hardware AES implementations under setup-time violations. For the setup-time violation, it is more difficult to predict the faulty value than the introduced difference itself. Therefore, the faulty calculation results have been always paired with the fault-free calculations as the information leakage. However, the faulty calculation results under statistical analyses can directly leak the secret. This leakage is mainly caused by the circuit structure rather than the transition differences for variant input data. Generally, this work explains the mechanism of the non-uniform distribution of faulty calculation results. For the widely used composite field based AES S-box, we explain and demonstrate that the probability of the emergence of a particular faulty value is much higher than other values. We use the key recovery method proposed by Fuhr et al., and show the successful key recovery using only the faulty calculation results. In addition, against the attack target that encrypts random plaintexts, we extend the attack in case the faults are injected remotely using electromagnetic interference without any injection timing trigger.","A Proof of Strong Normalisation of the Typed Atomic Lambda-CalculusThe atomic lambda-calculus is a typed lambda-calculus with explicit sharing, which originates in a Curry-Howard interpretation of a deep-inference system for intuitionistic logic. It has been shown that it allows fully lazy sharing to be reproduced in a typed setting. In this paper we prove strong normalization of the typed atomic lambda-calculus using Tait's reducibility method.","An Economical Query Cost Model in the CloudThe Cloud Computing    $\\mathcal{C}\\mathcal{C}$    brings a new approach of information technology IT consumption and is changing the investment manner of enterprises and companies. While the reputation of    $\\mathcal{C}\\mathcal{C}$    is increasing, a large number of applications managing large amount of data are moving towards the Cloud which incorporates several new dimension: payment, query processing, etc.. The analytical data management applications are an example of those applications. They are intended to the decision support process requiring complex queries. To optimize these queries, optimization structures such as indexes and materialized views are required. In the traditional database infrastructures centralized, parallel, distributed, etc., the choice of the optimal configuration of optimization structures is usually guided by mathematical cost models. They are used to quantify the quality of the obtained solutions. The purpose of our work is to develop a cost model to select materialized views in the Cloud. The main characteristic of our cost model is that it considers the payment cost and the query processing paradigm. Intensive experiments were conducted using our cost model and the obtained results are deployed in an assimilated Cloud infrastructure.","Learning Features for Activity Recognition with Shift-Invariant Sparse CodingIn activity recognition, traditionally, features are chosen heuristically, based on explicit domain knowledge. Typical features are statistical measures, like mean, standard deviation, etc., which are tailored to the application at hand and might not fit in other cases. However, Feature Learning techniques have recently gained attention for building approaches that generalize over different application domains. More conventional approaches, like Principal Component Analysis, and newer ones, like Deep Belief Networks, have been studied so far and yielded significantly better results than traditional techniques. In this paper we study the potential of Shift-invariant Sparse Coding (SISC) as an additional Feature Learning technique for activity recognition. We evaluate the performance on several publicly available activity recognition data sets and show that classification based on features learned by SISC outperforms other previously presented Feature Learning techniques.","Utilizing Cloud-Computation to Analyze the Causative Factors of Rainfall-Induced LandslideAmong the various natural hazards, landslides are among the most widespread and damaging one. It can be triggered by various external stimuli and pose significant threat to human safety and natural environment. Geospatial computingis currentlyfacing a daunting challenge in data management and processing with ever-increasing complexity and heterogeneity .Different approaches have been developed to produce landslide susceptibility maps. This paper reports a pilot study of analyzing the causative factors of landslide and proposes to utilize the geospatial cloud-computing method in mapping the rainfall-induced landslide susceptibility. A series of geospatial data of triggering stimulus are acquired. The cloud computation platform is utilized to analyze some selected environmental parameters in Lantau Island, Hong Kong. The emergence of cloud computing brings potential solutions to solve the geospatial intensity problems and will enable the public to better prepare for such deadly events and to help mitigate any potential damages.","Augmented Interface Systems for the Darcy-Stokes ProblemThe final publication is available at Springer via http://dx.doi.org/10.1007/978-3-642-35275-1_48","New Long-Term Glimpse of RC4 Stream CipherIn 1996, Jenkins pointed out a correlation between the hidden state and the output keystream of RC4, which is well known as the Glimpse theorem. With a permutation of size N-bytes, the probability of guessing one location by random association is 1/N, whereas the existing correlations related to glimpse allow an adversary to guess a permutation location, using the knowledge of the keystream output bytes, with probability 2/N. To date, this is the best known state-leakage based on glimpse. For the first time in RC4 literature, we show that there are certain events that leak state information with a probability of 3/N, considerably higher than the existing results. Further, the new glimpse correlation that we observe is a long-term phenomenon; it remains valid at any stage of the evolution of RC4 Pseudo Random Generation Algorithm PRGA. This new glimpse with a considerably higher probability of state-leakage may potentially have serious ramifications towards state-recovery attacks on RC4.","Unsupervised Fiber Bundles Registration Using Weighted Measures Geometric DemonsBrain image registration aims at reducing anatomical variability across subjects to create a common space for group analysis. Multi-modal approaches intend to minimize cortex shape variations along with internal structures, such as fiber bundles. A difficulty is that it requires a prior identification of these structures, which remains a challenging task in the absence of a complete reference atlas. We propose an extension of the log-Geometric Demons for jointly registering images and fiber bundles without the need of point or fiber correspondences. By representing fiber bundles as Weighted Measures we can register subjects with different numbers of fiber bundles. The efficacy of our algorithm is demonstrated by registering simultaneously T 1 images and between 37 and 88 fiber bundles depending on each of the ten subject used. We compare results with a multi-modal T 1 + Fractional Anisotropy (FA) and a tensor-based registration algorithms and obtain superior performance with our approach.","A novel framework for image forgery localizationImage forgery localization is a very active and open research field for the difficulty to handle the large variety of manipulations a malicious user can perform by means of more and more sophisticated image editing tools. Here, we propose a localization framework based on the fusion of three very different tools, based, respectively, on sensor noise, patch-matching, and machine learning. The binary masks provided by these tools are finally fused based on some suitable reliability indexes. According to preliminary experiments on the training set, the proposed framework provides often a very good localization accuracy and sometimes valuable clues for visual scrutiny.","A discipline for program verification based on backpointers and its use in observational disjointnessIn the verification of programs that manipulate the heap, logics that emphasize localized reasoning, such as separation logic, are being used extensively. In such logics, state conditions may only refer to parts of the heap that are reachable from the stack. However, the correct implementation of some data structures is based on state conditions that depend on unreachable locations. For example, reference counting depends on the invariant that \"the number of nodes pointing to a certain node is equal to its reference counter\". Such conditions are cumbersome or even impossible to formalize in existing variants of separation logic.#R##N##R##N#In the first part of this paper, we develop a minimal programming discipline that enables the programmer to soundly express backpointer conditions, i.e., state conditions that involve heap objects that point to the reachable part of the heap, such as the above-mentioned reference counting invariant.#R##N##R##N#In the second part, we demonstrate the expressiveness of our methodology by verifying the implementation of concurrent copy-on-write lists (CCoWL). CCoWL is a data structure with observational disjointness, i.e., its specification pretends that different lists depend on disjoint parts of the heap, so that separation logic reasoning is made easy, while its implementation uses sharing to maximize performance. The CCoWL case study is a very challenging problem, to which we are not aware of any other solution.","Answer set programming modulo theories and reasoning about continuous changesAnswer Set Programming Modulo Theories is a new framework of tight integration of answer set programming (ASP) and satisfiability modulo theories (SMT). Similar to the relationship between first-order logic and SMT, it is based on a recent proposal of the functional stable model semantics by fixing interpretations of background theories. Analogously to a known relationship between ASP and SAT, \"tight\" ASPMT programs can be translated into SMT instances. We demonstrate the usefulness of ASPMT by enhancing action language C+ to handle continuous changes as well as discrete changes. We reformulate the semantics of C+ in terms of ASPMT, and show that SMT solvers can be used to compute the language. We also show how the language can represent cumulative effects on continuous resources.","Design guidelines for coffee vending machinesWalk-up-and-use-systems such as vending and self-service machines request special attention concerning an easy to use and self-explanatory user interface. In this paper we present a set of design guidelines for coffee vending machines based on the results of an expert-based usability evaluation of thirteen different models.","Acceleration Signal Based Linear Formation Driving Model: Algorithmic Description and Simulation ResultsPlatoon vehicles coordination is an important topic at Inte- lligent Transportation Systems these days. For coordinating two or more vehicles, it is needed both a communication method between them, and an environment sensing strategy enabling the triangulation and correc- tion, when needed, of each vehicle relative position within the desired platoon. In this research we present a new strategy to keep a group of vehicles in a fixed platoon, that may complement classic approaches. Usually, in a platoon, every follower vehicle try to keep a distance to the vehicle right ahead. That lateral and longitudinal control is kept considering the sensed distances by using laser, radar or vision. In the present paper we want to propose a new concept that con- sists on sharing the leader's acceleration signal all across the whole ve- hicle platoon. In a few words, all the followers try to implement the leader's sensed and transmitted acceleration. Theoretically, two solids experiencing the same accelerations will reproduce identical trajectories while keeping the initial relative distances, if they start from the same initial non-zero constant speed. In this paper we present this new concept, we list what are some of the technological challenges to be addressed before its implementation, and we finally share some initial simulation results.","Towards inter-organizational Enterprise Architecture Management - Applicability of TOGAF 9.1 for Network Organizations. ","Scaling graph computations at facebookWith over a billion nodes and hundreds of billions of edges, scalability is at the forefront of concerns when dealing with the Facebook social graph. This talk will focus on two recent advances in graph computations at Facebook. The first focus concerns the development of a novel graph sharding algorithm - Balanced Label Propagation - for load-balancing distributed graph computations. Using Balanced Label Propagation, we were able to reduce by 50% the query time of Facebook's 'People You May Know' service, the realtime distributed system responsible for the feature extraction and ranking of the friends-of-friends of all active Facebook users. The second focus concerns the 2011 computation of the average distance distribution between all active Facebook users. This computation, which produced an average distance of 4.74, was made possible by two recent computational advances: Hyper-ANF, a modern probabilistic algorithm for computing distance distributions, and Layered Label Propagation, a modern compression scheme suited for social graphs. The details of how this computation was coordinated will be described. The talk describes joint work with Lars Backstrom, Paolo Boldi, Marco Rosa, and Sebastiano Vigna.","The Study of the Role Analysis Method of Key Papers in the Academic Networks. ","Optimizing RDF(S) queries on cloud platformsScalable processing of Semantic Web queries has become a critical need given the rapid upward trend in availability of Semantic Web data. The MapReduce paradigm is emerging as a platform of choice for large scale data processing and analytics due to its ease of use, cost effectiveness, and potential for unlimited scaling. Processing queries on Semantic Web triple models is a challenge on the mainstream MapReduce platform called Apache Hadoop, and its extensions such as Pig and Hive. This is because such queries require numerous joins which leads to lengthy and expensive MapReduce workflows. Further, in this paradigm, cloud resources are acquired on demand and the traditional join optimization machinery such as statistics and indexes are often absent or not easily supported.   In this demonstration, we will present RAPID+, an extended Apache Pig system that uses an algebraic approach for optimizing queries on RDF data models including queries involving inferencing. The basic idea is that by using logical and physical operators that are more natural to MapReduce processing, we can reinterpret such queries in a way that leads to more concise execution workflows and small intermediate data footprints that minimize disk I/Os and network transfer overhead. RAPID+ evaluates queries using the  Nested TripleGroup Data Model and Algebra (NTGA). The demo will show comparative performance of NTGA query plans vs. relational algebra-like query plans used by Apache Pig and Hive.","NEON implementation of an attribute-based encryption schemeIn 2011, Waters presented a ciphertext-policy attribute- based encryption protocol that uses bilinear pairings to provide control access mechanisms, where the set of user's attributes is specified by means of a linear secret sharing scheme. Some of the applications foreseen for this protocol lie in the context of mobile devices such a smartphones and tablets, which in a majority of instances are powered by an ARM processor supporting the NEON vector set of instructions. In this paper we present the design of a software cryptographic library that implements a 127-bit security level attribute-based encryption scheme over mobile devices equipped with a 1.4GHz Exynos 4 Cortex-A9 processor and a developing board that hosts a 1.7 GHz Exynos 5 Cortex-A15 processor. For the latter platform and taking advantage of the inherent parallelism of the NEON vector instructions, our library computes a single optimal pairing over a Barreto-Naehrig curve approximately 2 times faster than the best timings previously reported on ARM platforms at this level of security. Further, using a 6-attribute access formula our library is able to encrypt/decrypt a text/ciphertext in less than 7.5mS and 15.67mS, respectively.","Digital Factory Assistant: Conceptual Framework and Research Propositions ","Construction of Privacy Preserving Hypertree Agent Organization as Distributed Maximum Spanning TreeDecentralized probabilistic reasoning, constraint reasoning, and deci- sion theoretic reasoning are some of the essential tasks of a multiagent system (MAS). Many frameworks exist for these tasks, and a number of them organize agents into a junction tree (JT). Although these frameworks all reap benefits of communication efficiency and inferential soundness from the JT organization, their potential capacity on agent privacy has not been realized fully. The contri- bution of this work is a general approach to construct the JT organization through a maximum spanning tree (MST), and a new distributed MST algorithm, that preserve agent privacy on private variables, shared variables and agent identities.","Design and Implementation of a Daily Activity Scheduler in the Context of a Personal Travel Information System ","Applying remote side-channel analysis attacks on a security-enabled NFC tagThe number of applications that rely on near-field communication (NFC) technology is significantly growing. Especially for security-related applications, short communication ranges as they are provided by NFC systems are advantageous to minimize the risk of eavesdropping. In this work we show that although the communication range of NFC systems is limited to several centimeters, side-channel information modulated on the reader signal can be measured at much larger distances. We name the side-channel information modulated on the reader signal parasitic load modulation. By measuring the parasitic load modulation of a tag, so-called remote side-channel analysis (SCA) attacks can be applied. We verify the practicability of such remote attacks by analyzing a security-enabled NFC tag with an integrated Advanced Encryption Standard (AES) module. The analyzed NFC tag operates at a carrier frequency of 13.56 MHz and uses the well known ISO 14443A communication standard. We were able to conduct successful remote SCA attacks at distances up to 1 m. No special measurement equipment is required, a self-made loop antenna, a broadband amplifier, and an oscilloscope are sufficient. We further formulate a relationship between attack performance and measurement distance that is confirmed by our practical results. These are the first remote SCA attacks on an NFC tag and on tags operating in the high-frequency range at 13.56 MHz at all. The results emphasize that the integration of suitable SCA countermeasures is inevitable.","Comparison and Analysis of Several Phonetic Decoding ApproachesThis article analyzes the phonetic decoding performance obtained with different choices of linguistic units. The context is to later use such an approach as a support for helping communication with deaf people, and to run it on an embedded decoder on a portable terminal, which introduces constrains on the model size. As a first step, this paper compares the performance of various approaches on the ESTER2 and ETAPE speech corpora. Two baseline systems are considered, one relying on a large vocabulary speech recognizer, and another one relying on a phonetic n-gram language model. The third model which relies on a syllable-based lexicon and a trigram language model, provides a good tradeoff between model size and phonetic decoding performance. The phone error rate is only 4% worse (absolute) than the phone error rate obtained with the large vocabulary recognizer, and much better than the phone error rate obtained with the phone n-gram language model. Phone error rates are then analyzed with respect to SNR and speaking rate.","Discriminative learning of first-order weighted abduction from partial discourse explanationsAbduction is inference to the best explanation. Abduction has long been studied in a wide range of contexts and is widely used for modeling artificial intelligence systems, such as diagnostic systems and plan recognition systems. Recent advances in the techniques of automatic world knowledge acquisition and inference technique warrant applying abduction with large knowledge bases to real-life problems. However, less attention has been paid to how to automatically learn score functions, which rank candidate explanations in order of their plausibility. In this paper, we propose a novel approach for learning the score function of first-order logic-based weighted abduction [1] in a supervised manner. Because the manual annotation of abductive explanations (i.e. a set of literals that explains observations) is a time-consuming task in many cases, we propose a framework to learn the score function from partially annotated abductive explanations (i.e. a subset of those literals). More specifically, we assume that we apply abduction to a specific task, where a subset of the best explanation is associated with output labels, and the rest are regarded as hidden variables. We then formulate the learning problem as a task of discriminative structured learning with hidden variables. Our experiments show that our framework successfully reduces the loss in each iteration on a plan recognition dataset.","Fine-Grained Software Evolution Using UML Activity and Class ModelsModern software systems that play critical roles in society's infrastructures are often required to change at runtime so that they can continuously provide essential services in the dynamic environments they operate in. Updating open, distributed software systems at runtime is very challenging. Using runtime models as an interface for updating software at runtime can help developers manage the complexity of updating software while it is executing. In this work we describe an approach to updating Java software at runtime through the use of runtime models consisting of UML class and activity diagrams. Changes to models are turned into changes on Java source code, which is then propagated to the runtime system using the JavAdaptor technology. In particular, the presented approach permits in-the-small software changes, i.e., changes at the code statement level, as opposed to in-the-large changes, i.e., changes at the component level. We present a case study that demonstrates the major aspects of the approach and its use.","Media Sharing in Situated Displays: Service Design Lessons from Existing Practices with Paper Leaflets ","GPU-Based Automatic Configuration of Differential Evolution: A Case Study ","Flocking and Generalized Factor AnalysisWe propose a new modeling paradigm for large dimensional aggregates of stochastic systems by Generalized Factor Analysis (GFA) models. These models describe the data as the sum of a flocking plus an uncorrelated idiosyncratic component. The flocking component describes a sort of collective orderly motion which admits a much simpler mathematical description than the whole ensemble while the idiosyncratic component describes weakly correlated noise. We first discuss static GFA representations and characterize in a rigorous way the properties of the two components. For wide-sense stationary sequences the character and existence of GFA models is completely clarified. The extraction of the flocking component of a random field is discussed for a simple class of separable random fields.","Using Behavior of Social Network Sites Based on Acceptance ModelThe population of social network sites (SNSs) users in the world is growing rapidly, and the growth rate is beyond imagination. In light of this, this study conducting in-depth interviews to discover the relevant clues and factors that may affect users' adoption of social network website. The results indicated that attitude has a significant influence on behavioral intention, and intrinsic motivation such as perceived playfulness has a positive influence on the creation of behavior intention. However, perceived usefulness shows no significant influence on behavioral motivation. Moreover, perceived playfulness, perceived ease of use, perceived usefulness, and relationship development all have significant influence on behavior and attitude.","Score Informed Tonic Identification for Makam Music of TurkeyTonic is a fundamental concept in many music traditions#R##N#and its automatic identification should be relevant for establishing#R##N#the reference pitch when we analyse the melodic#R##N#content of the music. In this paper, we present two methodologies#R##N#for the identification of the tonic in audio recordings#R##N#of makam music of Turkey, both taking advantage#R##N#of some score information. First, we compute a prominent#R##N#pitch and a audio kernel-density pitch class distribution#R##N#(KPCD) from the audio recording. The peaks in the#R##N#KPCD are selected as tonic candidates. The first method#R##N#computes a score KPCD from the monophonic melody extracted#R##N#from the score. Then, the audio KPCD is circularshifted#R##N#with respect to each tonic candidate and compared#R##N#with the score KPCD. The best matching shift indicates the#R##N#estimated tonic. The second method extracts the monophonic#R##N#melody of the most repetitive section of the score.#R##N#Normalising the audio prominent pitch with respect to each#R##N#tonic candidate, the method attempts to link the repetitive#R##N#structural element given in the score with the respective#R##N#time-intervals in the audio recording. The result producing#R##N#the most confident links marks the estimated tonic.#R##N#We have tested the methods on a dataset of makam music#R##N#of Turkey, achieving a very high accuracy (94.9%) with#R##N#the first method, and almost perfect identification (99.6%)#R##N#with the second method. We conclude that score informed#R##N#tonic identification can be a useful first step in the computational#R##N#analysis (e.g. expressive analysis, intonation analysis,#R##N#audio-score alignment) of music collections involving#R##N#melody-dominant content.","{log} as a Test Case Generator for the Test Template Framework{log} pronounced 'setlog' is a Constraint Logic Programming language that embodies the fundamental forms of set designation and a number of primitive operations for set management. As such, it can find solutions of first-order logic formulas involving set-theoretic operators. The Test Template Framework TTF is a model-based testing method for the Z notation. In the TTF, test cases are generated from test specifications, which are predicates written in Z. In turn, the Z notation is based on first-order logic and set theory. In this paper we show how {log} can be applied as a test case generator for the TTF. According to our experiments, {log} produces promising results compared to other powerful constraint solvers supporting the Z notation, such as ProB.","Nerding out on twitter: fun, patriotism and #curiosityThis paper presents an analysis of tweets collected over six days before, during and after the landing of the Mars Science Laboratory, known as Curiosity, in the Gale Crater on the 6th of August 2012. A sociological application of web science is demonstrated by use of parallel coordinate visualization as part of a mixed methods study. The results show strong, predominantly positive, international interest in the event. Scientific details dominated the stream, but, following the successful landing, other themes emerged such as fun, and national pride.","The Heritage of the People\u2019s Europe Project: An Aggregative Data Infrastructure for Cultural Heritage ","Approximation algorithms for the antenna orientation problemWe consider the following Antenna Orientation Problem: Given a connected Unit Disk Graph (UDG) formed by n identical omnidirectional sensors, what is the optimal range (or radius) which is necessary and sufficient for a given antenna beamwidth (or angle) \u03c6 so that after replacing the omnidirectional sensors by directional antennae of beamwidth \u03c6 we can determine an appropriate orientation of each antenna so that the resulting graph is strongly connected? The problem was first proposed and studied in Caragiannis et al. [3] where they showed that the antenna orientation problem can be solved optimally for \u03c6\u22658 \u03c0/5, and is NP-Hard for \u03c6&lt;2 \u03c0/3, where there is no approximation algorithm with ratio less than $\\sqrt{3}$, unless P=NP. In this paper we study beamwidth/range tradeoffs for the antenna orientation problem. Namely, for the full range of angles in the interval [0 , 2 \u03c0] we compare the antenna range provided by an orientation algorithm to the optimal possible for the given beamwidth. We employ the concept of (2,\u03c6)-connectivity, a generalization of the well-known 2-connectivity, which relates connectivity in the directed graph to the best possible antenna orientation at a given point of the graph and use this to propose new antenna orientation algorithms that ensure improved bounds on the antenna range for given angles and analyze their complexity.","A Query Expansion Approach Using the Context of the Search ","Analyzing business process architecturesIn recent years, Business Process Management has gained maturity in private and public organizations. Organization own large process collections. Organizing, analyzing, and managing them becomes more complex. In the course of this development, research on Business Process Architectures has gotten more attention over the last decade. A Business Process Architecture describes the relationships between business processes within a process collections as well as the guidelines to organize them. However, formalization and verification techniques are still missing in this context. To overcome this gap we propose a novel Petri net based Business Process Architecture formalization. Based on this, we can resort to known Petri net verification techniques for the analysis of Business Process Architectures patterns and anti-patterns in regard to their structural and behavioral properties. Our methodology is evaluated on a real use case from the public administration.","Assessment of body surface potential mapping in VDT-OperatorsComputer is a genius invention that has made human work more efficient. In spite of undeniable benefits, everyday long-term contact with computer screens is an occupational risk, which induces various undesirable health consequences. Exposure of the VDT-operators to the harmful occupational factors may lead to functional disorders like arrhythmia. BSPM is a diagnostic method enabling global and precise sampling the heart potentials all over the thoracic surface owing to the large number of recording electrodes. Data collected from 87 ECG waveforms is graphically presented as the body surface maps of various formats. Non-dipolar distribution of QRST isointegral maps reflects a heterogeneity of the refractory periods of the ventricles, which is supposed to account for creating a substrate for malignant and life- threatening arrhythmias. This method can be a specific indicator of the increased risk of severe ventricular arrhythmias occurring prior to abnormalities detectable on the standard 12-lead ECG recordings.","Automatic Detection of Different Harvesting Stages in Lettuce Plants by Using Chlorophyll Fluorescence Kinetics and Supervised Self Organizing Maps (SOMs) ","Ramsey goes visibly pushdownChecking whether one formal language is included in another is vital to many verification tasks. In this paper, we provide solutions for checking the inclusion of the languages given by visibly pushdown automata over both finite and infinite words. Visibly pushdown automata are a richer automaton model than the classical finite-state automata, which allows one, e.g., to reason about the nesting of procedure calls in the executions of recursive imperative programs. The highlight of our solutions is that they do not comprise automata constructions for determinization and complementation. Instead, our solutions are more direct and generalize the so-called Ramsey-based inclusion-checking algorithms, which apply to classical finite-state automata and proved effective there, to visibly pushdown automata. We also experimentally evaluate our algorithms thereby demonstrating the virtues of avoiding determinization and complementation constructions.","Resource sharing for control of wildland firesWildland fires (or wildfires) occur on all continents except for Antarctica. These fires threaten communities, change ecosystems, destroy vast quantities of natural resources and the cost estimates of the damage done annually is in the billions of dollars. Controlling wildland fires is resource-intensive and there are numerous examples where the resource demand has outstripped resource availability. Trends in changing climates, fire occurrence and the expansion of the wildland-urban interface all point to increased resource shortages in the future. One approach for coping with these shortages has been the sharing of resources across different wildland-fire agencies. This introduces new issues as agencies have to balance their own needs and risk-management with their desire to help fellow agencies in need. Using ideas from the field of multiagent systems, we conduct the first analysis of strategic issues arising in resource-sharing for wildland-fire control. We also argue that the wildland-fire domain has numerous features that make it attractive to researchers in artificial intelligence and computational sustainability.","Web Service Testing Tools: A Comparative StudyQuality of Service (QoS) has gained more importance with the increase in usage and adoption of web services. In recent years, various tools and techniques developed for measurement and evaluation of QoS of web services. There are commercial as well as open-source tools available today which are being used for monitoring and testing QoS for web services. These tools facilitate in QoS measurement and analysis and are helpful in evaluation of service performance in real-time network. In this paper, we describe three popular open-source tools and compare them in terms of features, usability, performance, and software requirements. Results of the comparison will help in adoption and usage of these tools, and also promote development and usage of open-source web service testing tools.","IRON: a machine for the automated synthesis of normative systemsThe automated synthesis of norms for coordination of multi-agent systems remains an open and complex problem. In this paper we present the Intelligent Robust On-line Norm Synthesis Machine (IRON), a system whose goal is the automated synthesis of norms. IRON is capable of synthesising norms that are at the same time effective (to ensure coordination) and necessary (to avoid over-regulation). IRON has been tested on a simulated traffic scenario to successfully synthesise norms that help cars avoid collisions. IRON is equipped with visualization features that provide support for an intuitive and informed monitoring of the synthesis process.","Some New Progress in Analyzing and Mining Uncertain and Probabilistic Data for Big Data AnalyticsUncertainty is ubiquitous in big data. Consequently, analyzing and mining uncertain and probabilistic data is important in big data analytics. In this short article, we review some recent progress in mining uncertain and probabilistic data in the hope that the problems, progress, and challenges can inspire interdisciplinary dialogues and lead to new research opportunities.","Unimodular Loop Transformations with Source-to-Source Translation for GPUsHeterogeneous computing architectures offer the opportunity to exploit the extremely high performances of systems which are composed of different subsystems, assuring at the same time low energy consumption and accessible costs. In order to benefit from all these advantages, each computing unit should be programmed by using a specific model with properly optimized code to process its workload at best.#R##N##R##N#In the path of building a source-to-source transformer tool to automate the translation of code for heterogeneous architectures made by a combination of several CPUs and GPUs, a series of translator building blocks on top of ROSE compiler infrastructure have been built. In this work is presented the module that performs unimodular loop transformations and that provides output for GPUs.#R##N##R##N#Transformers can be used in the tool either manually according to user preference, or automatically driven by knowledge based techniques, e. g. algorithmic concept recognition. A chain of code transformations can produce parallel code, relieving accelerators and multicore programming hardness.","Allowing Non-identifying Information Disclosure in Citizen Opinion EvaluationThe continuous participation of citizens in the decisional processes of the community through the submission of their opinions is a key factor of e-democracy. To do this, it appears very promising the use of lightweight e-voting systems relying on existing social networks, as a good way to solve the trade-off among security, usability and scalability requirements. Among the other security features, anonymity of citizens i.e., secreteness should be guaranteed, at least to be sure that the action of people is actually free from conditioning. However, the decisional process would be better driven if the opinions of citizens were mapped to social, economic, working, personal, non-identifying attributes. In this paper, by extending a previous solution working on existing social networks, we overcome the above limit by re-interpreting the classical concept of secreteness in such a way that a preference expressed by a citizen can be related to a number of certified attributes chosen by the citizen herself, yet keeping her anonymity.","Unifying Theories of Programming in IsabelleThis is a tutorial introduction to the two most basic theories in Hoare &amp; He's Unifying Theories of Programming and their mechanisation in the Isabelle interactive theorem prover. We describe the theories of relations and of designs pre-postcondition pairs, interspersed with their formalisation in Isabelle and example mechanised proofs.","Course lectures as problem-based learning interventions in virtual worldsVirtual Worlds (VWs) present considerable potential as future learning platforms, but further studies are required to assess their effectiveness in constructivist and collaborative learning situations. The paper investigates the suitability of VWs as a platform for hosting PBL (Problem-Based Learning) activities and explores their affordances in terms of collaboration support and learning effectiveness. We have designed an educational VW and developed a number of tools that support collaborative learning activities. Using this environment, we have conducted a PBL intervention that required from students to collaboratively design the user interface of a multimedia kiosk. We performed a thorough, formative, multi-method evaluation of the learning activity. The results reveal several encouraging findings about PBL and collaboration mediated by VWs, and lead to a series of recommendations.","AVR-Tree: Speeding Up the NN and ANN Queries on Location DataIn the paper, we study the problems of nearest neighbor queries (NN) and all nearest neighbor queries (ANN) on location data, which have a wide range of applications such as Geographic Information System (GIS) and Location based Service (LBS). We propose a new structure, termed AVR-Tree, based on the R-tree and Voronoi diagram techniques. Compared with the existing indexing techniques used for NN and ANN queries on location data, AVR-Tree can achieve a better trade- off between the pruning effectiveness and the index size for NN and ANN queries. We also conduct a comprehensive performance evaluation for the proposed techniques based on both real and synthetic data, which shows that AVR-Tree based NN and ANN algorithms achieve better performance compared with their best competitors in terms of both CPU and I/O costs.","Relationships for Cost and Uncertainty of Decision Trees ","Developing Transferable Clickstream Analytic Models Using Sequential Pattern Evaluation IndicesIn this paper, a method for constructing transferable \"web\" and \"clickstream\" prediction models based on sequential pattern evaluation indices is proposed. To predict end points, click streams are assumed as sequential data. Further, a sequential pattern generation method is applied to extract features of each click stream data. Based on these features, a classification learning algorithm is applied to construct click stream end point prediction models. In this study, the evaluation indices for sequential patterns are introduced to abstract each clickstream data for transferring the constructed predictive models between different periods. This method is applied to a benchmark clickstream dataset to predict the end points. The results show that the method can obtain more accurate predictive models with a decision tree learner and a classification rule learner. Subsequently, the evaluation of the availability for transferring the predictive morels between different periods is discussed.","Investigating Energy Consumption of an SRAM-based FPGA for Duty-Cycle ApplicationsWireless Sensor Networks (WSNs), in addition to enabling monitoring solutions for numerous new applications areas, have gained huge popularity as a cost-effective, dynamically scalable, easy to deploy and maintainable alternatives to conventional infrastructure-based monitoring solutions.A WSN consists of spatially distributed autonomous wireless sensor nodes that measure desired physical phenomena and operate in a collaborative manner to relay the acquired information wirelessly to a central location. A wireless sensor node, integrating the required resources to enable infrastructure-less distributed monitoring, is constrained by its size, cost and energy. In order to address these constraints, a typical wireless sensor node is designed based on low-power and low-cost modules that in turn provide limited communication and processing performances. Data and computation intensive wireless monitoring applications, on the other hand, not only demand higher communication bandwidth and computational performance but also require practically feasible operational lifetimes so as to reduce the maintenance cost associated with the replacement of batteries. In relation to the communication and processing requirements of such applications and the constraints associated with a typical wireless sensor node, this thesis explores energy efficient wireless sensor node architecture that enables realization of data and computation intensive applications.Architectures enabling raw data transmission and in-sensor processing with various technological alternatives are explored. The potential architectural alternatives are evaluated both analytically and quantitatively with regards to different design parameters, in particular, the performance and the energy consumption. For quantitative evaluation purposes, the experiments are conducted on vibration and image-based industrial condition monitoring applications that are not only data and computation intensive but also are of practical importance.Regarding the choice of an appropriate wireless technology in an architecture enabling raw data transmission, standard based communication technologies including infrared, mobile broadband, WiMax, LAN, Bluetooth, and ZigBee are investigated. With regards to in-sensor processing, different architectures comprising of sequential processors and FPGAs are realized to evaluate different design parameters, especially the performance and energy efficiency. Afterwards, the architectures enabling raw data transmission only and those involving in-sensor processing are evaluated so as to find an energy efficient solution. The results of this investigation show that in-sensor processing architecture, comprising of an FPGA for computation purposes, is more energy efficient when compared with other alternatives in relation to the data and computation intensive applications.Based on the results obtained and the experiences learned in the architectural evaluation study, an FPGA-based high-performance wireless sensor platform, the SENTIOF, is designed and developed. In addition to performance, the SETNIOF is designed to enable dynamic optimization of energy consumption. This includes enabling integrated modules to be completely switched-off and providing a fast configuration support to the FPGA. In order to validate the results of the evaluation studies, and to assess the performance and energy consumption of real implementations, both the vibration and image-based industrial monitoring applications are realized using the SENTIOF. In terms of computational performance for both of these applications, the real-time processing goals are achieved. For example, in the case of vibration-based monitoring, real-time processing performance for tri-axes (horizontal, vertical and axial) vibration data are achieved for sampling rates of more than 100 kHz.With regards to energy consumption, based on the measured power consumption that also includes the power consumed during the FPGA\u2019s configuration process, the operational lifetimes are estimated using a single cell battery (similar to an AA battery in terms of shape and size) with a typical capacity of 2600 mA. In the case of vibration-based condition monitoring, an operational lifetime of more than two years can be achieved for duty-cycle interval of 10 minutes or more. The achievable operational lifetime of image-based monitoring is more than 3 years for a duty-cycle interval of 5 minutes or more.","Garbage-Free reversible constant multipliers for arbitrary integersWe present a method for constructing reversible circuitry for multiplying integers by arbitrary integer constants. The method is based on Mealy machines and gives circuits whose size are (in the worst case) linear in the size of the constant. This makes the method unsuitable for large constants, but gives quite compact circuits for small constants. The circuits use no garbage or ancillary lines.","VALO5 \u2013 Innovation, Maturity Growth, Quality and ValorisationOrganisations and individuals maximise the likelihood of success through managing innovation. Ensuring the high quality of both process and product, sustaining and exploiting innovations creates value to the stakeholders. In this paper we explore the nexus of maturity, quality and valorisation. We consider that the growth of organisational maturity changes the nature and role of quality management and characterises valorisation. We propose a Valorisation model based on the INCISIV framework (which incorporates the PDCA Deming Improvement cycle) and the CMMI model for understanding, evaluating, measuring and improving the valorisation process, and the valorisation results.","Interaction of the elderly viewer with additional multimedia content to support the appreciation of television programsFor many people, television is still the main form of entertainment. The elderly population, in particular, spends much time at home and uses the television for companionship and entertainment. However, in some countries, due to low education level or the absence of it, to physical limitations and/or cognitive difficulties, to the lack of prior knowledge, among other difficulties, part of the elderly viewers do not enjoy enough the programs to have satisfaction with them. With the interactivity provided by the Digital TV, additional information may help the elderly viewer to better appreciate television programs and have more fun. This paper presents data from an observational case study conducted in the Brazilian scenario to analyze the interaction of elderly viewers with TV programs enriched with additional multimedia content in different formats. From the experience, some good practices for the design of additional multimedia content to the elderly viewer were formalized.","A Quality Control Model for Trustworthy Crowdsourcing in Collaborative Learning ","Science of winning soccer : emergent pattern-forming dynamics in association footballQuantitative analysis is increasingly being used in team sports to better understand performance in these stylized, delineated, complex social systems. Here we provide a first step toward understanding the pattern-forming dynamics that emerge from collective offensive and defensive behavior in team sports. We propose a novel method of analysis that captures how teams occupy sub-areas of the field as the ball changes location. We used the method to analyze a game of association football (soccer) based upon a hypothesis that local player numerical dominance is key to defensive stability and offensive opportunity. We found that the teams consistently allocated more players than their opponents in sub-areas of play closer to their own goal. This is consistent with a predominantly defensive strategy intended to prevent yielding even a single goal. We also find differences between the two teams' strategies: while both adopted the same distribution of defensive, midfield, and attacking players (a 4:3:3 system of play), one team was significantly more effective both in maintaining defensive and offensive numerical dominance for defensive stability and offensive opportunity. That team indeed won the match with an advantage of one goal (2 to 1) but the analysis shows the advantage in play was more pervasive than the single goal victory would indicate. Our focus on the local dynamics of team collective behavior is distinct from the traditional focus on individual player capability. It supports a broader view in which specific player abilities contribute within the context of the dynamics of multiplayer team coordination and coaching strategy. By applying this complex system analysis to association football, we can understand how players' and teams' strategies result in successful and unsuccessful relationships between teammates and opponents in the area of play.","The GMM Problem as One of the Estimation Methods of a Probability Density FunctionIn data analysis, we must be conscious of the probability density function of population distribution. Then it is a problem why the probability density function is expressed.#R##N##R##N#The estimation of a probability density function based on a sample of independent identically distributed observations is essential in a wide range of applications. The estimation method of probability density function \u0097 (1)a parametric method (2)a nonparametric method and (3)a semi-parametric method etc. \u0097 it is. In this paper, GMM problem is taken up as a semi-parametric method and We use a wavelet method as a powerful new technique. Compactly supported wavelets are particularly interesting because of their natural ability to represent data with intrinsically local properties.","Tagging and folksonomies for information retrieval in Web 2.0The aim of this paper is to emphasize the role of tagging and folksonomies in information retrieval in Web 2.0. Also, this paper justifies the existence of tagging and folksonomies for better information retrieval in Web 2.0. In recent years, Web 2.0 has become popular due to increased collaborations over the internet. Folksonomies are the characteristics of Web 2.0, which are user generated tagging services. Literature shows that folksonomies greatly enhance information retrieval in Web 2.0. In this paper we study the role of tagging and folksonomies in social information retrieval, types of folksonomies in various sites. Also, this paper summarizes the experiment carried out on social bookmarking site Dogear, to show that tagging is an effective way to retrieve the information on web-based applications. The relation between the users, tagged documents and tags has been summarized in this paper. Even though tagging plays a major role in enhancing information retrieval, literature shows uncontrolled vocabulary hinders the potential of tagging process. Motivation: The concept of tagging and folksonomies doesn't exist yet in a fast growing professional networking site LinkedIn. In this paper we propose a concept of tagging and folksonomy for LinkedIn to perform information retrieval efficiently.","Comparison of CHOKe and gCHOKe Active Queues Management Algorithms with the Use of Fluid Flow Approximation ","SuDoC: Semi-unsupervised Classification of Text Document Opinions Using a Few Labeled Examples and ClusteringThe presented novel procedure named SuDoC --- or Semi-unsupervised Document Classification --- provides an alternative method to standard clustering techniques when it is necessary to separate ai\u00be?very large set of textual instances into groups that represent the text-document semantics. Unlike the conventional clustering, SuDoC proceeds from an initial small set of typical specimen that can be created manually and which provides the necessary bias for generating appropriate classes. SuDoC starts with a higher number of generated clusters and --- to avoid over-fitting --- reiteratively decreases their quantity, increasing the resulting classification generality. The unlabeled instances are automatically labeled according to their similarity to the defined labeled samples, thus reaching higher classification accuracy in the future. The results of the presented strengthened clustering procedure are demonstrated using ai\u00be?real-world data set represented by hotel guests' unstructured reviews written in natural language.","Performance Analysis of SMAC Protocol in Wireless Sensor Networks Using Network Simulator (Ns-2)Energy effeciency of medium access control has been an active research area in wireless sensor networks since past few years. SMAC stands for Sensor-MAC protocol, which is designed on the basis of periodic listen- sleep mechanism of nodes for avoiding energy wastage because of idle listening. SMAC reduces energy consumptions because of collision, overhearing, control packet overhead and idle listening. This paper discusses the basic attribute of MAC protocols, their classification and the importance of SMAC protocol in wireless sensor networks. SMAC is developed primarily for Mote platform, and thereafter also implemented in Network Simulator-2.So without real hardware one can analyze the performance of SMAC under various application specific scenarios with NS-2.In this paper, the performance of SMAC protocol is analyzed under high and low traffic rates with different duty cycles in single hop scenario without the routing effect. The residual energy is also measured in each scenario. Since wireless sensor networks are application specific, so the behavior of SMAC is studied when the data transport performance and hence the throughput and jitter also plays an important role along with the energy effeciency. Finally it has been shown that under higher traffic loads, if the value of duty cycle is increased to optimum value, the residual energy of the node is improved with a better throughput.","PAC optimal planning for invasive species management: improved exploration for reinforcement learning from simulator-defined MDPsOften the most practical way to define a Markov Decision Process (MDP) is as a simulator that, given a state and an action, produces a resulting state and immediate reward sampled from the corresponding distributions. Simulators in natural resource management can be very expensive to execute, so that the time required to solve such MDPs is dominated by the number of calls to the simulator. This paper presents an algorithm, DDV, that combines improved confidence intervals on the Q values (as in interval estimation) with a novel upper bound on the discounted state occupancy probabilities to intelligently choose state-action pairs to explore. We prove that this algorithm terminates with a policy whose value is within e of the optimal policy (with probability 1-\u03b4) after making only polynomially-many calls to the simulator. Experiments on one benchmark MDP and on an MDP for invasive species management show very large reductions in the number of simulator calls required.","A Toolbox for Provably Optimal Multistage Strict Group Testing StrategiesGroup testing is the problem of identifying up to d defectives in a set of n elements by testing subsets for the presence of defectives. Let t(n,d,s) be the optimal number of tests needed by an s-stage strategy in the strict group testing model where the searcher must also verify that no more than d defectives are present. We develop combinatorial tools that are powerful enough to compute many exact t(n,d,s )v alues. This extends the work of Huang and Hwang (2001) for s = 1 to multistage strategies. The latter are interesting since it is known that asymptoti- cally nearly optimal group testing is possible already in s = 2 stages. Besides other tools we generalize d-disjunct matrices to any candidate hypergraphs, which enables us to express optimal test numbers for s =2 as chromatic numbers of certain conflict graphs. As a proof of concept we determine almost all test numbers for n \u2264 10, and t(n, 2, 2) for some larger n. In the group testing problem, a set of n elements is given, each being either defective (positive) or non-defective (negative) .L etP denote the unknown set of positive elements. A group test takes any subset Q of elements, called a pool .T he test (or pool) is positive if Q \u2229 P \ufffd \u2205, and negative otherwise. In the latter case, obviously, all elements in Q are recognized as negative. The goal is to identify P using few tests. A group testing strategy may be organized in s stages ,w here all tests within a stage are executed in parallel. In adaptive group testing s is not limited, hence tests can be done sequentially. Case s = 1 is called nonadaptive. Small s are desired in applications where the tests take much time. It is expected that |P |\u2264 d, for some fixed bound d, with the understanding that |P | &gt;d is unlikely but not impossible. A searcher wants to identify P if |P |\u2264 d, and just report \"|P | &gt;d \" otherwise. This setting is called strict group testing, in contrast to hypergeometric group testing where |P |\u2264 d is \"promised\" to the searcher. It was argued in, e.g., (1) that strict group testing is preferable. It does not rely on the assumption |P |\u2264 d. In a few lines one cannot possibly give even a cursory overview of the applica- tions of group testing in biology and computer science, and of the main complex- ity results. We only refer to the books (7,8) and a few recent papers (2,5,11,16,19)","Non-photorealistic Rendering with Reduced Colour PalettesIn contrast to photorealistic rendering, where richer colours are likely to be preferred, non-photorealistic rendering can often benefit from some abstraction, and colour palette reduction is one direction. By using a small number of carefully selected colours the overall tonal distribution can be well expressed with less visual clutter. This is also essential to simulate certain art forms, such as cartoons, comics, paper-cuts, woodblock printing, etc. that naturally prefer or require reduced palettes. In this chapter we will summarise major techniques used in colour palette reduction, such as region segmentation, thresholding and colour palette selection. Most approaches consider images as input and generate stylised image renderings while some work also considers video stylisation, in which case temporal coherence is essential. We finish this chapter with some discussions of potential future directions.","Assessing the completeness of geographical dataGeographical databases are often incomplete, especially when built up incrementally and by volunteers. A prominent example is OpenStreetMap. Often such databases contain also metadata saying that certain features are completely captured for certain areas. We show how to use such metadata to analyse in which areas queries return a complete answer. Such \"completeness areas\" can be computed via standard spatial operations. Still larger completeness areas can be derived if not only metadata but also the actual content of the database is taken into account. Finally, we discuss which challenges arise if one wants to practically utilize the completeness metadata in OpenStreetMap.","A Robust Approach for Palm ROI Extraction Based on Real-Time Region LearningA palmprint based authentication system that can work with a popular webcam in non-contact acquisition mode is potentially a good choice for biometric applications.However,this camera based imaging acquisition mode causes the difficulty for the location of palmprint due to the unstable palm position and variable illumination condition and effects the extraction of palm region of interest(ROI).In particular,changes in illumination of the system effect its performance heavily. The process of extract palm ROI has been discussed in different papers, but hardly does very well under variable light conditions and pose changes.In this paper,we propose a robust approach for localizing the palm and extracting the ROI based on real-time region learning.A dynamical region is learned to binarize the image and get the hand contour to extract the palm ROI. In a database of 1000 video clips of hand under different illumination and poses,the accurate extraction rate reaches 92%.","An Application of K-Means Clustering for Improving Video Text Detection ","Online shopping customer data analysis by using association rules and cluster analysisData Mining is the process of exploration and analysis of large quantities of data in order to discover meaningful patterns and rules. Data mining is considered as the only solution towards efficient use of increasing amounts of data worldwide. The process of converting data into information is achieved by means of data mining. In this study, first the concept of data mining is presented, then CRISP-DM process are described. In this paper Cluster Analysis and Association Rules are used to analyze the data. k-means Algorithm, Confidence and Support Ratios are theoretically explained and these techniques applied to a data set obtained from 314 customers from 7 regions of Turkey to identify their profile.","Examining the Influence of Political Factors on the Design of a New Road ","An experimental environment for analyzing collaborative learning interactionIn collaborative learning, participants progress their learning through multimodal information in a face-to-face environment. In addition to conversation, non-verbal information such as looking at other participants and note taking plays an important role in facilitating effective interaction. By exploiting such non-verbal information in the analysis of collaborative learning activities, this research proposes a collaborative learning environment in which the non-verbal information of participants is collected to analyze learning interaction. For this purpose, we introduce multimodal measurement devices and implement an integration tool for developing a multimodal interaction corpus of collaborative learning.","Tangible agile mapping: ad-hoc tangible user interaction definitionPeople naturally externalize mental systems through physical objects to leverage their spatial intelligence. The advent of tangible user interfaces has allowed human computer interaction to utilize these skills. However, current systems must be written from scratch and designed for a specific purpose, thus meaning end users cannot extend or repurpose the system. This paper presents Tangible Agile Mapping, our architecture to address this problem by allowing tangible systems to be defined ad-hoc. Our architecture addresses the tangible ad-hoc definition of objects, properties and rules to support tangible interactions. This paper also describes Spatial Augmented Reality TAM as an implementation of this architecture that utilizes a projector-camera setup combined with gesture-based navigation to allow users to create tangible systems from scratch. Results of a user study show that the architecture and our implementation are effective in allowing users to develop tangible systems, even for users with little computing or tangible experience.","Time Series Forecasting Using Distribution Enhanced Linear Regression ","Semi-automated Magnification of Small Motions in Videos ","Block-Sorted quantified conjunctive queriesWe study the complexity of model checking in quantified conjunctive logic, that is, the fragment of first-order logic where both quantifiers may be used, but conjunction is the only permitted connective. In particular, we study block-sorted queries, which we define to be prenex sentences in multi-sorted relational first-order logic where two variables having the same sort must appear in the same quantifier block. We establish a complexity classification theorem that describes precisely the sets of block-sorted queries of bounded arity on which model checking is fixed-parameter tractable. This theorem strictly generalizes, for the first time, the corresponding classification for existential conjunctive logic (which is known and due to Grohe) to a logic in which both quantifiers are present.","Efficient Counting of Maximal Independent Sets in Sparse GraphsThere are a number of problems that require the counting or the enu- meration of all occurrences of a certain structure within a given data set. We consider one such problem, namely that of counting the number of maximal inde- pendent sets (MISs) in a graph. Along with its complement problem of counting all maximal cliques, this is a well studied problem with applications in several research areas. We present a new efficient algorithm for counting all MISs suitable for sparse graphs. Similar to previous algorithms for this problem, our algorithm is based on branching and exhaustively considering vertices to be either in or out of the current MIS. What is new is that we consider the vertices in a predefined order so that it is likely that the graph will decompose into multiple connected com- ponents. When this happens, we show that it is sufficient to solve the problem for each connected component, thus considerably speeding up the algorithm. We have performed extensive experiments comparing our algorithm with the previ- ous best algorithms for this problem using both real world as well as synthetic input graphs. The results from this show that our algorithm outperforms the other algorithms and that it enables the solution of graphs where other approaches are clearly infeasible. As there is a one-to-one correspondence between the MISs of a graph and the maximal cliques of its complement graph, it follows that our algorithm also solves the problem of counting the number of maximal cliques in a dense graph. To our knowledge, this is the first algorithm that can handle this problem.","Capacity Analysis of IEEE 802.11ah WLANs for M2M CommunicationsFocusing on the increasing market of the sensors and actuators networks, the IEEE 802.11ah Task Group is currently working on the standardization of a new amendment. This new amendment will operate at the sub-1GHz band, ensure transmission ranges up to 1 Km, data rates above 100 kbps and very low power operation. With IEEE 802.11ah, the WLANs will offer a solution for applications such as smart metering, plan automation, eHealth or surveillance. Moreover, thanks to a hierarchical signalling, the IEEE 802.11ah will be able to manage a higher number of stations (STAs) and improve the 802.11 Power Saving Mechanisms. In order to support a high number of STAs, two different signalling modes are proposed, TIM and Non-TIM Offset. In this paper we present a theoretical model to predict the maximum number of STAs supported by both modes depending on the traffic load and the data rate used. Moreover, the IEEE 802.11ah performance and energy consumption for both signalling modes and for different traffic patterns and data rates is evaluated. Results show that both modes achieve similar Packet Delivery Ratio values but the energy consumed with the TIM Offset is, in average, 11.7% lower.","A cyclic weighted median method for l 1 low-rank matrix factorization with missing entriesA challenging problem in machine learning, information retrieval and computer vision research is how to recover a low-rank representation of the given data in the presence of outliers and missing entries. The L1-norm low-rank matrix factorization (LRMF) has been a popular approach to solving this problem. However, L1-norm LRMF is difficult to achieve due to its nonconvexity and non-smoothness, and existing methods are often inefficient and fail to converge to a desired solution. In this paper we propose a novel cyclic weighted median (CWM) method, which is intrinsically a coordinate decent algorithm, for L1-norm LRMF. The CWM method minimizes the objective by solving a sequence of scalar minimization sub-problems, each of which is convex and can be easily solved by the weighted median filter. The extensive experimental results validate that the CWM method outperforms state-of-the-arts in terms of both accuracy and computational efficiency.","On the design of neighboring fuzzy median filter for removal of impulse noisesThe digital images are easily affected by the noises; hence the image filters are often regarded as preprocessing of image processing system. If the image has serious damage or high-noise, the traditional image filters are usually unable to handle well. The application of median filter has been investigated. As an advanced method compared with standard median filtering, the adaptive median filter performs spatial processing to preserve detail and smooth non-impulsive noise. In this paper, a novel filter method, a neighboring selection method based on the fuzzy median filter, is proposed to improve the existing filter so that more image details can be preserved while effectively suppressing impulse noise. The proposed filter mechanism is composed of a new efficient noise eliminator based on the ideal of image rotation and LVQ network. Extensive simulation results demonstrate that our scheme performs significantly improve the default filter.","Process for Applying Derived Property Based Traceability Framework in Software and Systems Development Life Cycle ","Da Was Near with Me in the Very Important Stages of My Life ","Applying distributed optimization for QoS-security tradeoff in a distributed information systemIn a distributed information system, Quality of Service (QoS) and Information Assurance (IA) compete for the same set of resources. This tension increases in the presence of cyber attacks. Previous work formulated the problem of trading off QoS against IA as a DCOP whose solution sets the local configuration at individual decision-making nodes to optimize overall levels of QoS and IA delivered by the system. In this paper, we report on the first implementation of max-sum in a realistic distributed system running on multiple machines. Sample results from mission-oriented scenarios based on published documentation and run in an emulated network show the advantage of tradeoff-driven adaptation in meeting QoS and IA requirements.","RAMS: a fast, low-fidelity, multiple agent discrete-event simulatorRAMS is a low-fidelity discrete-event simulator, created for simulating multiple agents in a single environment in faster than real-time. The simulator is designed to be modular and versatile for use in future research in the area of coordinated teams of Unmanned Aircraft Systems (UAS) and other robotic vehicles. A low-fidelity wireless network module is incorporated for simulating network connectivity between agents. Algorithms for controlling the agents can be dynamically loaded in a wrapper, minimizing the effort required to port the algorithms from the simulator to an actual hardware platform. The agent model consists of a low-fidelity motion model based on simple flight dynamics combined with dynamically loaded guidance and control algorithms. The RAMS simulator differs for other simulation efforts in this area by providing a low to medium fidelity agent model and network simulation for use in rapid evaluation of high-level control and coordination algorithms. This paper discusses the motivation, basic architectural design, and implementation of the RAMS simulator.","Class-Specific Regression Random Forest for Accurate Extraction of Standard Planes from 3D Echocardiography ","Developing a multivariate electronic medical record integration model for primary health care. ","Developing the Agile IS Development Practices in Large-Scale IT Projects: The Trust-Mediated Organizational Controls and IT Project Team Capabilities PerspectivesThis paper is based on multiple case studies on the construction of the Beijing Capital International Airport Terminal 3 in preparation for the 2008 Olympic Games that investigated the processes of instilling agile IS development practices in large-scale IT projects. This study develops useful theoretical constructs that will help researchers and practitioners who wish to learn about agile IS development practices as developed in largescale IT projects. Adopting a contingent view, we uncover four factors that are critical in this development processes, namely: project uncertainty profile and project completion urgency; IT project team capabilities; organizational control mechanisms; and trust relationships among the IT project team, the vendors, and the users. Depending on the unpredictable nature of the project and the trust level among the IT project team, the vendors, and the users, we have uncovered the IT project team capabilities and the organizational control mechanisms that are needed to assure the success of a large-scale IT project. We posit that the interplay between the IT project team capabilities and the trust-mediated organizational control mechanisms forms the theoretical basis that defines agile IS development practice in large-scale IT projects. We argue that our findings provide insights to practitioners who are attempting to introduce agile IS development practices into any large-scale IT project. From a research perspective, the theory developed in this paper also sheds light on the importance of adopting a contingency view when researching agile IS development practices in a largescale IT project and the factors to consider. This underpinning theoretical perspective will aid in the design of all future researches.","Regularizing Soft Decision TreesRecently,wehaveproposedanewdecisiontreefamilycalledsoftdecision trees where a node chooses both its left and right children with different probabilities as given by a gating function, different from a hard decision node which chooses one of the two. In this paper, we extend the original algorithm by introducing local dimension reduction viaL 1 andL 2 regularization for feature selection and smoother fitting. We compare our novel approach with the standard decision tree algorithms over 27 classification data sets. We see that both regularized versions have similar generalization ability with less complexity in terms of number of nodes, whereL 2 seems to work slightly better thanL 1 .","TEBRA - An automatic prompting system for persons with cognitive disabilities in brushing teethWe introduce a novel Cognitive Assistive Technology. The TEBRA system assists persons with cognitive disabilities in brushing teeth by prompting the user. We develop the system based on an analysis of the task using qualitative data analysis. We recognize different subtasks applying a hierarchical recognition framework based on a Bayesian Network.  The user\u2019s progress in the task is monitored using a Finite State Machine and dynamic timing model which allows for different velocities of task execution. We evaluate the TEBRA system in a first study with regular users. We found that the system is able to provide appropriate prompts in terms of timing and modality to assist a user through the complex task of brushing teeth.","The GEYSERS Concept and Major Outcomes ","An Asynchronous RGB-D Sensor Fusion Framework Using Monte-Carlo Methods for Hand Tracking on a Mobile Robot in Crowded EnvironmentsGesture recognition for human-robot interaction is a prerequisite for many social robotic tasks. One of the main technical difficulties is hand tracking in crowded and dynamic environments. Many existing methods have only been shown to work in clutter-free settings.#R##N##R##N#This paper proposes a sensor fusion based hand tracking algorithm for crowded environments. It is shown to significantly improve the accuracy of existing hand detectors, based on depth and RGB information. The main novelties of the proposed method include: a) a Monte-Carlo RGB update process to reduce false positives; b) online skin colour learning to cope with varying skin colour, clothing and illumination conditions; c) an asynchronous update method to integrate depth and RGB information for real-time applications. Tracking performance is evaluated in a number of controlled scenarios and crowded environments. All datasets used in this work have been made publicly available.","An Expert System to Improve the Energy Efficiency of the Reaction Zone of a Petrochemical Plant ","Variable Importance in Nonlinear Kernels (VINK): Classification of Digitized HistopathologyQuantitative histomorphometry is the process of modeling appearance of disease morphology on digitized histopathology images via image-based features (e.g., texture, graphs). Due to the curse of di- mensionality, building classifiers with large numbers of features requires feature selection (which may require a large training set) or dimension- ality reduction (DR). DR methods map the original high-dimensional features in terms of eigenvectors and eigenvalues, which limits the poten- tial for feature transparency or interpretability. Although methods exist for variable selection and ranking on embeddings obtained via linear DR schemes (e.g., principal components analysis (PCA)), similar methods do not yet exist for nonlinear DR (NLDR) methods. In this work we present a simple yet elegant method for approximating the mapping between the data in the original feature space and the transformed data in the ker- nel PCA (KPCA) embedding space; this mapping provides the basis for quantification of variable importance in nonlinear kernels (VINK). We show how VINK can be implemented in conjunction with the popular Isomap and Laplacian eigenmap algorithms. VINK is evaluated in the contexts of three different problems in digital pathology: (1) predict- ing five year PSA failure following radical prostatectomy, (2) predicting Oncotype DX recurrence risk scores for ER+ breast cancers, and (3) distinguishing good and poor outcome p16+ oropharyngeal tumors. We demonstrate that subsets of features identified by VINK provide sim- ilar or better classification or regression performance compared to the original high dimensional feature sets.","IT Capabilities and Innovation Performance: The Mediating Role of Market Orientation ","A Turing Test to Evaluate a Complex Summarization TaskThis paper deals with a new strategy to evaluate a Natural Language Processing NLP complex task using the Turing test. Automatic summarization based on sentence compression requires to asses informativeness and modify inner sentence structures. This is much more intrinsically related with real rephrasing than plain sentence extraction and ranking paradigm so new evaluation methods are needed. We propose a novel imitation game to evaluate Automatic Summarization by Compression ASC. Rationale of this Turing-like evaluation could be applied to many other NLP complex tasks like Machine translation or Text Generation. We show that a state of the art ASC system can pass such a test and simulate a human summary in 60% of the cases.","Odor Perception through Network Self-organization: Large Scale Realistic Simulations of the Olfactory Bulb ","BRDF Estimation for Faces from a Sparse Dataset Using a Neural NetworkWe present a novel five source near-infrared photometric stereo 3D face capture device. The accuracy of the system is demonstrated by a comparison with ground truth from a commercial 3D scanner. We also use the data from the five captured images to model the Bi-directional Reflectance Distribution Function BRDF in order to synthesise images from novel lighting directions. A comparison of these synthetic images created from modelling the BRDF using a three layer neural network, a linear interpolation method and the Lambertian model is given, which shows that the neural network proves to be the most photo-realistic.","Algorithms for hub label optimizationWe consider the problem of approximating optimal hub labelings in the context of labeling algorithms for the shortest path problem. A previous result was a O(logn) approximating for minimizing the total label size. We give an O(logn)-approximation algorithm for the maximum label size. We also give O(logn)-approximation algorithms for natural generalizations of the problem: Minimizing an lp norm of the labeling and simultaneously minimizing lp and lq norms.","Synthesized Algorithms of Concept Similarity Based on the Semantic Correlation Prerequisite ","Link label prediction in signed social networksOnline social networks continue to witness a tremendous growth both in terms of the number of registered users and their mutual interactions. In this paper, we focus on online signed social networks where positive interactions among the users signify friendship or approval, whereas negative interactions indicate antagonism or disapproval. We introduce a novel problem which we call the link label prediction problem: Given the information about signs of certain links in a social network, we want to learn the nature of relationships that exist among the users by predicting the sign, positive or negative, of the remaining links. We propose a matrix factorization based technique MF-LiSP that exhibits strong generalization guarantees. We also investigate the applicability of logistic regression [8] in this setting. Our experiments on Wiki-Vote, Epinions and Slashdot data sets strongly corroborate the efficacy of these approaches.","Comparing discourse tree structuresThe existing discourse parsing systems make use of different theories to put at the basis of processes of building discourse trees. Many of them use Recall, Precision and F-measure to compare discourse tree structures. These measures can be used only on topologically identical structures. However, there are known cases when two different tree structures of the same text can express the same discourse interpretation, or something very similar. In these cases Precision, Recall and F-measures are not so conclusive. In this paper, we propose three new scores for comparing discourse trees. These scores take into consideration more and more constraints. As basic elements of building the discourse structure we use those embraced by two discourse theories: Rhetorical Structure Theory (RST) and Veins Theory, both using binary trees augmented with nuclearity notation. We will ignore the second notation used in RST --- the name of relations. The first score takes into account the coverage of inner nodes. The second score complements the first score with the nuclearity of the relation. The third score computes Precisions, Recall and F-measures on the vein expressions of the elementary discourse units. We show that these measures reveal comparable scores there where the differences in structure are not doubled by differences in interpretation.","On the Acceptance of Privacy-Preserving Authentication Technology: The Curious Case of National Identity CardsMany attempts have been made to replace the ubiquitous username-and-password authentication scheme in order to improve user security, privacy and usability. However, none of the proposed methods have gained wide-spread user acceptance. In this paper, we examine the users' perceptions and concerns on using several alternative authentica- tion methods on the Internet. We investigate the adoption of the new German national identity card, as it is the first eID-enabled card with dedicated features to enable privacy-preserving online authentication. Even though its large-scale roll-out was backed by a national govern- ment, adoption rates and acceptance are still low. We present results of three focus groups as well as interviews with service providers, showing that preserving privacy is just one of several factors relevant to the ac- ceptance of novel authentication technologies by users as well as service providers.","Scalable k-nearest neighbor graph construction based on greedy filteringK-Nearest Neighbor Graph (K-NNG) construction is a primitive operation in the field of Information Retrieval and Recommender Systems. However, existing approaches to K-NNG construction do not perform well as the number of nodes or dimensions scales up. In this paper, we present greedy filtering, an effcient and scalable algorithm for selecting the candidates for nearest neighbors by matching only the dimensions of large values. The experimental results show that our K-NNG construction scheme, based on greedy filtering, guarantees a high recall while also being 5 to 6 times faster than state-of-the-art algorithms for large, high-dimensional data.","Intelligent Energy Management System for the Optimization of Power Consumption ","A Novel Web Tunnel Detection Method Based on Protocol BehaviorsThe web tunnel is a common attack technique in the Internet and it is very easy to be implemented but extremely difficult to be detected. In this paper, we propose a novel web tunnel detection method which focuses on protocol behaviors. By analyzing the interaction processes in web communications, we give a scientific definition to web sessions that are our detection objects. Under the help of the definition, we extract four first-order statistical features which are widely used in previous research of web sessions. Utilizing the packet lengths and inter-arrival times in the transport layer, we divide TCP packets into different classes and discover some statistical correlations of them in order to extract another three second-order statistical features of web sessions. Further, the seven features are regarded as a 7- dimentional feature vector. Exploiting the vector, we adopt a support vector machine classifier to distinguish tunnel sessions from legitimate web sessions. In the experiment, our method performs very well and the detection accuracies of HTTP tunnels and HTTPS tunnels are 82.5% and 91.8% respectively when the communication traffic is above 500 TCP packets.","Entity search on the webMore than the half of queries in the logs of a web search engine refer directly to a single named entity or a named set of entities [1]. To support entity search queries, search engines have begun developing targeted functionality, such as rich displays of factual information, question-answering and related entity recommendations. In this talk, we will provide an overview of recent work in the field of entity search, illustrated by the example of the Spark system, a large-scale system currently in use at Yahoo! for related entity recommendations in web search. Spark combines various knowledge bases and collects evidence from query logs and social media to provide the most relevant related entities for every web query with an entity intent. We discuss the methods used in Spark as well as how the system is evaluated in daily use.","Key Induction and Key Mapping Using Pitch-Class Set AssertionsThis paper introduces the key-assertion method, a parsimo- nious analytic method for labelling key areas using pitch-class content. Sensitivity to key change is maximized, providing a detailed account of tonal areas, large and small. The method also produces a surprising heuristic for guessing the overall key of a piece, which performs well in comparison with other methods. 1 Key Induction Key induction, determining the key or keys of a piece of tonal music, is a cen- tral problem in computational music research, with applications such as pitch spelling, music transcription, and harmonic analysis, and implications for re- search in music cognition. Current methods for key induction tend to divide the problem into two parts: deciding on a (single) key to describe a musical seg- ment, and deciding how to segment a piece of music into different key areas - \"key mapping.\" This paper presents a new method for key induction which is more parsimo- nious in its assumptions about tonality than other known methods, and which formalizes a previously unmodelled parameter: sensitivity to key change. 1.1 The Key of a Segment In recent research, a variety of mechanisms for deciding the key of a musical segment have been designed using theoretical models (1,2), analysis of music data (3) or the results of human psychological testing (4,5). In all of these mechanisms, each key is modelled as a point in some math- ematical space - either as a geometrical point in a described space, or as a histogram of likelihoods of each pitch class occurring in the given key. The key of an unlabelled musical segment is then determined by taking its pitch-class content (possibly weighted by duration), and performing a calculation compar- ing the segment to each of key models. The key which yields the highest score in comparison with the segment is estimated to be the key of the segment. While the key models and comparison calculations are different, they all treat key in an essentially similar way. They treat key as a distribution of pitch classes,","Adaptive Confidence Regions of Motion Predictions from Population Exemplar ModelsPrecise radiation therapies require not only accurate prediction of the motion of the structures in the treatment region, but also confidence values of these predictions to enable planning of residual motion and detection of failure predictions. While various motion models have been proposed for the prediction of motion in the abdomen due to free-breathing, none has provided confidence regions. In this study we use the conditional probability density function of statistical liver motion models for predicting confidence regions, propose a method for optimizing the accuracy of the confidence regions and show the adaptability of the confidence regions due to partial observations when using exemplar models. The average accuracy of the confidence regions of single Gaussian SG models could be improved to the level of the exemplar models. Exemplar models provided on average better motion predictions 1.14i\u00be?mm and slightly smaller 68% confidence regions 1.36i\u00be?mm than the SG models 1.21i\u00be?mm, 1.43i\u00be?mm resp.. The confidence region size correlated temporally on average weakly r=0.35 with the errors of the motion prediction for the exemplar models, leading to a higher percentage of treatable locations and lower motion prediction errors per duty cycle than SG models.","The influence of social networking sites on participation in the 2012 presidential electionSocial networking sites are gaining in popularity, and candidates for president have been getting more involved in these online platforms. In order to examine whether a presidential candidate's presence on social networking sites influences people's political participation, we conducted a survey asking users a series of questions related to their social networking involvement, political involvement, and political involvement on social networking sites, specifically with regard to the 2012 presidential election. Our results indicate that despite being politically minded, these users do not use Facebook for political reasons and a candidate's online presence does not influence their decision on how to vote.","Automated segmentation of the cerebellar lobules using boundary specific classification and evolutionThe cerebellum is instrumental in coordinating many vital functions ranging from speech and balance to eye movement. The effect of cerebellar pathology on these functions is frequently examined using volumetric studies that depend on consistent and accurate delineation, however, no existing automated methods adequately delineate the cerebellar lobules. In this work, we describe a method we call the Automatic Classification of Cerebellar Lobules Algorithm using Implicit Multi-boundary evolution (ACCLAIM). A multiple object geometric deformable model (MGDM) enables each boundary surface of each individual lobule to be evolved under different level set speeds. An important innovation described in this work is that the speed for each lobule boundary is derived from a classifier trained specifically to identify that boundary. We compared our method to segmentations obtained using the atlas-based and multi-atlas fusion techniques, and demonstrate ACCLAIM's superior performance.","Computing model of individual emotion in the mass incidents with venting angerBased on emotional contagion theory and combined emotional contagion scale with modeling and simulating research methods then put forward a computing model of individual emotion in the mass incidents with venting anger. In the model, emotional contagion scale is used to measure emotional contagion sensitivity of the agents. The agents have parameters such as five basic emotions, explicit emotions, comprehensive emotions and so on. A large number of simulation results show that the model can simulate the changes of individual basic emotions, the group basic emotions and the group comprehensive emotions in the process of emotional contagion.","Lightweight End-User Software SharingThis paper looks into the sharing of end-user software (referred to as \"script\"). Based on this study four implications are drawn: reduce the effort to make scripts shareable, minimize deployment burdens, less stringent protection mechanisms, and tap into communities of practice as for sharing. To attend these implications, we introduce a URL-based distribution schema for scripts combined with an IP-address- based authorization model. This makes scripts URL-addressable and easy to install, because choosing to install a script means that all of the necessary frameworks, plug-ins, etc. that are needed to make this script run are simultaneously installed. On the other hand, IP-based protection uses IP network prefixes as cypher keys. A script language is used as a proof of concept.","On multi-enabledness in time Petri netsWe consider time Petri nets with multiple-server semantics. We first prove that this setting is strictly more expressive, in terms of timed bisimulation, than its single-server counterpart. We then focus on two choices for the firing of multiple instances of the same transition: the more conservative safety-wise non deterministic choice, where all firable instances may fire in any order, and a simpler alternative, First Enabled First Fired (FEFF), where only the oldest instance may fire, obviously leading to a much more compact state-space. We prove that both semantics are not bisimilar but actually simulate each other with strong timed simulations, which in particular implies that they generate the same timed traces. FEFF is then very appropriate to deal with linear timed properties of time Petri nets.","A grounded procedure for managing data and sample size of a home medical device assessmentThe selection of participants for usability assessment, together with the minimum number of subjects required to obtain a set of reliable data, is a hot topic in Human Computer Interaction (HCI). Albeit, prominent contributions through the application of different p estimation models argued that five users provide a good benchmark when seeking to discover interaction problems a lot of studies have complained this five-user assumption. The sample size topic is today a central issue for the assessment of critical-systems, such as medical devices, because lacks in usability and, moreover, in the safety in use of these kind of products may seriously damage the final users. We argue that rely on one-size-fits-all solutions, such as the five-user assumption (for websites) or the mandated size of 15 users for major group (for medical device) lead manufactures to release unsafe product. Nevertheless, albeit there are no magic numbers for determining \"a priori\" the cohort size, by using a specific procedure it is possible to monitoring the sample discovery likelihood after the first five users in order to obtain reliable information about the gathered data and determine whether the problems discovered by the sample have a certain level of representativeness (i.e., reliability). We call this approach \"Grounded Procedure\" (GP).The goal of this study is to present the GP assumptions and steps, by exemplifying its application in the assessment of a home medical device.","Advancing Social Science through Agent-Based Modeling ","A Constraint and Rule in an Enhancement of Binary Particle Swarm Optimization to Select Informative Genes for Cancer ClassificationGene expression data have been analyzing by many researchers by using a range of computational intelligence methods. From the gene expression data, selecting a small subset of informative genes can do cancer classification. Nevertheless, many of the computational methods face difficulties in selecting small subset since the small number of samples needs to be compared to the huge number of genes (high-dimension), irrelevant genes and noisy genes. Hence, to choose the small subset of informative genes that is significant for the cancer classification, an enhanced binary particle swarm optimization is proposed. Here, the constraint of the elements of particle velocity vectors is introduced and a rule for updating particle's position is proposed. Experiments were performed on five different gene expression data. As a result, in terms of classification accuracy and the number of selected genes, the performance of the introduced method is superior compared to the conventional version of binary particle swarm optimization (BPSO). The other significant finding is lower running times compared to BPSO for this proposed method.","Detecting Vulnerabilities in Java-Card Bytecode Verifiers Using Model-Based TestingJava Card security is based on different elements among which the bytecode verifier is one of the most important. Finding vul- nerabilities is a complex, tedious and error-prone task. In the case of the Java bytecode verifier, vulnerability tests are typically derived by hand. We propose a new approach to generate vulnerability test suites using model-based testing. Each instruction of the Java bytecode language is represented by an event of an Event-B machine, with a guard that de- notes security conditions as defined in the virtual machine specification. We generate vulnerability tests by negating guards of events and gen- erating traces with these faulty events using the ProB model checker. This approach has been applied to a subset of twelve instructions of the bytecode language and tested on five Java Card bytecode verifiers. Vulnerabilities have been found for each of them. We have developed a complete tool chain to support the approach and provide a proof of concept.","Parallel GF(3m) multiplier for trinomialsIn this paper, we propose a parallel multiplier over arbitrary finite field GF(p^m). In particular, we apply the proposed multiplier to GF(3^m) defined by irreducible trinomial which has received a great interest recently. The proposed GF(3^m) multiplier is not only the first parallel multiplier with explicit complexities, but its complexities also match with generalized forms of the complexities of the most efficient GF(2^m) multiplier.","Learning from Multiple Experts with Random Forests: Application to the Segmentation of the Midbrain in 3D Ultrasound ","Framework for Storing and Processing Relational Entities in Stream Mining ","An Efficient Ranging Protocol Using Multiple Packets for Asynchronous Real-Time Locating Systems ","Generating Value from Open Government DataA driving force for change in society is the trend towards Open Government Data (OGD). While the value generated by OGD has been widely discussed by public bodies and other stakeholders, little attention has been paid to this phenomenon in the academic literature. Hence, we developed a conceptual model portraying how data as a resource can be transformed to value. We show the causal relationships between four contextual, enabling factors, four types of value generation mechanisms and value. We use empirical data from 61 countries to test these relationships, using the PLS method. The results mostly support the hypothesized relationships. Our conclusion is that if openness is complemented with resource governance, capabilities in society and technical connectivity, use of OGD will stimulate the generation of economic and social value through four different archetypical mechanisms: Efficiency, Innovation, Transparency and Participation.","Body Ownership of Virtual Avatars: An Affordance Approach of TelepresenceVirtual environments are an increasing trend in today\u2019s society. In this scope, the avatar is the representation of the user in the virtual world. However, that relationship lacks empirical studies regarding the nature of the interaction between avatars and human beings. For that purpose it was studied how the avatar\u2019s modeled morphology and dynamics affect its control by the user. An experiment was conducted to measure telepresence and ownership on participants who used a Kinect Natural User Interface (NUI). The body ownership of different avatars was assessed through a behavioral parameter, based on the concept of affordances, and a questionnaire of presence. The results show that the feelings of telepresence and ownership seem to be greater when the kinematics and the avatar\u2019s proportions are closer to those of the user.","Cubic Graphs with Minimum Number of Spanning Trees. ","Established and innovative facets of interactive prototypes: a case studyIn this paper we highlight four facets of interactive prototypes in user-centered design approaches. After reflecting on their established role in the design and validation phases, we consider recent innovative uses of prototypes in communicating with development/bidders and also to enhance training. To illustrate our experiences, we draw upon a recent successfully completed redesign project in the field of electrical engineering.","Dynamic evolutionary membrane algorithm in dynamic environmentsSeveral problems that we face in real word are dynamic in nature. For solving these problems, a novel dynamic evolutionary algorithm based on membrane computing is proposed. In this paper, the partitioning strategy is employed to divide the search space to improve the search efficiency of the algorithm. Furthermore, the four kinds of evolutionary rules are introduced to maintain the diversity of solutions found by the proposed algorithm. The performance of the proposed algorithm has been evaluated over the standard moving peaks benchmark. The simulation results indicate that the proposed algorithm is feasible and effective for solving dynamic optimization problems.","An Indoor Contaminant Sensor Placement Toolbox for Critical Infrastructure Buildings ","On the use of a proportional-share market for application SLO support in cloudsVirtualization provides increased control and flexibility on how resources are allocated to applications. However, common resource provisioning mechanisms do not fully use these advantages; either they provide limited support for applications demanding quality of service, or the resource allocation complexity is high. To address these issues we developed Themis, a market-based application management platform. By limiting the coupling between the applications and resource management, Themis can support diverse types of applications and performance goals while ensuring maximized resource usage. In this paper we present the performance of Themis when users execute batch applications with different Service Level Objectives such as deadlines.","Modeling the Organizational Regulatory Space: A Joint Design Approach ","Improving 2D-3D registration optimization using learned prostate motion data. ","Compositional verification of application-level security propertiesAutomatic model checking can be employed to verify that security properties are fulfilled by a system model. However, since security requirements constrain most, if not all, functional modules of a system, such a proof needs to consider nearly all of the system's control and data flows. For complex real-life applications, that leads to a large state space to be explored effectively restricting the applicability of a model checker. To deal with this problem, we advocate a compositional approach utilizing the features of our model-based engineering technique SPACE. Both functional behavior and security-related aspects are specified using UML 2 activities. Further, we supplement each activity with an interface behavior description which will be extended by a security contract modeling certain security properties to be fulfilled by the activity. This enables us to verify application-level security properties by using contracts instead of their respective activities in model checker runs so that the number of states to be checked is significantly reduced. The approach is exemplified by an Android application example in which one's location must only be shared with certain recipients.","Parallel microscopic simulation of metropolitan-scale trafficWe present a scalable and high-performance microscopic simulator capable of simulating metropolitan-scale traffic. We analyze the requirements for a realistic level of detail and present techniques for optimizing the performance of the simulator and maintain coherence when scaling into parallel computing architectures. To demonstrate its capabilities, we simulate the San Francisco Bay Area road network. Finally, we provide a performance comparison with other free/open-source simulators and show that our simulator not only outperforms existing solutions but also scales well when running in multi-core environments.","A Preliminary Study on Early Diagnosis of Illnesses Based on Activity Disturbances ","A New Multiobjective Genetic Programming for Extraction of Design Information from Non-dominated Solutions ","Feature Selection Parallel Technique for Remotely Sensed Imagery Classification ","Improved EMD Usable Speech Detection for Co-channel Speaker Identification ","Towards anthropomorphic movements for industrial robotsIn order to increase productivity for processes that involve the interaction of human and robot, a promising approach is to increase the transparency of robot movements. Based on the hypothesis that anthropomorphic movements are more transparent to a human operator, this paper presents methodologies and techniques to generate humanlike movements for industrial robots.","Structure approximation of most probable explanations in bayesian networksTypically, when one discusses approximation algorithms for (NP-hard) problems (like Traveling Salesperson, Vertex Cover, Knapsack), one refers to algorithms that return a solution whose value is (at least ideally) close to optimal; e.g., a tour with almost minimal length, a vertex cover of size just above minimal, or a collection of objects that has close to maximal value. In contrast, one might also be interested in approximation algorithms that return solutions that resemble the optimal solutions, i.e., whose structure is akin to the optimal solution, like a tour that is almost similar to the optimal tour, a vertex cover that differs in only a few vertices from the optimal cover, or a collection that is similar to the optimal collection. In this paper, we discuss structure-approximation of the problem of finding the most probable explanation of observations in Bayesian networks, i.e., finding a joint value assignment that looks like the most probable one, rather than has an almost as high value. We show that it is NP-hard to obtain the value of just a single variable of the most probable explanation. However, when partial orders on the values of the variables are available, we can improve on these results.","Situated Analysis of Interactions between Cognitively Impaired Older Adults and the Therapeutic Robot PAROIn order to explore the social and behavioral mechanisms behind the therapeutic effects of PARO, a robot resembling a baby seal, we conducted an eight-week-long study of the robot's use in a group activity with older adults in a local retirement facility. Our research confirms PARO's positive effects on participants by increasing physical and verbal interaction as evidenced by our behavioral analysis of video recorded interactions. We also analyzed the behavioral patterns in the group interaction, and found that the mediation of the therapist, the individual interpretations of PARO by different participants, and the context of use are significant factors that support the successful use of PARO in therapeutic implementations. In conclusion, we discuss the importance of taking the broader social context into account in robot evaluation.","Mining Appliance Usage Patterns in Smart Home Environment ","Symbolic Regression of Boolean Functions by Genetic Programming ","Bayesian Learning of Recursively Factored EnvironmentsModel-based reinforcement learning techniques have historically encountered a number of difficulties scaling up to large observation spaces. One promising approach has been to decompose the model learning task into a number of smaller, more manageable sub-problems by factoring the observation space. Typically, many different factorizations are possible, which can make it difficult to select an appropriate factorization without extensive testing. In this paper we introduce the class of recursively decomposable factorizations, and show how exact Bayesian inference can be used to efficiently guarantee predictive performance close to the best factorization in this class. We demonstrate the strength of this approach by presenting a collection of empirical results for 20 different Atari 2600 games.","CUVIM: extracting fresh information from social networkSocial network preserves the life of users and provides great potential for journalists, sociologists and business analysts. Crawling data from social network is a basic step for social network information analysis and processing. As the network becomes huge and information on the network updates faster than web pages, crawling is more difficult because of the limitations of bandwidth, politeness etiquette and computation power. To extract fresh information from social network efficiently and effectively, this paper presents a novel crawling method of social network. To discover the feature of social network, we gather data from real social network, analyze them and build a model to describe the discipline of users' behavior. With the modeled behavior, we propose methods to predict users' behavior. According to the prediction, we schedule our crawler more reasonably and extract more fresh information. Experimental results demonstrate that our strategies could obtain information from SNS efficiently and effectively.","SCMF: sparse covariance matrix factorization for collaborative filteringMatrix factorization (MF) is a popular collaborative filtering approach for recommender systems due to its simplicity and effectiveness. Existing MF methods either assume that all latent features are uncorrelated or assume that all are correlated. To address the important issue of what structure should be imposed on the features, we investigate the covariance matrix of the latent features learned from real data. Based on the findings, we propose an MF model with a sparse covariance prior which favors a sparse yet non-diagonal covariance matrix. Not only can this reflect the semantics more faithfully, but imposing sparsity can also have a side effect of preventing overfitting. Starting from a probabilistic generative model with a sparse covariance prior, we formulate the model inference problem as a maximum a posteriori (MAP) estimation problem. The optimization procedure makes use of stochastic gradient descent and majorization-minimization. For empirical validation, we conduct experiments using the MovieLens and Netflix datasets to compare the proposed method with two strong baselines which use different priors. Experimental results show that our sparse covariance prior can lead to performance improvement.","Real Name Verification Law on the Internet: A Poison or Cure for Privacy? ","Some Recent Work on Multi-objective Approaches to Search-Based Software EngineeringMulti-objective algorithms have been used to solve difficult software engineering problems for a long time. This article summarises some selected recent work of applying latest meta-heuristic optimisation algorithms and machine learning algorithms to software engineering problems, including software module clustering, testing resource allocation in modular software system, protocol tuning, Java container testing, software project scheduling, software project effort estimation, and software defect prediction. References will be given, from which the details of such application of computational intelligence techniques to software engineering problems can be found.","SketchSPORE: A Sketch Based Domain Separation and Recognition System for Interactive Interfaces ","Rule-Level Verification of Graph Transformations for Invariants Based on Edges' Transitive ClosureThis paper develops methods to reason about graph transformation rules for proving the preservation of structural properties, especially global properties on reachability. We characterize a graph transformation rule with an applicability condition specifying the matching conditions of the rule on a host graph as well as the properties to be preserved during the transformation. Our previous work has demonstrated the possibility to reason about a graph transformation at rulelevel with applicability conditions restricted to Boolean combinations of edge expressions. We now extend the approach to handle the applicability conditions containing transitive closure of edges, which implicitly refer to an unbounded number of nodes. We show how these can be internalized into a finite pattern graph in order to enable verification of global properties on paths instead of local properties on edges only.","Drugs don't work in patients who don't take them: Dr. Drin, the new ICT paradigm for chronic therapies. ","Using Social Networking Services to Support LearningSocial media tools are increasingly being used in education, providing students with a medium in which they can actively engage with each other and with their teachers, co-create knowledge, share experiences, work and learn collaboratively. Learning implies not only access to information but also access to other people; in this context, social networking services SNS appear well suited for educational use, since they offer social space for people to gather online and make connections. The paper provides an overview on the use of these SNS to support learning. Two approaches are summarized: i the pedagogical repurposing of existing popular SNS i.e., Facebook; ii the design of dedicated educational SNS. The latter is illustrated in more detail with the Lintend platform, a system conceived and implemented by the authors. A critical perspective is also included, and future research directions are drawn from it.","Tools for software verification : Introduction to the special section from the seventeenth international conference on tools and algorithms for the construction and analysis of systemsTools for software verification : Introduction to the special section from the seventeenth international conference on tools and algorithms for the construction and analysis of systems","Incremental Algorithms for Selecting Horizontal Schemas of Data Warehouses: The Dynamic CaseLooking at the problem of effectively and efficiently parti- tioning data warehouses, most of state-of-the-art approaches, which are very often heuristic-based, are static, since they assume the existence of an a-priori known set of queries. Contrary to this, in real-life applications, queries may change dynamically and fragmentation heuristics need to in- tegrate these changes. Following this main consideration, in this paper we propose and experimentally assess an incremental approach for selecting data warehouse fragmentation schemes using genetic algorithms.","Verifying MSMAS Model Using CIFF.MSMAS is a software development methodology that facilities the design and development of complex distributed systems based on the multiagent systems paradigm. MSMAS explicitly supports the institutional organisational structure and follows a declarative modelling style to specify behavioural restric- tions on the members of the institution, their roles, the business processes reg- ulating their behavior and the communication protocols regulating their mutual interactions. All these aspects are visually represented, by adapting the DECLARE graphical language, proposed for the declarative specification of constraint-based business processes. In this paper we discuss the main elements of MSMAS, and show how they can be equipped with a formal, expectation-based semantics, tai- lored to theSCIFF Abductive Logic Programming-based framework. In particu- lar, we show how the MSMAS constructs can be formalized in SCIFF, and then exploit this correspondence to specify and verify formal properties over MSMAS models, by leveraging on the SCIFF reasoning capabilities. 1 Background With a growing interest in modelling the social structure of modern distributed sys- tems and increased research activities around using role norms and institutions as an organisational type to capture these social aspects, it seems that modelling efforts are disconnected from implementation at the application level. Some metamodels lack sup- porting design tools or if not they lack design verification and run-time validation ca- pabilities. The MSMAS (6,5) methodology aims to establish a link between modelling and implementation by combining business oriented metamodelling with institution and role modelling and supports a formal proof mechanism for design and runtime vali- dation. MSMAS allows multi agent system (MAS) designers to model self-managing MASs using visual graphic models. Here, we take self-manging to mean the ability of the system to recognize execution errors or undesired behaviour and the ability to respond by replanning in order to recover from the failure or to stop the undesired ac- tivities.MSMAS has three phases: the first phase is to capture the system requirements through the Use Cases Models and to create the System Goals Model. The second phase starts with the high level design of the required Business Processes to achieve the sys- tem goals and the specification of the system organisational structure through the In- stitutions Models. Then, a detailed design of the business activities, a full specification","Mathematical Morphology for Real-Valued Images on Riemannian ManifoldsThis paper introduces mathematical morphology for real- valued images whose support space is a Riemannian manifold. The start- ing point consists in replacing the Euclidean distance in the canonic quadratic structuring function by the Riemannian distance. Besides the definition of Riemannian dilation/erosion and Riemannian opening/clo- sing, their properties are explored. We generalize also some theoretical results on Lasry-Lions regularization for Cartan-Hadamard manifolds. Theoretical connections with previous works on adaptive morphology and on manifold shape are considered. Various useful image manifolds are formalized, with an example using real-valued 3D surfaces.","Extraction of the Foreground Regions by Means of the Adaptive Background Modelling Based on Various Colour Components for a Visual Surveillance System ","Coastal Hurricane Inundation Prediction for Emergency Response Using Artificial Neural NetworksEmergency managers require both fast and accurate estimates of hurricane inundation to make critical decisions about evacuations, structure closures, and other emergency response activities before, during, and after events. Probability analyses require multiple simulations which, generally, cannot be performed with the physics-based models under the time constraints during emergency conditions. To obtain highly accurate results with a fast turnaround computation time a \"surrogate\" modeling approach is employed. This surrogate modeling approach uses an extensive database of storms and storm responses and applies \"smart\" pattern recognition tools such as Artificial Neural Networks (ANN) as well as interpolation techniques. The goal is to provide forecasts of hurricane inundation and waves with the accuracy of high- resolution, high-fidelity models but with very short execution time (minutes). The city of New Orleans as well as surrounding municipalities along the Gulf of Mexico coastal area encompasses the region used to demonstrate this approach. The results indicate that the developed surge prediction tool could be used to forecast both magnitude and duration to peak surge for multiple selected points in a few minutes of computational time once the storm parameters are provided. In this paper, only results of surge magnitude are presented.","A Model for Setting Optimal Data-Acquisition Policy and its Application with Clinical DataManual data acquisition is often subject to incompleteness \u2013 data attributes that are missing due to time and data-availability constraints, which might damage data usability for analyses and decision making. This study introduces a novel optimization model for setting mandatory versus voluntary attributes in a dataset. This model may direct the decision of whether or not to enforce the acquisition of certain attributes, given certain constraints and dependencies. The feasibility and the potential contribution of the proposed model were evaluated with a clinical dataset that reflects Colonoscopy procedures performed in a large hospital over a 4-year period. The evaluation demonstrated that the model can be reasonably estimated within the given context, and that its implementation may contribute important insight toward improving data quality. The current data-acquisition setup was shown to be suboptimal, and some further evaluation identified factors that influence incompleteness and may require revisions to current data acquisition policies.","Knowledge Graphs as Context Models: Improving the Detection of Cross-Language Plagiarism with ParaphrasingEuropean Commission WIQ-EI IRSES (no. 269180) and DIANA-APPLICATIONS - [TIN2012-38603-C02-01]","A Clustering Framework Applied to DNA Microarray DataThis paper presents a case study to show the competence of our evolutionary framework for cluster analysis of DNA microarray data. The proposed framework joins a genetic algorithm for hierarchical clustering with a set of visual components of cluster tasks given by a tool. The cluster visualization tool allows us to display different views of clustering results as a means of cluster visual validation. The results of the genetic algorithm for clustering have shown that it can find better solutions than the other methods for the selected data set. Thus, this shows the reliability of the proposed framework.","Towards nominal context-free model-checkingTwo kinds of automata are introduced, for recognising regular and context-free nominal languages. We compare their expressive power with that of analogous proposals in the literature. Some properties of our languages are proved, in particular that emptiness of a context-free nominal language L is decidable, and that the intersection of L with a regular nominal language is still context-free. This paves the way for model-checking systems against access control properties in the nominal case, which is our main objective.","Anytime perceptual grouping of 2D features into 3D basic shapes2D perceptual grouping is a well studied area which still has its merits even in the age of powerful object recognizer, namely when no prior object knowledge is available. Often perceptual grouping mechanisms struggle with the runtime complexity stemming from the combinatorial explosion when creating larger assemblies of features, and simple thresholding for pruning hypotheses leads to cumbersome tuning of parameters. In this work we propose an incremental approach instead, which leads to an anytime method, where the system produces more results with longer runtime. Moreover the proposed approach lends itself easily to incorporation of attentional mechanisms. We show how basic 3D object shapes can thus be detected using a table plane assumption.","A Low-Power Wideband High Dynamic Range Single-Stage Variable Gain Amplifier ","Designing effective user interfaces for crowdsourcing: an exploratory studyWe investigate characteristics of the technology platform for different types of crowdsourcing initatives, as characterized by their task type--specifically we classify crowdsourcing applications by task structure, task interdependence, and task commitment. The method employed is to examine best practices of well-known crowdsourcing applications, investigating their user interface features, and characteristics that make them successful examples of crowdsourcing. Among the best practices uncovered were the following: easy searching for information; adaptive user interfaces that learned from the crowd; easy-to-use mobile interfaces; the ability to vote ideas up or down; credentialing; and creating sticky user interfaces that engaged the user. Finally, we consider issues for further study and investigation.","Design and Analysis of a Spatial Remote Center of Compliance MechanismThis paper presents a novel monolithic spatial remote center of compliant orientation-adjusting mechanism to resolve the parallelism alignment problem in the application of micro/nanofabrication. The mechanism is combined by two leaf-type isosceles-trapezoidal flexure pivots in a parallel manner to enable the spatial rotations around a fixed remote center. Based on the stiffness matrix method, the static model of the compliant mechanism is constructed to directly give the compliance factors that completely define the elastic response of the mechanism. The locations of remote center of compliance are also analyzed for the compliant mechanism in different loading cases. The finite element analysis results are then given to validate the analytical model and the remote center locations. The deviation of the analytical approach is less than 7% with respect to the finite element analysis method. Using the analytical model, the influences of the geometry parameters on the compliance factors and the remote center locations are graphically evaluated to provide theoretical guidelines for the practical design. The spatial remote center of compliant mechanism has the advantage of simple structure, balance, compactness, and can achieve high precision of rotation during the orientation motions.","Compressing Semantic Metadata for Efficient Multimedia RetrievalThe growth in multimedia production has increased the size of au- diovisual repositories, and has also led to the formation of increasingly large metadata collections about these contents. Deciding how these collections are effectively represented is challenging due to their variety and volume. Besides, large volumes also affect the performance of metadata retrieval tasks, compromis- ing the success of multimedia search engines. This paper focuses on this scenario and describes a case study in which semantic technologies are used for address- ing metadata variety, and advanced compression techniques for dealing with the volume dimension. As a result, we obtain a multimedia search prototype that con- sumes compressed RDF metadata. This approach efficiently resolves a subset of SPARQL queries by implementing representative multimedia searches, and also provides full-text search in compressed space.","Multi-scale Image Segmentation Using MSERRecently several research works propose image segmentation algo- rithms using MSER. However they aim at segmenting out specific regions cor- responding to user-defined objects. This paper proposes a novel algorithm based on MSER which segments natural images without user intervention and captures multi-scale structure. The algorithm collects MSERs and then parti- tions whole image plane by redrawing them in specific order. To denoise and smooth the region boundaries, hierarchical morphological operations are devel- oped. To illustrate effectiveness of the algorithm's multi-scale structure, effects of various types of LOD control are shown for image stylization.","When Aspect-Orientation Meets Software Product Line Engineering ","Towards an Automatic Creation of Localized Versions of DBpediaDBpedia is a large-scale knowledge base that exploits Wikipedia as primary data source. The extraction procedure requires to manually map Wikipedia infoboxes into the DBpedia ontology. Thanks to crowdsourcing, a large number of infoboxes has been mapped in the English DBpedia. Consequently, the same procedure has been applied to other languages to create the localized versions of DBpedia. However, the number of accomplished mappings is still small and limited to most frequent infoboxes. Furthermore, mappings need maintenance due to the constant and quick changes of Wikipedia articles. In this paper, we focus on the problem of automatically mapping infobox attributes to properties into the DBpedia ontology for extending the coverage of the existing localized versions or building from scratch versions for languages not covered in the current version. The evaluation has been performed on the Italian mappings. We compared our results with the current mappings on a random sample re-annotated by the authors. We report results comparable to the ones obtained by a human annotator in term of precision, but our approach leads to a significant improvement in recall and speed. Specifically, we mapped 45,978 Wikipedia infobox attributes to DBpedia properties in 14 different languages for which mappings were not yet available. The resource is made available in an open format.","A Detailed Analysis of a Multi-agent Diverse TeamIn an open system we can have many different kinds of agents. However, it is a challenge to decide which agents to pick when forming multi-agent teams. In some scenarios, agents coordinate by voting continuously. When forming such teams, should we focus on the diversity of the team or on the strength of each member? Can a team of diverse (and weak) agents outperform a uniform team of strong agents? We propose a new model to address these questions. Our key contributions include: (i) we show that a diverse team can overcome a uniform team and we give the necessary conditions for it to happen; (ii) we present optimal voting rules for a diverse team; (iii) we perform synthetic experiments that demonstrate that both diversity and strength contribute to the performance of a team; (iv) we show experiments that demonstrate the usefulness of our model in one of the most difficult challenges for Artificial Intelligence: Computer Go.","How to Teach Regulatory Compliant Data Warehouse EngineeringThe steady increase of regulatory reporting requirements for banks increases the demand for compliant data warehouse and reporting systems. Data warehouse designers are forced to work in interdisciplinary teams consisting of accountants and legal experts in order to meet the regulatory requirements. In this paper, we present a teaching concept that simulates a realistic data warehouse development scenario in financial service industries. By applying this teaching concept, students learn how to design compliant data warehouse systems. Implicitly students experience the challenges of interdisciplinary data warehouse engineering teams and conceptual (reference) modeling. The didactical concept, which is based on learning levels, sensitizes students for the usefulness and applicability of conceptual (reference) modeling and was positively evaluated in two elective courses.","Automated Co-Analysis of MALDI and H&amp;E Images of Retinal Tissue for an Improved Spatial MALDI Resolution ","Evolutionary Synthesis of Control Rules by Means of Analytic Programming for the Purpose of High Order Oscillations Stabilization of Evolutionary Synthesized Chaotic System ","GAMA: A Spatially Explicit, Multi-level, Agent-Based Modeling and Simulation PlatformAgent-based modeling is now widely used to investigate complex systems but still lacks integrated and generic tools to support the representation of features usually associated with real complex systems, namely rich, dynamic and realistic environments or multiple levels of agency. The GAMA platform has been developed to address such issues and allow modelers, thanks to the use of a high-level modeling language, to build, couple and reuse complex models combining various agent architectures, environment representations and levels of abstraction.","A study on the randomness reduction effect of extreme learning machine with ridge regressionIn recent years, Extreme Learning Machine (ELM) has attracted comprehensive attentions as a universal function approximator. Comparing to other single layer feedforward neural networks, its input parameters of hidden neurons can be randomly generated rather than tuned, and thereby saving a huge amount of computational power. However, it has been pointed out that the randomness of ELM parameters would result in fluctuating performances. In this paper, we intensively investigate the randomness reduction effect by using a regularized version of ELM, named Ridge ELM (RELM). Previously, RELM has been shown to achieve generally better generalization than the original ELM. Furthermore, we try to demonstrate that RELM can also greatly reduce the fluctuating performance with 12 real world regression tasks. An insight into this randomness reduction effect is also given.","ACO-Based bayesian network ensembles for the hierarchical classification of ageing-related proteinsThe task of predicting protein functions using computational techniques is a major research area in the field of bioinformatics. Casting the task into a classification problem makes it challenging, since the classes (functions) to be predicted are hierarchically related, and a protein can have more than one function. One approach is to produce a set of local classifiers; each is responsible for discriminating between a subset of the classes in a certain level of the hierarchy. In this paper we tackle the hierarchical classification problem in a local fashion, by learning an ensemble of Bayesian network classifiers for each class in the hierarchy and combining their outputs with four alternative methods: a) selecting the best classifier, b) majority voting, c) weighted voting, and d) constructing a meta-classifier. The ensemble is built using ABC-Miner, our recently introduced Ant-based Bayesian Classification algorithm. We use different types of protein representations to learn different classification models. We empirically evaluate our proposed methods on an ageing-related protein dataset created for this research.","Improved Colon Navigation for Efficient Polyp Detection in Virtual ColonoscopyColon cancer is a leading cause of death in the world and its early diagnosis highly increases the chances of survival. Virtual colonoscopy is a widely spreading technology that is used for polyp detection, the primary cause of colon cancer. This paper revisits an existing virtual colonoscopy technique, called Fly-over. It splits the colon into two halves along its centerline and assigns a camera to each half for navigation. While cutting the colon along its centerline increases the possibility of having missed polyps, the technique is re-visited here and the cutting framework is changed, which improved the rate of detection. Clinical validation was assessed by testing the navigation technique on several cases of real and synthetic challenging polyps versus other techniques. Fly-over technique provides efficient polyp detection of up to 100% with the least distortion rate.","Locality in Continuous Fitness-Valued Cases and Genetic Programming Difficulty ","Improved View Selection Algorithm in Data Warehouse ","The design in the development of exergames: a new game for the contribute to control childhood obesityObesity is increasing alarmingly worldwide, especially in children's audience, due to the adoption of sedentary habits. The exergames are a new class of digital games that have arisen over the possible use of technology, low cost, to unite physical activity to video games such as Nintendo Wii, X-Box 360, among others. And these have been gaining ground due to immersion of users, working their cognitive skills, attention and memory. This study presents a new game, the PEGGO developed by Federal University of Pernambuco, with data supporting the use for this type of game in order to contribute to help control childhood obesity.","Characterizing video access patterns in mainstream media portalsWatching online videos is part of the daily routine of a considerable fraction of Internet users nowadays. Understanding the patterns of access to these videos is paramount for improving the capacity planning for video providers, the conversion rate for advertisers, and the relevance of the whole online video watching experience for end users. While much research has been conducted to analyze video access patterns in user-generated content (UGC), little is known of how such patterns manifest in mainstream media (MSM) portals. In this paper, we perform the first large-scale analysis of video access patterns in MSM portals. As a case study, we analyze interaction logs across a total of 38 Brazilian MSM portals, including six of the largest portals in the country, over a period of eight weeks. Our analysis reveals interesting static and temporal video access patterns in MSM portals, which we compare and contrast to the access patterns reported for UGC websites. Overall, our analysis provides several insights for an improved understanding of video access on the Internet beyond UGC websites.","UML Diagrams Generation Process by Using Knowledge-Based SubsystemThe main scope of the paper is to present UML diagrams generation process from enterprise model. The paper analyzes the differences between traditional information systems (IS) engineering and knowledge-based engineering. There is proposed to use knowledge-based subsystem for the purpose of avoiding empirically based IS development process.","From Loyalty Points to Virtual Currencies: Expanding Loyalty Schemes for Mobile Platforms ","Stochastic Bounds and Histograms for Network Performance Analysis ","Data transmission latency and sense of controlLatency has been identified as a major bottleneck for usability of human-system interaction devices. However, the theoretical basis of the effect of latency on action control mechanisms remains weak. In this study, we aimed to investigate the cognitive implications of latency for Human-Computer Interaction. We proposed models of agency (i.e., mechanism underlying the feeling of control) as a possible interpretative framework on the nature of the transformation induced by latency. In a series of 3 experiments, we propose to tackle this problem by (1) characterizing the effects (performance and agency) of transmission delays on UAS camera control, and (2) designing and evaluating HMI solutions to mitigate these effects with regard to the agency principle. Our results showed that (1) latency decreases sense of agency and human performance, (2) models of agency could provide HMI solution for latency compensation. Interests of agentive experience accounts for better system design are discussed.","Multivariate Modelling of Cross-Commodity Price Relations Along the Petrochemical Value Chain ","Autonomous Navigation Applying Dynamic-Fuzzy Cognitive Maps and Fuzzy Logic ","Cloud Search Engine for IaaSCloud based online storage enables the storage of massive data. In these systems, a full text search engine is very important for finding documents. In this paper, we propose a distributed search engine suitable for searching a cloud. In our previous work, we developed a distributed search engine, the cooperative search engine (CSE). We now extend the CSE to search clouds. In a cloud, elasticity and reliability are important. We realize these by employing consistent hashing for distributed index files in the cloud. In this paper, we describe the improved CSE architecture and its implementation for a cloud search.","Person Detection with a Computation Time Weighted AdaBoostIn this paper, a boosted cascade person detection framework with heterogeneous pool of features is presented. The boosted cascade construction and feature selection is carried out using a modified AdaBoost that takes computation time of features into consideration. The final detector achieves a low Miss Rate of 0.06 at 10'\u2014' 3 False Positive Per Window on the INRIA public dataset while achieving an average speed up of 1.8\u00d7 on the classical variant.","How to Identify Tomorrow's Most Active Social Commerce Contributors? Inviting Starlets to the Reviewer Hall of Fame ","Biological models for active vision: towards a unified architectureBuilding a general-purpose, real-time active vision system completely based on biological models is a great challenge. We apply a number of biologically plausible algorithms which address different aspects of vision, such as edge and keypoint detection, feature extraction, optical flow and disparity, shape detection, object recognition and scene modelling into a complete system. We present some of the experiments from our ongoing work, where our system leverages a combination of algorithms to solve complex tasks.","Problematic Use of Massively Multiplayer Online Games: Scale Development and Validation ","A probabilistic medium access scheme for d2d terminals to improve data transmission performance of flashlinqIn existing wireless communication systems such as cellular network, base station can become bottleneck since terminals have to exchange data traffic each other only through a base station. In order to solve this problem, device-to-device (D2D) communication has been considered. Recently, Qualcomm Inc. has introduced FlashLinQ (FLQ) for D2D communication, which has a radio frame based on orthogonal frequency division multiplex (OFDM). In FLQ, terminals distributively access to medium based on their D2D link qualities and interference from other terminals. However, terminal with low link quality can cause that other terminals excessively give up their medium access. In order to solve this problem, we propose a probabilistic medium access scheme for D2D terminals in FLQ. In the proposed scheme, terminal stochastically tries accessing to medium based on its link quality, and the excessive yieldings of other terminals are reduced. Through simulation, we evaluate performance of the proposed scheme by comparing that of FLQ. We show that the proposed scheme can improve performance of FLQ by simulation results.","Multi-tenant Network Monitoring Based on Software Defined Networking ","Using JOANA for Information Flow Control in Java Programs \u2013 A Practical Guide ","A sensor data mediator bridging the OGC sensor observation service (SOS) and the OASIS open data protocol (OData)The World-Wide Sensor Web is generating tremendous amount of real-time sensor data streams, and will enable scientists to observe phenomena that are previously unobservable. As the concept of sensor web is to connect all the sensors and their data to achieve shared goals, improving the openness and accessibility of sensor data is important. Open Geospatial Consortium Sensor Observation Service (SOS) defines standard web service protocols for sharing sensor data online in an interoperable manner. However, the SOS has a relatively weak ecosystem, which makes it difficult to build and consume; and it only supports predefined queries. On the other hand, the OASIS Open Data Protocol (OData) has a strong ecosystem and flexible query functions. But the soft-typing approach of OData requires it to have a commonly agreed data model to be interoperable. As we find that the two standards can benefit from each other, we propose a sensor data mediator solution and define an SOS entity data model for OData (SOS-OData) to bridge these two standards. Our prototype demonstrates that the proposed system can convert between existing SOS services and SOS-OData services. As a result, we can not only consume SOS data with the flexible OData protocol, but can also easily build an SOS-compliant service with the strong OData ecosystem. We argue that the bridge between these two standards would lead us to the vision of open data for sensor web.","A Novel Region Growing Segmentation Algorithm for Mass Extraction in Mammograms ","SynC-LD: Synchronous Collaborative IMS Learning Design Authoring on the WebThe IMS Learning Design LD specification enables the formal definition of teaching and learning flows. Several IMS LD authoring tools have been developed, most of them desktop based. There are few authoring tools that are deployed in a browser based environment, and some have built-in support for asynchronous collaboration during authoring via shared repositories. However, there are currently no tools available that enable synchronous, collaborative authoring in real-time. This demonstration presents SynC-LD, a novel widget-based tool that closes this gap. It supports browser-based, collaborative visual modeling of activity flows and the definition of IMS LD elements and their attributes. Multiple users can collaborate synchronously on the same learning design, which is achieved through inter-widget communication technology. Initial end-user trials show that the SynC-LD tool is usable and that IMS LD authors see potential in real-time IMS LD authoring.","A Pruning Algorithm for Extreme Learning MachineIt is difficult for Extreme Learning Machine ELM to estimate the number of hidden nodes used to match with the learning data. In this paper, a novel pruning algorithm based on sensitivity analysis is proposed for ELM. The measure to estimate the necessary number of hidden layer nodes is presented according to the defined sensitivity. When the measure is below the given threshold, the nodes with smaller sensitivities are removed from the existent network all together. Experimental results show that the proposed method can produce more compact neural network than some other existing similar algorithms.","Simulating a walk of digital human model directly in massive 3d laser-scanned point cloud of indoor environmentsRecently, human behavior simulations in 3-dimensional environment models have been enabled by the advance in computer performances. However, manually building the 3D models for the simulations are still costly and time-consuming, and the resultant models are sometimes inaccurate and do not necessarily reflect as-built environments. The final goal of our research is to realize the accessibility evaluation of \"as-built\" environments based on the human behavior simulation. To achieve the goal, in this study, we developed a technology where as-built 3D environment models could be constructed in a fully automatic way from laser-scanned 3D point clouds measured from as-built indoor environments. Additionally, we realized a basic walking simulation function in the as-built environment model represented by the point clouds. The modeling and simulation efficiency and accuracy were evaluated.","Product Reputation Manipulation: The Impact of Shill Reviews on Perceived QualityOnline reviews have become a popular method for consumers to express personal evaluations and buyers to use as a source of product quality information in purchasing decisions. However, integrity of review systems is threatened by evidence about the prevalence of shill reviews. To understand the impact of shill reviews, an experiment was conducted to collect shill reviews and measure the impact of shill reviews on perceived product quality. The results showed positive shill reviews significantly increased quality perceptions of consumers for thinly reviewed products. This finding provides strong evidence about the risks of shill reviews and emphasizes the need to develop effective detection and prevention methods.","Online Matching of Multiple Regular Patterns with Gaps and Character ClassesGiven a dictionary D of regular expressions and a text T , the online regular-pattern-matching problem is to single out, for each text position T (c), those expressions in D that have a match ending at T (c), while processing T only once. This problem is considered in the context of regular patterns over bounded-length gaps and keywords, where the gaps are specified by wildcards and character classes and the keywords are strings over the input alphabet. Our algorithm is based on constructing the Aho-Corasick pattern-matching automaton for the set of keywords, and representing as a bit vector the set of keywords that can precede a given keyword in a regular-pattern instance. For a dictionary D with r patterns and with ki keywords in pattern i, the preprocessing takes time O(|D| + r=1 k 2 i log ki/w), where w denotes the number of bits in a memory word. When only fixed-length wildcard gaps without character classes are allowed, the time spent by our matching algorithm for each text character T (c )i s at mostO((log r + k/w)(Kc + 1)), where k =m ax{k1 ,...,k r} and Kc is the number of keyword occurrences in D matched at text position T (c).","Outlines of Objects Detection by AnalogyIn this paper we propose a new technique for outlines of objects detection. We exploit the set of contours computed using the image analogies principle. A set of artificial patterns are used to locate contours of any query image, each one permits the location of contours corresponding to a specific intensity variation. We studied these contours and a theoretical foundation is proposed to explain the slow motion of these contours around regions boundaries. Experiments are conducted and the obtained results are presented and discussed.","Freedom of information and abuse of media in the process of globalization.Freedom of information, Freedom of expression, Freedom of speech, Globalization, Media, Media abuse, Abuse of media, Milan Palevic, Srdjan Djordjevic","EEG Dataset Reduction and Classification Using Wave Atom TransformBrain Computer Interface (BCI) systems perform intensive processing of the electroencephalogram (EEG) data in order to form control signals for external electronic devices or virtual objects. The main task of a BCI system is to correctly detect and classify mental states in the EEG data. The efficiency (accuracy and speed) of a BCI system depends upon the feature dimensionality of the EEG signal and the number of mental states required for control. Feature reduction can help improve system learning speed and, in some cases, classification accuracy. Here we consider Wave Atom Transform (WAT) of the EEG data as a feature reduction method. WAT takes input data and concentrates its energy in a few transform coefficients. WAT is used as a data preprocessing step for feature extraction. We use artificial neural networks (ANNs) for classification and perform research with varying number of neurons in a hidden layer and different network training functions (Levenberg-Marquardt, Conjugate Gradient Backpropagation, Bayesian Regularization). The novelty of the paper is the application of WAT in the EEG data processing. We conclude that the method can be successfully used for feature extraction and dataset feature reduction in the BCI domain.","Emergence in Nascent Online Communities: An Affordance Perspective. ","Display pointing: a qualitative study on a recent screen pairing technique for smartphonesIn this paper, we investigate display pointing as a recent mobile pairing technique for public screens enabling the simple targeting of the remote display with the mobile device. We evaluate a functional prototype in a user study emphasizing the crucial first connection phase independent from any consequent interaction style. In the presented initial study, we deliberately focus on the qualitative issues of this technique and identified a list of practical and fun aspects. According to the results, the display pointing approach is perceived as a (partly too) fast, robust and fascinating pairing technique which has the potential to gamify the connection process.","Local Shape Analysis for Overlaid Data Structures ","Computer-Aided Detection of Microcalcifications in Digital Mammograms to Support Early Diagnosis of Breast Cancer ","New online algorithms for story scheduling in web advertisingWe study storyboarding where advertisers wish to present sequences of ads (stories) uninterruptedly on a major ad position of a web page. These jobs/stories arrive online and are triggered by the browsing history of a user who at any time continues surfing with probability \u03b2. The goal of an ad server is to construct a schedule maximizing the expected reward. The problem was introduced by Dasgupta, Ghosh, Nazerzadeh and Raghavan (SODA'09) who presented a 7-competitive online algorithm. They also showed that no deterministic online strategy can achieve a competitiveness smaller than 2, for general \u03b2.#R##N##R##N#We present improved algorithms for storyboarding. First we give a simple online strategy that achieves a competitive ratio of 4/(2\u2212\u03b2), which is upper bounded by 4 for any \u03b2. The algorithm is also 1/(1\u2212\u03b2)-competitive, which gives better bounds for small \u03b2. As the main result of this paper we devise a refined algorithm that attains a competitive ratio of c=1+\u03c6, where \u03d5 = (1 + \u221a5)/2 is the Golden Ratio. This performance guarantee of c\u22482.618 is close to the lower bound of 2. Additionally, we study for the first time a problem extension where stories may be presented simultaneously on several ad positions of a web page. For this parallel setting we provide an algorithm whose competitive ratio is upper bounded by $1/(3-2\\sqrt{2})\\approx 5.828$, for any \u03b2. All our algorithms work in phases and have to make scheduling decisions only every once in a while.","Multi-target detection and recognition by UAVs using online POMDPsThis paper tackles high-level decision-making techniques for robotic missions, which involve both active sensing and symbolic goal reaching, under uncertain probabilistic environments and strong time constraints. Our case study is a POMDP model of an online multi-target detection and recognition mission by an autonomous UAV. The POMDP model of the multi-target detection and recognition problem is generated online from a list of areas of interest, which are automatically extracted at the beginning of the flight from a coarse-grained high altitude observation of the scene. The POMDP observation model relies on a statistical abstraction of an image processing algorithm's output used to detect targets. As the POMDP problem cannot be known and thus optimized before the beginning of the flight, our main contribution is an \"optimize-while-execute\" algorithmic framework: it drives a POMDP sub-planner to optimize and execute the POMDP policy in parallel under action duration constraints. We present new results from real outdoor flights and SAIL simulations, which highlight both the benefits of using POMDPs in multi-target detection and recognition missions, and of our \"optimize-while-execute\" paradigm.","Dynamic Version of the ACDT/ACDF Algorithm for H-Bond Data Set AnalysisThis article is devoted to the new application of the ACDT/ACDF algorithms. In this work we distinguish ant colony optimization and join it with decision tree construction algorithms, the proposed approach builds more stable decision forests. Additionally, we would like to mention that it is possible to analyze the overloaded data sets. Several methods are proposed in this study, each considered different pseudo-samples from training data sets. We combine ideas from ACO, Boosting and Random Forests. We show that our algorithms perform comparable to common approaches. Moreover, we demonstrate the suitability of our method to H-bonds detections in protein structures.","Graph-based Approach to Automatic Taxonomy Generation (GraBTax)We propose a novel graph-based approach for constructing concept hierarchy from a large text corpus. Our algorithm, GraBTax, incorporates both statistical co-occurrences and lexical similarity in optimizing the structure of the taxonomy. To automatically generate topic-dependent taxonomies from a large text corpus, GraBTax first extracts topical terms and their relationships from the corpus. The algorithm then constructs a weighted graph representing topics and their associations. A graph partitioning algorithm is then used to recursively partition the topic graph into a taxonomy. For evaluation, we apply GraBTax to articles, primarily computer science, in the CiteSeerX digital library and search engine. The quality of the resulting concept hierarchy is assessed by both human judges and comparison with Wikipedia categories.","Knowledge Maximizer: Concept-Based Adaptive Problem Sequencing for Exam PreparationTo support introductory Java programming students in preparing for their exams, we developed Knowledge Maximizer as a concept-based problem sequencing tool that considers a fine-grained concept-level model of student knowledge accumulated over the semester and attempts to bridge the possible knowledge gaps in the most efficient way. This paper presents the sequencing approach behind the Knowledge Maximizer and its classroom evaluation.","Dimensionality reduction of phone log-likelihood ratio features for spoken language recognition. ","Incremental Constrained Clustering: A Decision Theoretic ApproachTypical constrained clustering algorithms incorporate a set of must-link and cannot-link constraints into the clustering process. These instance level constraints specify relationships between pairs of data items and are generally derived by a domain expert. Generating these constraints is considered as a cumbersome and expensive task.#R##N##R##N#In this paper we describe an incremental constrained clustering framework to discover clusters using a decision theoretic approach. Our framework is novel since we provide an overall evaluation of the clustering in terms of quality in decision making and use this evaluation to \"generate\" instance level constraints. We do not assume any domain knowledge to start with. We show empirical validation of this approach on several test domains and show that we achieve better performance than a feature selection based approach.","Impact of the Production Mix Preservation on the ORV ProblemWe present a sequencing problem given on JIT (Just In Time) manufacturing environments, with the objective of minimizing the variation of manufacturing rates (ORV: Output Rate Variation). Specif- ically, we propose an extension based on requiring to the sequences the preservation of the production mix throughout the products manufactur- ing. To solve the ORV and the extended problem, we propose algorithms based on BDP (Bounded Dynamic Programming) and we perform two computational experiments based on instances from the literature.","Real-Time Stereo Rendering Technique for Virtual Reality System Based on the Interactions with Human View and Hand GesturesThis paper proposes the methods of generating virtual reality system with stereo vision, simple and widely used 3D stereoscopic displays. However, we are motivated by not only 3D stereo display but also realistic rendered scenes popped out of screen which can be thought of as an interactive system addressing the human-to-virtual-objects manipulation. The user of the system can observe the objects in the scene in 3D stereoscopy and can manipulate directly by using hand gestures. We present the technique to render the 3D scene out of the screen and use KINECT device to keep track of user's hand movement to render the objects according to the user's view.","Text-Independent Phoneme Segmentation via Learning Critical Acoustic Change PointsThe conventional methods of automatic text-independent phoneme segmentation detect phoneme boundaries via calculating the acoustic changes along speech signals followed by a peak picking pro- cedure according to user-defined rules. Instead, this paper presents a learning-based method in which the phoneme boundaries are viewed as critical points in the acoustic change context of speech signals. First, we adopt a metric learning procedure in the calculation of acoustic changes, in order to make the acoustic changes at phoneme boundaries more dis- criminative. Then, latent-dynamic conditional random field is used to model the acoustic change context of speech signals for the detection of phoneme boundaries. The experiments demonstrate that our method outperforms the rule-based methods reported in previous work.","Knowledge Management Strategy and Service Firm Performance: A Comparison of Firms Competing on Low- Cost versus High-QualityThis study contributes to the knowledge management literature by comparing the effects of four knowledge strategy configurations on the performance of service firms competing on low-cost versus high-quality. Data was collected from 107 hospitality establishments operating in South Africa. Firms competing on low-cost and high-quality were classified into one of four groups based on their approach to knowledge management and were then compared on two dimensions of service firm performance. Results suggest that information (IT) based approaches to knowledge management are associated with high performance amongst hospitality services firms competing on low-cost whilst human capital based approaches are associated with high performance amongst firms competing on quality. Implications for knowledge management are discussed.","Food Product Traceability by Using Automated Identification TechnologiesFood product traceability from harvesting, through food processing to the final food product and through the retailer to the end consumer is a significant process that has to ensure food quality and safety. The traceability enables the end consumer to get information from all previous stages of the food product, leading back to the food origin. In this way, the consumer can get more information on the specific product, and thus make a decision on buying the product that suits his needs best. In each stage of the food product transformation, important data are generated for the subsequent chain participants. Every participant should have access to certain data of interest to them. This can be achieved by using automated identification technologies, like RFID (Radio Frequency IDentification) and two-dimensional barcode, which allow faster data acquisition, recording and reading processes than the traditional means, and provide up-to-date information in each product stage. Furthermore, these technologies allow the possibility to record large amounts of data for each specific product, and interconnect all the data in a database. This paper discusses the process of providing traceability of food products, recording, transmitting and reading of significant data in specific stages of food product chain, with the application of automated identification technologies, including the possibility of obtaining additional data from a database, according to appropriate access level of each participant in the chain. Advantages and disadvantages of automated identification technologies are discussed, with the proposition for using specific technologies in certain food product stages.","Reference Value Generator of Maximum Power Point Coordinates of the Photovoltaic Panel External Characteristic ","A new method for BCI spelling using a 7 segments displayResearch on Brain Computer Interfaces (BCI) covers a wide specturm of applications. In this paper we tackle the problem of spelling words which could be used by people with harmful motor skills. The P300 has been widely used to communicate with the machine using a set of stimuli. For the word spelling problem, several approaches have been proposed although the most popular consists on an array of characters.#R##N##R##N#The novelty of the work proposed in this paper is that the panel that estimulates the user generating the P300 usually performs better in terms of efficiency and allows a better visual focalisation.#R##N##R##N#At this preliminary stage of the research, several experiments were carried out using simulated signals showing that, indeed, the new way of stimulating the user could make word spelling faster.","Big Data Workloads Drawn from Real-Time Analytics Scenarios Across Three Deployed Solutions ","Arbeitszeit und Arbeitsvolumen in Deutschland \u2013 Methodische Grundlagen und Ergebnisse der ArbeitszeitrechnungTo present and analyze the aggregated development of the labor market comprehensively, it is not sufficient to look at the figures of employment. In fact, it is necessary to calculate the volume of work relating to specific periods as a product from employment figures and working hours. The IAB working time measurement concept (AZR) forms the basis for the analysis of the developments of working hours and their causes. In the AZR changes in collective agreements and economic trends flow together with shifts in employment structures, producing a differentiated picture of the scope, structure and development of the annual working time of gainfully employed persons. The results of the AZR offer a suitable basis for the evaluation of labor market developments and further perspectives. Copyright Springer-Verlag Berlin Heidelberg 2013","Interactive Principal Components Analysis: A New Technological Resource in the Classroom ","Fall Detection System Based on Kinect Sensor Using Novel Detection and Posture Recognition Algorithm ","Smart social architecture for green distributed networksNowadays, the energy consumption and efficiency of wireless networks have become a societal challenge. In this paper a novel system architecture is proposed to achieve green communications. The proposed smart social architecture exploits the flexibility and adaptability of cognitive radio CR technology to interact with the environment and achieve eco-sustainability by means of finding the best transmission opportunities. However, the effort required for CR nodes to obtain sensing measurements might make less effective the potential energy efficiency gain obtainable in CR networks. We thus propose to combine CR and social network technologies to maximize the energy efficiency and the associated context awareness in terms of energy and radio knowledge. In this way it is also possible to reduce the sensing burden of CR devices. Through the proposed approach, a greater awareness of environmental impacts by CR paradigm can be instilled in participating users, devices and backbones. This is based on a novel extension of the concept of social network, and specifically by allowing socialization among all the network actors, both users as it is already done today and cognitive devices to develop a much lighter and more flexible distributed infrastructure. The functionalities of the network elements and their interfaces are described in detail.","A comparison between different encoding strategies for snake-like robot controllersIn this paper, we present the results of the tests we have performed with different encoding strategies for evolving controllers for a snake-like robot. This study is aimed at finding the best encoding for on-line learning of basic skills, such as locomotion (both free and directed to an objective) and obstacle avoidance. The snake moves in a virtual world, which realistically simulates all the physical conditions of the real world. This is the first step of our research on on-line, embedded and open-ended evolution of robot controllers, where robots have to learn how to survive during their lifetime, and occasionally mate with other robots. A simple (1+1) evolutionary strategy has been adopted for lifetime learning. The results of the tests have shown that the best results, tested on the locomotion skills, is the 'He1Sig' controller, that uses a different set of parameters for each segment of the snake but only one mutation rate, common to all parameters, that is encoded in the chromosome and therefore undergoes evolution itself.","Integrating Potential Users Into the Development of a Medical Wrist Watch in Four Steps ","Defining patient-centered characteristics of a telerehabilitation system for patients with COPD.Abstract Studies have shown that pulmonary rehabilitation in patients with chronic obstructive pulmonary disease (COPD) can help to restore or enhance residual functional capacity and improve quality of life. Home-based telemedicine systems can promote comprehensive pulmonary rehabilitation in COPD patients. Successful acceptance of such systems depends on how well they reflect needs, values and preferences of older adults with COPD. However, patient-centered characteristics of pulmonary telerehabilitation systems were not systematically defined particularly in older adults. The goal of this pilot study was to assess older COPD patient acceptance of pulmonarytelerehabilitation and to develop patient-centered characteristics of computer technology to support pulmonary rehabilitation at homes of older adults with COPD based on their values, needs, and preferences. A prototype pulmonarytelerehabilitaton system was developed and demonstrated to patients. The system feasibility and acceptance was assessed by identifying patient ability to operate the system independently and by collecting open-ended feedback via semi-structured qualitative interview and attitudinal surveys. Older adults found this technology easy to operate and potentially useful personal rehabilitation. Patient-centered specifications of a comprehensive pulmonary telerehabilitation system in older adults with COPD were identified.","Learning and Creativity in the Global WorkspaceThe key goal of cognitive science is to produce an account of the phenomenon of mind which is mechanistic, empirically supported, and credible from the perspective of evolution. In this talk, I will present a model based on Baars' (1) Global Workspace account of consciousness, that attempts to provide a general, uniform mechanism for information regulation. Key ideas involved are: information content and entropy (4,8), expectation (3,7), learning multi-dimensional, multi-level representations (2) and data (5), and data-driven segmentation (6). The model was originally based in music, but can be generalised to language (9). Most importantly, it can account for not only perception and action, but also for creativity, possibly serving as a model for original linguistic thought.","Real-Time Covert Timing Channel Detection in Networked Virtual EnvironmentsDespite extensive research on malware and Trojan horses, covert chan- nels are still among the top computer security threats. These attacks, which are launched using specially-crafted content or by manipulat- ing timing characteristics, transmit sensitive information to adversaries while remaining undetected. Current detection approaches typically analyze deviations from legitimate network traffic statistics. These ap- proaches, however, are not applicable to highly dynamic, noisy environ- ments, such as cloud computing environments, because they rely heavily on historical traffic and tedious model training. To address these chal- lenges, we present a real-time, wavelet-based approach for detecting covert timing channels. The novelty of the approach comes from lever- aging a secure virtual machine to mimic a vulnerable virtual machine. A key advantage is that the detection approach does not require histor- ical traffic data. Experimental results demonstrate that the approach exhibits good overall performance, including a high detection rate and a low false positive rate.","Patients as Innovators \u2013 The Development of Innovative Ideas with the IdeenschmiedeOnline Communities for Patients (POC) are very interactive sites where patients communicate with one another about diseases, therapies and how to deal with diseases and about personal experiences they have had. They also develop and share innovative ideas that make their everyday life easier. However, this happens mostly in an unsystematic and uncontrolled manner, as IT-supported interaction and communication tools in POC do not typically meet the specific requirements of ideation. For this ideation process, we developed a module called Ideenschmiede, which extends POC to support the collaborative and systematic idea development. The evaluation of the published ideas shows that the concept of the Ideenschmiede leads to ideas with an above-average quality level, indicating that collaborative ideation may also work in the healthcare context.","Planning as Inference in a Hierarchical Predictive MemoryIn the predictive brain hypotheses, the functional mechanism of the brain is suggested to infer the cause of current states within the predictions by brains. Recently, there have been several approaches to explain the action gen- eration within the predictive brain hypotheses: the brain predicts the animal's own action, which the animal realizes to fulfill the prediction. In this study, we suggest a predictive brain models to produce the goal directed behaviors. We introduced the Planning as Inference (PAI) framework to a hierarchical predictive memory model. PAI is a computational framework for goal-directed behavior generation. PAI explains the decision of an action for a state in the probabilistic distribution. The distribution is inferred from the evidences of current state and the perspective evidence of goal achievement. We used a hie- rarchical predictive memory system to predict the agent's self-action states. Following to the PAI, the predictions were inferred from the evidence of the ongoing state and the evidence from assumption of the goal achievement. The agents realizes the predicted actions to minimize prediction errors. We imple- mented our method in embodied robotics system and our model could generate structured spontaneous behavior and goal directed behaviors. Our result opens understanding for the goal-directed behavior in predictive brain hypotheses.","Program Transformation for Non-interference Verification on Programs with PointersNovel approaches for dynamic information flow monitoring are promising since they enable permissive (accepting a large subset of executions) yet sound (rejecting all insecure executions) enforcement of non-interference. In this paper, we present a dynamic information flow monitor for a language supporting pointers. Our flow-sensitive monitor relies on prior static analysis in order to soundly enforce non-interference. We also propose a program transformation that preserves the behavior of initial programs and soundly inlines our security monitor. This program transformation enables both dynamic and static verification of non-interference.","Social Networking and Social Media in the United States, South Korea, and China ","Using kinect for 2D and 3D pointing tasks: performance evaluationWe present a study to comparatively evaluate the performance of computer-based 2D and 3D pointing tasks. In our experiments, based on the ISO 9241-9 standard methodology, a Microsoft Kinect device and a mouse were used by seven participants. For the 3D experiments we introduced a novel experiment layout, supplementing the ISO. We examine the pointing devices' conformance to Fitts' law and we measure a number of extra parameters that describe more accurately the cursor movement trajectories. Throughput, measured in bits per second is the most important performance measure. For the 2D tasks using Microsoft Kinect, Throughput is almost 39% lower than using the mouse, Target Re-Entry is 10 times up and Missed Clicks count is almost 50% higher. However, for the 3D tasks the mouse has a 9% lower Throughput than the Kinect, while Target Re-Entry and Missed Clicks are almost identical. Our results are also compared to older studies, and we finally show that the Kinect, operated by the user's hand and voice, is a suitable and effective input method for pointing and clicking, especially in 3D tasks.","Extending extreme learning machine with combination layerWe consider the Extreme Learning Machine model for accurate regression estimation and the related problem of selecting the appropriate number of neurons for the model. Selection strategies that choose \"the best\" model from a set of candidate network structures neglect the issues of model selection uncertainty. To alleviate the problem, we propose to remove this selection phase with a combination layer that takes into account all considered models. The proposed method in this paper is the Extreme Learning Machine(Jackknife Model Averaging), where Jackknife Model Averaging is a combination method based on leave-one-out residuals of linear models. The combination approach is shown to have better predictive performance on several real-world data sets.","Hypothesis exploration for malware detection using planningIn this paper we apply AI planning to address the hypothesis exploration problem and provide assistance to network administrators in detecting malware based on unreliable observations derived from network traffic. Building on the already established characterization and use of AI planning for similar problems, we propose a formulation of the hypothesis generation problem for malware detection as an AI planning problem with temporally extended goals and actions costs. Furthermore, we propose a notion of hypothesis \"plausibility\" under unreliable observations, which we model as plan quality.We then show that in the presence of unreliable observations, simply finding one most \"plausible\" hypothesis, although challenging, is not sufficient for effective malware detection. To that end, we propose a method for applying a stateof-the-art planner within a principled exploration process, to generate multiple distinct high-quality plans. We experimentally evaluate this approach by generating random problems of varying hardness both with respect to the number of observations, as well as the degree of unreliability. Based on these experiments, we argue that our approach presents a significant improvement over prior work that are focused on finding a single optimal plan, and that our hypothesis exploration application can motivate the development of new planners capable of generating the top high-quality plans.","Optimizing Usability on Video Streaming Devices and Smart TV\u2019s ","Health Condition Alarm SystemA Health Condition Alarm System has been developed to provide practitioners an update on their patients' conditions in real-time. This paper focuses on how researchers and doctors can use the system to create vital sign ranges and alarm levels as well as to see the alarm alerts. The system is web-based and open-access, and the research team would like to collaborate with practitioners, hospitals, laboratories, and medical professionals to expand the system's application domains. The research team has leveraged two quality control methods, X-Chart and Westgard Multi-Rule, to decide the alarm level of a patient's health condition and the alarm timing. Four alarm levels (i.e., normal, subnormal, cautious, and alert) can then be decided by the mean values and standard deviations of the patient examination data.","OpenACC Parallelisation for Diffusion Problems, Applied to Temperature Distribution on a Honeycomb Around the Bee Brood: A Worked Example Using BiCGSTAB ","Design and Implementation of HDFS over Infiniband with RDMANowadays more and more data have been generated every day in some enterprises such as facebook and google. These data need to be collected and analyzed in time. So the speed of transmitting data must be very high and the latency must be very low. Hadoop is applied in these enterprises and they use several data centers to store and process these data. But if the amount of data is growing fast or we will use only one data center then the bandwidth of the Ethernet Hadoop Distributed File System (HDFS) using cannot meet the need. The bandwidth of the Ethernet is going to become the performance bottleneck of HDFS. In order to solve this problem we will introduce a relatively new switched fabric communication link\u2014-Infiniband in this paper. Based on Infini- band we have designed a new communication mechanism of HDFS and implemented it by modifying the code of HDFS. We use remote direct memory access (RDMA) to send and receive data rather than socket. The new HDFS will not use original stream mode to transmit data. Instead it will dynamically expand buffer and use changeable threshold. In this way the new HDFS will make CPU idle and improve performance. Unlike IPoIB which only uses Infiniband hardware device, our optimized HDFS is not only based on Infiniband hardware but also changes the code of HDFS to use RDMA. Our HDFS uses socket to transmit control mes- sage and RDMA to transmit data to make full use of the bandwidth of Infiniband. So applying the Infiniband with RDMA network bandwidth has not been the performance bottleneck of HDFS any more. According to the experiment results we have found that the network bandwidth of HDFS over Infiniband is 60 percent higher than the Ethernet and our optimized HDFS has much better performance than the HDFS over the Ethernet. On the other hand, the performance of our HDFS is also higher than the one which only use IPoIB.","Automatic Resource Scaling for Web Applications in the Cloud ","Causality-Based verification of multi-threaded programsWe present a new model checking procedure for concurrent systems against safety properties such as data races or atomicity violations. Our analysis sidesteps the state space explosion problem by inferring causal dependencies for concurrent traces instead of searching over a space of reachable states, and can be understood as an interplay between local trace inference and termination analysis based on causal loops. Local trace inference introduces new actions anywhere in the trace if they causally follow from the context. Our procedure terminates if we either find a complete error trace or the whole space of potential error traces is covered by causal loops. The causality-based verification of multi-threaded programs can be dramatically faster than the standard state space traversal. In particular, we show that the complexity of verifying multi-threaded programs with locks reduces from exponential to polynomial.","A Natural Interface for the Training of Medical Personnel in an Immersive and Virtual Reality System ","Study on the Application of GIS in Comprehensive Risk Assessment of Hazardous Chemical PlantsComprehensive risk assessment is very important work for effective prevention and control of chemical accidents in hazardous chemical procedure industries. This paper first proposes a perspective and workflow for comprehensive risk assessment of hazardous chemical plants. Several key components: case base, vulnerability analysis model, indicator system based risk assessment model are included in the workflow. As a kind of professional tool for geographical information manipulation, GIS can provide strong support for analysis of case data, especially some spatial location relevant data, which are in the majority among all case information. Next, GIS can provide support for implementation and run of vulnerability analysis models. Further, with strong spatial analysis capability of GIS, one can carry out Impact evaluation of a chemical accident. Thus, GIS can provide versatile support in comprehensive risk assessment of hazardous chemical plants. In this paper, we will affirm: Spatial analysis and visualization of GIS can facilitate the management of case base and provide fundamental support for vulnerability analysis and risk assessment models.","Evolutionary Customer Evaluation: a Dynamic Approach to a Banking Case ","Low-cost data deduplication for virtual machine backup in cloud storageIn a virtualized cloud cluster, frequent snapshot backup of virtual disks improves hosting reliability; however, it takes significant memory resource to detect and remove duplicated content blocks among snapshots. This paper presents a low-cost deduplication solution scalable for a large number of virtual machines. The key idea is to separate duplicate detection from the actual storage backup instead of using inline deduplication, and partition global index and detection requests among machines using fingerprint values. Then each machine conducts duplicate detection partition by partition independently with minimal memory usage. Another optimization is to allocate and control buffer space for exchanging detection requests and duplicate summaries among machines. Our evaluation shows that the proposed multi-stage scheme uses a small amount of memory while delivering a satisfactory backup throughput.","Humanoid Interface for Artificially Intelligent Role-Based Game PlayingInnovations of technology can change the way humans interact with their world. The demand for robotic technology is not exclusively influenced by the component specifications of what a robot is built of, but instead driven by the applications and potential of a robot. Humanoid robots are the best interface for human and robotic interaction because they are ergonomically designed to physically mimic a person thereby benefiting mankind by having the potential to physically operate in an environment designed for society. Moreover, humans are more apt to treat humanoid robots as companions because humans are more likely to project a personality onto the robot. This paper attempts to explore two topics: the advantages of entertainment based applications for humanoids as a vehicle for role-based game playing, and exploring the model for humanoid interaction with either a human adversary or a humanoid adversary. This paper also mentions entertainment based application implementations on systems with limited resources. We utilized the DARwIn- OP as a vehicle to demonstrate a fundamental application of basic artificial intelligence. In playing the role-based game of tic-tac-toe, we created a model for human to humanoid robot interaction as well as humanoid robot to humanoid robot interaction.","The Good, The Bad, The Weird: Audience Evaluation of a Real Robot in Relation to Science Fiction and Mass MediaWhen researchers develop robots based on a user-centered design approach, two important questions might emerge: How does the representation of robots in science fiction and the mass media impact the general attitude naive users have towards robots and how will it impact the attitude towards the specifically developed robot? Previous research has shown that many expectations of naive users towards real robots are influenced by media representations. Using three empirical studies (focus group, situated interviews, online survey) as a case in point, this paper offers a reflection on the interrelation of media representations and the robot IURO(Interactive Urban Robot). We argue that when it comes to the evaluation of a robot, \"good\" and \"bad\" media representations impact the attitude of the participants in a different way. Our results indicate that the previous experience of fictional robots through the media leads to \"weird\", double-minded feelings towards real robots. To compensate this, we suggest using the impact of the mass media to actively shape people's attitude towards real robots.","The synthetic littermateI suggest how a new type of biohybrid society --- a huddle of neonatal rat pups comprising biological and synthetic litttermates --- could be used to model the interaction between self-organisation at the neural level and self-organisation at the level of group behaviours.","Bat Monitoring System for Wind FarmsAbstract   In this work we present a bat monitoring system for wind farms. The proposed system includes a thermal camera and an ultrasound acquisition device to detect and record bats that come into the detection range of each one of these devices. All events are registered simultaneously with climatic variables and sent to a central database using 3G/4G. The system was designed to allow several monitoring systems to send data to the central server at the same time. We expect this system to allow the determination of climatic conditions that favor bat activity, especially in the proximity of wind turbines, and to use this information to define shutdown strategies to mitigate bat mortality caused by these infrastructures.","Towards Morphological Image Regularization Using the Counter-Harmonic MeanThe introduction of nonlinear filters which approximate flat dilation and erosion is an issue that has been studied during the past years. In the litera- ture, we can find works which involve the definition of robust morphological-like filters from well-known operators such as the Counter-Harmonic Mean (CHM). The main goal of this paper is to provide the reader with a morphological CHM- based regularization which simultaneously preserve both the structural informa- tion in areas of the image with high gradient and the morphological effect in the areas with low gradient. With this purpose, we introduce a suitable mathemat- ical framework and then deal with the variational formulation which is derived from it. Practical aspects of the implementation are discussed and some results are provided to illustrate the behaviour of our approach.","A case study on the impacts of computerized provider order entry (CPOE) system on hospital clinical workflow. ","Mining of Association Patterns in Social Network Data (Face Book 100 Universities) through Data Mining Techniques and Methods ","Improved Flow Shop Schedules with Total Completion Time Criterion ","Mapping Polygons with Agents That Measure Angles ","Multipath Algorithms and Strategies to Improve TCP Performance over Wireless Mesh Networks ","DireWolf - distributing and migrating user interfaces for widget-based web applicationsWeb applications have overcome traditional desktop applications especially in collaborative settings. However, the bulk of Web applications still follow the \"single user on a single device\" computing model. Therefore, we created the DireWolf framework for rich Web applications with distributed user interfaces (DUIs) over a federation of heterogeneous commodity devices supporting modern Web browsers such as laptops, smart phones and tablet computers. The DUIs are based on widget technology coupled with cross-platform inter-widget communication and seamless session mobility. Inter-widget communication technologies connect the widgets and enable real-time collaborative applications as well as runtime migration in our framework. We show that the DireWolf framework facilitates the use case of collaborative semantic video annotation. For a single user it provides more flexible control over different parts of an application by enabling the simultaneous use of smart phones, tablets and computers. The work presented opens the way for creating distributed Web applications which can access device specific functionalities such as multi-touch, text input, etc. in a federated and usable manner.","Linking BI Competency and Assimilation through Absorptive Capacity: A Conceptual FrameworkBusiness intelligence (BI) can help support decision-making processes and so contribute to improved BI assimilation and organisational performance. However, a BI undertaking may be effective and profitable for some organisations but not others. How can these differing outcomes be explained for those firms that have adopted BI systems? Drawing on the literature pertaining to absorptive capacity theory, IT competency, and BI assimilation we develop a conceptual framework to investigate the relationships between BI competency, absorptive capacity, and BI assimilation. This research provides insights for BI stakeholders in understanding the mediating role of organisational absorptive capacity within a complex BI environment, enabling many organisations that have implemented BI to leverage the benefits from their costly investments. The conceptual framework provides a sound basis for further research to shed light on the effects of BI competency and organisational absorptive capacity on BI assimilation. Contributions to research and practice are discussed.","Concurrency relations between digital planesIn this paper we examine concurrency relations between planes whose position is not precisely known. The simplest case consists of four planes, where we have to determine whether the four planes can be forced to pass through one common intersection point by moving them slightly within specified limits. We prove that if such a concurrency relation is possible then it can be found in a finite number of steps by a simple geometrical construction. This result remains valid for larger collections of planes, with multiple concurrency relations, provided each pair of relations shares at most one plane, and the relations do not form cycles.","Executive Compensation and Strategic Risk- Taking in ITThis study examines how the risk-taking incentive of top executives drives the strategic risk-taking in corporate IT implementation. We use the risk incentive provided in executive compensation to capture top executives\u2019 risk-taking incentive, and develop measures of aggressive IT implementation to capture strategic risk-taking in IT implementation. Our analysis provides empirical evidence that the risk incentive of executive compensation drives aggressive IT implementation. We also consider how firm diversification may influence the relationship between the risk incentive of top executives and aggressive IT implementation. Our finding indicates that the relationship between the risk incentive of top executives and aggressive IT implementation is stronger in focal firms\u2019 primary industries than in their secondary industries, which suggests that diversification supports IT risk taking by providing riskseeking executives more opportunities in the areas that are less familiar to them.","Modified Incomplete Cholesky Preconditioned Conjugate Gradient Algorithm on GPU for the 3D Parabolic EquationIn this study, for solving the three-dimensional partial differential equation u t =u xx +u yy +u zz , an efficient parallel method based on the modified incomplete Cholesky preconditioned conjugate gradient algorithm MICPCGA on the GPU is presented. In our proposed method, for this case, we overcome the drawbacks that the MIC preconditioner is generally difficult to be parallelized on the GPU due to the forward/backward substitutions, and thus present an efficient parallel implementation method on the GPU. Moreover, a vector kernel for the sparse matrix-vector multiplication, and optimization of vector operations by grouping several vector operations into a single kernel are adopted. Numerical results show that our proposed forward/backward substitutions and MICPCGA on the GPU both can achieve a significant speedup, and compared to an approximate inverse SSOR preconditioned conjugate gradient algorithm SSORPCGA, our proposed MICPCGA obtains a bigger speedup, and outperforms it in solving the three-dimensional partial differential equation.","Contextual Validity in Hybrid LogicHybrid tense logic is an extension of Priorean tense logic in which it is possible to refer to times using special propositional symbols called nominals. Temporal indexicals are expressions such as now, yesterday, today, tomorrow and four days ago that have highly context-dependent interpretations. Moreover, such indexicals give rise to a special kind of validity--contextual validity--that interacts with ordinary logical validity in interesting and often unexpected ways. In this paper we model these interactions by combining standard techniques from hybrid logic with insights from the work of Hans Kamp and David Kaplan. We introduce a simple proof rule, which we call the Kamp Rule, and first we show that it is all we need to take us from logical validities involving now to contextual validities involving now too. We then go on to show that this deductive bridge is strong enough to carry us to contextual validities involving yesterday, today and tomorrow as well.","On The Willingness To Pay For Privacy As A Freemium Model: First Empirical Evidence. ","Evaluating selective ARQ and slotted handshake based access in real world underwater networksMedium Access Control (MAC) is an essential component of protocol stacks in Underwater Acoustic Networks (UANs). Numerous dedicated UAN MAC protocols have been proposed and studied via analysis and simulations. However, limited work has been done on evaluating these protocols in real ocean environments. To achieve a better understanding on how MAC protocols perform in real world UANs, we implemented Selective ARQ and Slotted Handshake based Access (SASHA) on UAN nodes. SASHA embraces some most essential and representative techniques in UAN MAC design, including selective ARQ, time slotting, handshake and collision avoidance. Moreover, a sea test was conducted at Atlantic Ocean to evaluate the performance of SASHA. With the experimental data, we are able to study how the aforementioned techniques affect the performance of SASHA. we also analyze the hop-by-hop and end-to-end behavior of SASHA. Specifically, we investigate the transmission delay and queuing delay of a data packet on one hop. From the findings, some issues are discovered and the corresponding design guidelines are emerged.","From the ground-up: role of usability and aesthetics evaluation in creating a knowledge-based website for the u.s. army corps of engineersGovernment agency websites are places where both tacit and implicit organizational knowledge is managed. To maximize benefits to the organization, these websites must be tailored not only to meet immediate employee needs, but they should also be aesthetically pleasing enough to keep workers engaged and interested in exploring and sharing information. Usability testing allows users to interact with websites and give vital feedback. Knowledge acquired during the usability testing process can be used to improve the information architecture of the website and its content. Preferences for aesthetic features can be gauged simultaneously. This study included usability and aesthetics tests with federal employees who interact with the Natural Resources Management Gateway, a complex information-rich website, on a regular basis. The study clarified the relative importance of both usability and aesthetic features on employee satisfaction and identified the most preferred home page design. Involvement of employees in early design stages of knowledge management systems is strongly advised.","Building a Robust Extreme Learning Machine for Classification in the Presence of Outliers ","Contraharmonic Mean Based Bias Field Correction in MR ImagesOne of the key problems in magnetic resonance MR image analysis is to remove the intensity inhomogeneity artifact present in MR images, which often degrades the performance of an automatic image analysis technique. In this regard, the paper presents a novel approach for bias field correction in MR images using the merit of contraharmonic mean, which is used in low-pass averaging filter to estimate the near optimum bias field in multiplicative model. A theoretical analysis is presented to justify the use of contraharmonic mean for bias field estimation. The performance of the proposed approach, along with a comparison with other bias field correction algorithms, is demonstrated on a set of MR images for different bias fields and noise levels.","Authentication with Time Features for Keystroke Dynamics on Touchscreens ","Transparent digital contents sharing for science teachersTo support science teachers for preparing their classes, this paper presents concepts and principles on digital contents sharing. The proposed framework is divided into three parts: The first part proposes the maturity levels for science teacher activities based on SECI model and CMMI. The second part designs the system components on DLMS (Distributed e-learning management system) which allows science teachers to share digital contents efficiently. The third part illustrates the scenario how the proposed framework works. The possibility for prototype system based on REST (Representational State Transferred) ful Web service is also discussed. This proposal expects to save time for preparing digital contents for science teachers as they mature on digital contents.","Static Analysis of Partial Referential Integrity for Better Quality SQL DataReferential integrity ensures the consistency of data between database relations. The SQL standard proposes different semantics to deal with partial information under referential integrity. Simple semantics neglects tuples with nulls, and enjoys built-in support by commercial database systems. Partial semantics does check tuples with nulls, but does not enjoy built-in support. We investigate this mismatch between the SQL standard and real database systems. Indeed, insight is gained into the trade-off between cleaner data under partial semantics and the efficiency of checking simple semantics. The cost for referential integrity checking is evaluated for various dataset sizes, indexing structures and degrees of cleanliness. While the cost of partial semantics exceeds that of simple semantics, their performance trends follow similar patterns under growing database sizes. Applying multiple index structures and exploiting appropriate validation mechanisms increase the efficiency of checking partial semantics.","The NEBULA Future Internet Architecture ","Topic Modeling for Search and Exploration in Multivariate Research Data Repositories ","Hidden view game: designing human computation games to update maps and street viewsAlthough the Web has abundant information, it does not necessarily contain the latest, most recently updated information. In particular, interactive map websites and the accompanying street view applications often contain information that is a few years old and are somewhat outdated because street views can change quickly. In this work, we propose Hidden View - a human computation mobile game that enables the updating of maps and street views with the latest information. The preliminary implementation of the game is described and some results collected from a sample user study are presented. This work is the first step towards leveraging human computation and an individual's familiarity with different points-of-interest to keep maps and street views up to date.","A New Class of Functions for Integrating Weighting Means and OWA Operators ","Applying the Nominal Group Technique for Metadata Training of Domain ExpertsLow metadata quality is a problem faced by most digital repositories, affecting resource discoverability and the overall quality of services and search mechanisms that are supported by these repositories. Metadata training of human annotators presents itself as a major challenge to contribute towards higher metadata quality for the digital resources hosted in repositories. This paper discusses the positive results of previous approaches to metadata training in the cases of a educational, cultural and scientific/research repositories, and it attempts to improve them by using the Nominal Group technique.","A Hybrid Gene Selection and Classification Approach for Microarray Data Based on Clustering and PSO ","Checking Compatibility of Web Services BehaviorallyWeb services composition is an emerging paradigm for enabling application integration within and across organizational boundaries. In this context, we propose an approach based on Symbolic Observation Graphs (SOG) allowing to decide whether two (or more) web services can cooperate safely. The compatibility between two web services is defined by the well known soundness property on open workflow nets. This property guarantees the absence of anomalies (e.g. deadlock) that can appear after composition. We propose to abstract the concrete behavior of a web service using a SOG and show how composition of web services as well as the compatibility check can be achieved through the composition of their abstractions (i.e. SOGs). This approach allows to respect the privacy of the services since SOGs are based on collaborative activities only and hide the internal structure and behavior of the corresponding service.","Wavelet SIFT Feature Descriptors for Robust Face Recognition ","Facilitators and barriers to patients' engagements with personal health records: systematic reviewThe purpose of this paper is to identify the facilitators and barriers to patents' engagement with Personal Health Records (PHR). We performed systematic review searching Pub Med, IEEE, and Google Scholar for studies published between January, 2001 to September, 2012. Among the 508 articles identified, 14 articles included in the result. We extracted the key study characteristics and categorized facilitators and barriers using the Technology Acceptance Model (TAM). In total, there were 10 barriers, and 6 facilitators identified. The 6 facilitators were related to both perceived usefulness and ease of use, where the barriers were mostly related to ease of use. Recruited participants were mostly older patients with chronic diseases. The result of this review indicates that patients in general recognize the value of PHR but they appear to have technical difficulties.","Combining All Pairs Shortest Paths and All Pairs Bottleneck Paths ProblemsWe introduce a new problem that combines the well known All Pairs Shortest Paths (APSP) problem and the All Pairs Bottleneck Paths (APBP) problem to compute the shortest paths for all pairs of vertices for all possible flow amounts. We call this new problem the All Pairs Shortest Paths for All Flows (APSP-AF) problem. We firstly solve the APSP-AF problem on directed graphs with unit edge costs and real edge capacities in $\\tilde{O}(\\sqrt{t}n^{(\\omega+9)/4}) = \\tilde{O}(\\sqrt{t}n^{2.843})$ time, where $n$ is the number of vertices, $t$ is the number of distinct edge capacities (flow amounts) and $O(n^{\\omega}) &lt; O(n^{2.373})$ is the time taken to multiply two $n$-by-$n$ matrices over a ring. Secondly we extend the problem to graphs with positive integer edge costs and present an algorithm with $\\tilde{O}(\\sqrt{t}c^{(\\omega+5)/4}n^{(\\omega+9)/4}) = \\tilde{O}(\\sqrt{t}c^{1.843}n^{2.843})$ worst case time complexity, where $c$ is the upper bound on edge costs.","Access to books: human rights, copyright and accessibilityThis paper will explore the tension between the right to read (ensuring intellectual property does not create an unreasonable barrier to access) and the protection afforded to literary works by copyright, particularly how copyright policy can limit access to content. Using statutory analysis of international copyright law and human rights law, it will look at the way Human Rights treaties have addressed intellectual property in the past, and will compare them to the United Nations Convention on the Rights of Persons with Disabilities. This will be followed by a discussion the proposed World Intellectual Property Organization Treaty on Limitations and Exceptions for Visually Impaired Persons/Persons with Print Disabilities and how this proposed treaty will increase access to content for persons with disabilities. The conclusion of this analysis is that copyright policy must evolve in order to keep up with technology to enable equal access to content for persons with disabilities.","A knowledge-based integrated approach for discovering and repairing declare mapsProcess mining techniques can be used to discover process models from event data. Often the resulting models are complex due to the variability of the underlying process. Therefore, we aim at discovering declarative process models that can deal with such variability. However, for real-life event logs involving dozens of activities and hundreds or thousands of cases, there are often many potential constraints resulting in cluttered diagrams. Therefore, we propose various techniques to prune these models and remove constraints that are not interesting or implied by other constraints. Moreover, we show that domain knowledge (e.g., a reference model or grouping of activities) can be used to guide the discovery approach. The approach has been implemented in the process mining tool ProM and evaluated using an event log from a large Dutch hospital. Even in such highly variable environments, our approach can discover understandable declarative models.","New Perspectives on Interactivity in Project Management Tools ","Digital Natives and the Metamorphosis of the European Information Society. The Emerging Behavioral Trends Regarding Privacy and Their Legal Implications ","Evaluating user interface design using hierarchical requirements extraction method (REM)The paper shows the hierarchical requirements extraction method in order to evaluate user interface design. REM has two functions, (1) extracting the source of systems, products and GUI problems, (2) constructing the ultimate purpose of systems, products and GUI. The process is as follows. After the problems are acquired by checklist and so on, the solutions for problems are derived using the function solved the problems. The purpose of solutions is defined from view point of the relation of \"purpose and means\". The ultimate purpose is examined repeatedly based on the solutions from view point of the relation of \"purpose and means\", and finally defined. Next the cause of problems is defined from view point of the relation of \"results and cause\". The source of the problems is examined repeatedly from view point of the relation of \"results and cause\", and defined.","Clojure: modular programming with functional, concurrent language on the JVMClojure: Modular Programming with Functional, Concurrent Language on the JVM The complexity of software demands well structured architecture. Structure in software in quintessential for writing good code which is easy to debug and extend. Well structured software can be reused and can reduce future programming costs. Modularity is key. Conventional languages like C++ and Java place restrictions on the on the way software can be modularized. Functional languages release these restrictions which features like higher order functions and lazy evaluation. Functional programs have immutable variables which implies no side-effects at all. A function call can have no effect other than to compute its result. This eliminates a major source of bugs, and also makes the order of execution irrelevant - since no side-effect can change the value of an expression, it can be evaluated at any time. This relieves the programmer of the burden of prescribing the flow of control. Since expressions can be evaluated at any time, one can freely replace variables by their values and vice versa - that is, programs are \"referentially transparent\". This freedom helps make functional programs more tractable mathematically than their conventional counterparts. Functional programming languages provide two new kinds of glue - higher-order functions and lazy evaluation. Using these glues one can modularise programs in new and exciting ways, and we've shown many examples of this. Smaller and more general modules can be re-used more widely, easing subsequent programming. Here we introduce Clojure - a functional programming language for the JVM with focus on concurrency and interoperability with Java. Clojure programs are easier to understand, write, test, optimize, and parallelize. Clojure's Java interop forms are powerful, giving you direct access to the semantics of the Java platform. One can have performance and semantic equivalence to Java. Most importantly, there is never a need to \"drop down\" to a lower-level language for a little extra power. Moreover, Lisp is simple in two critical ways: it separates reading from evaluation, and the language syntax is made from a tiny number of orthogonal parts. This provides syntactic abstraction which captures design patterns, and S-expressions are XML, JSON, and SQL as they should have been. Clojure is also powerful, providing a compiler and macro system at runtime. Furthermore, Clojure has late-bound decision making and easy DSLs. Clojure's time model is simple, separating values, identities, state, and time. Thus, programs can perceive and remember information, without fear that somebody is about to scribble over the past. Protocols are simple, separating polymorphism from derivation. This implies safe, ad hoc extensibility of type and abstractions, without a tangle of design patterns or fragile monkey patching. With the emergence of multicore architectures it is very beneficial to use a language that is designed to be concurrent. Usually there several programming with concurrent programming including expensive computations may need to execute in parallel on multiple cores (or multiple boxes) in order to complete in a timely manner. Tasks that are blocked waiting for a resource should stand down and let other tasks use available processors. User interfaces need to remain responsive while performing long-running tasks. Operations that are logically independent are easier to implement if the platform can recognize and take advantage of their independence. If the program ever has two variables that refer to the same data, those variables are different observers. If your program allows mutability at all, then you must think carefully about state. Mutable languages tend to tackle the challenge by locking and defensive copying. Choosing what and where to lock is a difficult task. If you get it wrong, all sorts of bad things can happen. Race conditions between threads can corrupt data. Deadlocks can stop an entire program from functioning at all. Clojure's model for state and identity solves these problems. The bulk of program code is functional. Reference models for the parts of the application that you find more convenient to deal with using mutable state (despite its disadvantages). Let's get started working with state in Clojure, using the most notorious of Clojure's reference models: software transactional memory. All of the distinctive features in Clojure are there to provide simplicity, power, or both. Transactional Properties Like database transactions, STM transactions guarantee some important properties: Updates are atomic. If you update more than one ref in a transaction, the cumulative effect of all the updates will appear as a single instantaneous event to anyone not inside your transaction. Updates are consistent. Refs can specify validation functions. If any of these functions fail, the entire transaction will fail. Updates are isolated. Running transactions cannot see partially completed results from other transactions. Databases provide the additional guarantee that updates are durable. Because Clojure's transactions are in-memory transactions, Clojure does not guarantee that updates are durable. If you want a durable transaction in Clojure, you should use a database. Together, the four transactional properties are called ACID. Databases provide ACID; Clojure's STM provides ACI. If you change more than one ref in a single transaction, those changes are all coordinated to \"happen at the same time\" from the perspective of any code outside the transaction. In this half day hands on workshop, we intend to go over the concurrency model in Clojure along. Furthermore, we will illustrate the compilation process of Clojure, with respect to the JVM. And then we will talk about the compilation time for other imperative languages like Go, Scala and Erlang and draw a comparison of them. And show the advantages and disadvantages, i.e. bytecode on a VM v.s. C-like machine code program. Lastly, we will talk about the how Clojure's performance partially relies on JVM's development, and then introduces a little bit of IBM's work on JVM, in a high level.","Data analysis of (non-)metric proximities at linear costsDomain specific (dis-)similarity or proximity measures, employed e.g. in alignment algorithms in bio-informatics, are often used to compare complex data objects and to cover domain specific data properties. Lacking an underlying vector space, data are given as pairwise (dis-)similarities. The few available methods for such data do not scale well to very large data sets. Kernel methods easily deal with metric similarity matrices, also at large scale, but costly transformations are necessary starting with non-metric (dis-) similarities. We propose an integrative combination of Nystrom approximation, potential double centering and eigenvalue correction to obtain valid kernel matrices at linear costs. Accordingly effective kernel approaches, become accessible for these data. Evaluation at several larger (dis-)similarity data sets shows that the proposed method achieves much better runtime performance than the standard strategy while keeping competitive model accuracy. Our main contribution is an efficient linear technique, to convert (potentially non-metric) large scale dissimilarity matrices into approximated positive semi-definite kernel matrices.","Spectral Representation of Some Computably Enumerable Sets with an Application to Quantum ProvabilityWe propose a new type of quantum computer which is used to prove a spectral representation for a class S of computable sets. When S \u2208S codes the theorems of a formal system, the quantum computer produces through measurement all theorems and proofs of the formal system. We conjecture that the spectral representation is valid for all computably enumerable sets. The conjecture implies that the theorems of a general formal system, like Peano Arithmetic or ZFC, can be produced through measurement; however, it is unlikely that the quantum computer can produce the proofs as well, as in the particular case of S. The analysis suggests that showing the provability of a statement is different from writing up the proof of the statement.","Ordinal Random Forests for Object Detection ","Formula preprocessing in MUS extractionEfficient algorithms for extracting minimally unsatisfiable subformulas (MUSes) of Boolean formulas find a wide range of applications in the analysis of systems, e.g., hardware and software bounded model checking. In this paper we study the applicability of preprocessing techniques for Boolean satisfiability (SAT) in the context of MUS extraction. Preprocessing has proven to be extremely important in enabling more efficient SAT solving. Hence the study of the applicability and the effectiveness of preprocessing in MUS extraction is highly relevant. Considering the extraction of both standard and group MUSes, we focus on a number of SAT preprocessing techniques, and formally prove to what extent the techniques can be directly applied in the context of MUS extraction. Furthermore, we develop a generic theoretical framework that captures MUS extraction problems, and enables formalizing conditions for correctness-preserving applications of preprocessing techniques that are not applicable directly. We experimentally evaluate the effect of preprocessing in the context of group MUS extraction.","Educational inclusiveness through ludic engagement and digital creativityThis paper describes an approach to teaching and learning that combines elements of ludic engagement, gamification and digital creativity in order to make the learning of a serious subject a fun, interactive and inclusive experience for students regardless of their gender, age, culture, experience or any disabilities that they may have. This approach has been successfully used to teach software engineering to first year students but could in principle be transferred to any subject or discipline.","A Declarative Approach to View Selection Modeling ","TripleCheckMate: A Tool for Crowdsourcing the Quality Assessment of Linked DataLinked Open Data (LOD) comprises of an unprecedented volume of structured datasets on the Web. However, these datasets are of varying quality ranging from extensively curated datasets to crowd- sourced and even extracted data of relatively low quality. We present a methodology for assessing the quality of linked data resources, which comprises of a manual and a semi-automatic process. In this paper we fo- cus on the manual process where the first phase includes the detection of common quality problems and their representation in a quality problem taxonomy. The second phase comprises of the evaluation of a large num- ber of individual resources, according to the quality problem taxonomy via crowdsourcing. This process is implemented by the tool TripleCheck- Mate wherein a user assesses an individual resource and evaluates each fact for correctness. This paper focuses on describing the methodology, quality taxonomy and the tools' system architecture, user perspective and extensibility.","The Relative Disagreement Model of Opinion Dynamics: Where Do Extremists Come From?In this paper we introduce a novel model that can account for the spread of extreme opinions in a human population as a purely local, selforganising process. Our starting point is the well-known and influential Relative Agreement (RA) model of opinion dynamics introduced by Deffuant et al. (2002). The RA model explores the dynamics of opinions in populations that are initially seeded with some number of \"extremist\" individuals, who hold opinions at the far ends of a continuous spectrum of opinions represented in the abstract RA model as a real value in the range [-1.0, +1.0]; but where the majority of the individuals in the population are, at the outset, \"moderates\", holding opinions closer to the central mid-range value of 0.0. Various researchers have demonstrated that the RA model generates opinion dynamics in which the influence of the extremists on the moderates leads, over time, to the distribution of opinion values in the population converging to attractor states that can be qualitatively characterised as one of either uni-polar and bi-polar extremes, or reversion to the centre (\"central convergence\"). However, a major weakness of the RA model is that it pre-supposes the existence of extremist individuals, and hence says nothing to answer the question of \"where do extremists come from?\" In this paper, we introduce the Relative Disagreement (RD) model, in which extremist individual arise spontaneously and can then exert influence over moderates, forming large groups of polar extremists, via an entirely internal, self-organisation process. We demonstrate that the RD model can readily exhibit the uni-polar, bi-polar, and central-convergence attractors that characterise the dynamics of the RA model, and hence this is the first paper to describe an opinion dynamic model in which extremist positions can spontaneously arise and spread in a population via a self-organising process where opinion-influencing interactions between any two individuals are characterised not only by the extent to which they agree, but also by the extent to which they disagree.","Cognitive Approaches for Digital Forensic Readiness Planning ","A Simple and Effective Decomposition for the Multidimensional Binpacking ConstraintThe  multibin_packing  constraint captures a fundamental substructure of many assignment problems, where a set of items, each with a fixed number of dimensions, must be assigned to a number of bins with limited capacities. In this work we propose a simple decomposition for  multibin_packing  that uses a  bin_packing  constraint for each dimension, a set of  all_different  constraints automatically derived from a conflict graph, plus two alternative symmetry breaking approaches. Despite its simplicity, the proposed decomposition is very effective on a number of instances recently proposed in the literature.","Complex-demand knapsack problems and incentives in AC power systemsWe consider AC electrical systems where each electrical device has a power demand expressed as a complex number, and there is a limit on the magnitude of total power supply. Motivated by this scenario, we introduce the complex-demand knapsack problem (C-KP), a new variation of the traditional knapsack problem, where each item is associated with a demand as a complex number, rather than a real number often interpreted as weight or size of the item. While keeping the same goal as to maximize the sum of values of the selected items, we put the capacity limit on the magnitude of the sum of satisfied demands.#R##N##R##N#For C-KP, we prove its inapproximability by FPTAS (unless P = NP), as well as presenting a (1/2-e)-approximation algorithm. Furthermore, we investigate the selfish multi-agent setting where each agent is in charge of one item, and an agent may misreport the demand and value of his item for his own interest. We show a simple way to adapt our approximation algorithm to be monotone, which is sufficient for the existence of incentive compatible payments such that no agent has an incentive to misreport. Our results shed insight on the design of multi-agent systems for smart grid.","The Logic of NEAR and FARWe propose a new qualitative spatial logic based on metric (distance) relations between spatial objects. We provide a sound and complete axiomatisation of the logic with respect to metric models. The logic is intended for use in checking consistency of matching geospatial individuals from different data sets, where some data sets may be imprecise (e.g. crowd-sourced data).","Towards Semantic Merging of Versions of BDI Agent Systems ","Simplifying the task of group gift givingGift Giving is a complex and ubiquitous task that would benefit from the simpler and more user-centred style of interaction offered by the Personal Web vision. In this paper we begin by reviewing relevant literature on gift giving, and we identify key roles and requirements of gift giving. We examine current approaches to the support of group gift giving online and review some of their deficiencies. We then discuss the role that recommender systems and social media can play in facilitating gift giving interactions. As a first step towards simpler and more effective group gift giving in the Personal Web, we review results of research studies that we have conducted showing opportunities and challenges with respect to further development of gift giving online communities, and group gift giving services. We conclude with suggestions on future directions for online group gift giving noting the contribution that the Personal Web approach can make in this domain.","Cloud model glowworm swarm optimization algorithm for functions optimizationFor basic artificial glowworm swarm optimization algorithm has a slow convergence and easy to fall into local optimum, and the cloud model has excellent characteristics with uncertainty knowledge representation, an artificial glowworm swarm optimization algorithm based on cloud model is presented by utilizing these characteristics. The algorithm selects an optimal value of each generation as the center point of the cloud model, compares with cloud droplets and then achieves the better search value of groups which can avoid falling into the local optimum and can speed up the convergence rate of the algorithm. Finally, we use the standard function to test the algorithm. And the test results show that the convergence and the solution accuracy of our proposed algorithm have been greatly improved compared with the basic artificial glowworm swarm optimization algorithm.","Extraction, Analysis, and Visualization of Temporal Association Rules from Interval-Based Clinical Data ","Towards Facilitating Scientific Publishing and Knowledge Exchange Through Linked DataIn this position paper, we describe our vision of an architecture of participation for semantic linking and contextualizing of research articles. We discuss requirements of such an architecture and showcase an early first prototype.","PurposeNet: A Knowledge Base Organized around Purpose *We show how purpose can be used as a central guiding principle for organizing knowledge about artifacts. It allows the actions in which the artifact participates to be related naturally to other objects. Similarly, the structure or parts of the artifact can also be related to the actions. A conceptual base, architecture and implementation of a semantic knowledge base called PurposeNet, with an evaluation performed in comparison with other knowledge bases, shows that PurposeNet is a superior method in terms of coverage. Building an exhaustive knowledge base is a laborious and intense task, it needs human expertise and it needs good web data processing tools so that information from the web can be easily extracted in order to build the knowledgebase semi-automatically. In order to maintain the quality of the resource, it has been, till now, a case where the knowledge base was manually created. Nevertheless, creating such a huge resource completely in manual mode would be a time-consuming work. PurposeNet also makes it possible for automatic extraction of simple facts (or information) from text for populating a richly structured knowledge base. Therefore artifact related information which is useful for our knowledge base is available in various resources such as WordNet, Wikipedia and other web corpora. Results are reported on conducting a few experiments on detecting and extracting purpose of artifacts from web corpus. An experiment in domain-specific questionanswering from a given passage shows that PurposeNet used along with scripts (or knowledge of stereotypical situations), can lead to substantially higher accuracy in question answering. In the domain of car racing, individually they produce correct answers to 50% and 37.5% questions respectively, but together they produce 89% correct answers. These experimental results in domain-specific question-answering have produced promising results.","Colouring space - a coloured framework for spatial modelling in systems biologyIn this paper we introduce a technique to encode spatial attributes of dynamic systems using coloured Petri nets and show how it can be applied to biological systems within the spirit of BioModel Engineering. Our approach can be equally applied to qualitative, stochastic, continuous or hybrid models of the same physical system, and can be used as the basis for multiscale modelling. We illustrate our approach with two case studies, one from the continuous and one from the stochastic paradigm. In this paper we only discuss the case of finite colours, and by unfolding our method can take advantage of all the analytical machinery and simulation techniques that have been developed for the uncoloured family of Petri net classes.","There are no CNF problemsSAT technology has improved rapidly in recent years, to the point now where it can solve CNF problems of immense size. But solving CNF problems ignores one important fact: there are NO problems that are originally CNF. All the CNF that SAT solvers tackle is the result of modelling some real world problem, and mapping the high-level constraints and decisions modelling the problem into clauses on binary variables. But by throwing away the high level view of the problem SAT solving may have lost a lot of important insight into how the problem is best solved. In this talk I will hope to persuade you that by keeping the original high level model of the problem one can realise immense benefits in solving hard real world problems.","What Do We Mean by Information Technology Enabled Organisational Transformation ","Indoor and Outdoor Mobile Navigation by Using a Combination of Floor Plans and Street Maps ","A Feature Selection Method Using Hierarchical ClusteringFeature selection refers to a problem to select a subset of features which are most optimal for intended tasks. As one of well-known feature selection methods, clustering features into several groups and picking one feature from each group have been used for unsupervised feature selection. Since the purpose of clustering in feature selection is to select a feature from each group, the quality of the feature to be selected should be considered in the clustering process. In this paper, we propose a feature selection method using hierarchical clustering. A new similarity measure between two feature groups is defined by directly using the representative feature in each group. Experimental results show that our method can select good features even for supervised learning.","Feasibility analysis of the privacy attributes of the personal wellness information model.A feasibility analysis has been performed to study the applicability of privacy attributes with a developed wellness information model. Information privacy concerns specifically access to individually identifiable personal information and one's ability to control information about oneself. We carried out a user scenario walk-through of the privacy attributes related to the wellness components. The walk-through showed a need to relate self-regulating privacy policies to the pervasive context so that during various trust-building processes, a person is aware and can control the use, disclosure and even secondary use of his personal, private wellness information.","Decentralized semantic coordination via belief propagationThis paper proposes a generic decentralized method for interconnected entities to compute globally coherent sets of mappings with respect to the semantics of ontological specifications and their subjective mapping preferences. This problem is formed as an optimization problem between inter-dependent agents. Globally coherent sets of mappings are computed by means of a distributed extension of the max-plus algorithm, taking also into account the feedback entities receive on their subjective mappings from distant others. Experimental results from a large number of networks of varying complexity show the strengths of the proposed approach and point to further work.","An Algorithm Model for Gross Cognitive Reappraisal StrategyIn this paper, we use the mathematical model of Finite State Machine to describe the conversion process of individual's emotional state based on Gross's process model of emotion regulation strategies. In the model, we abstract Gross cognitive reappraisal strategy into a quanti- tative parameter and propose a kind of preliminary algorithm description for the influence cognitive reappraisal strategy has on the emotional con- version process. At last, we make simulation experiment for the algorithm model, and the experimental results show that the proposed algorithm proposed can effectively describe the relationship between reappraisal strategy and emotion-generative process.","Network latency impact on performance of software deployed across multiple cloudsIn cloud computing, an \"edge cloud\" may be introduced close to some of the end users, to give faster service for very demanding applications. The transactions that require heavy processing capacity and longer processing times are seen as more suitable to be carried out at the \"core\" cloud. Parts in the core and edge may then have to communicate, introducing associated network latencies. An application should be deployed across edge and core with the aim to reduce the overall effect of network latencies, in order to meet end user response time goals. In this paper, we use a Layered Queueing Network performance model to explore the impact of network latency and some possible deployment choices on the responsiveness of an application called HCAT (Home Care Aides Technology). The evaluations show that the use of the edge cloud may cause performance degradation, rather than gain, for some kinds of applications.","Zero-Visibility Cops and Robber Game on a GraphWe examine the zero-visibility cops and robber graph search- ing model, which differs from the classical cops &amp; robber game in one way: the robber is invisible. We show that this model is not monotonic. We also provide bounds on both the zero-visibility copnumber and mono- tonic zero-visibility copnumber in terms of the pathwidth.","Semi-automatic Adaptation of Mappings between Life Science Ontologies ","The restricted word shadow problemRecently we introduced and studied the shadow minimization problem under word-subword relation. In this paper we consider this problem for the restricted case and give optimal solution.","An Inequality Paradigm for Probabilistic KnowledgeWe propose an inequality paradigm for probabilistic reasoning based on a logic of upper and lower bounds on conditional probabilities. We investigate a family of probabilistic logics, generalizing the work of Nilsson [14]. We develop a variety of logical notions for probabilistic reasoning, including soundness, completeness justification; and convergence: reduction of a theory to a simpler logical class. We argue that a bound view is especially useful for describing the semantics of probabilistic knowledge representation and for describing intermediate states of probabilistic inference and updating. We show that the Dempster-Shafer theory of evidence is formally identical to a special case of our generalized probabilistic logic. Our paradigm thus incorporates both Bayesian \"rule-based\" approaches and avowedly non-Bayesian \"evidential\" approaches such as MYCIN and DempsterShafer. We suggest how to integrate the two \"schools\", and explore some possibilities for novel synthesis of a variety of ideas in probabilistic reasoning.","Biological Plausibility in an Artificial Neural Network Applied to Real Predictive TasksBiologically plausible artificial neural networks represent a promising novel approach in bio-inspired computational systems. In these systems, the models are based on existing knowledge of neurophysiolog- ical processing principles. Research in this field has increased in the last few years and has generated new viewpoints, propositions and models that are closer to the known features of the human brain. Some re- searchers have recently focused their studies on this innovative field in order to establish a consensus on what an artificial neural network is in the domain of biological realism. Domain specific synthetic data sets are generally used in the evaluation of those artificial neural networks because they simulate predictive tasks and potential problems caused by human intervention. This paper deals with the analysis of influence of the anomalies generated by human intervention in credit approval process. Such anomalies modify real classification, performance and accuracy. In this analysis, we evaluated a real data set that represents human ac- tions over personal credit approval and fraud identification by using a biologically more plausible artificial neural network proposal.","Inference and Declaration of Independence in Task-Parallel ProgramsThe inherent difficulty of thread-based shared-memory programming has recently motivated research in high-level, task-parallel programming models. Recent advances of Task-Parallel models add implicit synchronization, where the system automatically detects and satisfies data dependencies among spawned tasks. However, dynamic dependence analysis incurs significant runtime overheads, because the runtime must track task resources and use this information to schedule tasks while avoiding conflicts and races.#R##N##R##N#We present SCOOP, a compiler that effectively integrates static and dynamic analysis in code generation. SCOOP combines context-sensitive points-to, control-flow, escape, and effect analyses to remove redundant dependence checks at runtime. Our static analysis can work in combination with existing dynamic analyses and task-parallel runtimes that use annotations to specify tasks and their memory footprints. We use our static dependence analysis to detect non-conflicting tasks and an existing dynamic analysis to handle the remaining dependencies. We evaluate the resulting hybrid dependence analysis on a set of task-parallel programs.","An Illustrative Comparison of Rough k-Means to Classical Clustering ApproachesRough clustering has gained increasing attention in the last decade with applications in such diverse areas like bioinformatics, traffic control and retail. The relationship between rough clustering and, in particular, fuzzy and possibilistic concepts is still a topic that is raised first and foremost by practitioners who are looking for an adequate clustering algorithm. Therefore, we compare rough k-means to fuzzy c-means, possibilistic c-means and to classical k-means in our paper. We show that rough k-means is closer related to classical k-means than to fuzzy and possibilistic c-means. Besides brief theoretical evaluations we perform illustrative experiments on artificial data and the IRIS data.","Application of Geometric Differential Evolution Algorithm to Design Minimal Phase Digital Filters with Atypical Characteristics for Their Hardware or Software ImplementationIn this paper, the application of a geometric differential evo- lution algorithm to design minimal phase digital filters with atypical characteristics is presented. Owing to the method proposed, we can de- sign digital filters for any numerical systems in dedicated hardware im- plementation. Moreover, with the use of a geometric differential evolution algorithm, we can create digital filters for hardware and/or software im- plementation using the same design algorithm. In the paper, a design of two digital filters in the Q.15 numerical format (for hardware realiza- tion) and in the real number numerical format (for software realization) is presented. The results obtained using the proposed method are better than the results obtained with the use of the other methods.","WT-LDA: User Tagging Augmented LDA for Web Service ClusteringClustering Web services that groups together services with similar functionalities helps improve both the accuracy and efficiency of the Web service search engines. An important limitation of existing Web service clustering approaches is that they solely focus on utilizing WSDL Web Service Description Language documents. There has been a recent trend of using user-contributed tagging data to improve the performance of service clustering. Nonetheless, these approaches fail to completely leverage the information carried by the tagging data and hence only trivially improve the clustering performance. In this paper, we propose a novel approach that seamlessly integrates tagging data and WSDL documents through augmented Latent Dirichlet Allocation LDA. We also develop three strategies to preprocess tagging data before being integrated into the LDA framework for clustering. Comprehensive experiments based on real data and the implementation of a Web service search engine demonstrate the effectiveness of the proposed LDA-based service clustering approach.","An interface design method for e-commerce sites' homepage considering users' emotionsThis paper proposes a useful method to understand the relationship between web design elements, Kansei evaluation and users' emotions based on Kansei Engineering, taking E-commerce sites for example. Firstly it establishes customers' evaluation image words through a survey of the web interface preference. Then it collects the data of Kansei evaluation and users' emotions to different websites by an emotion assessment test. Lastly it builds the relation models between web design elements, Kansei evaluation and users' emotions using the quantification theory I and partial least squares (PLS) method, and confirms the validity of the models.","Modeling the Input Variables and Setting on the Static System Model at Using the Genetic Algorithm for Fault Location in the Power Transmission GridIn the paper is presented a method for fault location in the power grid through waveform matching of the recorded wave from failure with simulation from the static system model wave failure. The basis of the approach is comparing of the phase of the waves. The search process to find the best waveform match is actually an optimization problem. The genetic algorithm is used to find the optimal solution. The proposed method is suitable in cases where data from digital fault recorders are scarce. In these circumstances, the proposed approach provides more accurate results compared to the other known techniques. But for the correct operation of this method for fault locating in the system exercise influence both the form of the acquired form from digital fault recorders input data thus the correlation between the power transmission system and the static system model. Namely these issues are the subject of this paper.","Human support system for elderly people in daily lifeThis report proposes a new support system that allows elderly people able to live with a sense of security without the help of other people. In this system, by using sensors, it is possible to watch closely the condition of elderly people from a distant public institution. Furthermore, the significant information to maintain their physical condition is presented by this system. Then, according to an experiment using this system, the possibility is made clear that this system would be useful for the support of elderly people.","Using Byzantine Fault-Tolerance to Improve Dependability in Federated Cloud ComputingComputing Clouds are typically characterized as large scale systems that exhibit dynamic behavior due to variance in workload. However, how exactly these characteristics affect the dependability of Cloud systems remains unclear. Furthermore provisioning reliable service within a Cloud federation, which involves the orchestration of multiple Clouds to provision service, remains an unsolved problem. This is especially true when considering the threat of Byzantine faults. Recently, the feasibility of Byzantine Fault-Tolerance within a single Cloud and federated Cloud environments has been debated. This paper investigates Cloud reliability and the applicability of Byzantine Fault-Tolerance in Cloud computing and introduces a Byzantine fault-tolerance framework that enables the deployment of applications across multiple Cloud administrations. An implementation of this framework has facilitated in-depth experiments producing results comparing the reliability of Cloud applications hosted in a federated Cloud to that of a single Cloud.","Magnetic Resonance Wireless Power Transmission Using a LLC Resonant Circuit for a Locomotion Robot\u2019s Battery Charging ","Common and Dissociable Neural Substrates for 2-Digit Simple Addition and Subtraction ","Analyzing the Equivalence Zoo in Abstract ArgumentationNotions of equivalence which are stronger than standard equivalence in the sense that they also take potential modifications of the available information into account have received considerable interest in nonmonotonic reasoning. In this paper we focus on equivalence notions in argumentation. More specifically, we establish a number of new results about the relationships among various equivalence notions for Dung argumentation frameworks which are located between strong equivalence [1] and standard equivalence. We provide the complete picture for this variety of equivalence relations which we call the equivalence zoo for the most important semantics.","2013 Special Issue: Configurable hardware integrate and fire neurons for sparse approximationSparse approximation is an important optimization problem in signal and image processing applications. A Hopfield-Network-like system of integrate and fire (IF) neurons is proposed as a solution, using the Locally Competitive Algorithm (LCA) to solve an overcomplete L1 sparse approximation problem. A scalable system architecture is described, including IF neurons with a nonlinear firing function, and current-based synapses to provide linear computation. A network of 18 neurons with 12 inputs is implemented on the RASP 2.9v chip, a Field Programmable Analog Array (FPAA) with directly programmable floating gate elements. Said system uses over 1400 floating gates, the largest system programmed on a FPAA to date. The circuit successfully reproduced the outputs of a digital optimization program, converging to within 4.8% RMS, and an objective cost only 1.7% higher on average. The active circuit consumed 559 @mA of current at 2.4 V and converges on solutions in 25 @ms, with measurement of the converged spike rate taking an additional 1 ms. Extrapolating the scaling trends to a N=1000 node system, the spiking LCA compares favorably with state-of-the-art digital solutions, and analog solutions using a non-spiking approach.","Service Designs for Lifestyle Changes ","On the Semantic Security of Functional Encryption Schemes ","MobiSIM: a simulation library for resource prediction of smartphones and wireless sensor networksThe prediction of resource consumption is an essential task in the development of heavily resource-constrained systems, like smartphones and wireless sensor networks. In particular, good estimations on energy consumption are difficult to achieve, as they depend on the application's behavior, the used hardware and environment parameters. To address these issues, we introduce MobiSIM, an open-source OMNeT++ simulation library. MobiSIM allows the modeling of embedded systems to gain valuable information on the system's dynamic characteristics of resource consumption. The benefit of MobiSIM over other simulation systems is the focus on resource usage. Most other simulators focus on highly detailed system models to allow for the execution of native program code. These simulators are highly platform specific and complex to handle. We decided to use a coarse-grained, event-driven and platform-independent system model while still using detailed resource models for various devices. We will show that for several simulation purposes the application code can be modeled by a behavioral description, rendering instruction-accurate code execution unnecessary.","Generating Elliptic CoordinationIn this paper, we focus on the task of generating elliptic sentences. We extract from the data provided by the Surface Realisation (SR) Task 2398 input whose corresponding output sentence contain an ellipsis. We show that 9\\% of the data contains an ellipsis and that both coverage and BLEU score markedly decrease for elliptic input (from 82.3% coverage for non-elliptic sentences to 65.3% for elliptic sentences and from 0.60 BLEU score to 0.47). We argue that elided material should be represented using phonetically empty nodes and we introduce a set of rewrite rules which permits adding these empty categories to the SR data. Finally, we evaluate an existing surface realiser on the resulting dataset. We show that, after rewriting, the generator achieves a coverage of 76% and a BLEU score of 0.74 on the elliptical data.","Method Shells: Avoiding Conflicts on Destructive Class Extensions by Implicit Context SwitchesWe propose method shells, which is a module system for avoiding conflicts on customization by language mechanisms such as as- pects in AspectJ and open classes in Ruby. These mechanisms allow pro- grammers to customize a library without rewriting original source code but by only describing differences in a separate file. We call these mech- anisms destructive class extensions. A problem with destructive class extensions is conflicts on customization. Different customizations may differently modify the same class. To address this problem, we propose a new module system named method shells. With this system, program- mers can avoid conflicts since the module system automatically switches a set of customizations that has to be applied together according to the contexts declared by programmers. We present the idea of this module system and then its formal semantics. We also present an extension of Java that supports method shells.","Low-Cost Whole-Body Touch Interaction for Manual Motion Control of a Mobile Service RobotMobile service robots for interaction with people need to be easily maneuverable by their users, even if physical restrictions make a manual pushing and pulling impossible. In this paper, we present a low cost approach that allows for intuitive tactile control of a mobile service robot while preserving constraints of a differential drive and obstacle avoidance. The robot's enclosure has been equipped with capacitive touch sensors able to recognize proximity of the user's hands. By simulating forces applied by the touching hands, a desired motion command for the robot is derived and combined with other motion objectives in a local motion planner (based on Dynamic Window Approach in our case). User tests showed that this haptic control is intuitively understandable and outperforms a solution using direction buttons on the robot's touch screen.","Automatic prostate MR image segmentation with sparse label propagation and domain-specific manifold regularizationAutomatic prostate segmentation in MR images plays an important role in prostate cancer diagnosis. However, there are two main challenges: (1) Large inter-subject prostate shape variations; (2) Inhomogeneous prostate appearance. To address these challenges, we propose a new hierarchical prostate MR segmentation method, with the main contributions lying in the following aspects: First, the most salient features are learnt from atlases based on a subclass discriminant analysis (SDA) method, which aims to find a discriminant feature subspace by simultaneously maximizing the inter-class distance and minimizing the intra-class variations. The projected features, instead of only voxel-wise intensity, will be served as anatomical signature of each voxel. Second, based on the projected features, a new multi-atlases sparse label fusion framework is proposed to estimate the prostate likelihood of each voxel in the target image from the coarse level. Third, a domain-specific semi-supervised manifold regularization method is proposed to incorporate the most reliable patient-specific information identified by the prostate likelihood map to refine the segmentation result from the fine level. Our method is evaluated on a T2 weighted prostate MR image dataset consisting of 66 patients and compared with two state-of-the-art segmentation methods. Experimental results show that our method consistently achieves the highest segmentation accuracies than other methods under comparison.","Phishing for the Truth: A Scenario-Based Experiment of Users\u2019 Behavioural Response to EmailsUsing a role play scenario experiment, 117 participants were asked to manage 50 emails. To test whether the knowledge that participants are under- taking a phishing study impacts on their decisions, only half of the participants were informed that the study was assessing the ability to identify phishing emails. Results indicated that the participants who were informed that they were undertaking a phishing study were significantly better at correctly managing phishing emails and took longer to make decisions. This was not caused by a bias towards judging an email as a phishing attack, but instead, an increase in the ability to discriminate between phishing and real emails. Interestingly, participants who had formal training in information systems performed more poorly overall. Our results have implications for the interpretation of previous phishing studies, the design of future studies and for training and education campaigns, as it suggests that when people are primed about phishing risks, they adopt a more diligent screening approach to emails.","Intelligent Modeling and Prediction of Elastic Modulus of Concrete Strength via Gene Expression Programming ","What Emotions Do Novices Experience during Their First Computer Programming Learning Session ","Real-Time Television ROI Tracking Using Mirrored Experimental DesignsReal-time conversion tracking is the holy grail of TV advertisers. We show how to use thousands of tiny areas available via commercial cable and satellite systems to create low cost tracking cells. These areas are created as \"mirrors\" of a national campaign, and run in parallel with it. With properly controlled areas, it is possible to calculate national effects due to TV using statistical methods. We show performance of the method on a large-scale TV advertising campaign where it was used successfully to maintain a real-time CPA target of $60 for 179 days.","An Implementation, Execution and Simulation Platform for Processes in Heterogeneous Smart EnvironmentsDeveloping ambient intelligence for a smart home is a complex task. We present how to define intelligent system behavior through processes on an adequate level of abstraction with the SHIP-tool. Based on the representation of the environment in a formal logical description, communication with the environment is realized via updates of the logical description. Processes are built from basic actions to update the current logical descriptions and include means to monitor the evolution of the environment in a temporal logic formalism. The SHIP-tool implements the process language and serves both for simulation and execution. The paper describes two examples of assisting services in a real smart home living lab, one for light and door control in emergency situations, and one for the scheduling of two parallel wheelchair transports.","Towards Completeness and Lawfulness of Business Process Models ","Baseline: practical control variates for agent evaluation in zero-sum domainsAgent evaluation in stochastic domains can be difficult. The commonplace approach of Monte Carlo evaluation can involve a prohibitive number of simulations when the variance of the outcome is high. In such domains, variance reduction techniques are necessary, but these techniques require careful encoding of domain knowledge. This paper introduces baseline as a simple approach to creating low variance estimators for zero-sum multi-agent domains with high outcome variance. The baseline method leverages the self play of any available agent to produce a control variate for variance reduction, subverting any extra complexity inherent with traditional approaches. The baseline method is also applicable in situations where existing techniques either require extensive implementation overhead or simply cannot be applied. Experimental variance reduction results are shown for both cases using the baseline method. Baseline is shown to surpass state-of-the-art techniques in three-player computer poker and is competitive in two-player computer poker games. Baseline also shows variance reduction in human poker and in a mock Ad Auction tournament from the Trading Agent Competition, domains where variance reduction methods are not typically employed.","Audio-Haptic Rendering of Water Being Poured from Sake BottleThe impression of food can be affected by \"rendition\"\u0096i.e., the surrounding environment such as the appearance of the food and the dish\u0096not just by its taste. We focused on the sound and vibration of liquid being poured from a Japanese Sake bottle as a haptic rendition of liquid. Sake bottles are known for their unique \"glug\" sound and vibration which we believe affects the subjective impression of the liquid in the bottle. To examine this idea, we proposed a method that reproduces the vibration of pouring liquid from a Japanese Sake bottle by measuring and modeling real vibrations. We measured the vibration of water by tilting a Sake bottle at different angles, and created a model consisting of two decaying sinusoidal waves of different frequencies. To verify the appropriateness of the model, we developed two types of devices; a bottle-shaped device with embedded vibrators and an attachment type device for any plastic bottle.","Design of Face Detection System Based on FPGATo solve the real-time problem of face detection, considering the realization bottleneck of AdaBoost pure software algorithm, FPGA-based hardware acceleration platform strategy is proposed. The paper analyzes the algorithm and partition the module for accelerating. The ZYNq-7000 platform FPGA from XILINX is adopted in the experiment, in which the hardware and software co-design is used. The final results show that it can detect face sat a 17fps speed with high hit rate and low false detection rate. Face detection is a computerized technology that can achieve the locations and sizes of human faces in arbitrary (digital) images. It detects the facial features only and ignores the else, such as buildings, trees and bodies. Face detection technology can be used in face reorganization, video conference, image and video retrieval, intelligent human-computer interaction and other fields. With the development of embedded technology and smart device, face detection technology will play an important role in meeting the requirements of mobilization and outdoor work. There're two key indicators in measuring the performance of face detection: Accuracy and Speed. Proposed by Freund and Scrapire, AdaBoost target detection algorithm in accuracy and speed has reached a higher level. AdaBoost face detection algorithm is applied to achieve a true real-time detection, which makes real-time embedded platform and face detection possible. There is already some research and practice in this area currently, but most of the research work is in software. AdaBoost algorithm has a heavy load and large amount of data, so the pure software implementation of the access point's chart will come across the bottleneck of the algorithm. Therefore, the detection algorithm embedded platform with the ability of the processor alone cannot achieve real-time requirements, so we need to find a hardware acceleration AdaBoost algorithm approach (3). In this paper, due to the bottlenecks of its design improved algorithms for software implementation hardware-accelerated method is applied and it achieves the square and the integral image and integration of real-time calculation and classification features of value. The ZYNq-7000 platform FPGA from XILINX is used in this paper.","A Bayesian Criterion for Evaluating the Robustness of Classification Rules in Binary Data Sets ","New Distances for Improving Progressive Alignment AlgorithmDistance computation between sequences is an important method to compare between biological sequences. In fact, we attribute a value to the se- quences in order to estimate a percentage of similarity that can help to extract structural or functional information. Distance computation is also more impor- tant in the progressive multiple alignment algorithm. Indeed, it can influence the branching order of the sequences alignment and then the final multiple align- ment. In this paper, we present new methods for distance computation in order to improve the progressive multiple alignment approach. The main difference between our distances and the other existed methods consists in the use of all the sequences of the set in the pair-wise comparison. We tested our distances on BALIBASE benchmarks and we compared with other typical distances. We obtained very good results.","Stand up, heroes!: gamification for standing people on crowded public transportationThere are quite many commuters who are forced to keep standing on crowded public transportation in Japan, and they often feel fatigue and frustration. Stand Up, Heroes! (SUH) is an EELF-based gamification system to motivate commuters to keep standing. In SUH, they have their own avatars which grow according to their time of standing. As the result of a twelve-week practical evaluation, it is found that SUH can stimulate commuters' motivation during first eight weeks. Growing-up avatars are most effective for stimulation and fun. However, some participants cannot feel fun or stimulation for standing from SUH, because their public transportation which they get on is not so crowded that they can seat on the transportation.","Active Semi-supervised Community Detection Algorithm with Label Propagation ","Patient Clustering with Uncoded Text in Electronic Medical RecordsWe propose a mixture model for text data designed to capture underlying structure in the history of present illness section of electronic medical records data. Additionally, we propose a method to induce bias that leads to more homogeneous sets of diagnoses for patients in each cluster. We apply our model to a collection of electronic records from an emergency department and compare our results to three other relevant models in order to assess performance. Results using standard metrics demonstrate that patient clusters from our model are more homogeneous when compared to others, and qualitative analyses suggest that our approach leads to interpretable patient sub-populations when applied to real data. Finally, we demonstrate an example of our patient clustering model to identify adverse drug events.","Probabilistic Cost Enforcement of Security Policies ","Age Estimation Using Local Binary Pattern Kernel Density EstimateWe propose a novel kernel method for constructing local bi- nary pattern statistics for facial representation in human age estimation. For age estimation, we make use of the de facto support vector regression technique. The main contributions of our work include (i) evaluation of a pose correction method based on simple image flipping and (ii) a com- parison of two local binary pattern based facial representations, namely a spatially enhanced histogram and a novel kernel density estimate. Our single- and cross-database experiments indicate that the kernel density estimate based representation yields better estimation accuracy than the corresponding histogram one, which we regard as a very interesting find- ing. In overall, the constructed age estimation system provides compa- rable performance against the state-of-the-art methods. We are using a well-defined evaluation protocol allowing a fair comparison of our results.","Issues in Harvesting Resources from Agricultural RepositoriesHarvesters facilitate aggregating metadata from various repositories and other sources such as journals and enable a centralized access to full text and objects. While harvesting can be fairly simple and straight forward, it is not without its challenges. This paper intends to highlight some of the issues in har- vesting metadata in agricultural domains. It suggests some possible solutions with instances from Demeter, a pkp based harvester compared with DSpace based harvesting facility implemented at Indian Statistical Institute. Also de- scribed is Tharvest, a thematic harvester model for agricultural resources from generic repositories.","Persuasive performance feedback: the effect of framing on self-efficacy.Self-monitoring technologies have proliferated in recent years as they offer excellent potential for promoting healthy behaviors. Although these technologies have varied ways of providing real-time feedback on a user\u2019s current progress, we have a dearth of knowledge of the framing effects on the performance feedback these tools provide. With an aim to create influential, persuasive performance feedback that will nudge people toward healthy behaviors, we conducted an online experiment to investigate the effect of framing on an individual\u2019s self-efficacy. We identified 3 different types of framing that can be applicable in presenting performance feedback: (1) the valence of performance (remaining vs. achieved framing), (2) presentation type (text-only vs. text with visual), and (3) data unit (raw vs. percentage). Results show that the achieved framing could lead to an increased perception of individual\u2019s performance capabilities. This work provides empirical guidance for creating persuasive performance feedback, thereby helping people designing self-monitoring technologies to promote healthy behaviors.","Motion sensing technology on rehabilitation for children with physical disabilitiesThis research is focus on application of hand-eye coordination of motion sensing for children with developmental disabilities. Based on the base technology of interactive technology, thereby bringing the children the experience of the interactive technology application. There are 2 demonstrations on this research. The equipments are actually applied on children with developmental disabilities, the research focus on using low-cost equipment, then the relative activities will be easy follow for children. In this research, the devices relied upon user-friendly design, reducing the working load. The projector will be presented other children to participate and share interactive content, extended deep Tablet PC application. The aim of this study was to evaluate whether training via interactive effect enhances the motivation of CP children. These findings suggest that training of sense of hand-eye coordination could help to increase the motivation of training for children with different needs.","Fuzzy-PI Switch Control in Intermediate Frequency Heating Process of 3PE-Coating ","Online Dispute Resolution and Models of Relational Law and Justice: A Table of Ethical PrinciplesRegulatory systems constitute a set of coordinated complex behavior individual and collective which can be grasped through rules, values and principles that constitute the social framework of the law. Relational law, relational justice and the design of regulatory models can be linked to emergent agreement technologies and new versions of Online Dispute Resolution ODR and Negotiation Support Systems NSS. We define the notions of public space and information principles, extending the concept of 'second order validity' to the fields of ODR and NSS.","A layered multidimensional model of complex objectsMultidimensional modeling is nowadays recognized to best reflect the decision makers' analytical view on data. In this paper, we address some modeling features that we believe existing multidimensional models do not fully cover, such as considering real life entities that are meant to be analyzed as complex objects, allowing for simple and complex measures, treating facts and dimension members equally and observing hierarchies within and between complex entities. We propose a layered multidimensional model based on the concept of complex object which encapsulates data and structure complexity and eases the creation and manipulation of complex data cubes. We need to define our model at three layers. The first layer class diagram describes complex objects and captures the hierarchical organization of their attributes. The second layer package of classes describes the multidimensional model as a set of complex objects that are connected by relationships and some of which are organized in hierarchies. The third layer package of packages describes complex cubes which are derived from the multidimensional model. We show the benefits and feasibility of our proposals through their implementation in a real-life case study.","Promoting Integrated Social and Medical Care through Semantic Integration and Context Visualization ","Cultural Diversity - New Challenge to Medical Device Use Safety for International Markets ","Achievability of Asymptotic Minimax Regret in Online and Batch PredictionThe normalized maximum likelihood model achieves the minimax coding (log-loss) regret for data of xed sample size n. However, it is a batch strategy, i.e., it requires that n be known in advance. Furthermore, it is computationally infeasible for most statistical models, and several computationally feasible alternative strategies have been devised. We characterize the achievability of asymptotic minimaxity by batch strategies (i.e., strategies that depend on n) as well as online strategies (i.e., strategies independent of n). On one hand, we conjecture that for a large class of models, no online strategy can be asymptotically minimax. We prove that this holds under a slightly stronger denition of asymptotic minimaxity. Our numerical experiments support the conjecture about non-achievability by so called last-step minimax algorithms, which are independent of n. On the other hand, we show that in the multinomial model, a Bayes mixture dened by the conjugate Dirichlet prior with a simple dependency on n achieves asymptotic minimaxity for all sequences, thus providing a simpler asymptotic minimax strategy compared to earlier work by Xie and Barron. The numerical results also demonstrate superior nite-sample behavior by a","Temporal Phase Shift: Visual Illusion by Phase-Shifted Light Projection and Its Applications ","Some Global Measures for Shape Retrieval ","Work System Theory: Overview of Core Concepts, Extensions, and Challenges for the FutureThis paper presents a current, accessible, and overarching view of work system theory. WST is the core of an integrated body of theory that emerged from a long-term research project to develop a systems analysis and design method for business professionals called the work system method (WSM). After discussing WST\u2019s basic premises and its two central frameworks, this paper summarizes the relationship between WST and WSM. It shows how experience with early versions of WSM led to three extensions of WST that addressed limitations-inuse in one of the central frameworks in WST. After comparisons with related theories, this paper closes with an evaluation of progress to date, new directions for research related to WST, and implications for the IS discipline. The two appendices summarize the long term research from which WST emerged and use a positioning map to show how WST is related to other topics in the IS discipline.","The Effects of Negative Interaction Feedback in a Web Navigation AssistantRecommender systems are a common solution used to assist users in searching and retrieving information on the web due to the benefits that can be obtained from the evaluation and filtering of the vast amount of information available. This article presents a user study on the feasibility of using negative interaction, that is the absence of interaction with some items in a list of suggestions, as implicit feedback used to improve the performance of a web navigation assistant. Results showed an increment of 16.65% in the acceptance of the suggestions provided by the assistant and an increment of 43.05% in the average use of the suggestions window when using negative interaction with respect to not using this feedback mechanism.","Maximal clique enumeration in finding near neighbourhoodsThe problem considered in this article stems from the observation that practical applications of near set theory require efficient determination of all the tolerance classes containing objects from the union of two disjoints sets. Near set theory consists in extracting perceptually relevant information from groups of objects based on their descriptions. Tolerance classes are sets where all the pairs of objects within a set must satisfy the tolerance relation and the set is maximal with respect to inclusion. Finding such classes is a computationally complex problem, especially in the case of large data sets or sets of objects with similar features. The contributions of this article are the observation that the problem of finding tolerance classes is equivalent to the MCE problem, empirical evidence verifying the conjecture from [15] that the extra perceptual information obtained by finding all tolerance classes on a set of objects obtained from a pair of images improves the CBIR results when using the tolerance nearness measure, and a new application of MCE to CBIR.","Inferences in Binary Regression Models for Independent Data with Measurement Errors in CovariatesWhen responses along with covariates are collected from a group of independent individuals in a binary regression setup, in some practical situations the observed covariates may be subject to measurement errors differing from the true covariates values. These imprecise observed covariates, when used directly, the standard statistical methods such as naive likelihood and quasi-likelihood methods yield biased and hence inconsistent regression estimates. Because there does not exist a corrected score function for this binary measurement error model, a considerable attention is given in the literature to develop approximate unbiased estimating equation in order to obtain consistent regression estimate. In this paper, we review some of these widely used approaches and suggest a softer (approximate) quasi-likelihood approach for consistent regression parameters estimation.","Heterogeneous Substructuring Methods for Coupled Surface and Subsurface FlowThe exchange of ground- and surface water plays a crucial role in a variety of practically relevant processes ranging from flood protection measures to preservation of ecosystem health in natural and human-impacted water resources systems.","Context-Aware Agile Business Process Engine: Foundations and ArchitectureFuture developments for enterprise process management must evolve from the current systems based on rigid, workflow based processes into context-aware, agile dynamic structures, which exploit local adaptability. In this idea paper, we define two forms of process agility. To enable these forms of agility, we present our vision of context-aware business process management based on declarative modeling combined with innovative context management and formal concept analysis. We finally describe the foundations and introduce the architecture of a context-aware agile business process engine (CAPE).","Compositional and Lightweight Dependent Type Inference for MLWe consider the problem of inferring expressive safety properties of higher-order functional programs using first-order decision procedures. Our approach encodes higher-order features into first-order logic formula whose solution can be derived using a lightweight counterexample guided refinement loop. To do so, we extract initial verification conditions from dependent typing rules derived by a syntactic scan of the program. Subsequent type-checking and type-refinement phases infer and propagate specifications of higher order functions, which are treated as uninterpreted first-order constructs, via subtyping chains. Our technique provides several benefits not found in existing systems: 1 it enables compositional verification and inference of useful safety properties for functional programs; 2 additionally provides counterexamples that serve as witnesses of unsound assertions: 3 does not entail a complex translation or encoding of the original source program into a first-order representation; and, 4 most importantly, profitably employs the large body of existing work on verification of first-order imperative programs to enable efficient analysis of higher-order ones. We have implemented the technique as part of the MLton SML compiler toolchain, where it has shown to be effective in discovering useful invariants with low annotation burden.","Design and Characterisation of a Full-Field Range Imaging Camera for Use in Mobile Applications ","Translating the idea of the egovernment one-stop-shop in indonesiaThis study aims to understand how the idea of an eGovernment one-stop-shop (OSS) has been translated into a new setting. Since the beginning of 2000, this idea has been implemented in a variety of ways by Indonesian local governments. Using an interpretive case study in the city of Yogyakarta, the study revealed that the specificity of each setting influences the translation process of the idea of OSS during its institutionalization. It also identified a set of editing rules used during the translation process. These include the editing rules concerning context (e.g., internal readiness); logic (e.g., corruption eradication); and formulation (e.g., standardized processes). The study also found that the idea translation was not a single round process.","Enhancing Software Search with Semantic Information from Wikipedia ","Production-Contextual Clinical InformationThere is a widespread health informatics vision of unlimited exchange, understanding and reuse of clinical information. However, it has also been pointed out that to understand clinical information it is to some extent necessary to know the circumstances of its production - the production-contextual clinical information.#R##N##R##N#The purpose of this study was to investigate the nature and significance of production-contextual clinical information in doctors' everyday clinical work in order to asses whether standardization is necessary and possible. The study was performed through observation and focus group interviews at a cardiology department in a midsize Danish hospital.#R##N##R##N#It was found that production-contextual clinical information is complex, extensive, non-quantitative, and that it has an elusive structure. It is concluded that while it may be possible to standardise a limited amount of production-contextual clinical information, a general standardisation may very well be impossible.","Emergence of New Global Airline Networks and Distributing Loads in Star AirportsWe have developed a method of emerging a small-world net- work, which has the shortest average path length among complex net- works known so far, in a self-organizing manner using an ACO (Ant-Colony Optimization)-inspired method. We call it an n-Star net- work. As one of the real-world applications, we showed the n-Star net- work could be applied to reorganizing a next generation global airline network, where several star nodes are assigned to the corresponding star cities selected from major cities in the world in advance, and we eval- uated the performance of the network using several kinds of network parameters. This method is a hybrid method using a bottom-up and top-down approach. In this study, without selecting any star cities in advance, using a bottom-up method only based on city population, city ranking, and distance between cities, etc., we tried to emerge a self- organizing global airline network by connecting links between important cities. As a result, the latter n-Star network is formed which is different from the former n-Star network, however, it is expected that both n-Star networks will concentrate heavy loads on their respective star airports. We will verify the concentration of load on the star airports through a simulation experiment, and propose an effective method for distributing the load over the whole airline network.","Time-Stealer: A Stealthy Threat for Virtualization Scheduler and Its CountermeasuresThird-party Cloud Computing, Amazon's Elastic Compute Cloud (EC2) for instance, provides Infrastructure as a Service (IaaS) solutions that pack multiple customer virtual machines (VMs) onto the same physical server with hardware virtualization technology. Xen is widely used in virtualization which charges VMs by wall clock time rather than resources consumed. Under this model, manipulation of the scheduler vulnerability may allow theft-of-service at the expense of other customers.#R##N##R##N#Recent research has shown that attacker's VM can consume more CPU time than fair share on Amazon EC2 in that Xen 3.x default Credit Scheduler's resolution was rather coarse. Although considerable changes have been made in Xen 4.x Credit Scheduler to improve the performance in case of such stealing attacks, we've found another alternative attack called Time-Stealer which can obtain up to 96.6% CPU cycles stealthily under some circumstances on XenServer6.0.2 platform by analyzing the source code thoroughly. Detection methods using benchmarks as well as a series of countermeasures are proposed and experimental results have demonstrated the effectiveness of these defense techniques.","Dimensionality reduction in data summarization approach to learning relational dataDue to the growing amount of digital data stored in relational databases, more new approaches are required to learn relational data. The DARA algorithm is designed to summarize data and it is one of the approaches introduced in relational data mining in order to handle data with one-to-many relations. The DARA algorithm transforms data stored in relational databases into a vector space representation by applying the information retrieval theory. Based on the experimental results, the DARA algorithm is proven to be very effective in learning relational data. However, DARA suffers a major drawback when the cardinalities of attributes are very high because the size of the vector space representation depends on the number of unique values that exist for all attributes in the dataset. This paper investigates the effects of discretizing the magnitude of terms computed and applying a feature selection process that reduces the cardinalities of attributes of the relational datasets on the predictive accuracy of the overall classification task. This involves the task of finding the best set of relevant features used to summarize the data, in which the feature selection processed is performed based on the magnitude of terms computed earlier. Based on the results obtained, it shows that the predictive accuracy of the classification task can be improved by improving the quality of the summarized data. The quality of the summarized data can be enhanced by appropriately discretizing the magnitude of terms computed earlier and also appropriately selecting only a certain percentage of the attributes.","Application of the HJ Biplot Methodology to Variation Greenhouse Gas Emissions in International CompaniesThe quantifying and reporting of greenhouse gas emissions is one of the most important tools for monitoring and auditing proposed to mitigate climate change, and it also directly affects business. It is thus vital at this time that we learn in detail whether firms actually report on greenhouse gas emissions and make the account entries that must be included within it. This research has a twofold objective: first to analyse the report on greenhouse gas emissions of international firms in the 2007, 2008 and 2009 period and to see what kind of variation occurs in CO2 emissions between 2006-2007, 2007-2008 and 2008-2009. Secondly we shall use the biplot methodology to represent emissions variations in firms grouped into geographic areas. To do so we group only the 89 firms in our study into the geographical areas of the Europe (EU), North America (NA), Asia (AS), and South America (SA). As regards the variation in CO2 emissions, it is noteworthy that variation in CO2 emissions for the 2006/2007 period are located closer to companies in North America, variation in CO2 emissions for 2007/2008 are located closer to European Union companies and very strikingly, the variation in CO2 emissions for the 2008/2009 period are located closer to companies in Asia and South America. This leads us to conclude that companies located in developing countries are nowadays the most aware of climate change and the need to reduce emissions.","An Effective Approach for Vocal Melody Extraction from Polyphonic Music on GPUMelody extraction from polyphonic music is a valuable but difficult problem in music information retrieval. The extraction incurs a large computational cost that limits its application. Growing processing cores and increased bandwidth have made GPU an ideal candidate for the development of fine-grained parallel algorithms. In this paper, we present a parallel approach for salience-based melody extraction from polyphonic music using CUDA. For 21 seconds of polyphonic clip, the extraction time is cut from 3 seconds to 33 milliseconds using NVIDIA GeForce GTX 480 which is up to 100 times faster. The increased performance allows the melody extraction to be carried out for real-time applications. Furthermore, the evaluation of the extraction on huge datasets is also possible. We give insight into how such significant speed gains are made and encourage the development and adoption of GPU in music information retrieval field.","IT And Collaboration In Service Innovation: A Dynamic Capability Perspective ","Partition-Based Hardware Transactional Memory for Many-Core ProcessorsTransactional memory is an appealing technology which frees programmer from lock-based programming. However, most of current hardware transactional memory systems are proposed for multi-core processors, and may face some challenges with the increasing of processor cores in many-core systems, such as inefficient utilization of transactional buffers, unsolved problem of transactional buffer overflow, etc. This paper proposes PM_TM, a hardware transactional memory for many-core processors. The system turns transactional buffers that are traditionally private to processor cores into shared by moving them from L1-level to L2-level, and uses partition mechanism to provide logically independent and dynamically expandable transactional buffers to transactional threads. As the result, the solution can utilize transactional buffers more efficient and moderate the problem of transactional buffer overflow. The system is simulated and evaluated using gems and simics simulator with STAMP benchmarks. Evaluation results show that the system achieves better performance and scalability than traditional solutions in many-core processors.","Assessing mental workload of in-vehicle information systems by using physiological metricsUse of physiological indices including ECGs and EMGs was investigated for estimation of drivers' mental workload induced by using in-vehicle information system (IVIS). The subject performed multiple simultaneous task paradigm consisted of driving using driving simulator, use of car navigation system and stimulus detection task paradigm. The results indicated that muscular loads obtained by EMGs tended to show higher activity in coherent with the level of mental workload and high correlation coefficient between muscular loads. The performance associated with stimulus detection task revealed the potential use of EMG signals as an index for evaluating mental workload.","A lightweight combinatorial approach for inferring the ground truth from multiple annotatorsWith the increasing importance of producing large-scale labeled datasets for training, testing and validation, services such as Amazon Mechanical Turk (MTurk) are becoming more and more popular to replace the tedious task of manual labeling finished by hand. However, annotators in these crowdsourcing services are known to exhibit different levels of skills, consistencies and even biases, making it difficult to estimate the ground truth class label from the imperfect labels provided by these annotators. To solve this problem, we present a discriminative approach to infer the ground truth class labels by mapping both annotators and the tasks into a low-dimensional space. Our proposed model is inherently combinatorial and therefore does not require any prior knowledge about the annotators or the examples, thereby providing more simplicity and computational efficiency than the state-of-the-art Bayesian methods. We also show that our lightweight approach is, experimentally on real datasets, more accurate than either majority voting or weighted majority voting.","A Model for Analyzing the Relation between Potassium (K) and Hemolysis Index (HI) with Clustering Method ","A Taxonomy of Performance Prediction Systems in the Parallel and Distributed Computing GridsAs Grids are loosely-coupled congregations of geographically distributed heterogeneous resources, the efficient utilization of the resources requires the support of a sound Performance Prediction System (PPS). The performance prediction of grid resources is helpful for both Resource Management Systems and grid users to make optimized resource usage decisions. There have been many PPS projects that span over several grid resources in several dimensions. In this paper the taxonomy for describing the PPS architecture is discussed. The taxonomy is used to categorize and identify approaches which are followed in the implementation of the existing PPSs for Grids. The taxonomy and the survey results are used to identify approaches and issues that have not been fully explored in research.","A Distributional Semantic Search Infrastructure for Linked Dataspaces ","Qualitative Cognition for Uncertainty Knowledge Using Cloud Model ","Measuring Stability and Discrimination Power of Metrics in Information Retrieval EvaluationRetrieval evaluation is always an important aspect in information retrieval web search and metrics are a key factor that needs to be carefully considered. In this paper, we propose a new method of measuring stability and discrimination power of a metric. The problem is initiated by Buckley and Voorhees. The advantage of the proposed method is that we are able to measure both aspects together in a systematic manner. Five metrics are tested in the study. They are average precision over all relevant documents, recall-level precision, normalized discount cumulative gain, precision at 10 documents level, and reciprocal rank. Experimental results show that normalized discount cumulative gain is the best, which is followed by average precision over all relevant documents, recall-level precision, precision at 10 documents level, while reciprocal rank is the worst.","Approximate Queries with Adaptive Processing ","Evidence-based trust metrics in web servicesIn a service ecosystem of complementary and competing web services, clients have many options but, at the same time, determining which one to trust can be a challenge. While there have been several proposals in literature about web services trust measurement, none has been actually adopted. Even the notion of trust itself is not clearly established in the context of the web-services' stack of standards. In this paper, we propose a service that collects different types of service-quality measurements from clients, as well as evidence in the form of relevant request/response headers, in order to produce aggregate trust metrics of service providers. Our experimental analysis using simulations shows that the proposed trust-aggregator service framework is feasible and effective in measuring trust metrics.","Transparency of military threat evaluation through visualizing uncertainty and system rationaleThreat evaluation (TE) is concerned with determining the intent, capability and opportunity of detected targets. To their aid, military operators use support systems that analyse incoming data and make inferences based on the active evaluation framework. Several interface and interaction guidelines have been proposed for the implementation of TE systems; however there is a lack of research regarding how to make these systems transparent to their operators. This paper presents the results from interviews conducted with TE operators focusing on the need for and possibilities of improving the transparency of TE systems through the visualization of uncertainty and the presentation of the system rationale.","Exploration of the T-Interval-Connected Dynamic Graphs: The Case of the RingIn this paper, we study the T-interval-connected dynamic graphs from the point of view of the time necessary and sufficient for their exploration by a mobile entity (agent). A dynamic graph (more precisely, an evolving graph) is T-interval-connected (T \u2264 1) if, for every window of T consecutive time steps, there exists a connected spanning subgraph that is stable (always present) during this period. This property of connection stability over time was introduced by Kuhn, Lynch and Oshman [6] (STOC 2010). We focus on the case when the underlying graph is a ring of size n, and we show that the worst-case time complexity for the exploration problem is 2n '\u2014' T '\u2014' \u0398(1) time units if the agent knows the dynamics of the graph, and    $n+ \\frac{n}{\\max\\{1, T-1\\} } (\\delta-1) \\pm \\Theta(\\delta)$    time units otherwise, where i\u00be? is the maximum time between two successive appearances of an edge.","Evaluating interaction with websites: case study of a government website of the brazilian ministry of labor and employmentThis paper presents a usability evaluation of the MTE (Ministry of Labor e Employment) website in order to measure the effectiveness, efficiency and user satisfaction regarding the website. The participants were 12 users (07 users were female and 05 male). The results indicate that although the education level of all participants and computing experience, many of them have had difficulty in finding information and do not recommend the site.","Continuum dynamics model of the primary visual cortex for contour detection.We model the neural dynamics in the primate primary visual cortex in terms of a continuous director field that describes the average rate and the average orientational preference of active neurons at a particular point in the cortex. This representation has a correspondence to the Landau - de Gennes order parameter for nematic liquid crystal in two dimensions. Our linear-nonlinear dynamical model incorporates long range connectivity patterns that enforce context dependence present in the visual field. The model can distinguish large contiguous objects from the background clutter by suppressing the clutter and by filling-in occluded elements of object contours. This results in high-precision, high-recall detection of large objects in cluttered scenes.","The SWAC approach for sharing a web application's codebase between server and clientA Web application's codebase is typically split into a server-side and a client-side with essential functionalities being implemented twice, such as validation or rendering. For implementing the codebase on the client, JavaScript, HTML and CSS are languages that all modern Web browsers can interpret. As the counterpart, the server-side codebase can be realized by plenty of programming languages, which provide facilities to implement standardized communication interfaces. While recent developments such as Node.js allow using JavaScript as a client-side programming languages outside the browser in a simple and efficient way also on the server-side, they lack offering a common codebase for the entire Web application. We present a flexible approach to enable sharing of presentation and business logic between server and client using the same codebase. Our approach aims at reducing development efforts and minimizing coding errors, while taking characteristic differences between server and client into account. We show the impact of our solution during an evaluation and in comparison to related work.","Ring GINA: A Wearable Computer Interaction Device ","Extracting and normalizing temporal expressions in clinical data requests from researchersAutomatic translation of clinical researcher data requests to executable database queries is instrumental to an effective interface between clinical researchers and \"Big Clinical Data\". A necessary step towards this goal is to parse ample temporal expressions in free-text researcher requests. This paper reports a novel algorithm called TEXer. It uses heuristic rule and pattern learning for extracting and normalizing temporal expressions in researcher requests. Based on 400 real clinical queries with human annotations, we compared our method with four baseline methods. TEXer achieved a precision of 0.945 and a recall of 0.858, outperforming all the baseline methods. We conclude that TEXer is an effective method for temporal expression extraction from free-text clinical data requests.","Salus: Non-hierarchical Memory Access Rights to Enforce the Principle of Least Privilege ","Reconstructing 3D Face Shapes from Single 2D Images Using an Adaptive Deformation ModelThe Representational Power (RP) of an example-based model is its capability to depict a new 3D face for a given 2D face image. In this contribution, a novel approach is proposed to increase the RP of the 3D reconstruction PCA-based model by deforming a set of examples in the training dataset. By adding these deformed samples together with the original training samples we gain more RP. A 3D PCA-based model is adapted for each new input face image by deforming 3D faces in the training data set. This adapted model is used to reconstruct the 3D face shape for the given input 2D near frontal face image. Our experimental results justify that the proposed adaptive model considerably improves the RP of the conventional PCA-based model.","Sci-Fi movies and the pessimistic view for the future controlled society of totalitarianismThe author proposes a view that most science-fiction movies that described not just the future technological development but the life in the future social organization are pessimistic and depict dystopian, rather than utopian societies. They can provide useful guidance to increase our awareness of what technology might bring to the user experience and of how we should take care for not falling into such a social organization.","Diffeomorphic metric mapping of hybrid diffusion imaging based on BFOR signal basisIn this paper, we propose a large deformation diffeomorphic metric mapping algorithm to align multiple b-value diffusion weighted imaging (mDWI) data, specifically acquired via hybrid diffusion imaging (HYDI), denoted as LDDMM-HYDI. We adopt the work given in Hosseinbor et al. (2012) and represent the q-space diffusion signal with the Bessel Fourier orientation reconstruction (BFOR) signal basis. The BFOR framework provides the representation of mDWI in the q-space and thus reduces memory requirement. In addition, since the BFOR signal basis is orthonormal, the L2 norm that quantifies the differences in q-space signals of any two mDWI datasets can be easily computed as the sum of the squared differences in the BFOR expansion coefficients. In this work, we show that the reorientation of the q-space signal due to spatial transformation can be easily defined on the BFOR signal basis. We incorporate the BFOR signal basis into the LDDMM framework and derive the gradient descent algorithm for LDDMM-HYDI with explicit orientation optimization. Using real HYDI datasets, we show that it is important to consider the variation of mDWI reorientation due to a small change in diffeomorphic transformation in the LDDMM-HYDI optimization.","Inferring transcriptional modules from microarray and ChIP-chip data using penalized matrix decompositionInferring transcriptional regulatory modules is a useful work for elucidating molecular mechanism. In this paper, we propose a new method for transcriptional regulatory module discovering. The algorithm uses penalized matrix decomposition to model microarray data. Which takes into account the sparse a prior information of transcription factors---gene (TFs---gene) interactions. At the same time, the ChIP-chip data are used as constraints for penalized matrix decomposition of gene expression data. Finally the regulatory modules can be inferred based on the factor matrix. Experiment on yeast dataset shows that our method can identifies more meaningful transcriptional modules relating to specific TFs.","Towards Comprehensive Measurement of Consistency Guarantees for Cloud-Hosted Data Storage Services ","Insights from Eye Movement into Dynamic Decision-Making Research and Usability Testing ","Using Meta-modelling for Construction of an End-User Development FrameworkA main activity in meta-design is the creation of design spaces allowing problem owners to act as system developers. Meta-design is a conceptual framework; it does not provide concrete design space solu- tions or engineering guidelines for constructing tools that support design spaces. This paper discusses the applicability of a model-driven engi- neering approach for the realization of an end-user service composition framework, in line with the conceptual meta-design framework. We re- port our experience of using meta-modelling techniques as supported by the Eclipse Modelling Framework (EMF) family of tools. In our work we found that meta-models are well-suited to formalize the composition lan- guage, and the core parts of the EMF framework are useful to represent the language elements and user-made compositions both at design and runtime. Although EMF-based tools exist for creating visual editors, we found that in our case these did not map well to the visual notation we selected for our end-users.","The Democracy Cube as a Framework for Guiding Participatory Planning for Community-based IT InitiativesLiterature suggests there is a need to build more theoretically-informed understandings of the social processes implicated in participatory IT planning and implementation (Jakku &amp; Thorburn, 2010). In this study, we explore the value of Archon Fung's (2006) \"democracy cube\" as a framework for qualitatively examining the process we undertook for planning a community-based IT strategy. Our planning process involved consultations with multiple stakeholder groups across five different communities, as well as from other entities involved in disaster management, with the aim of surfacing factors that shaped local communities' abilities to participate in disaster management activities. These factors, drawn from qualitative interviews and categorized using a SWOT framework, were subsequently translated into an IT strategy. In this paper, we revisit this process and examine it using Fung's (2006) three dimensions of democratic participation as a lens: participant selection (our use of multiple stakeholder groups); communication and decision (our consultation process); and authority and power (how participant input drove our strategy). We use the framework to identify the specific practices that made IT planning participative, as well as those that made it nonparticipative. We also use our empirical data to explore ways that the framework can be enhanced.","Model of opinion interactions base on evolutionary game in social networkDue to convenient information change at individual level in recent years, social network has become popular platform of information dissemination, more precisely, micro-blog has attracted a lot of attention, thus modeling the real opinion interactions on micro-blog is important. This paper is devoted to apply evolutionary game models to reveal some basic rules and features of opinion interactions in micro-blog. We have divided the users into three different kinds of player with respective payoff. Then the evolutionary game model simulates a group of individuals participating in a discussion, aiming at persuading opponent into an agreement. Our results show some characteristics consistent with facts, and also offer possible explanations for the emergence of some real features.","3D Robotic Catheter Shape Reconstruction and Localisation Using Appearance Priors and Adaptive C-Arm Positioning ","Classifying Political Orientation on Twitter: It\u2019s Not Easy!Numerous papers have reported great success at inferring the political orientation of Twitter users.  This paper has some unfortunate news to deliver: while past work has been sound and often methodologically novel, we have discovered that reported accuracies have been systemically overoptimistic due to the way in which validation datasets have been collected, reporting accuracy levels nearly 30% higher than can be expected in populations of general Twitter users. Using careful and novel data collection and annotation techniques, we collected three different sets of Twitter users, each characterizing a different degree of political engagement on Twitter - from politicians (highly politically vocal) to \"normal\" users (those who rarely discuss politics).  Applying standard techniques for inferring political orientation, we show that methods which previously reported greater than 90% inference accuracy, actually achieve barely 65% accuracy on normal users. We also show that classifiers cannot be used to classify users outside the narrow range of political orientation on which they were trained. While a sobering finding, our results quantify and call attention to overlooked problems in the latent attribute inference literature that, no doubt, extend beyond political orientation inference: the way in which datasets are assembled and the transferability of classifiers.","REDUCING THE TIME REQUIRED FOR HASHING OPERATIONSDue to the increasingly massive amounts of data that need to be ana- lyzed in digital forensic investigations, it is necessary to automatically recognize suspect files and filter out non-relevant files. To achieve this goal, digital forensic practitioners employ hashing algorithms to clas- sify files into known-good, known-bad and unknown files. However, a typical personal computer may store hundreds of thousands of files and the task becomes extremely time-consuming. This paper attempts to address the problem using a framework that speeds up processing by us- ing multiple threads. Unlike a typical multithreading approach, where the hashing algorithm is performed by multiple threads, the proposed framework incorporates a dedicated prefetcher thread that reads files from a device. Experimental results demonstrate a runtime efficiency of nearly 40% over single threading.","Towards Service Orchestration Between Smart Grids and Telecom NetworksIn the last years, the research efforts in smart grids SG and telecommunication networks TN have been considerable but never converged to a common view and, due to the lack of strong interactions between the two worlds, only limited benefits have been achieved. We envision in this paper that future TN as well as any other ICT application will interact with the SG, enabling 1 the TN to know the energy source and cost that is currently powering its equipment, 2 to turn the TN into an active client which can request to the SG the quantity and quality e.g. green of energy that it needs, and 3 a service orchestration between SG supply system and TN operations. As a consequence, the enabled interoperability between TN and SG would allow TN to take energy-aware management decisions in function of energy-related information provided by the SG. For example, TN can route packets with the objective of optimizing green criteria, while SG can route the energy towards the TN clients with the objective of not wasting surpluses of green energy. These new energy and data routing capabilities can be exploited not only by SG operators and telecom carriers but also by any energy consumer/producer within the ICT world. This may include industry and institutional ICT premises, datacenters, home automation, wireless and mobile cellular networks, which will be able to implement their own energy-aware management and operations M&amp;O by considering the quantity, quality and cost of the energy currently provided by the smart grid.","Discrete relative states to learn and recognize goals-based behaviors of groupsIn a crisis management context, situation awareness is challenging due to the complexity of the environment and the limited resources available to the security forces. The different emerging threats are difficult to identify and the behavior of the crowd (separated in groups) is difficult to interpret and manage. In order to solve this problem, the authors propose a method to detect threat and understand the situation by analyzing the collective behavior of groups inside the crowd and detecting their goals. This is done according to a set of learned, goal-based, group behavior models and observation sequences of the group. The proposed method computes the group estimated state before using Hidden Markov Model to recognize the goal by the group behavior. A realistic emergency scenario is simulated to demonstrate the performance of the algorithms, where a suicide-bomber wearing a concealed bomb enters a busy urban street. The proposed algorithms achieve the detection of the dangerous person in the crowd, in order to raise an alert and also predict casualties by identifying which groups did not notice the threat. Complex Event Processing is used to compare and evaluate the results. The algorithms were found more precise and more tolerant to noisy observations.","Deliberating about voting dimensionsIt has been claimed that deliberation is capable of overcoming social choice theory impossibility results, because it can justify the restriction of individual preferences to single-peaked profiles. Our aim is to better understand the relationship between single-peakedness and collective justifications of preferences.","Cryptanalysis of Brenner et al.'s somewhat homomorphic encryption schemeRecently, Brenner et al. proposed a symmetric somewhat homomorphic encryption scheme and applied it to solve some practical problems, such as the Millionaires' problem, which only need to evaluate circuits of limited depth. It is claimed that the security of their scheme is built on the hardness of integer factorization. In this paper, we use the Euclidean Greatest Common Divisor (GCD) algorithm to perform cryptanalysis on Brenner et al.'s scheme. We present several algorithms to find the secret key of their scheme. Our experiments have shown that our cryptanalysis is feasible and efficient.","You Are What You Eat: Learning User Tastes for Rating PredictionPoor nutrition is one of the major causes of ill-health and death in the western world and is caused by a variety of factors including lack of nutritional understanding and preponderance towards eating convenience foods. We wish to build systems which can recommend nutritious meal plans to users, however a crucial pre-requisite is to be able to recommend recipes that people will like. In this work we investigate key factors contributing to how recipes are rated by analysing the results of a longitudinal study (n=124) in order to understand how best to approach the recommendation problem. We identify a number of important contextual factors which can influence the choice of rating. Based on this analysis, we construct several recipe recommendation models that are able to leverage understanding of user's likes and dislikes in terms of ingredients and combinations of ingredients and in terms of nutritional content. Via experiment over our dataset we are able to show that these models can significantly outperform a number of competitive baselines.","A group based approach for path queries in road networksThe advancement of mobile technologies and map-based applications enables a user to access a wide variety of location-based services that range from information queries to navigation systems. Due to the popularity of map-based applications among the users, the service provider often requires to answer a large number of simultaneous (or contemporary) queries. Thus, processing queries efficiently on spatial networks (i.e., road networks) have become an important research area in recent years. In this paper, we focus on path queries that find the shortest path between a source and a destination of the user. In particular, we address the problem of finding the shortest paths for a large number of simultaneous path queries in road networks. Traditional systems that consider one query at a time are not suitable for many applications due to high computational and service cost overhead. We propose an efficient group based approach that provides a practical solution with reduced cost. The key concept of our approach is to group queries that share a common travel path and then compute the shortest path for the group. Experimental results show the effectiveness and efficiency of our group based approach.","PriGen: A Generic Framework to Preserve Privacy of Healthcare Data in the Cloud ","A Local Search Based Approximation Algorithm for Strong Minimum Energy Topology Problem in Wireless Sensor Networks ","Artificial Bee Colony-Based Approach for Optimal Capacitor Placement in Distribution Networks ","Using Mobile Phone Location Data for Urban Activity Analysis ","Functional Logic Programming: From Theory to CurryFunctional logic programming languages combine the most important declarative programming paradigms, and attempts to com- bine these paradigms have a long history. The declarative multi-paradigm language Curry is influenced by recent advances in the foundations and implementation of functional logic languages. The development of Curry is an international initiative intended to provide a common platform for the research, teaching, and application of integrated functional logic languages. This paper surveys the foundations of functional logic pro- gramming that are relevant for Curry, the main features of Curry, and extensions and applications of Curry and functional logic programming. Compared to traditional imperative languages, functional as well as logic lan- guages provide a higher and more abstract level of programming that leads to reliable and maintainable programs. Although the motivations are similar in both paradigms, the concrete languages differ due to their different foundations, namely the lambda calculus and first-order predicate logic. Thus, it is a natu- ral idea to combine these worlds of programming into a single paradigm, and attempts for doing so have a long history. However, the interactions between functional and logic programming features are complex in detail so that the concrete design of an integrated functional logic language is a non-trivial task. This is demonstrated by a lot of research work on the semantics, operational principles, and implementation of functional logic languages since more than two decades. Fortunately, recent advances in the foundation and implementation of functional logic languages have shown reasonable principles that lead to the design of practically applicable programming languages. The declarative multi- paradigm language Curry 1 (69,92) is based on these principles. It is developed by an international initiative of researchers in this area and intended to provide a common platform for the research, teaching, and application of integrated func- tional logic languages. This paper surveys the foundations of functional logic programming that are relevant for Curry, design decisions and main features of \ufffd This work was partially supported by the German Research Council (DFG) under grants Ha 2457/5-1 and Ha 2457/5-2 and the NSF under grant CCR-0218224. 1 http://www.curry-language.org","Centrality and Spectral Radius in Dynamic Communication NetworksWe explore the influence of the choice of attenuation factor on Katz centrality indices for evolving communication networks. For given snapshots of a network observed over a period of time, recently developed communicability indices aim to identify best broadcasters and listeners in the network. In this article, we looked into the sensitivity of communicability indices on the attenuation factor constraint, in relation to spectral radius (the largest eigenvalue) of the network at any point in time and its computation in the case of large networks. We proposed relaxed communicability measures where the spectral radius bound on attenuation factor is relaxed and the adjacency matrix is normalised in order to maintain the convergence of the measure. Using a vitality based measure of both standard and relaxed communicability indices we looked at the ways of establishing the most important individuals for broadcasting and receiving of messages related to community bridging roles. We illustrated our findings with two examples of real-life networks, MIT reality mining data set of daily communications between 106 individuals during one year and UK Twitter mentions network, direct messages on Twitter between 12.4k individuals during one week.","Concurrent CPU-GPU Code Optimization: The Two-Point Angular Correlation Function as Case Study ","HcBench: Methodology, Development, and Full-System Characterization of a Customer Usage Representative Big Data/Hadoop Benchmark ","On the Symbiosis between Enterprise Modelling and Ontology EngineeringIn different fields, ontologies are increasingly deployed to specify and fix the terminology of a particular domain. In enterprise modelling, their main use lies in serving as a knowledge base for enterprise model creation. Such models, based on one or several compatible so-called enterprise-specific ontologies, allow for model alignment and solve interoperability issues. On the other hand, enterprise models may enrich the enterprise-specific ontology with concepts emerging from practical needs. In order to achieve this reciprocal advantage, we developed an ontology-based enterprise modeling meta-method that facilitates modelers to construct their models using the enterprise-specific ontology. While doing so, modelers give their feedback for ontology improvement. This feedback is subject to community approval, after which it is possibly incorporated into the ontology, thereby evolving the ontology to better fit the enterprise's needs.","Toward Automated Design for Manufacturing FeedbackIterative loops and rework between design, manufacturing, and testing delay the development lead time for complex products like vehicles. This research focuses on creating an automated design for manufacturing (DFM) feedback system (ADFS) framework that reduces these iterations by providing early, fast, and informative feedback on manufacturability to designers. The proposed ADFS analyzes manufacturability in terms of part geometry with respect to a given set of process capabilities based on DFM guidelines for vehicle manufacturing. In order to increase the fidelity of the search, a heuristic approach to obtain manufacturing process fitness with respect to a part design is introduced. The proposed system framework will help to identify suitable manufacturing processes more quickly as well as provide visual feedback for geometric advice at the feature level with regard to the selected processes.","The Matthew Effect in Online Review Helpfulness ","Components and Functions of Crowdsourcing Systems - A Systematic Literature ReviewMany organizations are now starting to introduce crowdsourcing as a new model of business to outsource tasks, which are traditionally performed by a small group of people, to an undefined large workforce. While the utilization of crowdsourcing offers a lot of advantages, the development of the required system carries some risks, which are reduced by establishing a profound theo- retical foundation. Thus, this article strives to gain a better understanding of what crowdsourcing systems are and what typical design aspects are considered in the development of such systems. In this paper, the author conducted a sys- tematic literature review in the domain of crowdsourcing systems. As a result, 17 definitions of crowdsourcing systems were found and categorized into four perspectives: the organizational, the technical, the functional, and the human- centric. In the second part of the results, the author derived and presented com- ponents and functions that are implemented in a crowdsourcing system.","Extracting event-related information from article updates in wikipediaWikipedia is widely considered the largest and most up-to-date online encyclopedia, with its content being continuously maintained by a supporting community. In many cases, real-life events like new scientific findings, resignations, deaths, or catastrophes serve as triggers for collaborative editing of articles about affected entities such as persons or countries. In this paper, we conduct an in-depth analysis of event-related updates in Wikipedia by examining different indicators for events including language, meta annotations, and update bursts. We then study how these indicators can be employed for automatically detecting event-related updates. Our experiments on event extraction, clustering, and summarization show promising results towards generating entity-specific news tickers and timelines.","Exploring Video Steganography for Hiding Images Based on Similar Lifting Wavelet Coefficients ","Issues and Ongoing Work on State-Driven Workload Generation for Distributed Systems ","Paying the Price of Learning Independently in Route ChoiceIn evolutionary game theory, one is normally interested in the investigation about how the distribution of strategies changes along time. Equilibrium-based methods are not appropriate for open, dynamic systems, as for instance those in which individual drivers learn to select routes. In this paper we model route choice in which many agents adapt simultaneously. We investigate the dynamics with a continuous method (replicator dynamics), and with learning methods (social and individual). We show how the convergence to one of the Nash equilibria depends on the underlying learning dynamics selected, as well as on the pace of adjustments by the driver agents.","Designing User Learning Experience in Virtual Worlds: The Young Europeans for Democracy Serious Application ","Causal belief networks: handling uncertain interventionsEliciting the cause of an event will be easier if an agent can directly intervene on some variables by forcing them to take a specific value. The state of the target variable is therefore totally dependent of this external action and independent of its original causes. However in real world applications, performing such perfect interventions is not always feasible. In fact, an intervention can be uncertain in the sense that it may uncertainly occur. It can also have uncertain consequences which means that it may not succeed to put its target into one specific value. In this paper, we use the belief function theory to handle uncertain interventions that could have uncertain consequences. Augmented causal belief networks are used to model uncertain interventions.","Computer-Aided Detection of Non-polypoid Flat Lesions in CT Colonography: Observer Performance StudyTo evaluate the effect of computer-aided detection CADe on the performance of human readers in the detection of non-polypoid flat lesions from a large computed tomography CT colonography population. A total of 153 cathartic CT colonography cases, including 45 colonoscopy-confirmed, morphologically flat lesions, were sampled from a European multi-center CT colonography trial for asymptomatic patients at increased risk of colorectal cancer. Two readers expert and non-expert reviewed the 153 CT colonography cases and recorded all detected lesions using primary 3D interpretation and a CADe second-read paradigm. There were 17 patients with 18 flat lesions i\u00be?10 mm in size and 17 patients with 27 flat lesions 6 --- 9 mm in size. For the flat lesions i\u00be?10 mm, per-patient sensitivities of the expert reader for unassisted and CADe-assisted readings were 59% [95% CI: 36---78%] and 71% [47---87%], respectively, whereas those of the non-expert reader were 41% [21---65%] and 47% [37---59%], respectively. For 6-9 mm flat lesions, the corresponding per-patient sensitivities of the expert reader were 59% [36---78%] and 76% [53---89%], respectively, whereas those of the non-expert were 47% [37---59%] and 82% [59---93%]. The results indicate that the use of CADe can increase the sensitivity of human readers in the detection of flat lesions in a screening setting.","Silent Hill 2 and the Curious Case of Invisible AgencyThis paper outlines the concept of agency in interactive narratives and focuses on the video game Silent Hill 2 as a successful example that defies the very concept. In what ways agency was deemed as an essential part in interactive narratives and narrative video games are summarized. Then the method of agency in Silent Hill 2 is proposed as an alternative to our familiar understanding of the concept agency and is entitled as invisible agency.","Secure Key Management in the CloudWe consider applications involving a number of servers in the cloud that go through a sequence of online periods where the servers communicate, separated by offline periods where the servers are idle. During the offline periods, we assume that the servers need to securely store sensitive information such as cryptographic keys. Applications like this include many cases where secure multiparty computation is outsourced to the cloud, and in particular a number of online auctions and benchmark computations with confidential inputs. We consider fully autonomous servers that switch between online and offline periods without communicating with anyone from outside the cloud, and semi-autonomous servers that need a limited kind of assistance from outside the cloud when doing the transition. We study the levels of security one can --- and cannot --- obtain in this model, propose light-weight protocols achieving maximal security, and report on their practical performance.","Quality and Quantity Improvement for Current RDS-TMC ","Implementation of a Learning Style by E-Textbook Contents Reduction Processing ","Performance analysis and optimization of high density tree-based 3d multilevel FPGAA Tree-based 3D Multilevel FPGA architecture that unifies two unidirectional programmable interconnection network is presented in this paper. In a Tree-based FPGA architecture, the interconnects are arranged in a multilevel network with the switch blocks placed at different tree levels using Butterfly-Fat-Tree network topology. Two dimensional layout development of a Tree-based multilevel interconnect is a major challenge for Tree-based FPGA. A 3D interconnect network technology leverage on Through Silicon Via (TSVs) to re-distribute the Tree interconnects, based on network delay and thermal considerations into multiple silicon layers is discussed. The impact of of Through Silicon Vias and performance improvement of 3D Tree-based FPGA are analyzed. We present an optimized physical design technology leverage on TSV, Thermal-TSV (TTSV), and thermal analysis. Compared to 3D Mesh-based FPGA, the 3D Tree-based FPGA design reduces the number of TSVs by 29% and leads to a performance improvement of 53% based on our place and route experiments.","Modelling Power Adaption Flexibility of Data Centres for Demand-Response ManagementDemand-response management is an approach that includes the power demand side into the power management process to reshape power demand of consumers to the current availability of power. Data centres are major energy consumers that are highly interesting for demand-response management. However, in contrast to many other energy consumers, data centres have a highly dynamic flexibility in terms of power adaption, depending on the current situation, which makes their integration into demand-response management difficult. This paper suggests a model for the dynamic power adaption flexibility of data centres, to foster their integration into demand-response management.","MRF-Based Multiple Classifier System for Hyperspectral Remote Sensing Image Classification ","Modeling a human's learning processes to support continuous learning on human computer interactionThis paper presents the way to design the continuous learning support system for a human to achieve continuous learning. The objective of this research is to make a prototype system based on a learning process model to guide a human to achieve continuous learning. The main problem is how to keep supplying new goals to a learner for achieving continuous learning. To encourage the sense of continuous awareness toward goal discovery, we propose an idea to provide a human learner with invisible goals. This paper formalizes the continuous learning by a simple maze model with invisible goals and designs the maze sweeping task which involves multiple solutions and goals.","Evaluating Anytime Algorithms for Learning Optimal Bayesian NetworksExact algorithms for learning Bayesian networks guarantee to find provably optimal networks. However, they may fail in difficult learning tasks due to limited time or memory. In this research we adapt several anytime heuristic search-based algorithms to learn Bayesian networks. These algorithms find high-quality solutions quickly, and continually improve the incumbent solution or prove its optimality before resources are exhausted. Empirical results show that the anytime window A* algorithm usually finds higher-quality, often optimal, networks more quickly than other approaches. The results also show that, surprisingly, while generating networks with few parents per variable are structurally simpler, they are harder to learn than complex generating networks with more parents per variable.","Design Aspects of Secure Biometric Systems and Biometrics in the Encrypted Domain ","Web-based portal for sharing information through cad/plm software during the eco-product development processAgainst the backdrop of increasing global demand for environmentally sustain-able products, the integrated software platform for Green ENgineering dESIgn and product sustainability (G.EN.ESI) project aims to develop a software platform, for use in conjunction with CAD/PLM software, which simplifies the process of integrating environmental and economic requirements into the product development process. A key component of the platform, and the main focus of this paper, is its unique web based supply chain portal that has the ability to obtain information directly from the supply chain. This paper details the work undertaken in the early stages of its development to explore possible portal architectures based on their strategic alignment with goals of firms using it. Based on research and analysis of past and existing supplier portals and data collected through an online survey and a case study, four possible architectures of the web portal were derived using scenario planning and their viability was tested using use cases and wind-tunnelling. The results suggest that although all generated scenarios are viable, the one in which multiple buyers and multiple suppliers interact with a single web portal is the most favourable. The consolidation in buyers and suppliers mitigates any bargain power related issues that might arise, while making way for the possible development of an industry wide information sharing standard for eco-design. Moving forward, the project aims to gain a better understanding of supplier collaboration in new product development through the use of the portal by exploring the nature of the information being shared, the roles that users of the portal play and any competitive conditions associated with the use of the portal.","A Probabilistic Quantitative Analysis of Probabilistic-Write/Copy-SelectProbabilistic-Write/Copy-Select (PWCS) is a novel synchro- nization scheme suggested by Nicholas Mc Guire which avoids expensive atomic operations for synchronizing access to shared objects. Instead, PWCS makes inconsistencies detectable and recoverable. It builds on the assumption that, for typical workloads, the probability for data races is very small. Mc Guire describes PWCS for multiple readers but only one writer of a shared data structure. In this paper, we report on the formal analysis of the PWCS protocol using a continuous-time Markov chain model and probabilistic model checking techniques. Besides the origi- nal PWCS protocol, we also considered a variant with multiple writers. The results were obtained by the model checker PRISM and served to identify scenarios in which the use of the PWCS protocol is justified by guarantees on the probability of data races. Moreover, the analysis showed several other quantitative properties of the PWCS protocol.","The hardness of (\u03b5, m)-anonymityWhen a table containing individual data is published, disclosure of sensitive information should be prohibitive. (e, m)-anonymity was a new anonymization principle for preservation of proximity privacy, in publishing numerical sensitive data. It is shown to be NP-Hard to (e, m)-anonymize a table minimizing the number of suppressed cells. Extensive performance study verified our findings that our algorithm is significantly better than the traditional algorithms presented in the paper[1].","A Novel Approach for Monitoring SQL Anti-Forensic Attacks Using Pattern Matching for Digital Forensic Investigation ","Stock Trading with Random Forests, Trend Detection Tests and Force Index Volume Indicators ","Case study for experience vision: application for PCIn order to examine the new value of photo management software preinstalled on personal computers to develop a model for the next photo management software, I have to utilize the Experience Vision method. I will introduce the process from gathering information from the activity of novice users, structuring of their real user demands, to scenario creation.","Worker Perception of Quality Assurance Mechanisms in Crowdsourcing and Human Computation MarketsMany human computation systems utilize crowdsourcing marketplaces to recruit workers. Because of the open nature of these marketplaces, requesters need to use appropriate quality assurance mechanisms to guarantee high quality results. Previous research has mostly focused on the statistical aspects of quality assurance. Instead, we analyze the worker perception of five quality assurance mechanisms (Qualification Test, Qualification Restriction, Gold Standard, Majority Vote, Validating Review) according to subjective (fairness, offense, benefit) and objective (necessity, accuracy, cost) criteria. Based on theory from related areas like labor psychology, we develop a conceptual model and test it with a survey on Mechanical Turk. Our results show big differences in perception, especially with respect to Majority Vote which is rated low by workers. On the basis of these results, we show implications for theory and give requesters on crowdsourcing markets the advice to integrate the worker view when selecting an appropriate quality assurance mechanism.","Wordnet based multi-way concept hierarchy construction from text corpusIn this paper, we propose an approach to build a multiway concept hierarchy from a text corpus, which is based on WordNet and multi-way hierarchical clustering. In addition, a new evaluation metric is presented, and our approach is compared with 4 kinds of existing methods on the Amazon Customer Review data set.","Laugh When You\u2019re WinningDeveloping virtual characters with naturalistic game playing capabilities is an increasingly researched topic in Human-Computer Interaction. Possible roles for such characters include virtual teachers, personal care assistants, and companions for children. Laughter is an under-investigated emotional expression both in Human-Human and Human-Computer Interaction. The EU Project ILHAIRE, aims to study this phenomena and endow machines with laughter detection and synthesis capabilities. The Laugh when you\u2019re winning project, developed during the eNTERFACE 2013 Workshop in Lisbon, Portugal, aimed to set up and test a game scenario involving two human participants and one such virtual character. The game chosen, the yes/no game, induces natural verbal and non-verbal interaction between participants, including frequent hilarious events, e.g., one of the participants saying \u201cyes\u201d or \u201cno\u201d and so losing the game. The setup includes software platforms, developed by the ILHAIRE partners, allowing automatic analysis and fusion of human participants\u2019 multimodal data (voice, facial expression, body movements, respiration) in real-time to detect laughter. Further, virtual characters endowed with multimodal skills were synthesised in order to interact with the participants by producing laughter in a natural way.","A Study of Cross-Culture for a Suitable Information Feeding in Online Social Networks ","Christiane's HairWe explore the geometric and measure-theoretic properties of a set built by stacking central Cantor sets with continuously varying scaling factors. By using self-similarity, we are able to describe its main features in a fairly complete way. We show that it is made of an uncountable number of analytic curves, compute the exact areas of the gaps of all sizes, and show that its Hausdorff and box-counting dimensions are both equal to 2. It provides a particularly good example to introduce and showcase these notions because of the beauty and simplicity of the arguments. Our derivation of explicit formulas for the areas of all of the gaps is elementary enough to be explained to first-year calculus students.","A multilingual GRUG treebank for underresourced languagesIn this paper, we describe outcomes of an undertaking on building Treebanks for underresourced languages Georgian, Russian, Ukrainian, and German - one of the \"major\" languages in the NLT world. The monolingual parallel sentences in four languages were syntactically annotated manually using the Synpathy tool. The tagsets follow an adapted version of the German TIGER guidelines with necessary changes relevant for the Georgian, the Russian and the Ukrainian languages grammar formal description. An output of the monolingual syntactic annotation is in the TIGER-XML format. Alignment of monolingual repository into the bilingual Treebanks was done by the Stockholm TreeAligner software. A demo of the GRUG treebank resources will be held during a poster session.","Transcending Knowledge Gaps in Virtual Teams: Social Processes of Rapid Problem-Solving Bounded by TerminologyVirtual and distributed collaboration are increasingly important for organizations. This paper presents episodes of negotiated term definitions used to complete tasks in a voluntary, ad hoc game forum of an Alternate Reality Game (ARG). Episodes analyzed focus on specialized language used during problem solving. Terminology analysis reveals that players do not explicate definitions and construct shared mental models or knowledge. Instead, they transcend knowledge gaps in order to achieve action-oriented objectives. By focusing social processes on negotiated terminology for the purpose of task completion, the team rapidly meets goals.","An ANN Based Approach for Gait Prediction of a Lower-Limb Exoskeleton with Plantar Pressure SensorsThis paper proposes an approach based on Artificial Neural Network (ANN) method for gait prediction of a lower-limb exoskeleton equipped with plantar pressure sensors and a pair of crutches. This approach can be implemented to predict the exact moment to change gait motion status. Further, the proposed approach can help to decide the starting movement speed of the pilot, through predictions on angular velocities of joints of both knees and hips. In this way, the exoskeleton can cope better with the pilot. Experimental results show that the new approach can capture the starting point of a new move, as well as predict the starting movement speed based on inputs from pressure sensors installed under pilot's plantar and crutches.","Depth-Layer-Based Patient Motion Compensation for the Overlay of 3D Volumes onto X-Ray Sequences ","Evaluation of Product Quantization for Image SearchProduct quantization is an effective quantization scheme, with that a high-dimensional space is decomposed into a Cartesian product of low- dimensional subspaces, and quantization in different subspaces is conducted separately. We briefly discuss the factors for designing a product quantizer, and then design experiments to comprehensively investigate how these factors influence performance of image search. By this evaluation we reveal design principles that have not been well investigated before.","A procedural balanced map generator with self-adaptive complexity for the real-time strategy game planet warsProcedural content generation (PCG) is the programmatic generation of game content using a random or pseudo-random process that results in an unpredictable range of possible gameplay spaces. This methodology brings many advantages to game developers, such as reduced memory consumption. This works presents a procedural balanced map generator for a real-time strategy game: Planet Wars. This generator uses an evolutionary strategy for generating and evolving maps and a tournament system for evaluating the quality of these maps in terms of their balance. We have run several experiments obtaining a set of playable and balanced maps.","Requirements traceability across organizational boundaries: a survey and taxonomy[Context and motivation] Outsourcing of software development is an attractive business model. Companies expect cost reduction, enhanced efficiency, and exploited external resources. However, this paradigmatic shift also introduces challenges as stakeholders are spread across distinct organizations. [Question/problem] Requirements traceability supports stakeholders in satisfying information needs about developments and could be a viable way of addressing the challenges of interorganizational development. While requirements traceability has been the subject of significant research efforts, its application across organizational boundaries is a largely unexplored area. [Principal ideas/results] We followed a qualitative research approach. First, we developed a taxonomy identifying the needs of inter-organizational traceability. Second, we conducted semi-structured interviews with informants from 17 companies. Eventually, we applied qualitative content analysis to extract findings that supported and evolved our taxonomy. [Contribution] Practitioners planning and managing inter-organizational relationships can use our findings as a conceptual baseline to effectively leverage traceability in those settings. Effective traceability supports projects in accomplishing their primary goal of maximizing business value.","Eine Bestandsaufnahme von Standardisierungspotentialen und -l\u00fccken im Cloud ComputingDie Standardisierung im Cloud Computing ist erst im Entstehen be- griffen. Sie gewinnt jedoch zunehmend an Eigendynamik. Bisherige Standardi- sierungsbemuhungen stecken konzeptionell in den Kinderschuhen, da unein- heitliche Definitionen und fehlendes Orientierungswissen ein zielorientiertes Handeln behindern. Die vorliegende Arbeit schlagt deshalb eine konsistente Taxonomie fur die strukturierte Betrachtung und begriffliche Eindeutigkeit bei der Beschreibung und Bewertung von Standards vor. Darauf aufbauend wird ein Vorgehensmodell zur Analyse der aktuellen Standardisierungslage vorge- stellt. Dieses verwendet eine Standardisierungslandkarte, die das Forschungs- feld anhand der Dimensionen Herausforderungen und Ansatzpunkte aufspannt. Die vorgenommene Analyse erfasst gegenwartige Standardisierungspotentiale und -lucken im Cloud Computing. Die abschliesend vorgenommene Bewertung zeigt Handlungsoptionen kunftiger Standardisierungsbemuhungen auf.","Stretchy Time Pattern Mining: A Deeper Analysis of Environment Sensor DataMining sequential patterns on environment sensor data is a challenging task; the data can present noises and may also contain sparse patterns, which are difficult to be detected. The knowledge extracted from environment sensor data can be used to determine climate changes. However, there is a lack of methods that can handle this kind of database. In this paper, we propose a method to mine sequential patterns in sparse, incomplete and noisy sensor data. The proposed method, called Stretchy Time Windows (STW), allows the mining of sequential patterns that present time gaps between their events. We propose an algorithm to implement STW, called Miner of Stretchy Time Sequences (MSTS). The proposed algorithm works with sequences of any size and uses a balanced strategy to analyze the search space. Our experiments show that MSTS returns sequences that have a longer period of analysis than GSP a traditional frequent pattern mining algorithm. In fact, 5 times larger than GSP and higher number of patterns (2.3 times) when compared to previous methods.","The picard algorithm for ordinary differential equations in coqOrdinary Differential Equations (ODEs) are ubiquitous in physical applications of mathematics. The Picard-Lindelof theorem is the first fundamental theorem in the theory of ODEs. It allows one to solve differential equations numerically. We provide a constructive development of the Picard-Lindelof theorem which includes a program together with sufficient conditions for its correctness. The proof/program is written in the Coq proof assistant and uses the implementation of efficient real numbers from the CoRN library and the MathClasses library. Our proof makes heavy use of operators and functionals, functions on spaces of functions. This is faithful to the usual mathematical description, but a novel level of abstraction for certified exact real computation.","What if there was no oxygen?: responding to hypothetical questions in an intelligent tutoring agentOur aim is for intelligent tutoring agents to replace traditional and even online textbooks with personalized, adaptive, one-to-one instruction. We focus on science subjects, and describe an approach to answering hypothetical questions from the student, such as \"Would cellular respiration continue in the absence of oxygen?\"","A Logical Interpretation of Dempster-Shafer Theory, with Application to Visual RecognitionWe formulate Dempster Shafer Belief functions in terms of Propositional Logic using the implicit notion of provability underlying Dempster Shafer Theory. Given a set of propositional clauses, assigning weights to certain propositional literals enables the Belief functions to be explicitly computed using Network Reliability techniques. Also, the logical procedure corresponding to updating Belief functions using Dempster's Rule of Combination is shown. This analysis formalizes the implementation of Belief functions within an Assumption-based Truth Maintenance System (ATMS). We describe the extension of an ATMS-based visual recognition system, VICTORS, with this logical formulation of Dempster Shafer theory. Without Dempster Shafer theory, VICTORS computes all possible visual interpretations (i.e. all logical models) without determining the best interpretation(s). Incorporating Dempster Shafer theory enables optimal visual interpretations to be computed and a logical semantics to be maintained.","Supporting shared decision making within the MobiGuide project.This paper describes our approach for fostering and facilitating communication among patients and caregivers in the context of shared decision making, i.e., when decisions must be taken not only on the basis of scientific evidence but also of the patient\u2019s preferences and context. This happens because clinical practice guidelines cannot provide recommendations for every possible situation, and cannot foresee every change in a patient\u2019s context, which might imply the deviation from a previously acknowledged recommendation. Within the EU-funded project MobiGuide (www.mobiguide-project.eu), supporting remote patient management, we propose decision theory as a methodological framework for a tool that, during face to face encounters, is used to tailor pre-defined, generic decision models to the individual patient, by involving the patient himself in the customization of the model parameters. Although this approach is not appropriate for all patients, it leads, in well-chosen cases, to a more informed choice, with potentially better treatment compliance.","Three-dimensional tubular self-assembling structure for bio-hybrid actuationThis work aims at reporting an innovative approach towards the development of a three-dimensional cell-based bio-hybrid actuator. The system, made of polydimethylsiloxane and based on a stress-induced rolling membrane technique, was provided with different elastic moduli (achieved by varying the monomer/curing agent ratio), with proper surface micro-topographies and with a proper surface chemical functionalization to assure a long-term stable protein coating. Finite element modeling allowed to correlate the overall contraction of the polymeric structure along its main axis (caused by properly modeled muscle cell contraction forces) with substrate thickness and with matrix mechanical properties.","Institution-Based Semantics for MOF and QVT-RelationsTo cope with formal verification issues within the Model- Driven Engineering (MDE) paradigm, a separation of duties between software developers is usually proposed: MDE experts define models and transformations, while formal verification experts conduct the verifica- tion process. This is often aided by (semi)automatic translations form the MDE elements to their formal representation in the semantic domain used for verification. From a formal perspective, this requires semantic- preserving translations between the MDE elements and the semantic do- main. The aim of this paper is to present formal semantics for the MOF and QVT-Relations languages which are standard languages for defining metamodels and model transformations, respectively. The semantics is based on the Theory of Institutions and reflect the conformance relation between models and metamodels, and the satisfaction of transforma- tion rules between pairs of models. The theory assists in the definition of semantic-preserving translations between our institutions and other logics which will be used for verification.","Unsupervised approach to generate informative structured snippets for job search enginesAiming to improve user experience for a job search engine, in this paper we propose an idea to switch from query-biased snippets used by most web search engines to rich structured snippets associated with the main sections of a job posting page, which are more appropriate for job search due to specific user needs and the structure of job pages. We present a very simple yet actionable approach to generate such snippets in an unsupervised way. The advantages of the proposed approach are two-fold: it doesn't require manual annotation and therefore can be easily deployed to many languages, which is a desirable property for a job search engine operating internationally; it fuses naturally with the trend towards Mobile Web where the content needs to be optimized for small screen devices and informativeness.","CAKE Distributed Environments for Context-Aware SystemsIn this paper, we introduce the distributed Context Awareness and Knowledge Environment CAKE. The design objectives for CAKE were to develop a system that is flexible enough to be used in different application domains, that supports re-use of components with the help of a well-defined plugin-system and application programming interface and that caters for privacy concerns by giving users access to personal context aware environments that share information selectively with other users' context aware environments. We describe related work on context middleware and the niche CAKE is targeting. We also argue for taking privacy concerns into account and outline how our framework addresses such issues. The concepts behind CAKE are introduced, and we describe how reasoning engines based on different paradigms can be put to work together in our framework. A first take on end-user programming is outlined and a prototypical implementation of the system presented.","QUEST: querying complex information by direct manipulationWhen users search for information in domains they are not familiar with, they usually struggle to formulate an adequate (textual) query. Often users end up with repeating re-formulations and query refinements without necessarily achieving their actual goals. In this paper we propose a user interface that is capable to offer users flexible and ergonomic interaction elements to formulate even complex queries in a simple and direct way. We call this concept QUEST (Query User Interface for Exploratory Search Tasks). The proposed radial user interface supports phrasing and interactive visual refinement of vague queries to search and explore large document sets. The main idea of this concept is to provide an integrated view of queries and related results, where both - queries and results - can be interactively manipulated and influence each other. Changes will be immediately visualized. The concept was implemented on a tablet computer and the usability was stepwise evaluated during a formative and a summative evaluation process. The results reveal high usability ratings, even if the concept was completely unknown to our test users.","Mapping study about usability requirements elicitationThe HCI community has developed guidelines and recommendations for improving the usability system that are usually applied at the last stages of the software development process. On the other hand, the SE community has developed sound methods to elicit functional requirements in the early stages, but usability has been relegated to the last stages together with other non-functional requirements. Therefore, there are no methods of usability requirements elicitation to develop software within both communities. An example of this problem arises if we focus on the Model-Driven Development paradigm, where the methods and tools that are used to develop software do not support usability requirements elicitation. In order to study the existing publications that deal with usability requirements from the first steps of the software development process, this work presents a mapping study. Our aim is to compare usability requirements methods and to identify the strong points of each one.","A Recommender System Model Combining Trust with Topic MapsRecommender Systems (RS) aim to suggest users with items that they might like based on users' opinion on items. In practice, information about the users' opinion on items is usually sparse compared ...","Dynamic Similarity-Aware Inverted Indexing for Real-Time Entity ResolutionEntity resolution is the process of identifying groups of records in a single or multiple data sources that represent the same real-world entity. It is an important tool in data de-duplication, in linking records across databases, and in matching query records against a database of existing entities. Most existing entity resolution techniques complete the resolution process offline and on static databases. However, real-world databases are often dynamic, and increasingly organizations need to resolve entities in real-time. Thus, there is a need for new techniques that facilitate working with dynamic databases in real-time. In this paper, we propose a dynamic similarity-aware inverted indexing technique (DySimII) that meets these requirements. We also propose a frequency-filtered indexing technique where only the most frequent attribute values are indexed. We experimentally evaluate our techniques on a large real-world voter database. The results show that when the index size grows no appreciable increase is found in the average record insertion time (around 0.1 msec) and in the average query time (less than 0.1 sec). We also find that applying the frequency-filtered approach reduces the index size with only a slight drop in recall.","Barcelona: A Design and Runtime Environment for Declarative Artifact-Centric BPMA promising approach to managing business operations is based on business artifacts, a.k.a. business entities with lifecycles [8, 6]. These are key conceptual entities that are central to guiding the operations of a business, and whose content changes as they move through those operations. A business artifact type is modeled using a an information model, which is intended to hold all business-relevant data about entities of this type, and b a lifecycle model, which is intended to hold the possible ways that an entity of this type might progress through the business. In 2010 a declarative style of business artifact lifecycles, called Guard-Stage-Milestone GSM, was introduced [4, 5]. GSM has since been adopted [7] to form the conceptual basis of the OMG Case Management Model and Notation CMMN standard [1]. The Barcelona component of the recently open-sourced [2] ArtiFact system supports both design-time and run-time environments for GSM. Both of these will be illustrated in the proposed demo.","DT-RANSAC: A Delaunay Triangulation Based Scheme for Improved RANSAC Feature Matching ","Universal access: a concept to be adapted to technological development and societal changeSociety is undergoing a transition toward an information society, due to the very fast development of ICT technology. This transition is creating a new complex social environment that requires new ways of looking at universal accessibility and methodologies to guarantee it. After an analysis of the present situation and possible developments, the main conclusion of the paper is that not only the information society (equipment and services) must be designed for all, but also that it must be designed by all. This means that users must be integrated not only in the phase of requirement analysis, but as actors in designing and implementing solutions.","Tailoring the Software Product Management Framework for Use in a Healthcare Organization: Case StudyMany reference models were developed for software process im- provement. Each model, however, is an idealized prescription that is applicable in a limited set of situation only. This paper has investigated how an existing reference model can be tailored to a domain it has not been designed for initial- ly. The tailoring approach is based on translating the reference model to the new domain and on inductive interviews for evaluating the translated model. The approach has been applied for assessing and improving strategic require- ments engineering practice in a healthcare organization with a framework for software product management.","Improving the Performance of High-Dimensional kNN Retrieval through Localized Dataspace Segmentation and Hybrid IndexingEfficient data indexing and nearest neighbor retrieval are challenging tasks in high-dimensional spaces. This work builds upon our previous analyses of iDistance partitioning strategies to develop the backbone of a new indexing method using a heuristic-guided hybrid index that further segments congested areas of the dataspace to improve overall performance for exact k-nearest neighbor kNN queries. We develop data-driven heuristics to intelligently guide the segmentation of distance-based partitions into spatially disjoint sections that can be quickly and efficiently pruned during retrieval. Extensive tests are performed on k-means derived partitions over datasets of varying dimensionality, size, and cluster compactness. Experiments on both real and synthetic high-dimensional data show that our new index performs significantly better on clustered data than the state-of-the-art iDistance indexing method.","Robust PLSA performs better than LDAIn this paper we introduce a generalized learning algorithm for probabilistic topic models (PTM). Many known and new algorithms for PLSA, LDA, and SWB models can be obtained as its special cases by choosing a subset of the following \"options\": regularization, sampling, update frequency, sparsing and robustness. We show that a robust topic model, which distinguishes specific, background and topic terms, doesn't need Dirichlet regularization and provides controllably sparse solution.","On the Optimality of Subsets of Features Selected by Heuristic and Hyper-heuristic ApproachesThe concepts of relevance and redundancy are central to feature selection algorithms that do not use a learning algorithm for subset evaluation. Redundancy is in fact a special form of relevance where there is a correlation (linear or nonlinear) between the input features of a problem. Therefore, having a good heuristic for measuring relevance can also help detect redundancy. In this paper, we show that there is a lack of generality in the solutions found by heuristic measures. Through some counter-examples we show that regardless of the type of heuristic measure and search strategy, filter methods cannot optimise the performance of all learning algorithms. We show how different measures may have different notions of relevance between features and how this could lead to not detecting important features in certain problems. We then propose a hyper-heuristic method that generates an appropriate relevance measure for each problem. The new approach can alleviate problems related to missing relevant features.","Routing low-speed traffic requests onto high-speed lightpaths by using a multiobjective firefly algorithmNowadays, the bandwidth requirements of the majority of traffic connection requests are in the range of Mbps. However, in optical networks each physical link is able to operate in the range of Gbps causing a huge waste of bandwidth as a result. Fortunately, using access station at each node of the optical network, several low-speed traffic requests may be multiplexed onto one high-speed channel. Multiplexing or grooming these low-speed requests is known in the literature as the Traffic Grooming problem - an NP-hard problem. Therefore, in this paper we propose the use of Evolutionary Computation for solving this telecommunication problem. The selected algorithm is an approach inspired by the flash pattern and characteristics of fireflies, the Firefly Algorithm (FA), but adapted to the multiobjective domain (MO-FA). After performing several experiments and comparing the results obtained by the MO-FA with those obtained by other approaches published in the literature, we can conclude that it is a good approach for solving this problem.","An FPT Algorithm for Tree Deletion SetWe give a 5 k n O(1) time xed-parameter algorithm for determining whether a given undirected graph on n vertices has a subset of at most k vertices whose deletion results in a tree. Such a subset is a restricted form of a feedback vertex set. While parameterized complexity of feedback vertex set problem and several of its variations have been well studied, to the best of our knowledge, this is the rst xed-parameter algorithm for this version of feedback vertex set.","MDL-Based Unsupervised Attribute RankingIn the present paper we propose an unsupervised attribute ranking method based on evaluating the quality of clustering that each attribute produces by partitioning the data into subsets according to its values. We use the Minimum Description Length (MDL) principle to evaluate the quality of clustering and describe an algorithm for attribute ranking and a related clustering algorithm. Both algorithms are empirically evaluated on benchmark data sets. The experiments show that the MDL-based ranking performs closely to the supervised information gain ranking and thus improves the performance of the EM and k-means clustering algorithms in purely unsupervised setting.","Deployment of Smart Spaces in Internet of Things: Overview of the Design Challenges ","Neural network H \u221e tracking control of nonlinear systems using GHJI methodIn this paper, an H\u221e optimal tracking control scheme based on generalized Hamilton-Jacobi-Isaacs (GHJI) equation is developed for discrete-time (DT) affine nonlinear systems. First, via system transformation, the optimal tracking problem is transformed into an optimal regulation problem with respect to the state tracking error. Second, with regard to the converted regulation problem, in order to obtain the H\u221e tracking control, the corresponding GHJI equation is formulated, and then the L2-gain analysis of the closed-loop nonlinear system are employed. Third, an iterative algorithm based on the GHJI equation by using neural networks (NNs) is introduced to solve the optimal control. Finally, simulation results are presented to demonstrate the effectiveness of the proposed scheme.","Cognitive factors involved in the ability to manipulate a digital cameraThe purpose of this study is to understand who user' property affects the ability to manipulate a digital camera. The N-back task, the action control scale, usability test, structural test, functional test, protocol analysis and some questioner are used to understand user' distinction. The relationships among each property and performance were cleared by correlation analysis. As a result, functional models about the camera are most important to use well.","Effects of a Frequency-Dependent Dissipative Element in Haptic InteractionThis paper presents an analytical investigation into effects of a frequency-dependent dissipative element added to a haptic interaction system. A stably displayable impedance range is analyzed by a discrete-time model of a haptic system with a frequency-dependent dissipative element that can reduce the high frequency inputs causing instability in a haptic system. A frequency- dependent dissipative element can, however, reduce the displayable impedance range by generating excessive energy. It is also shown that the generated energy may be reduced by including two linear half-wave rectifiers to a dissipative ele- ment, which in turn increases the stably displayable impedance range.","Data Modeling in the CloudIn this paper we describe ERDPlus, a free web-based data modeling tool we developed for use in academic settings. The paper includes a comparison of ERDPlus to forty existing data modeling tools. This comparison shows how ERDPlus differs from existing data-modeling tools, and how it facilitates data modeling education. Unlike the existing tools, ERDPlus is web-based, free for academic use, provides free cloud storage of diagrams, works on both Mac and Windows computers, and is capable of creating models for both operational and analytical databases. This paper also includes the description of the usability survey we undertook to validate that ERDPlus is easy to learn and use for novice students learning about data modeling.","Global analytic solution of fully-observed variational Bayesian matrix factorizationThe variational Bayesian (VB) approximation is known to be a promising approach to Bayesian estimation, when the rigorous calculation of the Bayes posterior is intractable. The VB approximation has been successfully applied to matrix factorization (MF), offering automatic dimensionality selection for principal component analysis. Generally, finding the VB solution is a nonconvex problem, and most methods rely on a local search algorithm derived through a standard procedure for the VB approximation. In this paper, we show that a better option is available for fully-observed VBMF--the global solution can be analytically computed. More specifically, the global solution is a reweighted SVD of the observed matrix, and each weight can be obtained by solving a quartic equation with its coefficients being functions of the observed singular value. We further show that the global optimal solution of empirical VBMF (where hyperparameters are also learned from data) can also be analytically computed. We illustrate the usefulness of our results through experiments in multi-variate analysis.","Collaborative Multi Organ Segmentation by Integrating Deformable and Graphical ModelsOrgan segmentation is a challenging problem on which significant progress has been made. Deformable models (DM) and graphical models (GM) are two important categories of optimization based image segmentation methods. Efforts have been made on integrating two types of models into one framework. However, previous methods are not designed for segmenting multiple organs simultaneously and accurately. In this paper, we propose a hybrid multi organ segmentation approach by integrating DM and GM in a coupled optimization framework. Specifically, we show that region-based deformable models can be integrated with Markov Random Fields (MRF), such that multiple models' evo- lutions are driven by a maximum a posteriori (MAP) inference. It brings global and local deformation constraints into a unified framework for simultaneous seg- mentation of multiple objects in an image. We validate this proposed method on two challenging problems of multi organ segmentation, and the results are promising.","Current Trends in Employee Recruitment Using the InternetReviewing the literature on innovative online services in context with recruiting, seven main services for applicants emerged: general job board services, advanced job search services, social and business network services, mobile services, advanced content and Web 2.0 services, notification services, and lead user services. The identified services from the literature analyses were compared with the state of the art implemented services on 100 international job boards. While English and German-language job boards follow the same trends in terms of services offered to applicants, the former are more innovative and have higher implementation rates of innovative services than the latter. Social and business network integration is increasingly popular but most job boards do not make use of dynamic content for company profiles, real-job- previews or employee testimonials. Notification services, particularly job alerts, have seen successful implementation.","Modelling higher dimensional data for GIS using generalised mapsReal-world phenomena have traditionally been modelled in 2D/3D GIS. However, powerful insights can be gained by integrating additional non-spatial dimensions, such as time and scale. While this integration to form higher-dimensional objects is theoretically sound, its implementation is problematic since the data models used in GIS are not appropriate. In this paper, we present our research on one possible data model/structure to represent higher-dimensional GIS datasets: generalised maps. It is formally defined, but is not directly applicable for the specific needs of GIS data, e.g. support for geometry, overlapping and disconnected regions, holes, complex handling of attributes, etc. We review the properties of generalised maps, discuss needs to be modified for higher-dimensional GIS, and describe the modifications and extensions that we have made to generalised maps. We conclude with where this research fits within our long term goal of a higher dimensional GIS, and present an outlook on future research.","3D Face Recognition Based on Intrinsic Features ","Usability Evaluation of a Voluntary Patient Safety Reporting System: Understanding the Difference between Predicted and Observed Time Values by Retrospective Think-Aloud Protocols ","How can a future safety net successfully detect conflicting ATC clearances: yet remain inconspicuous to the tower runway controller? first results from a SESAR exercise at hamburg airportTo increase runway safety a new safety net for Tower Runway Controllers was developed which detects if controllers give a clearance to an aircraft or vehicle contradictory to another clearance already given to another mobile. In a shadow mode validation exercise with eleven controllers at the operational environment of the airport Hamburg (Germany) operational feasibility was tested in order to clarify if operational requirements in terms of usability are fulfilled. At the same time operational improvements regarding safety were studied e.g. if the new safety net detects all conflicts and if nuisance alerts are suppressed.","Design and Implementation of Linked Network Security System Based on Virtualization in the Separate Network Environment ","Using Human-Centric Wireless Sensor Networks to Support Personal SecurityViolence and crime in large urban areas are a worldwide problem that is still open. After several attempts to reduce its occurrence and impact, there seems to be an agreement that crime preventive actions, which can be taken by citizens and security organizations, are the best way to address it. This paper proposes the use of human-centric wireless sensor networks to help address this problem, and the proposed solution is complementary to those already used by security organizations. The architecture and main components of these networks are described in detail. The article also describes a software system that implements most of the components of these networks. Such a system helps people be aware of the risks that appear to exist in a certain place at a certain time. Based on that information, citizens can take appropriate and on-time preventive actions. A preliminary evaluation of the system has been conducted, and the obtained results are also presented and discussed.","Improving System Performance Via Reevaluation of Models ","Transitional Spaces: Between Indoor and Outdoor SpacesTraditionally, spaces have been classified as being located either indoors or outdoors. On closer inspection, however, this distinction is not as clear cut as usually assumed. For example, when navigating complex urban landscapes, pedestrians frequently traverse tunnels, enclosed footbridges or partially roofed courtyards. In this paper, we investigate this type of spaces between indoor and outdoor areas. We present an initial definition of transitional spaces based on a conceptual analysis, and then report on results from an empirical study with 103 pedestrians, whom we interviewed in an urban area. A statistical and linguistic analysis of the outcomes of the study provides evidence for the existence of transitional spaces and their use. The outcomes also support an initial set of characteristics and properties that further clarify these areas. The results pave the way for the further investigation of transitional spaces, e.g. in terms of providing effective navigation support through them.","Voting with a Logarithmic Number of CardsConsider an election where there are two candidates and several voters. Such an election usually requires the same number of ballot papers as the number of voters. In this paper, we show that such an election can be conducted using only a logarithmic number of cards with two suits\u2014black and red\u2014with identical backs. That is, we can securely compute the summation of a number of inputs (0s and 1s) using a logarithmic number of cards with respect to the number of inputs.","Co-ranking Images and Tags via Random Walks on a Heterogeneous GraphRanking on image search results has attracted considerable attentions. Despite many graph-based ranking algorithms have demon- strated remarkable success, most of their applications are limited to sin- gle image-networks such as the network of tags associated with images. In this paper, we investigate the problem of co-ranking images and tags attached in a heterogeneous network, which consists of three graphs: the image graph connecting images, the tag graph connecting tags attached to the images, as well as the image-tag graph connecting the above two graphs together. Observing that existing ranking approaches do not con- sider images and tags simultaneously, a novel co-ranking method via random walks on all three graphs is proposed to significantly improve the ranking effectiveness on both images and tags. Experimental results conducted on three benchmark data sets show that our approach out- performs the state-of-the-art local ranking approaches for image ranking and tag ranking and scales well on large scale data sets.","Main Content Extraction from Web Documents Using Text Block Context ","A temporal model of text periodicities using Gaussian ProcessesTemporal variations of text are usually ignored in NLP applications. However, text use changes with time, which can affect many applications. In this paper we model periodic distributions of words over time. Focusing on hashtag frequency in Twitter, we first automatically identify the periodic patterns. We use this for regression in order to forecast the volume of a hashtag based on past data. We use Gaussian Processes, a state-ofthe-art bayesian non-parametric model, with a novel periodic kernel. We demonstrate this in a text classification setting, assigning the tweet hashtag based on the rest of its text. This method shows significant improvements over competitive baselines.","Process Discovery by Synthesizing Activity Proximity and User\u2019s Domain Knowledge ","Use of simulated physician handoffs to study cross-cover chart biopsy in the electronic medical record.Clinical handoffs involve the rapid transfer of patient information from one provider or team to another, through activities which may introduce errors and affect care delivery. \u201cCross-coverage\u201d requires quickly familiarizing oneself with unfamiliar patients whose management plans were established by another provider or team. Through this work, we describe physicians\u2019 information seeking approaches within an electronic medical record (EMR) during physician handoff and chart biopsy at a major academic medical center. We conducted simulated handoff sessions and interviews with 21 physicians using standardized patient cases and we analyzed screen capture data, and video and audio recordings of interactions with the EMR and handoff printouts. We found highly variable navigation of the EMR but greater similarity in physicians\u2019 EMR navigation behavior when the chart review was prompted by simulated interruptions. Understanding how physicians seek and assimilate patient data can inform handoff tool design and suggest strategies for explicitly supporting EMR chart biopsies.","Learning descriptive visual representation by semantic regularized matrix factorizationThis paper presents a novel semantic regularized matrix factorization method for learning descriptive visual bag-of-words (BOW) representation. Although very influential in image classification, the traditional visual BOW representation has one distinct drawback. That is, for efficiency purposes, this visual representation is often generated by directly clustering the low-level visual feature vectors extracted from local keypoints or regions, without considering the high-level semantics of images. In other words, this visual representation still suffers from the semantic gap and may lead to significant performance degradation in more challenging tasks (e.g., classification of community-contributed images with large intra-class variations). To overcome this drawback, we develop a semantic regularized matrix factorization method for learning descriptive visual BOW representation by adding Laplacian regularization defined with the tags (easy to access although noisy) of community-contributed images into matrix factorization. Experimental results on two benchmark datasets show the promising performance of the proposed method.","A Business Simulation with an Agent-Based Deliberative Model of Consumer Behaviour ","Improved boosting performance by exclusion of ambiguous positive examplesIn visual object class recognition it is difficult to densely sample the set of positive examples. Therefore, frequently there will be areas of the feature space that are sparsely populated, in whi ...","CapView: functionality-aware visual mashup development for non-programmersBuilding mashup applications from existing web resources becomes increasingly popular, and, in theory, accessible even for end users without programming skills. Current proposals for end user development of mashups mainly focus on visual wiring of component interfaces supplemented by recommendations on composition steps and a certain degree of automation. However, it is still a major challenge to provide an appropriate level of functional abstraction in order to visualize the functionality of a mashup and its components, and for composing on a functional level instead of merely assembling structural units. This becomes crucial, especially when non-programmers are the intended target group. In this paper, we propose CapView, a novel functionality-aware development view on running composite applications. CapView is part of the EDYRA platform and provides a functional overview of the mashup by abstracting from interface and wiring details. It enables users to understand mashup development as an assembly process that is centered on the capabilities of components and mashup fragments. We evaluate the concepts in a user study and present lessons learned.","Combining Float Car Data and Multispectral Satellite Images to Extract Road Features and Networks ","On Quality Ratings for Spoken Dialogue Systems -- Experts vs. UsersIn the field of Intelligent User Interfaces, Spoken Dialogue Systems (SDSs) play a key role as speech represents a true intuitive means of human communication. Deriving information about its quality can help rendering SDSs more user-adaptive. Work on automatic estimation of subjective quality usually relies on statistical models. To create those, manual data annotation is required, which may be performed by actual users or by experts. Here, both variants have their advantages and drawbacks. In this paper, we analyze the relationship between user and expert ratings by investigating models which combine the advantages of both types of ratings. We explore two novel approaches using statistical classification methods and evaluate those with a preexisting corpus providing user and expert ratings. After analyzing the results, we eventually recommend to use expert ratings instead of user ratings in general.","On the Sublinear Processor Gap for Parallel ArchitecturesIn the past, parallel algorithms were developed, for the most part, under the assumption that the number of processors is \u0398(n )( where n is the size of the input) and that if in practice the actual number was smaller, this could be resolved using Brent's Lemma to simulate the highly parallel solution on a lower-degree parallel architecture. In this paper, however, we argue that design and implementation issues of algo- rithms and architectures are significantly different\u2014both in theory and in practice\u2014between computational models with high and low degrees of parallelism. We report an observed gap in the behavior of a parallel architecture depending on the number of processors. This gap appears repeatedly in both empirical cases, when studying practical aspects of architecture design and program implementation as well as in theoretical instances when studying the behaviour of various parallel algorithms. It separates the performance, design and analysis of systems with a sub- linear number of processors and systems with linearly many processors. More specifically we observe that systems with either logarithmically many cores or with O(n \u03b1 )c ores (with \u03b1&lt; 1) exhibit a qualitatively different behavior than a system with a linear number of cores on the size of the input, i.e., \u0398(n ). The evidence we present suggests the exis- tence of a sharp theoretical gap between the classes of problems that can be efficiently parallelized with o(n) processors and with \u0398(n) processors unless P = NC .","Extended Initial Study on the Performance of Enhanced PSO Algorithm with Lozi Chaotic Map ","Right ventricular strain analysis from 3D echocardiography by using temporally diffeomorphic motion estimationQuantitative motion analysis of the right ventricle (RV) is important to study its function. However, the RV study is more difficult than that of left ventricle (LV) because of its complex shape and the limitations of the existing imaging methods. We propose a diffeomorphic motion estimation method and apply it to the 3D echocardiography of five open-chest pigs under different steady states. We first validate the motion estimation method by using sonomicrometry. Then we estimate the myocardium strain of different steady states. The RV free wall (RVFW) is divided into twelve segments and their strain patterns in each steady states together with the corresponding cardiac mechanics are analyzed. This is the first time to quantitatively analyze the RVFW segment strains from 3D echocardiography by using algorithm.","Nash Convergence of Gradient Dynamics in Iterated General-Sum GamesMulti-agent games are becoming an increasing prevalent formalism for the study of electronic commerce and auctions. The speed at which transactions can take place and the growing complexity of electronic marketplaces makes the study of computationally simple agents an appealing direction. In this work, we analyze the behavior of agents that incrementally adapt their strategy through gradient ascent on expected payoff, in the simple setting of two-player, two-action, iterated general-sum games, and present a surprising result. We show that either the agents will converge to Nash equilibrium, or if the strategies themselves do not converge, then their average payoffs will nevertheless converge to the payoffs of a Nash equilibrium.","HG-Bitmap Join Index: A Hybrid GPU/CPU Bitmap Join Index Mechanism for OLAP ","Community Distribution Outlier Detection in Heterogeneous Information NetworksHeterogeneous networks are ubiquitous. For example, bibliographic data, social data, medical records, movie data and many more can be modeled as heterogeneous networks. Rich information associated with multi-typed nodes in heterogeneous networks motivates us to propose a new definition of outliers, which is different from those defined for homogeneous networks. In this paper, we propose the novel concept of Community Distribution Outliers (CDOutliers) for heterogeneous information networks, which are defined as objects whose community distribution does not follow any of the popular community distribution patterns.We extract such outliers using a type-aware joint analysis of multiple types of objects. Given community membership matrices for all types of objects, we follow an iterative two-stage approach which performs pattern discovery and outlier detection in a tightly integrated manner. We first propose a novel outlier-aware approach based on joint non-negative matrix factorization to discover popular community distribution patterns for all the object types in a holistic manner, and then detect outliers based on such patterns. Experimental results on both synthetic and real datasets show that the proposed approach is highly effective in discovering interesting community distribution outliers.","Kinds of Full Physical ContainmentFull physical containment is the relation in which one physical entity is completely inside another. It is central to the description of natural resources held in reservoirs above or below the surface. Previous ontological representations of containment are located in abstract space, incomplete, or insufficiently incorporate voids, so in this paper we develop a complete taxonomy for the full containment relation that is situated in physical space and integrates voids. The taxonomy is formalized in a mereotopological theory and specializes the DOLCE foundational ontology, thus advancing hydro ontology development.","FAST-PVE: Extremely Fast Markov Random Field Based Brain MRI Tissue ClassificationWe present an extremely fast method named FAST-PVE for tissue classication and partial volume estimation of 3-D brain magnetic resonance images (MRI) using a Markov Random Field (MRF) based spatial prior. The tissue classication problem is central to most brain MRI analysis pipelines and therefore solving it accurately and fast is important. The FAST-PVE method is experimentally conrmed to tissue classify a standard MR image in under 10 seconds with the quantitative accuracy similar to other state of art methods. A key component of the FAST-PVE method is the fast ICM algorithm, which is generally applicable to any MRF-based segmentation method, and formally proven to produce the same segmentation result as the standard ICM algorithm.","Developing a Multi-facet Abstractions Framework for Designing a New Class of Traceability Applications ","A Mechanism to Improve Efficiency for Negotiations with Incomplete InformationClassic results in bargaining theory state that private information necessarily prevents the bargainers from reaping all possible gains from trade. In this paper we propose a mechanism for improving efficiency of negotiation outcome for multilateral negotiations with incomplete information. This objective is achieved by introducing biased distribution of resulting gains from trade to prevent bargainers from misrepresenting their valuations of the negotiation outcomes. Our mechanism is based on rewarding concession-making agents with larger shares of the obtainable surplus. We show that the likelihood for the negotiators to reach agreement is accordingly increased and the negotiation efficiency is improved.","An Improved Labelling for the INRIA Person Data Set for Pedestrian Detection ","A Methodology for the Development and Verification of Access Control Systems in Cloud ComputingCloud computing is an emergent technology that has generated significant interest in the marketplace and is forecasted for high growth. Moreover, Cloud computing has a great impact on different type of users from individual consumers and businesses to small and medium size (SMBs) and enterprise businesses. Although there are many benefits to adopting Cloud computing, there are significant barriers to adoption, viz. security and privacy. In this paper, we focus on carefully planning security aspects regarding access control of Cloud computing solutions before implementing them and, furthermore, on ensuring they satisfy particular organizational security requirements. Specifically, we propose a methodology for the development of access control systems. The methodology is capable of utilizing existing security requirements engineering approaches for the definition and evaluation of access control models, and verification of access control systems against organizational security requirements using techniques that are based on formal methods. A proof of concept example is provided that demonstrates the application of the proposed methodology on Cloud computing systems.","Compositional Verification of Software Product LinesWe present SPLEnD, the first compositional design verification engine for evolving software product lines(SPLs). The unique aspect of SPL development is the reuse of common features and management of variability among the family of products. The proposed design verification engine assumes that each SPL is composed of multiple features with each feature exhibiting variability. One novel aspect of SPLEnD is that it enables verification of SPLs, in which the variability information is captured differently at different levels of abstractions in the design and requirement stages. Another novel aspect of SPLEnD is that it enables compositional verification of designs against requirements. This involves first verifying the individual features separately, which provides a mapping between the variabilities at the requirement and design levels. The obtained mapping relations are then combined in the second step to check the conformance of the entire SPL. Feature level verification essentially involves standard model checking, while for the second step, a Quantified Boolean Formula (QBF) is synthesized and solved. The QBF avoids the explicit enumeration of all possible products thereby reducing the verification effort greatly. SPLEnD uses SPIN for the first step while the state of the art QBF solver CirQit is used for the second step. Thanks to the compositionality, SPLEnD easily handles the evolution of SPL by addition of new features and modification of existing features. Experimental results with SPLEnD look very promising: SPLs with several thousands of features were verified efficiently. A video of SPLEnD can be seen at http://www.cse.iitb.ac.in/$\\sim$krishnas/splend.swf or http://www.cse.iitb.ac.in/$\\sim$krishnas/splend.avi.","Telemedicine and Telemonitoring in HealthcareOver the last decade, there has been an increasing demand of information technology, specifically, telemedicine and telemonitoring in healthcare. Many elderly and disabled people are unable to look after themselves. They also desire quality healthcare. If the healthcare can be provided at home instead of only hospitals, the service could be more affordable, and people would feel more comfortable. Aiming to help elderly and disabled people, technology has been developed to provide assistance in various ways. Consequently, telemedicine and telemonitoring have been deeply embedded in healthcare industry and made significant impact. This report has provided a comprehensive review covering current progress of research in telemedicine and telemonitoring and their applications to healthcare services.","Compositional Reasoning for Multi-modal LogicsWe provide decomposition and quotienting results for multi- modal logic with respect to a composition operator, traditionally used for epistemic models, due to van Eijck et al. (Journal of Applied Non- Classical Logics 21(3-4):397-425, 2011), that involves sets of atomic propositions and valuation functions from Kripke models. While the com- position operator was originally defined only for epistemic S5 n models, our results apply to the composition of any pair of Kripke models. In particular, our quotienting result extends a specific result in the above mentioned paper by van Eijck et al. for the composition of epistemic models with disjoint sets of atomic propositions to compositions of any two Kripke models regardless of their sets of atomic propositions. We also explore the complexity of the formulas we construct in our decomposition result.","On M-type bag structuresIn this paper, the author introduces a structure called M-type bag structure which can be defined on a non-empty set associated with an indiscernibilty relation. It can be observed that an M-type bag structure represents a bag if the indiscernibility relation be defined in such a way that any two elementsof the set are indiscernible under a given set of criteria that considers the values of some predefined attribute set. This paper further studies some algebraic properties of M-type bag structures.","Strong connectivity of wireless sensor networks with double directional antennae in 3DUsing directional antennae in forming a wireless sensor network has many advantages over omnidirectional, including improved energy efficiency, reduced interference, increased security, and improved routing efficiency. We propose using double (Yagi) directional antennae in 3D space: for a given spherical angle such antennae transmit from their apex simultaneously directionally along two diametrically opposing cones in 3D. We study the resulting network formed by such directional sensors. We design a new algorithm to address strong connectivity of the resulting network and compare its hop-stretch factor with the three-dimensional omnidirectional model. We also obtain a lower bound on the minimum range required to ensure strong connectivity for sensors with double antennae. Further, we present simulation results comparing the diameter of a traditional sensor network using omnidirectional and one using directional antennae. \u00a9 2013 Springer-Verlag.","Freiform: a smartpen based approach for creating interactive paper prototypes for collecting dataThe creation of multi-modal data collection is a complex task for all empirically working scientific disciplines. Currently the data is collected using complex audio-video technology and is then manually processed, quite often in a computer supported way. In this project we developed a system allowing to easily create interactive paper prototypes for collecting data. The systems is based on smart pen technology, which allows the user to simply sketch out the form on paper by defining the field type and the field size. Once the sketch is available on paper, data collection can start. The system runs directly on the smart pen. Collected data will be stored in an XML-based, which can be further processed by external programs.","An Identity Parareal Method for Temporal Parallel ComputationsA new simplified definition of time-domain parallelism is introduced for explicit time evolution calculations, and is implemented on parallel machines with bucket-brigade type communications. By the use of an identity operator instead of introducing an approximate solver, a recurrence formula for the parareal-in-time algorithm is much simplified. In spite of such a simple definition, it is applicable to many of explicit time-evolution calculations. In addition, this approach overcomes several drawbacks known in the original parareal-in-time method. In order to implement this algorithm on parallel machines, a parallel bucket-brigade interface is introduced, which reduces programming and tuning costs for complicated space-time parallel programs.","Discovering Semantics from Data-Centric XMLIn database applications, the availability of a conceptual schema and semantics constitute invaluable leverage for improving the effectiveness, and sometimes the efficiency, of many tasks including query processing, keyword search and schema/data integration. The Object-Relationship-Attribute model for Semi-Structured data ORA-SS model is a conceptual model intended to capture the semantics of object classes, object identifiers, relationship types, etc., underlying XML schemas and data. We refer to the set of these semantic concepts as the ORA-semantics. In this work, we present a novel approach to automatically discover the ORA-semantics from data-centric XML. We also empirically and comparatively evaluate the effectiveness of the approach.","Distances Based on Non-rigid Alignment for Comparison of Different Object Instances ","Proactive Engineering and PLM: Current Status and Research Challenges ","Deep Neural Networks for Source Code Author IdentificationPlagiarism and copyright infringement are major problems in academic and corporate environments. Importance of source code authorship attribution arises as it is the starting point of detection for plagiarism, copyright infringement and law suit prosecution etc. There have been many research regard to this topic. Majority of these researches are based on various algorithms which compute similarity amongst source code files. However, for this Paper we have proposed Deep Neural Network DNN based technique to be used for source code authorship attribution. Results proved that DNN based author identification brings promising results once compared the accuracy against previously published research.","A Framework for Processing Uncertain RFID Data in Supply Chain Management ","A Statistical Shape Model for Multiple Organs Based on Synthesized-Based LearningThis paper presents a statistical shape model for multiple abdominal organs using synthesized-based learning to compensate the lack of a large manually labeled training data set. Experiments on 23 non-contrast CT volumes showed that a model trained on both true and synthesized data, outperforms conventional shape models, in terms of generalization, specificity and overlap of neighboring organs.","Control-Flow Analysis with SAT SolversControl-flow analyses statically determine the control-flow of programs. This is a nontrivial problem for higher-order programming languages. This work attempts to leverage the power of SAT solvers to answer questions regarding control-flow. A brief overview of a traditional control-flow analysis is presented. Then an encoding is given which has the property that any satisfying assignment will give a conservative approximation of the true control-flow, along with additional ideas to improve the precision and efficiency of the encoding. The results of the encodings are then compared to those of a traditional implementation on several example programs. This approach is competitive in some instances with hand-optimized implementations. Finally, the paper concludes with a discussion of the implications of these results and work that can build upon them.","A Framework for Formal Reasoning about Privacy Properties Based on Trust Relationships in Complex Electronic ServicesThis paper presents a formal approach for the analysis of privacy properties of complex electronic services. A flexible framework for logic reasoning allows for formally modeling these services in a typed first-order logic and for inferring privacy properties that can be inter- preted by all the stakeholders including consumers. The inference strat- egy consists of compiling user profiles according to the expectations of the consumer about the data practices of the service providers involved. The data in these profiles originates from information that has been dis- closed by the consumer during the service interactions or that may have been exchanged between organizations thereafter. The framework can in- fer relevant privacy properties from these profiles. To validate our work, the approach is applied to the modeling of a web shop.","Extended Algorithm for Solving Underdefined Multivariate Quadratic EquationsIt is well known that solving randomly chosen Multivariate Quadratic equations over a finite field (MQ-Problem) is NP-hard, and the security of Multivariate Public Key Cryptosystems (MPKCs) is based on the MQ-Problem. However, this problem can be solved efficiently when the number of unknowns n is sufficiently greater than that of equations m (This is called \"Underdefined\"). Indeed, the algorithm by Kipnis et al. (Eurocrypt'99) can solve the MQ-Problem over a finite field of even characteristic in a polynomial-time of n when n \u2265 m(m + 1). Therefore, it is important to estimate the hardness of the MQ-Problem to evaluate the security of Multivariate Public Key Cryptosystems. We propose an algorithm in this paper that can solve the MQ-Problem in a polynomial- time of n when n \u2265 m(m +3 )/2, which has a wider applicable range than that by Kipnis et al. We will also compare our proposed algorithm with other known algorithms. Moreover, we implemented this algorithm with Magma and solved the MQ-Problem of m =2 8 andn = 504, and it takes 78.7 seconds on a common PC.","Enhanced Conformal Predictors for Indoor Localisation Based on Fingerprinting MethodWe proposed the first Conformal Prediction (CP) algorithm for indoor localisation with a classification approach. The algorithm can provide a region of predicted locations, and a reliability measurement for each prediction. However, one of the shortcomings of the former approach was the individual treatment of each dimension. In reality, the training database usually contains multiple signal readings at each location, which can be used to improve the prediction accuracy. In this paper, we enhance our former CP with the Kullback-Leibler divergence, and propose two new classification CPs. The empirical studies show that our new CPs performed slightly better than the previous CP when the resolution and density of the training database are high. However, the new CPs performs much better than the old CP when the resolution and density are low. The purpose of indoor localisation is to identify and observe a user inside a building. Global Positioning System (GPS) has long been an optimal solution for outdoor localisation, yet the indoor counterpart remains an open research prob- lem, because of the harsh and complex indoor building structure. Current indoor localisation systems remain either too expensive or not accurate enough (4). In our previous work (2), we proposed the first Conformal Predictor (CP) for indoor localisation based on classification with the weighted K-nearest neighbours algo- rithm, which performed well in our test sets. However, in reality, the prediction accuracy depends on the resolution, and the density of the training database. In this paper, we enhance our former CP with the Kullback-Leibler divergence, which is a better way to compare two signal strength distributions. We propose two new conformal predictors for classification. The empirical studies show that our new CPs perform slightly better than the previous CP when the resolution and density of the training database are high. However, the new CPs performs much better than the previous CPs when the the resolution and density are low. The paper begins with a brief introduction of the indoor localisation prob- lem, and the concept of location fingerprinting. The next section describes our","Communicating in a ubicomp world: Interaction rules for guiding design of mobile interfaces ","Selection and implementation of navigation and information search strategies in bank web sites: turkish caseOne of the major issues in banking is \"consumer loan\". Most of the banks allow customers to apply for a \"personal\" or \"generic\" loan online. This procedure requires filling out forms with some \"familiar data\" and calculating the rates and fees for the total cost. Although online banking is a supported feature of banking in general, every system offers a different path for the same experience. This pilot study, which is the first step of a long-term study, focuses on three different bank web sites in Turkey and investigates the \"find and search\" strategies that users employ in order to apply for a specific amount of loan. For this purpose a qualitative usability test, based on a multi-method approach, was carried out with a sample of 11 Turkish senior year university students who were experienced Internet users and potential new customers. The participants were observed during the task executions and additional data was collected by the \"think aloud\" procedure, eye-tracking and video recording of the participants. Complementary data on user experience was collected by a final debriefing interview. The findings revealed significant usability problems caused specifically by the user interface features and information architecture of each system and enable to propose guidelines to improve user experience in form design and/or check-out process.","Investigating Pointing Tasks across Angularly Coupled Display Areas ","Solving Degree and Degree of Regularity for Polynomial Systems over a Finite Fields ","Analyzing Website Content for Improved R&amp;T Collaboration PlanningA well-known problem in research and technology (R&amp;T) planning is the selection of suited R&amp;T collaboration partners. We investigate the use of textual information from the website content of possible collaboration candidates to identify their suitability. This improves the selection of collaboration partners and it enables a successful processing of R&amp;T-projects. In a case study ` defense R&amp;T', organizations and companies that have proven their suitability as collaboration partner in former R&amp;T projects are selected (positive examples) as well as organizations and companies that have not. Latent semantic indexing with singular value decomposition and logistic regression modeling is used to identify semantic textual patterns from their websites' content. As a result of prediction modeling, some of these textual patterns are successful in predicting new organizations or companies as (un-) suited R&amp;T collaboration partners. These results support the acquisition of new collaboration partners and thus, they are valuable for the planning of R&amp;T.","The relationship between Flocking Behavior and the Emergence of LeadershipThis paper examines the relationship between flocking behaviour and leadership. In order to achieve this aim, we simulate two co-evolving populations of robots: predators and prey. Behavioural and quantitative analysis indicate that a wellstructured hierarchic leadership emerges in the population of predators after the evolution. The emergence of leadership relates to high levels of fitness, so leadership seems to be a winning strategy. We show that the leader role has been assumed by more explorative individuals. Moreover, exploratory behaviours mostly appear when there is a low following behaviour. Therefore, exploratory and following capabilities seem to be complementary both within every replication and within simulations with different perceptual conditions. On the other hand, leadership seems to be a strategy to enable followers to be more explorative. Index Terms: Leadership, Evolutionary Robotics, Flocking","Soft Computing for the Analysis of People Movement Classification ","A Hybrid Genetic Programming with Particle Swarm Optimization ","A Pattern-based Approach for Initial Diagram LayoutIn a diagram editor, one can distinguish initial from incremental diagram layout. The former computes a diagram layout from scratch, whereas the latter adjusts an existing layout after diagram modifications.    In previous work, we have proposed a pattern-based approach as a solution for incremental diagram layout in visual language editors. Each LP encapsulates certain layout behavior. A diagram's layout is then defined by simultaneously applying several LPs to the diagram. This solution has been designed for an interactive environment where the user may select and alter the layout behavior at runtime. This paper describes an extension of this approach that now supports initial diagram layout, too. While the old version only enabled freehand editing, the extended version now supports diagram import and structured editing as well.","Transparent ROP exploit mitigation using indirect branch tracingReturn-oriented programming (ROP) has become the primary exploitation technique for system compromise in the presence of non-executable page protections. ROP exploits are facilitated mainly by the lack of complete address space randomization coverage or the presence of memory disclosure vulnerabilities, necessitating additional ROP-specific mitigations.#R##N##R##N#In this paper we present a practical runtime ROP exploit prevention technique for the protection of third-party applications. Our approach is based on the detection of abnormal control transfers that take place during ROP code execution. This is achieved using hardware features of commodity processors, which incur negligible runtime overhead and allow for completely transparent operation without requiring any modifications to the protected applications. Our implementation for Windows 7, named kBouncer, can be selectively enabled for installed programs in the same fashion as user-friendly mitigation toolkits like Microsoft's EMET. The results of our evaluation demonstrate that kBouncer has low runtime overhead of up to 4%, when stressed with specially crafted workloads that continuously trigger its core detection component, while it has negligible overhead for actual user applications. In our experiments with in-the-wild ROP exploits, kBouncer successfully protected all tested applications, including Internet Explorer, Adobe Flash Player, and Adobe Reader.","Quantifying political leaning from tweets and retweetsMedia outlets and pundits have been quick to embrace online social networks to disseminate their own opinions. But pundits\u2019 opinions and news coverage are often marked by a clear political bias, as widely evidenced during the fiercely contested 2012 U.S. presidential elections. Given the wide availability of such data from sites like Twitter, a natural question is whether we can quantify the political leanings of media outlets using OSN data. In this work, by drawing a correspondence between tweeting and retweeting behavior, we formulate political leaning estimation as an ill-posed linear inverse problem. The result is a simple and scalable approach that does not require explicit knowledge of the network topology. We evaluate our method with a dataset of 119 million election-related tweets collected from April to November, and use it to study the political leaning of prominent tweeters and media sources.","Exploiting Machine Learning for Predicting Nodal Status in Prostate Cancer PatientsProstate cancer is the second cause of cancer in males. The#R##N#prophylactic pelvic irradiation is usually needed for treating prostate#R##N#cancer patients with Subclinical Nodal Metestases. Currently, the physi-#R##N#cians decide when to deliver pelvic irradiation in nodal negative patients#R##N#mainly by using the Roach formula, which gives an approximate estima-#R##N#tion of the risk of Subclinical Nodal Metestases.#R##N#In this paper we study the exploitation of Machine Learning techniques#R##N#for training models, based on several pre-treatment parameters, that#R##N#can be used for predicting the nodal status of prostate cancer patients.#R##N#An experimental retrospective analysis, conducted on the largest Italian#R##N#database of prostate cancer patients treated with radical External Beam#R##N#Radiation Therapy, shows that the proposed approaches can effectively#R##N#predict the nodal status of patients.","Network Performance Analysis Based on Quotient Space TheorySome performance analyses in complex network e.g., shortest path, etc. are complicated. Generally, human have natural ability to solve complex problems by approximating the optimal solution step by step. The granular computing model based on QST Quotient Space Theory provides not only a hierarchical description from fine to coarse but also an effective approach from coarse to fine to solve these complex problems. This paper proposes some methods on complex network performance analysis based on QST. Firstly, maximum cover network chain is used to solve the shortest path problem. Then, a method to find the optimal path of a weighted network is put forward. Finally, dynamic network is decomposed into a series of static networks to solve the maximum flow problem in dynamic network. Theoretical proofs and experimental results show that QST is an effective tool for complex problem solving.","Improving Labor Productivity and Labor Elasticity at Multiproduct Japanese Cuisine Restaurant Introducing Cell-Production SystemThis study examined improvement of labor productivity and elastici- ty of labor hour on sales of a multiproduct Japanese cuisine restaurant. Conven- tionally, multiproduct restaurant operations include a line production system in the kitchen. Japanese chefs are assumed to be low-skilled workers with staff members supported by someone. A cell production system is introduced into a Japanese Cuisine restaurant to improve it. Results show that the cell production system improves both labor productivity and elasticity of labor hours because the system reduces fixed labor hours during less-busy times in the kitchen. To introduce the system, it is important to educate and train kitchen staff members because the system requires preparation of other staff members' food orders during idle time.","Interoperability Standards for Cloud ArchitectureEnabling cloud infrastructures to evolve into a transparent platform raises interoperability issues. Interoperability#R##N#requires standard data models and communication technologies compatible with the existing Internet#R##N#infrastructure. To reduce vendor lock-in situations, cloud computing must implement common strategies regarding#R##N#standards, interoperability and portability. Open standards are of critical importance and need to be embedded into interoperability solutions. Interoperability is determined at the data level as well as the service level. Relevant modelling standards and integration solutions shall be analysed in the context of clouds.","MDL-based models for transliteration generationThis paper presents models for automatic transliteration of proper names between languages that use different alphabets. The models are an extension of our work on automatic discovery of patterns of etymological sound change, based on the Minimum Description Length Principle. The models for pairwise alignment are extended with algorithms for prediction that produce transliterated names. We present results on 13 parallel corpora for 7 languages, including English, Russian, and Farsi, extracted from Wikipedia headlines. The transliteration corpora are released for public use. The models achieve up to 88% on word-level accuracy and up to 99% on symbol-level F-score. We discuss the results from several perspectives, and analyze how corpus size, the language pair, the type of names (persons, locations), and noise in the data affect the performance.","A study for conducting waves by using the multi-channel surface EMGThe surface electromyogram (EMG) is recorded as the interference electric potential generated by motor units in muscle. Therefore, it may be possible to analyze the muscle contraction mechanism in order to examine the composition of the interference signal of the surface EMG. We herein propose a new method by which to analyze the composition of the surface EMG. The proposed method involves searching conducting wave which mean similar waveforms considered same wave appearing during several channels by using multi-channel surface EMG, and we can analyze surface EMG as a set of conducting waves. The proposed method is referred to as the multi-channel method for conducting waves (m-ch method). We analyzed multi-channel EMG using the proposed method.","Sampling estimators for parallel online aggregationOnline aggregation provides estimates to the final result of a computation during the actual processing. The user can stop the computation as soon as the estimate is accurate enough, typically early in the execution. When coupled with parallel processing, this allows for the interactive data exploration of the largest datasets. In this paper, we identify the main functionality requirements of sampling-based parallel online aggregation--partial aggregation, parallel sampling, and estimation. We argue for overlapped online aggregation as the only scalable solution to combine computation and estimation. We analyze the properties of existent estimators and design a novel sampling-based estimator that is robust to node delay and failure. When executed over a massive 8TB TPC-H instance, the proposed estimator provides accurate confidence bounds early in the execution even when the cardinality of the final result is seven orders of magnitude smaller than the dataset size and achieves linear scalability.","BC-BSP: A BSP-Based Parallel Iterative Processing System for Big Data on Cloud ArchitectureMany applications in real life can produce and collect large amount of data and many of them can be modeled by Graph. The number of vertexes of a graph could be several hundreds of millions to billions and the number of edges could be ten or more times of the number of its vertexes. A BSP-based system for large-scale data especially graph data parallel and iterative processing is discussed in this paper. The system has the ability to flexible configuration and the extendibility for functions and strategies such as adjusting the parameters according to the volume of data and supporting multiple aggregation functions at the same time, to process large-scale data, to tolerate faults, to balance load, and to run clustering or classification algorithms on metric datasets. Lots of experiments are done to evaluate the extendibility of the system implemented in the paper, and the comparison between BC-BSP-based applications and MapReduce-based ones are made. The experimental results show that BSP-based applications have higher efficiency than that of MapReduce-based applications when the volume of data can be put in the memory during the course of processing; on the contrary the latter are better than the former, and the performance of BC-BSP platform outperforms Hama and Giraph.","A brain-computer interface to a plan-based narrativeInteractive Narrative is a form of digital entertainment heavily based on AI techniques to support narrative generation and user interaction, significant progress arriving with the adoption of planning techniques. However, there is a lack of unified models that integrate generation, user responses and interaction.#R##N##R##N#This paper addresses this by revisiting existing Interactive Narrative paradigms, granting explicit status to users' disposition towards story characters as part of narrative generation as well as adding support for new forms of interaction. We demonstrate this with a novel Brain-Computer Interface (BCI) design, incorporating empathy for a main character derived from brain signals within filmic conceptions of narrative which drives generation using planning techniques.#R##N##R##N#Results from an experimental study with a fully-implemented system demonstrate the effectiveness of a EEG neurofeedback-based approach, showing that subjects can successfully modulate empathic support of a character in a medical drama. MRI analysis also shows activations in associated regions of the brain during expression of support.","ExecScent: mining for new C&amp;C domains in live networks with adaptive control protocol templatesIn this paper, we present ExecScent, a novel system that aims to mine new, previously unknown C&amp;C domain names from live enterprise network traffic. ExecScent automatically learns control protocol templates (CPTs) from examples of known C&amp;C communications. These CPTs are then adapted to the \"background traffic\" of the network where the templates are to be deployed. The goal is to generate hybrid templates that can self-tune to each specific deployment scenario, thus yielding a better trade-off between true and false positives for a given network environment. To the best of our knowledge, ExecScent is the first system to use this type of adaptive C&amp;C traffic models.#R##N##R##N#We implemented a prototype version of ExecScent, and deployed it in three different large networks for a period of two weeks. During the deployment, we discovered many new, previously unknown C&amp;C domains and hundreds of new infected machines, compared to using a large up-to-date commercial C&amp;C domain blacklist. Furthermore, we deployed the new C&amp;C domains mined by ExecScent to six large ISP networks, discovering more than 25,000 new infected machines.","Transformation of Models in an MDA Approach for Collaborative Distributed ProcessesThis paper studies the specification, mapping and the transforming of behavioral aspects of Open Distributed Processing Information Language, within the context of Model Driven Architecture. In order to specify the executable behavior of a system and to make the processes of the Information executable and controllable, the Reference Model for Open Distributed Processing can be used as a meta-model for behavioral specifications. In the Information language the behavior is specified in terms of schema dynamic, processes, actions, state and the relationships between these concepts. In this work we describe how behavior process can be generated exploiting the benefits of a MDA approach. We define the behavior models by using UML profile and their transformations into BPEL artifacts.","A novel sparse group Gaussian graphical model for functional connectivity estimationThe estimation of intra-subject functional connectivity is greatly complicated by the small sample size and complex noise structure in functional magnetic resonance imaging (fMRI) data. Pooling samples across subjects improves the conditioning of the estimation, but loses subject-specific connectivity information. In this paper, we propose a new sparse group Gaussian graphical model (SGGGM) that facilitates joint estimation of intra-subject and group-level connectivity. This is achieved by casting functional connectivity estimation as a regularized consensus optimization problem, in which information across subjects is aggregated in learning group-level connectivity and group information is propagated back in estimating intra-subject connectivity. On synthetic data, we show that incorporating group information using SGGGM significantly enhances intra-subject connectivity estimation over existing techniques. More accurate group-level connectivity is also obtained. On real data from a cohort of 60 subjects, we show that integrating intra-subject connectivity estimated with SGGGM significantly improves brain activation detection over connectivity priors derived from other graphical modeling approaches.","Audio transportation system for blind peopleThe purpose of this study was to design, develop and evaluate audio-based software to assist people who are blind in public bus transportation. The audio-based software for mobile devices Audiotransantiago was designed in order to provide information regarding authorized bus stops for the entire bus service in the city of Santiago de Chile (known as Transantiago). The study was designed to allow users who are blind to build up a mental map that is adjusted to their surroundings while traveling on the bus system. It was found that the use of the software improved information processing skills, tempo-spatial orientation and orientation and mobility skills (O&amp;M), as users were able to navigate from one place to another without having to obtain information prior to their trip.","Domain adaptation of statistical machine translation models with monolingual data for cross lingual information retrievalStatistical Machine Translation (SMT) is often used as a black-box in CLIR tasks. We propose an adaptation method for an SMT model relying on the monolingual statistics that can be extracted from the document collection (both source and target if available). We evaluate our approach on CLEF Domain Specific task (German-English and English-German) and show that very simple document collection statistics integrated in SMT translation model allow to obtain good gains both in terms of IR metrics (MAP, P10) and MT evaluation metrics (BLEU, TER).","Developing a Hybrid Framework for a Web-Page Recommender System ","Constructing Brain Connectivity Graph by Modified Sparse RepresentationIn the field of neuroimaging, fMRI is an important tool for brain connectivity analysis. However, the architecture of functional connectivity within the human brain connectome cannot be exactly interpreted at the voxel level by using the traditional correlation analysis. To address this problem, we propose a modified sparse representation (MSR) method to construct the connectivity graph in an automatical and efficient way. The MSR approach uses the sparse representation instead of the correlation coefficient to relate brain regions or voxels. Degree centrality (DC), closeness centrality (CC), betweenness centrality (BC), and eigenvector centrality (EC) are employed to extract the features of fMRI connective patterns. With the extracted features, we then experimentally compare affirmative and negative sentences processing on the Star/Plus database, which shows significant difference via MSR method. Compared with the traditional correlation method, MSR shows higher significance between the two cognitive processing tasks.","Studying Mobile Internet Technologies with Agent Based Mean-Field ModelsWe analyze next generation cellular networks, offering con- nectivity to mobile users through LTE as well as WiFi. We develop a framework based on the Markovian agent formalism, which can model several aspects of the system, including the dynamics of user traffic and the allocation of the network radio resources. In particular, through a mean-field solution, we show the ability of our framework to capture the system behavior in flash-crowd scenarios, i.e., when a burst of traffic requests takes place in some parts of the network service area.","A Model-Constructing Satisfiability CalculusWe present a new calculus where recent model-based decision procedures and techniques can be justified and combined with the standard DPLLT approach to satisfiability modulo theories. The new calculus generalizes the ideas found in CDCL-style propositional SAT solvers to the first-order setting.","Pilot operating characteristics analysis of long landing based on flight QAR dataLong landing events make up the largest percentage of all exceedance incidents and multiply the risk of runway excursions in landing phase. For the aim of exploring operating factors causing long landing, this study examined the pilot operating characteristics of long landing events by the methods of variance analysis, regression modeling and flare operation analysis based on flight QAR data. Finally it concluded that flare is the most critical operation in landing, which determining the touchdown distance by two key factors of flare time and flare height. Both of the control column and throttle operation plays an important role in the flare process. Pilots' faster pulling up columns and softer throttle closing is probably helpful for a successful flare. In addition, pilots need to control the aircraft to an appropriate groundspeed and descent rate before descending to the flare initial point. The conclusions are expected to be applied into practice to prevent the happening of long landing events.","An Integral System Based on Open Organization of Agents for Improving the Labour Inclusion of Disabled People ","Refinement-Based Similarity Measure over DL Conjunctive QueriesSimilarity assessment is a key operation in case-based reason- ing and other areas of artificial intelligence. This paper focuses on mea- suring similarity in the context of Description Logics (DL), and specif- ically on similarity between individuals. The main contribution of this paper is a novel approach based on measuring similarity in the space of Conjunctive Queries, rather than in the space of concepts. The advan- tage of this approach is two fold. On the one hand it is independent of the underlying DL, and thus, there is no need to design similarity measures for different DL, and on the other hand, the approach is computationally more efficient than searching in the space of concepts.","Head direction estimation from silhouetteDue to the absence of features that may be extracted from face, heading direction estimation for low resolution images is a diffi- cult task and requires the taking into account all information that may be inferred from human body in image, particularly its silhouette. We propose in this paper a set of geometric features extracted from shape head-shoulders, feet and knees shapes which jointly allow the estima- tion of body direction. Other features extracted from head-shoulders are proposed for heading direction estimation based on body direction. The constraint of camera position related to proposed features is discussed and results of conducted experiments are presented.","Central clustering of categorical data with automated feature weightingThe ability to cluster high-dimensional categorical data is essential for many machine learning applications such as bioinfomatics. Currently, central clustering of categorical data is a difficult problem due to the lack of a geometrically interpretable definition of a cluster center. In this paper, we propose a novel kernel-density-based definition using a Bayes-type probability estimator. Then, a new algorithm called k-centers is proposed for central clustering of categorical data, incorporating a new feature weighting scheme by which each attribute is automatically assigned with a weight measuring its individual contribution for the clusters. Experimental results on real-world data show outstanding performance of the proposed algorithm, especially in recognizing the biological patterns in DNA sequences.","Permutation-Based Pruning for Approximate K-NN SearchIn this paper, we propose an effective indexing and search algorithms for approximate K-NN based on an enhanced implementation of the Metric Suffix Array and Permutation-Based Indexing. Our main contribution is to propose a sound scalable strategy to prune objects based on the location of the reference objects in the query ordered lists. We study the performance and efficiency of our algorithms on large-scale dataset of millions of documents. Experimental results show a decrease of computational time while preserving the quality of the results.","Comparing Schedules in the SINR and Conflict-Graph Models with Different Power Schemes ","Flexible structural constraints in XQuery full-textIn this paper we describe the implementation and the efficiency evaluations of an XQuery Full-Text extension that allows users to express vagueness in XML query specifications. By the extended language the user may specify two new flexible structural axes, the evaluation of which is performed by the query engine via an approximate matching on the fragment structure. The approximate evaluation of the flexible structural constraints produces a fragment score, which may be possibly combined with the score computed by the evaluation of keyword-based constraints. The implementation reported in this paper has been defined on top of the BaseX query engine system.","The day after patch tuesday: effects observable in IP darkspace trafficWe investigated how Patch Tuesday affects the volume and characteristics of malicious and unwanted traffic as observed by a large IPv4 (/8) darkspace monitor over the first six months of 2012. We did not discover significant changes in overall traffic volume following Patch Tuesday, but we found a significant increase of the number of active hosts sending to our darkspace monitor the day after Patch Tuesday for all six investigated months. Our early results suggest the effects of Patch Tuesday are worth deeper investigation. Detecting time intervals during which new sources become active can help tune sampling methods toward activity periods that likely contain more interesting information (i.e., many new malicious sources) than other time periods.","Poison Identification Based on Bayesian Network: A Novel Improvement on K2 Algorithm via Markov Blanket ","Influence of organizational culture and communication on the successful implementation of information technology in hospitalsIn this paper, we report on a case study examining types of organiza- tional culture influencing communication as an important factor in the study of successful IT adoption and implementation in health care. We observed a hospital organization and focused on technological innovations and the accom- panying communication factors in the successful implementation of IT. The re- sults demonstrate the importance of the organizational culture as an important factor in establishing well-balanced communication as a primary influence fac- tor in the implementation of new technologies. Based on theoretical and empiri- cal insights, we propose a model describing the relationship of organizational culture, communication, and the level of success in the implementation and adaptation of new IT systems in hospitals.","Does an Information Service Provider Improve the MarketThis study aims to theoretically analyze whether the information ser- vice provider improves the market efficiency. We construct a model where a good supplied by a producer has a risk to be harmful for a consumer because of an accident and it brings monetary losses to both consumers and producers. The accident risk is endogenously determined by the efforts of producers and con- sumers and the information of safety provided by the producers. The informa- tion service provider requires producers to provide information and certifies the credibility of information. In the equilibrium, if the entry cost for the informa- tion service provider is small, the optimal effort levels spent by the consumer and producer increase and the risk of accident decreases, which improves the market efficiency.","Dynamic Multi-video Summarization of Sensor-Rich Videos in Geo-SpaceUser generated videos are much easier to be produced today due to the progress in camera technology on mobile devices. The ubiq- uitous built-in sensors in digital devices greatly enrich these videos with sensor descriptions, especially geo-spatial properties. A repository of such sensor-rich videos can be a great source of information for prospective tourists when they plan to visit a city and would like to get a preview of its main areas. In this study we propose an interactive geo-video search system. When a user specifies a start point and a destination (e.g. ,o n am ap), the sys- tem dynamically retrieves a video summarization along the path between the two points. Moreover, the query can be interactively updated dur- ing the video playback, by changing either the tour path or the target destination. The main features of our technique are, first, that it is fully automatic and leverages sensor meta-data information which is acquired in conjunction with videos. Second, the system dynamically adapts to query updates in real-time, and no prior knowledge is required by users. Third, a concise but comprehensive summarization from multiple user generated videos is proposed for any queried route. Finally, the system incrementally adapts to the latest contributions to the video repository.","Markov Decision Processes with Functional RewardsMarkov decision processes MDP have become one of the standard models for decision-theoretic planning problems under uncertainty. In its standard form, rewards are assumed to be numerical additive scalars. In this paper, we propose a generalization of this model allowing rewards to be functional. The value of a history is recursively computed by composing the reward functions. We show that several variants of MDPs presented in the literature can be instantiated in this setting. We then identify sufficient conditions on these reward functions for dynamic programming to be valid. In order to show the potential of our framework, we conclude the paper by presenting several illustrative examples.","Persistent patterns in integer discrete circlesWe study patterns that appear in discrete circles with integer center and radius. As the radius goes to infinity, the patterns get closer to digital straight segments: the notion of tangent words (described in Monteil DGCI 2011) allows to grasp their shape. Unexpectedly, some tangent convex words do not appear infinitely often due to deep arithmetical reasons related to an underlying Pell-Fermat equation. The aim of this paper is to provide a complete characterization of the patterns that appear in integer discrete circles for infinitely many radii.","Leader Election and Centers and Medians in Tree NetworksWe give a weak leader election algorithm, which elects a leader or two neighboring co-leaders of an anonymous tree network, as well as give distributed algorithms for finding centers and medians of anonymous tree networks. All algorithms are in the comparison model, are self-stabilizing and silent under the unfair daemon. Each of the three problems is solved in O(Diam) rounds with step complexity O(n\u00b7Diam). The per process space complexity is O(1) for weak leader election, O(logDiam) for finding centers, and O(logn) for finding medians. These are the minimum possible space complexities for self-stabilizing silent algorithms. The main innovation is the introduction of the constant space implementation of parent pointers using the finite Abelian group i\u00be?5.","Attitude-Driven Web Consensus Support System for Large-Scale GDM Problems Based on Fuzzy Linguistic Approach ","Design and Analysis on a New Underwater RobotThis paper describes the analysis of the architecture, and control system of a new underwater robot named underwater disk robot (UDR), which has six degrees of freedom (DOF) motion. With such thruster positions, the vehicle has omnidirectional manoeuvrability without heading motion. Also, the motion of the streamline disk-shaped UDR hull is less affected by side disturbances because the UDR can move robustly, swiftly along any direction, and the hull reduce the drag force on its body in the horizontal motion. Heave and pitch motion simulation studies of the UDR were carried out with the computational fluid dynamics (CFD) software. required format.","Comparative Conformance Cases for Monitoring Multiple Implementations of Critical RequirementsThe paper presents the concept and the mechanism of comparative conformance cases which support conformance monitoring in situations where a standard or other set of requirements are being implemented at multiple sites. The mechanism is enabled by NOR-STA services which implement the TRUST-IT methodology and are deployed in the cloud in accordance with the SaaS model. In the paper we introduce the concept of comparative conformance cases, explain the software services used to implement them and present a case study of monitoring the implementation of the EC Regulation No. 994/2010, related to risk management of gas supply infrastructures across Europe.","Social Groups Detection in Crowd through Shape-Augmented Structured Learning ","SMT-Based Array Invariant GenerationThis paper presents a constraint-based method for generating universally quantified loop invariants over array and scalar variables. Constraints are solved by means of an SMT solver, thus leveraging recent advances in SMT solving for the theory of non-linear arithmetic. The method has been implemented in a prototype program analyzer, and a wide sample of examples illustrating its power is shown.","Evaluation of the Mini-Models Robustness to Data Uncertainty with the Application of the Information-Gap TheoryThe paper describes a new method based on the information- gap theory which enables an evaluation of the mini-models robustness to a specified kind of uncertainty in the data. There are presented concepts of a robustness and an opportunity of mini-models and calculations of these concepts were performed for a simple 1-D data set and next, for a more complicated 6-D data set. In both cases the method worked cor- rectly and enabled evaluation of the robustness and the opportunity for a given lowest acceptable quality rc or a windfall quality rw. Additionally the method enabled choosing of the most robust model for a given level of an uncertainty.","Algorithmic Debugging for Intelligent Tutoring: How to Use Multiple Models and Improve DiagnosisIntelligent tutoring systems (ITSs) are capable to intelli- gently diagnose learners' problem solving behaviour only in limited and well-defined contexts. Learners are expected to solve problems by closely following a single prescribed problem solving strategy, usually in a fixed- order, step by step manner. Learners failing to match expectations are often met with incorrect diagnoses even when human teachers would judge their actions admissible. To address the issue, we extend our pre- vious work on cognitive diagnosis, which is based on logic programming and meta-level techniques. Our novel use of Shapiro's algorithmic debug- ging now analyses learner input independently against multiple models. Learners can now follow one of many possible algorithms to solve a given problem, and they can expect the tutoring system to respond with im- proved diagnostic quality, at negligible computational costs.","Challenges and Opportunities for Security with Differential PrivacyDifferential Privacy has recently emerged as a measure for protecting privacy in distorted data. While this seems to solve many problems, in practice it still leaves a number of security challenges, and even raises new ones. We give an example of a secure two-party dot product protocol and use this as an example to demonstrate a number of challenges arising from the interaction of information security and differential privacy. We show that independently meeting the requirements of secure multiparty computation and differential privacy does not result in a solution meeting the real goals of privacy and security. Through this, we outline challenges and opportunities for further research.","Autonomic Computing to Manage Green Core Networks with Quality of ServiceIn a context where data and computing services are moving to external specialized datacenters the manual management of these systems is becoming an issue. Human administrators have to deal with hardware resources optimization while meeting the users' needs. In our approach we propose to reconfigure both a set of applications deployed in a datacenter by adapting their behaviors using autonomic computing and the wired network by switching on and off its equipments like routers, modules. We take into account both the energetic costs with the network equipments and the quality of service provided to the end user by the deployed applications. The main contribution of the proposed model is to consider a compromise between the total power consumption of the network equipments and the application quality of service. We validated our approach by simulating deployed applications on the Grid'Mip infrastructure similar to a small core network made up of Cisco routers part of Grid'5000 project.","Researcher homepage classification using unlabeled dataA classifier that determines if a webpage is relevant to a specified set of topics comprises a key component for focused crawling. Can a classifier that is tuned to perform well on training datasets continue to filter out irrelevant pages in the face of changed content on the Web? We investigate this question in the context of researcher homepage crawling.   We show experimentally that classifiers trained on existing datasets for homepage identification underperform while classifying \"irrelevant\" pages on current-day academic websites. As an alternative to obtaining datasets to retrain the classifier for the new content, we propose to use effectively unlimited amounts of unlabeled data readily available from these websites in a co-training scenario. To this end,  we design novel URL-based features  and use them in conjunction with content-based features as complementary views of the data to obtain remarkable improvements in accurately identifying homepages from the current-day university websites.   In addition,  we propose a novel technique for \"learning a conforming pair of classifiers\"  using mini-batch gradient descent. Our algorithm seeks to minimize a loss (objective) function quantifying the difference in predictions from the two views afforded by co-training. We demonstrate that tuning the classifiers so that they make \"similar\" predictions on unlabeled data strongly corresponds to the effect achieved by co-training algorithms. We argue that this loss formulation provides insight into understanding the co-training process and can be used even in absence of a validation set.","Object Detection Using Active Contour Model with Depth ClueThis paper proposes a new method that uses depth clue with the classical contour models for detecting salient objects in noisy images. Unfortunately, most of the proposed stopping functions, including gradi- ent and polarity, fail to detect objects effectively in many circumstances. On the other hand, depth disparity information, if available, could pro- vide better clues for object detection. Thanks to the newly available low cost depth sensors, such as Microsoft Kinect, the use of depth disparity for solving object detection becomes reality. The proposed method takes the advantage of the existing contour models by using the depth dispar- ity clues, from Kinect sensor, instead of two-dimensional clues, in the model stopping function. The depth disparity is applied in the external energy function of the active contour model for detecting the object of interest in the image. The experiments, carried out on real images, have shown the success and effectiveness of our proposed method to detect salient objects.","Error Analysis for Tablet User Interface Transfers Based on Operational Knowledge InterferenceOperational errors were collected and analyzed with regard to the use of different tablet UIs. The effects of previous operational knowledge upon the use of new devices were clarified through user experiments in which forty subjects participated. A comparison was made of three different types of tablet UIs that were equipped with three different operating systems: iOS 5, Windows 8 (release preview), and Windows 7. The results showed the user's dependence upon previous operational knowledge when using a new tablet PC. This dependency was demonstrated both in the ratio of the users' accurate operation, and in their process of exploring an unknown operation.","Location-Based Mobile Recommendations by Hybrid Reasoning on Social Media StreamsIn this paper, we introduce BOTTARI: an augmented reality application that offers personalized and location-based recommendations of Point Of Interests based on sentiment analysis with geo-semantic query and reasoning. We present a mobile recommendation platform and application working on semantic technologies knowledge representation and query for geo-social data, and inductive and deductive stream reasoning, and the lesson learned in deploying BOTTARI in Insadong. We have been collecting and analyzing tweets for three years to rate the few hundreds of restaurants in the district. The results of our study show the commercial feasibility of BOTTARI.","Weak keys of the full MISTY1 block cipher for related-key differential cryptanalysisThe MISTY1 block cipher has a 64-bit block length, a 128-bit user key and a recommended number of 8 rounds. It is a Japanese CRYPTREC-recommended e-government cipher, a European NESSIE selected cipher, and an ISO international standard. Despite of considerable cryptanalytic efforts during the past fifteen years, there has been no published cryptanalytic attack on the full MISTY1 cipher algorithm. In this paper, we present a related-key differential attack on the full MISTY1 under certain weak key assumptions: We describe 2103.57 weak keys and a related-key differential attack on the full MISTY1 with a data complexity of 261 chosen ciphertexts and a time complexity of 290.93 encryptions. For the first time, our result exhibits a cryptographic weakness in the full MISTY1 cipher (when used with the recommended 8 rounds), and shows that the MISTY1 cipher is distinguishable from an ideal cipher and thus cannot be regarded to be an ideal cipher.","Improving Range Query Result Size Estimation Based on a New Optimal HistogramMany commercial relational Data Base Management Systems DBMSs maintain histograms to approximate the distribution of values in the relation attributes and based on them estimate query result sizes. A histogram approximates the distribution by grouping data into buckets. The estimation-errors resulting from the loss of information during the grouping process affect the accuracy of the decision, made by query optimizers, about choosing the most economical evaluation plan for a query. In front of this challenging problem, many histogram-based estimation techniques including the equi-depth, the v-optimal, the max-diff and the compressed histograms have well contributed to approximate the cost of a query evaluation plan. But, most of the times the obtained estimates have much error. Motivated by the fact that inaccurate estimations can lead to wrong decisions, we propose in this paper an efficient algorithm, called Compressed-V2, for accurate histogram constructions. Both theoretical and effective experiments are done using benchmark data set showing the promising results obtained using the proposed algorithm. We think that this algorithm will significantly contribute for helping to solve the problem of Multi-Query Optimization MQO resulting from queries interactions especially in Relational Data Warehouses RDW which represent the ideal environment in which complex OLAP queries interact with each other.","Finding Network Communities Using Random Walkers with Improved Accuracy ","Correlation-Immune Boolean Functions for Leakage Squeezing and Rotating S-Box Masking against Side Channel AttacksBoolean functions, from F2n to F2, have been playing an important role in stream ciphers, because they can be used in their pseudo-random generators to combine the outputs to several LFSR (in the so-called combiner model). Recall that the keystream (which is bitwise added to the plaintext for producing the ciphertext) is in such framework the sequence output by the function during a sufficient number of clock-cycles. The combiner Boolean function must then be balanced, that is, have uniform output distribution, for avoiding some straightforward distinguishing attack; and it should be correlation-immune of highest possible order. An n-variable Boolean function f (x1,...,xn) is correlation-immune of some order m&lt;n (in brief, m-CI) if fixing at most m of the n input variables x1,...,xn does not change the output distribution of the function, whatever are the positions chosen for the fixed variables and the values chosen for them (a balanced m-CI function is called m-resilient). Such m-th order correlation immunity allows resisting the Siegenthaler attack [15] at the order m ,w hich is a divide and conquer cryptanalysis using the existence of a correlation between the output to the function and m input bits xi1 ,...,xim ,t o make an exhaustive search of the initialization of the LFSRs of indices i1,...,im (given a sub-sequence of the keystream), without needing to know the initialization of the other LFSRs. The initialization of these other LFSRs can subsequently be recovered by diverse methods, allowing rebuilding the whole keystream. Of course, a correlation attack at the order m + 1 is possible if the function is not (m + 1)-CI, but the attacker needs then to know a longer part of the keystream for recovering the initialization of m + 1 LFSR in order to rebuild the rest of the keystream. The function must also have large algebraic degree for allowing resistance to the Berlekamp-Massey attack [12] and lie at large Hamming distance from affine functions, that is, have large nonlinearity, for allowing resistance to the fast correlation attack [13] and its variants.","Low-Level Music Feature Vectors Embedded as Watermarks ","Entity-Centric Search for Enterprise ServicesThe consumption of APIs, such as Enterprise Services ESs in an enterprise Service-Oriented Architecture eSOA, has largely been a task for experienced developers. With the rapidly growing number of such WebAPIs, users with little or no experience in a given API face the problem of finding relevant API operations --- e.g., mashups developers. However, building an effective search has been a challenge: Information Retrieval IR methods struggle with the brevity of text in API descriptions, whereas semantic search technologies require domain ontologies and formal queries. Motivated by the search behavior of users, we propose an iterative keyword search based on entities. The entities are part of a knowledge base, whose content stems from model-driven engineering. We implemented our approach and conducted a user study showing significant improvements in search effectiveness.","Optimization of Engineering Design Cycles in Enterprise IntegrationThe paper presents the concept of project life cycle optimization, which is based on the formalization of domain knowledge and decomposition of the controlled system into subsystems. The formalization of knowledge concerns each of the individual subsystems by describing its states and functions. Such an approach can greatly reduce costs and time, which is needed for multiple iterations during the project life cycle. This is because the formalization of knowledge simplifies modifications of the control system software and architecture, which means that there is no need to commence the designing process again. Moreover, owing to the presented approach, creation of ontology and more advanced control systems e.g. multiagent based algorithms are significantly shortened and simplified. The presented solution is currently being implemented in the designing process of a real micro-grid.","An XML-Based Policy Model for Access Control in Web Applications ","Characterization of Biomass Emissions and Potential Reduction in Small-Scale Pellet BoilerIn recent years it has been proved that residential biomass combus- tion has a direct influence on ambient air quality, especially in the case of cereals. The aim of this study is the characterization of the emissions in small- scale fixed-bed pellet boiler (heat output of 25 kW) of beech and corn, and of its potential reduction to an addition of calcium dihydroxide. In the biomass combustion test 7 fuel mixtures were investigated with regard to the particulate content (PM10), gaseous emissions and combustion chamber deposit. The corn kernels tanned with calcium dihydroxide determined a decrease in particulate emissions (54\u00b113 mg MJ -1 ) in comparison to corn, whereas in the combustion of corn pellet with 1% calcium dihydroxide high emissions were observed (193\u00b121 mg MJ -1 ). With regard to SO2 emissions, the combustion of corn with the additives make a reduction in comparison to additive-free corn.","A Fault Injection Based Approach to Assessment of Quality of Test Sets for BPEL ProcessesMutation testing is an effective technique for assessing a quality of test sets for software systems, but it suffers from high computational costs of generating and executing a large number of mutants. In the domain of BPEL processes each mutant needs to be deployed before it can be executed, thus the cost of processing mutants increases further. In contrast to mutation testing, fault injection is able to inject faults directly into the original process what re- duces the redeployment requirement. The paper presents an experiment of the application of software fault injection to assess quality of test sets for BPEL processes. Faults are introduced by a Software Fault Injector for BPEL Processes (SFIBP). SFIBP simulates effects of the faults by modifying invoca- tions of web-services and their internal variables. The experiment proved high superiority of the application of the SFIBP over the mutation testing, especially in the case of time requirements.","Multi Agent Reinforcement Learning for Gridworld Soccer LeadingpassSoccer robotics is an emerging field that combines artificial intelligence and mobile robotics with the popular sport of soccer. Robotic soccer agents need to cooperate to complete tasks or subtasks, one way is by learning to coordinate their action. Leadingpass is considered as a task that had to be performed successfully by the team, or opponent could intercept the ball that leads the team to lose the game. This paper describes how Reinforcement Learning (RL) methods are applied to the learning scenario, that the learning agents cooperatively complete the leadingpass task in the Gridworld soccer environment. Not only RL algorithms for single agent case, but also for multi agent case.","Surface Area Under the Motion Curve as a New Tool for Gait RecognitionThe main goal of Motion Capture based modeling is to understand the essence of human gait phenomenon. Actually the follow- ing methods can propose to recognize gaits: The Dynamic Time Warping. method is based on dynamic programming and is widely used for differ- ent time-series comparison applications (like voice recognition. Spectrum analysis of the motion signal leads to interesting results concerning per- son identification The proposed method for gait recognition that uses var- ious techniques of comparing the surface areas under the motion curves offers very accurate results. One of the most challenging problems in markerless motion capture, but offering a widespread application poten- tial is that of estimation of body pose from single video sequence.","The Influence of Context Knowledge for Multi-modal Affective Annotation ","Collaboration of Thin-Thick Clients for Optimizing Data Distribution and Resource Allocation in Cloud Computing ","Heterogeneous Computing vs. Big Data: The Case of Cryptanalytical ApplicationsThis work discusses the key opportunities introduced by Heterogeneous Computing for large-scale processing in the security and cryptography domain. Addressing the cryptanalysis of SHA-1 as a case-study, the paper analyzes and compares three different approaches based on Heterogeneous Computing, namely a hybrid multi-core platform, a computing facility based on a GPU architecture, and a custom hardware-accelerated platform based on reconfigurable devices. The case-study application provides important insights into the potential of the emerging Heterogeneous Computing trends, enabling unprecedented levels of computing power per used resource.","Efficient subsequence search in databasesFinding tuples in a database that match a particular subsequence (with gaps) is an important problem for a range of applications. Subsequence search is equivalent to searching for regular expressions of the type.* q1.* q2.* \u2026.* ql.*, where the subsequence is q1q2 \u2026ql. For efficient execution of these queries, there is a need for appropriate index structures that are both efficient and can scale to large problem sizes. This paper presents two index structures for such queries based on trie and bitmap. These indices are disk-resident, hence can be easily used by large databases with limited memory availability. Our indices are applicable to dynamic databases, where tuples can be added or deleted. Both indices are implemented and validated against a naive approach. The results show that the proposed indices are efficient, having low I/O and time overhead.","Smart hashing update for fast responseRecent years have witnessed the growing popularity of hash function learning for large-scale data search. Although most existing hashing-based methods have been proven to obtain high accuracy, they are regarded as passive hashing and assume that the labelled points are provided in advance. In this paper, we consider updating a hashing model upon gradually increased labelled data in a fast response to users, called smart hashing update (SHU). In order to get a fast response to users, SHU aims to select a small set of hash functions to relearn and only updates the corresponding hash bits of all data points. More specifically, we put forward two selection methods for performing efficient and effective update. In order to reduce the response time for acquiring a stable hashing algorithm, we also propose an accelerated method in order to further reduce interactions between users and the computer. We evaluate our proposals on two benchmark data sets. Our experimental results show it is not necessary to update all hash bits in order to adapt the model to new input data, and meanwhile we obtain better or similar performance without sacrificing much accuracy against the batch mode update.","Modeling and specification of real-time interfaces with UTPInterface modeling and specification are central issues of component-based software engineering. How a component will be used is specified in its interface. Real-time interfaces are interfaces with timing constraints relating the time of outputs with the time of inputs. The timing constraint of an interface may depend on the resource availability for the component. In this paper, we propose a general model for real-time interfaces. At a time during execution, an interface behaves according to a contract made with environment about its functionality as well as execution time to fulfill the contract. This contract is specified as a timed design using the UTP notations, and depends on the computation histories of the interface. We model this dependence as a partial function from computation histories of the interface to real-time contracts. How interfaces are composed to form new interfaces, how interfaces are refined, and how to represent interfaces finitely are also considered in this paper. We show that checking the consistency between an environment and an interface and checking the refinement between two interfaces when they are represented by an automaton can be done effectively.","Integrating the Palladio-Bench into the Software Development Process of a SOA ProjectThis paper presents how the performance modeling capabilities of the Palladio-Bench are integrated into the development process of new enterprise appli- cations based on a service-oriented architecture (SOA). The Palladio-Bench is used to predict the performance of applications early in the software development process. To better integrate the Palladio-Bench into this process, an automated transformation of existing software models into Palladio Component Models (PCM) is implemented. These software models contain the business processes represented in the new applica- tions and implementation details such as web services used within the processes. The performance of the modeled applications is mainly influenced by the response times of the web services. Therefore, the web service response time behavior is modeled us- ing software performance curves, which are automatically generated using monitoring data collected during software tests or in the production environment. Several inte- gration tools are developed to support this feedback loop between the different phases of a software life cycle. Besides these integration capabilities, the challenges of using PCM within this project are discussed and future enhancements for the Palladio-Bench itself are proposed.","The Solid Angle of Light Sources and Its Impact on the Suppression of Melatonin in HumansOur group conducted a preliminary study to examine the influence of different sizes of light sources, and therefore different illuminance levels, at the retina. Six participants were exposed to two lighting scenarios and saliva samples were collected to determine melatonin levels throughout the experiment. Melatonin levels were analyzed to compare the efficacy of each lighting scenario and its ability to suppress melatonin period. Our data is showing a trend that both lighting scenarios are capable of suppressing melatonin. Moreover, the preliminary data show that the lighting scenario with the large solid angle is more effective at suppressing melatonin compared to the lighting scenario with the small solid angle lighting scenario period. Further testing with a larger patient population will need to be done to prove statistical significance of our findings. Our further studies will repeat this experiment with a larger test group and modifying the time frame between different lighting scenarios period.","Exploring Early Warning Signs Of Failure In Offshore-Outsourced Software Development Projects At The Team Level ","Making sense of participation in cultural activities for childrenIntroduction. This paper investigates participatory practices in library activities for young children and their care-givers in a specific cultural context. Method. Using an ethnographic approach data were collected through participant observations of songtimes for babies and toddlers, and interviews and group interviews with staff and care-givers. Analysis. With a theoretical departure point in communities of practice the data were analysed by searching for themes and connections to cultural contexts. Trustworthiness was ensured through triangulation: observations of children\u2019s activities were related to the interpretations of care-givers\u2019 through interviews; member checking through feedback from adult participants; and, ongoing discussions of interpretations between the researchers. Results. The study's findings show how library activities for children can serve as spaces where both a community of practice focused on \u201cmothering\u201d can develop as well as special child communities of practice. Participation is identified as work involving children, adults and professionals in interaction with place and promoted by a view of place as dynamic rather than static. Conclusions. We conclude that participatory practices in library activities for young children are situated and co-evolve through intergenerational dialogue; they are also partial and ongoing. By promoting intercultural dialogue, library activities for young children may become more socially inclusive.","SIAM: social interaction analysis for multimediaThis paper describes the SIAM demonstrator, a system that illustrates the usefulness of indexing multimedia segments thanks to associated microblog posts. From a socialized multimedia content (i.e. video and associated microblog posts on Twitter), the system applies text mining techniques and derives a topic model to index socialized multimedia segments. That result may then be used inside many multimedia applications, such as in-media social navigation, multimedia summarization or composition, or exploration of multimedia collections according to various socially-based viewpoints.","Low-resolution image restoration using the combination method of sparse representation and PDE modelThe stable solutions of traditional partial differential equations (PDE) can cause obvious step effects when PDEs are utilized to restore low-resolution images, and the quality of images restored is hardly worse. To solve this problem above-mentioned, a new low-resolution image restoration method, based on the combination method of sparse representation and PDE model based on an enhanced total variation model (ETVM), is proposed in this paper. The dictionary of sparse representation of images is learned by using the K-means based singular value decomposition (K-SVD) algorithm. For images with large noise variance or low-resolution, K-SVD has better denoising robustness. The guiding ideology of low-resolution image restoration is that the K-SVD algorithm is used first to reduce unknown noise existed in low-resolution images, and then the PDE model based on total variation (TV) are utilized to restore the results denoised obtained by K-SVD. In test, a human-made and a real low-resolution image, called millimeter wave (MMW) image, are respectively used to testify our method proposed. Further, compared it with algorithms of K-SVD and PDE, at the same time, the pick signal noise ratio (PSNR) criterion is used to measure restored human-made low-resolution images. Considering different noise variance for a human-made low-resolution image, and in terms of PSNR values and the vision effect of restored images, simulation results show that our method proposed here can efficiently restore low-resolution images, and behave certain theory meaning and practicality.","Supporting and Consulting Infrastructure for Educators during Distance Learning Process: The Case of Russian Verbs of Motion ","Improvement the Bag of Words Image Representation Using Spatial Information ","Data Clustering with Differential Evolution Incorporating MacromutationsData clustering is one of the fundamental tools in data mining and requires the grouping of a dataset into a specified number of nonempty and disjoint subsets. Beside the usual partitional and hierarchical methods, evolutionary algorithms are employed for clustering as well. They are able to find good quality partitions of the dataset and successfully solve some of the shortcomings that the k-means, being one of the most popular partitional algorithms, exhibits. This paper proposes a differential evolution algorithm that includes macromutations as an additional exploration mechanism. The application probability and the intensity of the macromutations are dynamically adjusted during runtime. The proposed algorithm was compared to four variants of differential evolution and one particle swarm optimization algorithm. The experimental analysis conducted on a number of real datasets showed that the proposed algorithm is stable and manages to find high quality solutions.","Robust Feature for Transcranial Sonography Image Classification Using Rotation-Invariant Gabor Filter ","Data reduction for continuum of care: an exploratory study using the predicate-argument structure to pre-process radiology sentences for measurement of semantic similarityIn the clinical setting, continuum of care depends on integrated information services to assure a smooth progression for patient centered care, and these integrated information services must understand past events and personal circumstances to make care relevant. Clinicians face a problem that the amount of information produced in disparate electronic clinical notes is increasing to levels incapable of being processed by humans. Clinicians need a function in information services that can reduce the free text data to a message useful at time of care. Information extraction (IE) is a sub-field of natural language processing with the goal of data reduction of unstructured free text. Pertinent to IE is an annotated corpus that frames how IE methods should create a logical expression necessary for processing meaning of text. This study explores and reports on the requirements to using the predicate-argument statement (PAS) as the framework. A convenient sample from a prior study with ten synsets of 100 unique sentences from radiology reports deemed by domain experts to mean the same thing will be the text from which PAS structures are formed. Through content analysis of pattern recognition, findings show PAS is a feasible framework to structure sentences for semantic similarity measurement.","Datasets for the Evaluation of Substitution-Tolerant Subgraph IsomorphismDue to their representative power, structural de-scriptions have gained a great interest in the community working on graphics recognition. Indeed, graph based representations have successful been used for isolated symbol recognition. New challenges in this research field have focused on symbol recog-nition, symbol spotting or symbol based indexing of technical drawing. When they are based on structural descriptions, these tasks can be expressed by means of a subgraph isomorphism search. Indeed, in consists in locating the instance of a pattern graph representing a symbol in a target graph representing the whole document image. However, there is a lack of publicly available datasets allowing to evaluate the performance of subgraph iso-morphism approaches in presence of noisy data. In this paper, we present three datasets that can be used to evaluate the performance of algorithms on several tasks involving subgraph isomorphism. Two of these datasets have been synthetically generated and allow to evaluate the search of a single instance of the pattern with or without perturbed labels. The third dataset corresponds to the structural description of architectural plans and allows to evaluate the search of multiple occurrences of the pattern. These datasets are made available for download. We also propose several measures to qualify each of the tasks.","A New, Fast and Accurate Algorithm for Hierarchical Clustering on Euclidean DistancesA simple hierarchical clustering algorithm called CLUBS (for CLus- tering Using Binary Splitting) is proposed. CLUBS is faster and more accurate than existing algorithms, including k-means and its recently proposed refine- ments. The algorithm consists of a divisive phase and an agglomerative phase; during these two phases, the samples are repartitioned using a least quadratic dis- tance criterion possessing unique analytical properties that we exploit to achieve a very fast computation. CLUBS derives good clusters without requiring input from users, and it is robust and impervious to noise, while providing better speed and accuracy than methods, such as BIRCH, that are endowed with the same critical properties.","PoliSpell: An Adaptive Spellchecker and Predictor for People with DyslexiaPeople with dyslexia often face huge writing difficulties. Spellcheckers/predictors can help, but the current systems are not ap- propriate for them, because of the assumptions behind the models and because of heavy-to-use interfaces. This paper presents a system for spellchecking/predicting words, which can adapt both its model and its interface according to the individual behavior. The model takes into ac- count typical errors made by people with dyslexia, such as boundary er- rors, and the context for correcting real-word errors. The interface aims at reducing interaction with the user. The model and the interface are easily adaptable to general use.","A Modelling Approach to Support Enterprise Architecture Interoperability ","Unified Taxonomy for Reference Ontology of Shape Features in Product Model ","Deterministic and stochastic analysis of distributed order systems using operational matrixThe fractional order system, which is described by the fractional order derivative and integral, has been studied in many engineering areas. Recently, the concept of fractional order has been generalized to the distributed order concept, which is a parallel connection of fractional order integrals and derivatives taken to the infinitesimal limit in delta order. On the other hand, there are very few numerical methods available for the analysis of distributed order systems, particularly under stochastic forcing. This paper first proposes a numerical scheme for analyzing the behavior of a SISO linear system with a single term distributed order differentiator/integrator using an operational matrix in the time domain under both deterministic and random forcing. To assess the stochastic distributed order system, the existing Monte-Carlo, polynomial chaos and frequency methods are first adopted to the stochastic distributed order system for comparison. The numerical examples demonstrate the accuracy and computational efficiency of the proposed method for analyzing stochastic distributed order systems.","A dependency-sharing tool for global software engineeringThis project explores the design of a tool to facilitate a common task that software engineers find difficult --- the identification and management of dependencies between the many heterogeneous entities created in the course of a software development project. The focus of this tool is the value it might have during the maintenance phase. Maintenance engineers learn and understand the project differently from the original authors of the artifacts. Typically, they come to understand the project by investigating dependencies between entities- a task that can be very difficult and time-consuming. To deal with these differences, the Global Software Traceability (GST) Tool was designed and prototyped to explore improvements in the usability of maintaining dependency links after the project has been deployed. The GST Tool is a proof-of-concept design prototype used to investigate how to make such a tool both useful and usable. The tool was successful in creating an environment whose overhead was low enough to make it likely that it would be used despite the severe time constraints found in software maintenance.","VeriFast for java: a tutorialVeriFast is a separation logic-based program verifier for Java. This tutorial introduces the verifier's features step by step.","Modified Merge Sort Algorithm for Large Scale Data Sets ","Explicit-State software model checking based on CEGAR and interpolationAbstraction, counterexample-guided refinement, and interpolation are techniques that are essential to the success of predicate-based program analysis. These techniques have not yet been applied together to explicit-value program analysis. We present an approach that integrates abstraction and interpolationbased refinement into an explicit-value analysis, i.e., a program analysis that tracks explicit values for a specified set of variables (the precision). The algorithm uses an abstract reachability graph as central data structure and a path-sensitive dynamic approach for precision adjustment. We evaluate our algorithm on the benchmark set of the Competition on Software Verification 2012 (SV-COMP'12) to show that our new approach is highly competitive. We also show that combining our new approach with an auxiliary predicate analysis scores significantly higher than the SV-COMP'12 winner.","Beyond current guided bronchoscopy: a robust and real-time bronchoscopic ultrasound navigation system. ","Partial imitation hinders emergence of cooperation in the iterated prisoner's dilemma with direct reciprocityThe evolutionary time scales for various strategies in the iterated Prisoner's Dilemma on a fully connected network are investigated for players with finite memory, using two different kinds of imitation rules: the (commonly used) traditional imitation rule where the entire meta-strategy of the role model is copied, and the partial imitation rule where only the observed subset of moves is copied. If the players can memorize the last round of the game, a sufficiently large random initial population eventually reaches a cooperative equilibrium, even in an environment with bounded rationality (noise) and high temptation. With the traditional imitation rule the time scale to cooperation increases linearly with decreasing intensity of selection (or increasing noise) in the weak selection regime, whereas partial imitation results in an exponential dependence. Populations with finite lifetimes are therefore unlikely to ever reach a cooperative state in this setting. Instead, numerical experiments show the emergence and long persistence of a phase characterized by the dominance of always defecting strategies.","How to adapt applications for the Cloud environment Challenges and solutions in migrating applications to the CloudThe migration of existing applications to the Cloud requires adapting them to a new computing paradigm. Existing works have focused on migrating the whole application stack by means of virtualization and deployment on the Cloud, delegating the required adaptation effort to the level of resource management. With the proliferation of Cloud services allowing for more flexibility and better control over the application migration, the migration of individual application layers, or even individual architectural components to the Cloud, becomes possible. Towards this goal, in this work we focus on the challenges and solutions for each layer when migrating different parts of the application to the Cloud. We categorize different migration types and identify the potential impact and adaptation needs for each of these types on the application layers based on an exhaustive survey of the State of the Art. We also investigate various cross-cutting concerns that need to be considered for the migration of the application, and position them with respect to the identified migration types. Finally, we present some of the open research issues in the field and position our future work targeting these research questions.","EvAAL: Evaluating AAL Systems through Competitive BenchmarkingOwing to the complexity of Ambient Assisted Living (AAL) systems and platforms, the evaluation of AAL solutions is a complex task that will challenge researchers for years to come. However, the analysis and comparison of proposed solutions is paramount to enable us to assess research results in this area. We have thus organized an international contest called EvAAL: Evaluating AAL Systems through Competitive Benchmarking. Its aims are to raise interest within the research and developer communities in the multidisciplinary research fields enabling AAL, and to create benchmarks for the evaluation and comparison of AAL systems.","Making massive probabilistic databases practicalExistence of incomplete and imprecise data has moved the database paradigm from deterministic to proba- babilistic information. Probabilistic databases contain tuples that may or may not exist with some probability. As a result, the number of possible deterministic database instances that can be observed from a probabilistic database grows exponentially with the number of probabilistic tuples. In this paper, we consider the problem of answering both aggregate and non-aggregate queries on massive probabilistic databases. We adopt the tuple independence model, in which each tuple is assigned a probability value. We develop a method that exploits Probability Generating Functions (PGF) to answer such queries efficiently. Our method maintains a polynomial for each tuple. It incrementally builds a master polynomial that expresses the distribution of the possible result values precisely. We also develop an approximation method that finds the distribution of the result value with negligible errors. Our experiments suggest that our methods are orders of magnitude faster than the most recent systems that answer such queries, including MayBMS and SPROUT. In our experiments, we were able to scale up to several terabytes of data on TPC- H queries, while existing methods could only run for a few gigabytes of data on the same queries.","Software architects' experiences of quality requirements: what we know and what we do not know?[Context/motivation] Quality requirements (QRs) are a concern of both requirement engineering (RE) specialists and software architects (SAs). However, the majority of empirical studies on QRs take the RE analysts'/clients' perspectives, and only recently very few included the SAs' perspective. As a result, (i) relatively little is known about SAs' involvement in QRs engineering and their coping strategies, and (ii) whatever is known mostly comes from small and midsized projects. [Question/problem] The question in this exploratory study is how SAs cope with QRs in the context of large and contract-based software system delivery projects. [Principal ideas/results] We executed an exploratory case study with 20 SAs in the context of interest. The key results indicate the role SAs play in QRs engineering, the type of requirements communication processes SAs are involved in, the ways QRs are discovered, documented, quantified, validated and negotiated. Our most important findings are that in contract-based contexts: (1) the QRs are approached with the same due diligence as the functional requirements and the architecture design demand, (2) the SAs act proactively and embrace responsibilities over the QRs, (3) willingness to pay and affordability seem as important QRs prioritization criteria as cost and benefits do, and (4) QRs engineering is perceived as a social activity and not as much as a tool and method centric activity. [Contribution] The main contributions of the paper are (i) the explication of the QRs process from SAs' perspective, and (ii) the comparison of our findings with previously published results.","Nudging People Away from Privacy-Invasive Mobile Apps through Visual FramingSmartphone users visit application marketplaces (or app stores) to search and install applications. However, these app stores are not free from privacy-invasive apps, which collect personal information without sufficient disclosure or people\u2019s consent. To nudge people away from privacy-invasive apps, we created a visual representation of the mobile app\u2019s privacy rating. Inspired by \u201cFraming Effects,\u201d we designed semantically equivalent visuals that are framed in either a positive or negative way. We investigated the effect of the visual privacy rating, framing, and user rating on people\u2019s perception of an app (e.g., trustworthiness) through two experiments. In Study 1, participants were able to understand the intended meaning of the visual privacy ratings. In Study 2, we found a strong main effect for visual privacy rating on participants\u2019 perception of an app, and framing effects in a low privacy rating app. We discuss implications for designing visual privacy ratings, including the use of positive visual framing to nudge people away from privacy-invasive apps.","Cocaine Dependent Classification on MRI Data Extracting Features from Voxel Based MorphometryIn this paper, we present a method to discriminate cocaine dependent patients and healthy subjects using features computed from structural magnetic resonance imaging (MRI). After image preprocess- ing, we compute voxel based morphometry (VBM) applying Gaussian smoothing with three different full width at half maximum (FWHM) kernel sizes. VBM clusters guide the feature extraction process used to classify subjects as cocaine dependent patients or healthy controls. We apply five well known classifiers from the WEKA platform. Classifica- tion results are good reaching accuracy, sensitivity and specificity values above 90%. It is possible to apreciate that as the smoothing kernel size grows, the features are less discriminative, but the VBM clusters iden- tifying differences between both groups are bigger. We also obtain the location in the brain of the features selected and compare them with findings in the literature.","Improving communication of visual signals by text-to-speech softwarePrinted signals are well-documented aids to reading and memory for expository text. Despite their usefulness, many TTS applications fail to adequately communicate signaling. A theoretical framework called \"SARA\" provides an analysis of printed signals that identifies what specific information should be rendered in order to preserve the signaling function. Further, SARA identifies two important criteria --- the availability criterion and the accessibility criterion --- that should help guide the evaluation of alternative auditory renderings of signals.","Cooperating Objects Design Space and Markets. ","Information Security Investments: When Being Idle Equals NegligenceThe Learned Hand's rule, comparing security investments against the expected loss from data breaches, can be used as a simple tool to determine the negligence of the company holding the data. On the other hand, companies may determine their investments in security by maximizing their own net profit. We consider the well known Gordon-Loeb models as well as the more recent Huang-Behara models for the relationship between investments and the probability of money loss due to malicious attacks to determine the outcome of the application of three forms of Hand's rule: status quo (loss under no investments), ex-post (loss after investment), transitional (loss reduction due to investment). The company is always held negligent if it does not invest in both the status quo and the transitional form. In the ex-post form, it is instead held negligent just if the potential loss is below a threshold, for which we provide the exact expression.","Multi-cell Interaction Tracking Algorithm for Colliding and Dividing Cell Dynamic Analysis ","Mean Shift with Flatness ConstraintsMean shift still belongs to the intensively developed image- segmentation methods. Appropriately setting so called bandwidth, which is richly discussed in literature, seems to be one of its problems. If the bandwidth is too small, the results suffer from over-segmentation. If it is too big, the edges need not be preserved sufficiently and the details can be lost. In this paper, we address the problem of over-segmentation and preserving the edges in mean shift too. However, we do not aim at proposing a further method for determining the bandwidth. Instead, we modify the mean-shift method itself. We show that the problems with over-segmentation are inherent for mean shift and follow from its theoretical essence. We also show that the mean-shift process can be seen as a process of solving a certain Euler-Lagrange equation and as a process of maximising a certain functional. In contrast with other known functional approaches, however, only the fidelity term is present in it. Other usual terms, e.g., the term requiring a short length of boundaries between the segments or the term requiring the flatness (in intensity) of the corresponding filtered image are not present, which explains the behaviour of mean shift. On the basis of this knowledge, we solve the problems with mean shift by modifying the functional. We show how the new functional can be maximised in practice, and we also show that the usual mean-shift algorithm can be regarded as a special case of the method we propose. The experimental results are also presented.","Designing an agent based model for the efficient removal of red imported fire ant coloniesRed imported fire ants have proven to be a bane of the existence of many individuals in the southern United States. Defining methodologies for prevention, removal, and destruction of these invasive insects continues to be difficult due to their highly developed survival instincts. Multiple methods and processes exist to force the destruction of red imported fire ants yet their sheer numbers and ability to return to previously cleared spaces defines a need for greater understanding of the ant-to-ant interaction within these beds. The primary purpose of this research is to design a working model of a red imported fire ant bed that can be improved upon by interactions with the University of Texas at Tyler biology department. To meet this goal an understanding of agent-based models is first needed. Agent-based models (ABM) have the ability to generate complex behavior using easily understandable rules that can be altered by an individual with less knowledge of the computing process and more involvement in the system process. Another benefit of these models is their highly parallelized nature leading to other technological research routes to speed up the processes and create more cross discipline projects. Based on the ABM's highly parallelized nature, implementing this model on a system that can harness the low cost parallel processing environments of general purpose graphics processors and multicore CPUs is our ultimate goal. This paper outlines our initial steps in defining the model and designing a system that works effectively at a small scale on a sequential environment. Our future plans to port this model to a parallel processing environment are also detailed.","Information-Based Learning of Deep Architectures for Feature Extraction ","Sources of Power and CIO Influence and Their Impact: An Explorative Survey ","Parallel rendering of human-computer interaction industrial applications on multi-/many-core platformsIndustrial Human Computer Interaction (Industrial HCI) devices are beginning the transition from single-core to multi-/many-core technology. In practice, improving the real-time response time of graphical user interface (GUI) applications in multi-/many-core is difficult. This paper presents a novel parallel rendering approach targeted to improve the performance of Industrial HCI applications in multi-/many-core technology. This is accomplished through the identification of coarse-grain parallelism during the application design, and the exploitation of fine-grain parallelism during runtime using a dynamic scheduling algorithm and true parallel execution of GUI workloads. Using a real benchmark application, we show that response time can be reduce by up to 217% in a quad-core processor.","Adaptive Contention Window for Zone-Based Dissemination of Vehicular TrafficInter-Vehicular Communication (IVC) is very promising for advanced applications in traffic systems. However, current efforts and im- plementations still require more attention in order to turn such applications into reality. The data dissemination and the vehicular com- munication are two key concerns in order to make more feasible alter- native traffic information systems. In this paper we focus on the traffic data dissemination and the inter-vehicle communication applied to our traffic guidance architecture presented in (5). We present a twofold pro- posal: a mechanism for V2I, V2V traffic data dissemination and a simple but efficient mechanism to enhance broadcast communication. We show through extensive evaluations that our composite solution tends to be efficient under the design of our specific application guidelines.","Formal pattern specifications to facilitate semi-automated user interface generationThis paper depicts potentialities of formal HCI pattern specifications with regard to facilitate the semi-automated generation of user interfaces for interactive applications. In a first step existing proven and well accepted techniques in the field of model-based user interface development are highlighted and briefly reviewed. Subsequently it is discussed how we combine model-based and pattern-oriented methods within our user interface modeling and development framework in order to partly enable automated user interface generation. In this context a concrete pattern definition approach is introduced and illustrated with tangible examples from the domain of interactive knowledge sharing applications.","\"Comply or die\" is dead: Long live security-aware principal agentsInformation security has adapted to the modern collaborative organisational nature, and abandoned \"command-and-control\" approaches of the past. But when it comes to managing employee's information security behaviour, many organisations still use policies proscribing behaviour and sanctioning non-compliance. Whilst many organisations are aware that this \"comply or die\" approach does not work for modern enterprises where employees collaborate, share, and show initiative, they do not have an alternative approach to fostering secure behaviour. We present an interview analysis of 126 employees' reasons for not complying with organisational policies, identifying the perceived conflict of security with productive activities as the key driver for non-compliance and confirm the results using a survey of 1256 employees. We conclude that effective problem detection and security measure adaptation needs to be de-centralised - employees are the principal agents who must decide how to implement security in specific contexts. But this requires a higher level of security awareness and skills than most employees currently have. Any campaign aimed at security behaviour needs to transform employee's perception of their role in security, transforming them to security-aware principal agents.","Moderating Effect of Culture on IT and Health Standard: A Country-Level Analysis ","Training Neural Networks with Implicit VarianceWe present a novel method to train predictive Gaussian distributions pz|x for regression problems with neural networks. While most approaches either ignore or explicitly model the variance as another response variable, it is trained implicitly in our case. Establishing stochasticty by the injection of noise into the input and hidden units, the outputs are approximated with a Gaussian distribution by the forward propagation method introduced for fast dropout [1]. We have designed our method to respect that probabilistic interpretation of the output units in the loss function. The method is evaluated on a synthetic and a inverse robot dynamics task, yielding superior performance to plain neural networks, Gaussian processes and LWPR in terms of likelihood.","RoboCup 2012 Rescue Simulation League WinnersInside the RoboCup Rescue Simulation League, the mission is to use robots to rescue as many victims as possible after a disaster. The research challenge is to let the robots cooperate as a team. This year in total 15 teams from 8 different countries have been active in the competition. This paper highlights the approaches of the winners of the virtual robot competition, the infrastructure com- petition, and the agent competition.","Towards Hybrid Honeynets via Virtual Machine Introspection and Cloning ","Cognitive Principles to Support Information Requirements AgilityDespite the growing interest in agile information systems develop- ment approaches, we contend that existing approaches retain traditional assumptions about the structure of information, assumptions that inhibit agile responses to emerging and evolving information requirements. We suggest an approach, based on cognitive principles, to model information requirements by separating conceptual views of data from logical models, allowing the former to be changed without requiring changes to the latter.","A Platform for Citizen Sensing in Sentient CitiesThis work develops upon the concepts of Sentient City -l iving in a city that can remember, correlate, and anticipate - and Citizen Sensor Networks. We aim at technologies to interconnect people, allowing them to actively observe, report, collect, analyse, and disseminate information about urban events. We are investigating new methods and technologies to enhance administrators' capabil- ities in urban planning and management. We are proposing a platform to instru- ment citizens and cities, interconnect parties, analyse related events, and provide recommendation and feedback reports. The solution encompasses four types of elements: (i) mobile applications for intentional and non-intentional reporting of events; (ii) enhanced analytic models to centralize information, analyse the data, identify trends and operation patterns, and provide insightful information to de- cision makers; (iii) advanced social simulations to anticipate \"what if\" scenarios for infrastructure planning; and (iv) interfaces for monitoring, feedback, and rec- ommendation. This research builds upon the IBM Smarter Cities project, part of the IBM Smarter Planet program. The outcomes of this research yield signifi- cant social contributions. By using it, administrators can make reliable decisions that will impact social services, traffic, energy and utilities, public safety, retail, communications, and economic development.","Learning Movement Kinematics with a Targeted SoundThis study introduces an experiment designed to analyze the sensorimotor adaptation to a motion-based sound synthesis system. We investigated a sound-oriented learning task, namely to reproduce a tar- geted sound. The motion of a small handheld object was used to control a sound synthesizer. The object angular velocity was measured by a gy- roscope and transmitted in real time wirelessly to the sound system. The targeted sound was reached when the motion matched a given refer- ence angular velocity profile with a given accuracy. An incorrect velocity profile produced either a noisier sound or a sound with a louder high har- monic, depending on the sign of the velocity error. The results showed that the participants were generally able to learn to reproduce sounds very close to the targeted sound. A corresponding motor adaptation was also found to occur, at various degrees, in most of the participants when the profile is altered.","Collaborative Tracking: Dynamically Fusing Short-Term Trackers and Long-Term DetectorThis paper addresses the problem of long-term tracking of unknown objects in a video stream given its location in the first frame and without any other information. It's very challenging because of the existence of several factors such as frame cuts, sudden appearance changes and long-lasting occlusions etc. We propose a novel collaborative tracking framework fusing short-term trackers and long-term object detector. The short-term trackers consist of a frame-to-frame tracker and a weakly supervised tracker which would be updated under the weakly supervised information and re-initialized by long-term detector while the trackers fail. Additionally, the short-term trackers would provide multiple instance samples on the object trajectory for training a long-term detector with the bag samples with P-N constraints. Comprehensive experiments and comparisons demonstrate that our approaches achieve better performance than the state-of-the-art methods.","Edge- and detail-preserving sparse image representations for deformable registration of chest MRI and CT volumesDeformable medical image registration requires the optimisation of a function with a large number of degrees of freedom. Commonly-used approaches to reduce the computational complexity, such as uniform B-splines and Gaussian image pyramids, introduce translation-invariant homogeneous smoothing, and may lead to less accurate registration in particular for motion fields with discontinuities. This paper introduces the concept of sparse image representation based on supervoxels, which are edge-preserving and therefore enable accurate modelling of sliding organ motions frequently seen in respiratory and cardiac scans. Previous shortcomings of using supervoxels in motion estimation, in particular inconsistent clustering in ambiguous regions, are overcome by employing multiple layers of supervoxels. Furthermore, we propose a new similarity criterion based on a binary shape representation of supervoxels, which improves the accuracy of single-modal registration and enables multi-modal registration. We validate our findings based on the registration of two challenging clinical applications of volumetric deformable registration: motion estimation between inhale and exhale phase of CT scans for radiotherapy planning, and deformable multi-modal registration of diagnostic MRI and CT chest scans. The experiments demonstrate state-of-the-art registration accuracy, and require no additional anatomical knowledge with greatly reduced computational complexity.","An Adaptive Mitigation Framework for Handling Suspicious Network Flows via MPLS PoliciesAs network attacks become more complex, defence strategies must provide means to handle more flexible and dynamic requirements. The Multiprotocol Label Switching MPLS standard is a promising method to properly handle suspicious flows participating in such network attacks. Tasks such as alert data extraction, and MPLS routers configuration present an entailment to activate the defence process. This paper introduces a novel framework to define, generate and implement mitigation policies on MPLS routers. The activation of such policies is triggered by the alerts and expressed using a high level formalism. An implementation of the approach is presented.","Property-Testing in Sparse Directed Graphs: 3-Star-Freeness and ConnectivityWe study property testing in directed graphs in the bounded degree model, where we assume that an algorithm may only query the outgoing edges of a vertex, a model proposed by Bender and Ron in 2002. As our first main result, we we present a property testing algorithm for strong connectivity in this model, having a query complexity of $\\mathcal{O}(n^{1-\\epsilon/(3+\\alpha)})$ for arbitrary $\\alpha&gt;0$; it is based on a reduction to estimating the vertex indegree distribution. For subgraph-freeness we give a property testing algorithm with a query complexity of $\\mathcal{O}(n^{1-1/k})$, where $k$ is the number of connected componentes in the queried subgraph which have no incoming edge. We furthermore take a look at the problem of testing whether a weakly connected graph contains vertices with a degree of least $3$, which can be viewed as testing for freeness of all orientations of $3$-stars; as our second main result, we show that this property can be tested with a query complexity of $\\mathcal{O}(\\sqrt{n})$ instead of, what would be expected, $\\Omega(n^{2/3})$.","Explicit and Implicit Knowledge in Neighbourhood ModelsUnder relational models, epistemic logic agents are logically omniscient. A common strategy to avoid this has been to distinguish between implicit and explicit knowledge, and approaches based on relational models have used implicit knowledge as a primitive, defining explicit knowledge as implicit knowledge that satisfies some additional requirement. In this work we follow the opposite direction: using neighbourhood models, we take explicit knowledge as a primitive, then defining implicit knowledge as what the agent will know explicitly in an 'ideal' state. This approach, though natural, does not satisfy two 'intuitive' properties: explicit knowledge does not need to be implicit, and the consequent of an explicitly known implication with explicitly known antecedent does not need to be implicitly known; we discuss why this is the case. Then a modus ponens operation is defined, and it is shown how it satisfies a third 'intuitive' property: if the agent knows explicitly an implication and its antecedent, then after a modus ponens step she will know explicitly the consequent.","EEG feature selection based on time series classificationWe propose novel method of EEG signal analysis based on classification of feature time series. The algorithm classifies sequences of feature values and it calculates the error rate both for each time step and overall sequence. We compared the performance of the algorithm with a standard feature selection method based on forward inter-intra criterion. Both algorithms selected similar features. The algorithm was tested on the EEG data from 2 experiments focused on of spatial navigation and orientation. Participants traversed through the virtual tunnels and they could adopt two different reference frames (allocenctric and egocentric) to solve the task. The EEG signal was recorded within both tasks and the methods of feature extraction and both standard and timeseries selection and classification were applied to it. We identified differences between the groups of participants adopting allocentric and egocentric frames of reference in the parietal and central electrodes in right hemisphere. The novel algorithm provided more detail analysis of the EEG features compared to classic feature classification.","Capturing Semiotic and Social Factors of Organizational Evolution ","Toward an Integrated Quality Evaluation of Web Applications with DEVSThe increasing dynamic and complexity of Web systems turns quality evaluation at any stage of the development into a key issue for the project success in software development areas or organizations. This paper presents a novel approach to evaluate Web applications (WebApps) from their architectures, also considering their functionalities. Discrete EVents System Specification (DEVS) is proposed for behavior and structure analysis based on a set of quality criteria that serve as guidelines for development and evolution of these Web systems. Three quality attributes are considered in this version of the approach: performance, reliability, and availability, but the main advantages are potential scalability and adaptability that respond to the features of these systems.","Age Differences in Computer Input Device Use: A Comparison of Touchscreen, Trackball, and Mouse ","Fast fully automatic segmentation of the myocardium in 2D cine MR imagesA novel automatic initialization procedure for left ventricle (LV) cardiac magnetic resonance (CMR) segmentation is proposed through the combination of a LV localization method based on multilevel Otsu thresholding and an elliptical annular template matching algorithm. We then propose to adapt the recent B-spline Explicit Active Surfaces (BEAS) framework to the properties of CMR images by integrating two dedicated energy terms: a weighted localized Chan-Vese region-based energy to explicitly control the equilibrium point between the two regions around each interface and a combined local and global region-based formulation for the myocardial region. The proposed method has been validated on 45 mid-ventricular images taken from the 2009 MICCAI LV segmentation challenge. Results show the efficiency of our method both in terms of shape accuracy and computational times.","Rethinking the Privacy Calculus: On the Role of Dispositional Factors and AffectExisting research on information privacy has mostly relied on the privacy calculus model which views privacy-related decision making as a rational #N#process where individuals weigh the anticipated risks of disclosing personal data against the potential benefits. However, scholars have recently challenged two basic propositions of the privacy calculus model. First, some authors have distinguished between general and situational factors in the context of privacy calculus and have argued that perceived risks and perceived benefits are primarily related to a situation-specific privacy assessment. Second, a growing body of literature has argued that rational considerations in privacy assessment are bounded by limited resources or #N#heuristic thinking. In this research, we address both of these issues and develop a conceptual model that suggests (1) that dispositional factors such as privacy concerns and institutional trust may affect situation-specific privacy calculus and (2) that privacy assessment may also be determined by momentary affective dates.","EMIL: a rapid prototyping authoring environment for the design of interactive surface applicationsInteractive surfaces (IS) like digital tabletop systems offer a cornucopia of input possibilities like touch gestures or interaction with physical objects. Additionally, multiple users can interact simultaneously allowing for a collaborative setting. These aspects have increased the complexity of designing such interfaces as compared to WIMP interfaces. However, existing UI design approaches fall short of taking these aspects into account and existing design approaches for IS focus on software development. We introduce the EMIL environment that allows authors of design teams to create multi-touch and tangible user interfaces. In its core, EMIL consists of a software framework that provides interaction components (for instance, widgets like images or maps as well as interaction concepts like gestures) that are especially suited for IS. Authors like UI designers collaboratively create software prototypes directly at the IS without the need to write code. For this purpose, they use and adapt the components of the software framework in an authoring application. Authors collect and retrieve information about the interaction components in a knowledge database employing a tablet computer app. In a qualitative evaluation interview, EMIL has been well received by a design team of an advertising agency.","Factorial Multi-Task Learning : A Bayesian Nonparametric ApproachMulti-task learning is a paradigm shown to improve the performance of related tasks through their joint learning. However, for real-world data, it is usually difficult to assess the task relatedness and joint learning with unrelated tasks may lead to serious performance degradations. To this end, we propose a framework that groups the tasks based on their relatedness in a subspace and allows a varying degree of relatedness among tasks by sharing the subspace bases across the groups. This provides the flexibility of no sharing when two sets of tasks are unrelated and partial/total sharing when the tasks are related. Importantly, the number of task-groups and the subspace dimensionality are automatically inferred from the data. To realize our framework, we introduce a novel Bayesian nonparametric prior that extends the traditional hierarchical beta process prior using a Dirichlet process to permit potentially infinite number of child beta processes. We apply our model for multi-task regression and classification applications. Experimental results using several synthetic and real datasets show the superiority of our model to other recent multi-task learning methods. Copyright 2013 by the author(s).","Probabilistic Program Analysis with MartingalesWe present techniques for the analysis of infinite state probabilistic programs to synthesize probabilistic invariants and prove almost-sure termination. Our analysis is based on the notion of (super) martingales from probability theory. First, we define the concept of (super) martingales for loops in probabilistic programs. Next, we present the use of concentration of measure inequalities to bound the values of martingales with high probability. This directly allows us to infer probabilistic bounds on assertions involving the program variables. Next, we present the notion of a super martingale ranking function (SMRF) to prove almost sure termination of probabilistic programs. Finally, we extend constraint-based techniques to synthesize martingales and super-martingale ranking functions for probabilistic programs. We present some applications of our approach to reason about invariance and termination of small but complex probabilistic programs.","Dosukoi-Tap: The Virtual Paper Sumo GameWe have developed a virtual paper sumo game, \"Dosukoi-Tap\", a Japanese traditional game using paper figures. A player taps on his/her own-side of the sumo ring board. He/she lets his/her own wrestler rush and fight with its opponent. Our system simulates the feature of actual paper sumo and has solved some of the problems of actual one by employing multi-finger tracking and pressure-sensitive device.","Towards a Real Architecture of Wireless Ad-Hoc Router on Open-Source Linux Platform ","Exploring the Space of System Monitoring ","Discrete Rigid Transformation Graph Search for 2D Image RegistrationRigid image registration is an essential image processing task, with a large body of applications. This problem is usually formulated in the continuous domain, often in the context of an optimization framework. This approach leads to sometimes unwanted artifacts, e.g. due to interpolation. In the case of purely discrete applications, e.g., for template-based segmentation or classification, it is however preferable to avoid digitizing the result again after transformation. In this article, we deal with this point of view in the 2D case. Based on a fully discrete framework, we explicitly explore the parameter space of rigid transformations. This exploration leads to a local search scheme that can be involved in combinatorial optimization strategies.","Collaborative Elicitation of Conceptual Representations: A Corpus-Based ApproachKnowledge is an important resource for organisations, and being able to manage it is a key factor for success. New information management and knowledge sharing approaches should be able to cope not only with possible variations in business situations and contexts, but also with various and sometimes discordant viewpoints, which are inherent to collaborative environments. Developing, reusing and maintaining common interpretations of available information is crucial to support real-word organisational activities. The particularly challenging problem of knowledge elicitation is tackled here combining terminological and knowledge representation views. A corpus-based conceptual modelling architecture was designed and discussed together with the workflows for real-time context retrieval and lexical pattern discovery. The practical implementation and validation of this work are accomplished on the ConceptME system, a platform developed as part of this research line, providing knowledge and terminological tools and resources to support activities that involve collaborative conceptualisation processes according to the ColBlend method.","Inspection and crime prevention : an evolutionary perspectiveIn this paper, we analyse inspection games with an evolutionary perspective. In our evolutionary inspection game with a large population, each individual is not a rational payoff maximiser, but periodically updates his strategy if he perceives that other individuals' strategies are more successful than his own, namely strategies are subject to the evolutionary pressure. We develop this game into a few directions. Firstly, social norms are incorporated into the game and we analyse how social norms may influence individuals' propensity to engage in criminal behaviour. Secondly, a forward-looking inspector is considered, namely, the inspector chooses the level of law enforcement whilst taking into account the effect that this choice will have on future crime rates. Finally, the game is extended to the one with continuous strategy spaces.","Optimal Location and Size of Different Type of Distributed Generation with Voltage Step Constraint and Mixed Load ModelsThe optimal location and size of distributed generation in distribution network are essentially affected by type of DG, constraints, and loading condition. The type of distributed generation (DG) categorized on the basis of their terminal characteristic in terms of active and reactive power delivering capability have been considered for study. The voltage step change that occurs on sudden disconnection of DG is one of constraints to limit the size of DG more than the voltage level constraint. The loads connected to network are normally voltage dependent and varies with seasonal atmospheric conditions. The voltage dependency and seasonal variation of load necessitate to represent the load by load models for analysis. In this paper, the study has been carried out for distributed generation planning (DGP) for different type of DG in 38-bus test distribution system with voltage step constraint including normally considered constraints i.e. bus voltage constraint, line power capacity constraint, and seasonal mixed load models. The analysis shows that optimal location and size are significantly affected by type of DG, voltage step constraint, and load models.","Groups with a recursively enumerable irreducible word problemThe notion of the word problem is of fundamental importance in group theory. The irreducible word problem is a closely related concept and has been studied in a number of situations; however there appears to be little known in the case where a finitely generated group has a recursively enumerable irreducible word problem. In this paper we show that having a recursively enumerable irreducible word problem with respect to every finite generating set is equivalent to having a recursive word problem. We prove some further results about groups having a recursively enumerable irreducible word problem, amongst other things showing that there are cases where having such an irreducible word problem does depend on the choice of finite generating set.","Reversible delay-insensitive distributed memory modulesWe introduce two eight-line one-bit memory modules which are useful in the modelling of distributed memory in asynchronous delay-insensitive circuits. Our modules are reversible and together with the Merge element are serial-universal. We show how they can be used to realise Morita's Rotary Element and other reversible modules thus showing their computation universality. We also propose three sets of modules that are universal for all modules.","On the verification and computation of strong nash equilibriumComputing equilibria of games is a central task in computer science. A large number of results are known for Nash equilibrium (NE). However, these can be adopted only when coalitions are not an issue. When instead agents can form coalitions, NE is inadequate and an appropriate solution concept is strong Nash equilibrium (SNE). Few computational results are known about SNE. In this paper, we first study the problem of verifying whether a strategy profile is an SNE, showing that the problem is in P. We then design a spatial branch--and--bound algorithm to find an SNE, and we experimentally evaluate the algorithm.","Computability and Computational Complexity of the Evolution of Nonlinear Dynamical Systems ","Separating Obligations of Subjects and Handlers for More Flexible Event Type Verification ","Numerical Approximation of Rare Event Probabilities in Biochemically Reacting SystemsIn stochastic biochemically reacting systems, certain rare events can cause serious consequences, which makes their probabilities important to analyze. We solve the chemical master equation using a four-stage fourth order Runge-Kutta integration scheme in combination with a guided state space exploration and a dynamical state space truncation in order to approximate the unknown probabilities of rare but important events numerically. The guided state space exploration biases the system parameters such that the rare event of interest becomes less rare. For each numerical integration step, the portion of the state space to be truncated is then dynamically obtained using information from the biased model and the numerical integration of the unbiased model is conducted only on the remaining significant part of the state space. The efficiency and the accuracy of our method are studied through a benchmark model that recently received considerable attention in the literature.","Learning by Playing and Learning by MakingSerious video games have been proposed as a means to engage stu- dents with the Science, Technology, Engineering, Mathematics (STEM) curri- culum, but there is limited research on the required game elements and teaching practices. In particular, there is limited evidence on the effects of the storytel- ling element and of student involvement in making games on the learning per- formance and on the attitudes of the students. For this purpose, we designed a between groups experiment with eighty students (12 to 13 years old). They formed three equivalent groups of twenty students each who practiced with a serious game in three different ways. The first group played the storytelling game, the second played the same game but with no story, and the third was en- gaged with modifying the game code. Finally, the last (control) group practiced traditionally by solving exercises on paper. We found that girls with low grades benefited the most by playing the game and by engaging with the code and that the game making group wishes to repeat the exercise. Further research should perform similar studies with a focus on involving students in serious game modification, over longer periods of time and for additional curriculum topics.","Cryptanalysis of Pairing-Free Identity-Based Authenticated Key Agreement ProtocolsThe pairing-free ID-based authenticated key agreement ID-AKA protocol provides secure and efficient communication over the public network, which is introduced by Zhu et al. in 2007. Afterwards, a number of identity-based authenticated key agreement protocols have been proposed to meet a variety of desirable security and performance requirements. In this paper, we analyze Fiore and Gennaro's scheme and demonstrate key off-set and forgery attack. We identify that Farash and Attari's protocol is vulnerable to the forgery attack, key compromise impersonation attack, key off-set attack and known session key specific temporary information attack. We also show that Hou and Xu's scheme also fails to resist key off-set and forgery attack.","Efficient Graph Construction for Label Propagation Based Multi-observation Face RecognitionHuman-machine interaction is a hot topic nowadays in the communities of multimedia and computer vision. In this context, face recognition algorithms (used as primary cue for a person's identity assessment) work well under controlled conditions but degrade significantly when tested in real-world environments. Recently, graph-based label propagation for multi-observation face recognition was proposed. However, the associated graphs were constructed in an ad-hoc manner (e.g., using the KNN graph) that cannot adapt optimally to the data. In this paper, we propose a novel approach for efficient and adaptive graph construction that can be used for multi-observation face recognition as well as for other recognition problems. Experimental results performed on Honda video face database, show a distinct advantage of the proposed method over the standard graph construction methods.","On the Interpolation between Product-Based Message Passing Heuristics for SATThis paper introduces a notational frame to characterize the four basic product-based Message Passing (MP) heuristics currently available for SAT: Belief Propagation (BP), Survey Propagation (SP), Expectation Maximization BP Global (EMBPG) and Expectation Max- imization SP Global (EMSPG). Using this framework, the paper intro- duces indirect structural interpolation (ISI). Using this technique, we create a hierarchy of heuristics - each new level in this hierarchy consists of heuristics strictly more general than their predecessors. The final re- sult is the \u03c1\u03c3PMP i heuristic, which is able to mimic all product-based MP heuristics and is hence a generalization for all them.","Towards practical and fundamental limits of anonymity protectionA common function of anonymity systems is the embedding of subjects that are associated to some attributes in a set of subjects, the anonymity set. Every subject within the anonymity set appears to be possibly associated to attributes of every other subject within it. The anonymity set covers the associations between the subjects and their attributes. The limit of anonymity protection basically depends on the hardness of disclosing those hidden associations from the anonymity sets. This thesis analyses the protection limit provided by anonymity sets by studying a practical and widely deployed anonymity system, the Chaum Mix. A Mix is an anonymous communication system that embeds senders of messages in an anonymity set to hide the association to their recipients (i.e., attributes), in each communication round. It is well known that traffic analyses can uniquely identify a user\u2019s recipients by evaluating the sets of senders (i.e., the sender anonymity set) and recipients using the Mix in several rounds. The least number of rounds for that identification represents a fundamental limit of anonymity protection provided by the anonymity sets, similar to Shannon\u2019s unicity-distance. That identification requires solving NP-complete problems and was believed to be computationally infeasible.#R##N##R##N#This thesis shows by a new and optimised algorithm that the unique identification of a user\u2019s recipients is for many realistic Mix configurations computational feasible, in the average case. It contributes mathematical estimates of the mean least number of rounds and the mean time-complexity for that unique identification. These measure the fundamental, as well as the practical protection limit provided by the anonymity sets of a Mix. They can be applied to systematically identify Mix configurations that lead to a weak anonymity of a user\u2019s recipients. To the best of our knowledge, this has not been addressed yet, due to the computational infeasibility of past algorithms. All before-mentioned algorithms and analyses can be adapted to deduce information about a user\u2019s recipients, even in cases of incomplete knowledge about the anonymity sets, or a low number of observed anonymity sets.","Customers' Activity Recognition in Intelligent Retail EnvironmentsThis paper aims to propose a novel idea of an embedded intelligent system where low cost embedded vision systems can analyze human behaviors to obtain interactivity and statistical data, mainly devoted to customer behavior analysis. In this project we addressed the need for new services into the shop, involving consumers more directly and instigating them to increase their satisfaction and, as a consequence, their purchases. To do this, technology is very important and allows making interactions between costumers and products and between customers and the environment of the shop a rich source of marketing analysis.#R##N##R##N#We construct a novel system that uses vertical RGBD sensor for people counting and shelf interaction analysis, where the depth information is used to remove the affect of the appearance variation and to evaluate customers' activities inside the store and in front of the shelf, with products. Also group interactions are monitored and analyzed with the main goal of having a better knowledge of the customers' activities, using real data in real time.#R##N##R##N#Even if preliminary, results are convincing and most of all the general architecture is affordable in this specific application, robust, easy to install and maintain and low cost.","DOMINO \u2013 An Efficient Algorithm for Policy Definition and Processing in Distributed Environments Based on Atomic Data Structures ","Diagnosing Dependent Action Delays in Temporal Multiagent PlansDiagnosis of Temporal Multiagent Plans (TMAPs) aims at identifying the causes of delays in achieving the plan goals. So far, approaches to TMAP diag- nosis have relied on an assumption that might not hold in many practical domains: action delays are independent of one another. In this paper we relax this assump- tion by allowing (indirect) dependencies among action delays. The diagnosis of a given TMAP is inferred by exploiting a qualitative Bayesian Network (BN), through which dependencies among actions delays, even performed by different agents, are captured. The BN, used to compute the heuristic function, drives a standard A* search, which finds all the most plausible explanations. Results of a preliminary experimental analysis show that the proposed Bayesian-based heuristic function is feasible.","Business Rules Management Solutions: Added Value by Effective Means of Business InteroperabilityInteroperability research, to date, primarily focuses on data, processes and technology and not explicitly on business rules. The core problem of interoperability from an organisation's perspective is the added value generated from collaborating with other parties. The added value from a data, process and technology perspective has been widely researched. Therefore it is the aim of this study to provide insights into the added value for organisations to collaborate when executing business rules management solutions. Explanations of possibilities, opportunities and challenges can help to increase the understanding of business rules interoperability value creation. Presented results provide a grounded basis from which empirical and practical investigation can be further explored.","Particle Swarm Optimization for Average Approximation of Interval Type-2 Fuzzy Inference Systems Design in FPGAs for Real Applications ","A lemon lexicon for DBpediaAs the body of knowledge available as linked data grows, so does the need to provide methods that make this knowledge accessible for humans. Such methods usually require knowledge about how the vocabulary elements used in the available ontologies and datasets are verbalized in natural language. This has lead to much interest in the development of models and frameworks for publishing ontology lexica as linked data. In this paper we describe a process for the manual development of such lexica in lemon format and illustrate some of the key challenges involved. As a proof of concept, we provide a manually created English lexicon for the DBpedia ontology and describe its first release.","Applications of Ordinal Factor AnalysisOrdinal factorisation is a factor analytical tool based on For- mal Concept Analysis. It groups the so-called Boolean factors, given by suitable formal concepts, into well-structured families that can be inter- preted as many-valued factors. In this paper we put the ordinal factori- sation to work by testing it on well-documented medical data. We also compare the results with those obtained by established data reduction methods.","Modern Analytics in Field and Service Operations ","SID Signature Database: A Tunisian Off-line Handwritten Signature DatabaseOur research works are concerned with checking the off-line handwritten signature. We propose a base of Tunisian static handwritten signatures. In this paper, we go through the phase of designing the SID-Signature database and its various features. Afterwards, we present the results obtained by this base as part of our system of handwritten-signature verification.","A Multi-algorithmic Colour Iris Recognition SystemThe reported accuracies of iris recognition systems are generally higher on near infrared images than on colour RGB images. To increase a colour iris recognition system\u2019s performance, a possible solution is a multialgorithmic approach with an appropriate fusion mechanism. In the present work, this approach is investigated by fusing three algorithms at the score level to enhance the performance of a colour iris recognition system. The contribution of this paper consists of proposing 2 novel feature extraction methods for colour iris images, one based on a 3-bit encoder of the 8 neighborhood and the other one based on gray level co-occurrence matrix. The third algorithm employed uses the classical Gabor filters and phase encoding for feature extraction. A weighted average is used as a matching score fusion. The efficiency of the proposed iris recognition system is demonstrated on UBIRISv1 dataset.","Together or separate? algorithmic aggregation problemsAggregation problems arise when an expensive resource is shared by multiple agents. Shared access to this resource may result in agents incurring additional expenses, for example due to excessive wait time. This leads to a tradeoff between the frequency of access to the shared resource and the overhead costs for individual agents. Some participants of FCT may face this dilemma when heading to the airport after the conference. Sharing a cab saves overall cost, but it may create some inconvenience, or even additional expenses, if it results in an early or late arrival at the airport.#R##N##R##N#Aggregation problems of this nature are ubiquitous. For example, in the TCP Acknowledgment Problem in networks, control acknowledgement packets can be aggregated and transmitted together. This reduces network traffic, but it can also result in undesirable delays and complicate congestion control. In the Joint Replenishment Problem, extensively studied in the operations research area, retailers place orders for a commodity at the supplier. To satisfy these orders, the supplier sends shipments of the commodity to a shared warehouse, which then redistributes them to the suppliers. The objective is to minimize the total shipment cost and the retailers' cost of waiting for their shipments.#R##N##R##N#This talk will survey the existing work on efficient algorithms for such aggregation problems, attempting to provide a unified perspective and emphasizing connections between different variants. We will discuss both offline and online algorithms, focussing mostly on recent results on approximation algorithms for these problems and on the remaining open problems.","Impact of Geospatial Reasoning Ability and Perceived Task-Technology Fit on Decision-Performance: The Moderating Role of Task Characteristics ","Vehicle Queue Length Measurement Based on a Modified Local Variance and LBP ","Optimizing Program Performance via Similarity, Using a Feature-Agnostic ApproachThis work proposes a new technique for performance evaluation to predict performance of parallel programs across diverse and complex systems. In this work the term system is comprehensive of the hardware organization, the development and execution environment.#R##N##R##N#The proposed technique considers the collection of completion times for some pairs program,i\u00be?system and constructs an empirical model that learns to predict performance of unknown pairs program,i\u00be?system. This approach is feature-agnostic because it does not involve previous knowledge of program and/or system characteristics features to predict performance.#R##N##R##N#Experimental results conducted with a large number of serial and parallel benchmark suites, including SPEC CPU2006, SPEC OMP2012, and systems show that the proposed technique is equally applicable to be employed in several compelling performance evaluation studies, including characterization, comparison and tuning of hardware configurations, compilers, run-time environments or any combination thereof.","On Logical Depth and the Running Time of Shortest ProgramsThe logical depth with significance $b$ of a finite binary string $x$ is the shortest running time of a binary program for $x$ that can be compressed by at most $b$ bits. There is another definition of logical depth. We give two theorems about the quantitative relation between these versions: the first theorem concerns a variation of a known fact with a new proof, the second theorem and its proof are new. We select the above version of logical depth and show the following. There is an infinite sequence of strings of increasing length such that for each $j$ there is a $b$ such that the logical depth of the $j$th string as a function of $j$ is incomputable (it rises faster than any computable function) but with $b$ replaced by $b+1$ the resuling function is computable. Hence the maximal gap between the logical depths resulting from incrementing appropriate $b$'s by 1 rises faster than any computable function. All functions mentioned are upper bounded by the Busy Beaver function. Since for every string its logical depth is nonincreasing in $b$, the minimal computation time of the shortest programs for the sequence of strings as a function of $j$ rises faster than any computable function but not so fast as the Busy Beaver function.","Integrating cue descriptors in bubble space for place recognitionThis paper presents a new approach to the integration of different sensory cues in bubble space for place recognition. In bubble space, bubble surfaces enable the representation of all features in a manner that is implicitly dependent on robot pose while preserving their local S2-geometry. In the proposed approach, for each place, distinct groups of bubble surfaces conduce different cue descriptors which are then combined together. Unlike most previous work, merging cues of different nature is very simple regardless of the number of observations associated with each cue. Comparative experiments on a benchmark dataset indicate that while learning times are decreased considerably, recognition rates are comparable to state-of-the art approaches in place recognition.","Applications of Computer Vision to Vehicles: An Extreme Test ","Influence of Trust Assurances in Mobile Commerce Applications on the Formation of Online TrustIn this paper we investigate the influence of Trust Assurances in Mobile Commerce Applications on the formation of Online Trust. In comparison to existing measuring approaches we therefore developed a more detailed approach of capturing Online Trust. We carried out a study in which Online Trust was captured after an initial interaction with an unknown business partner in form of a fictional Mobile Commerce Application. The generated quantitative and qualitative data allowed for conclusions concerning the formation of Online Trust as well as the influence of Trust Assurances.","An AI-Based Process for Generating Games from Flat StoriesTERENCE is an FP7 ICT European project that is developing an adaptive learning system for supporting poor comprehenders and their educators. Its learning materialarebooksofstoriesandgames.Theso-calledsmartgamesservetostimulate story comprehension. This paper focuses on the analysis offlat stories with a specific annotation language and the generation of smart games from the analysed texts, mixingnatural language processingand temporal constraint-reasoning technologies. Thepaperendscommentingontheapproachtotheautomatedanalysisandextraction of information from stories for specific users and domains, briefly evaluating the benefits of the semi-automated generation process in terms of production costs.","Collaboration on Interactive CeilingsIn this paper we discuss how interactive ceilings may improve productivity and collaboration in office environments. The ceiling of an office offers an unobtrusive, unobstructed display and input area which is accessible to all persons in the room. Therefore, enhancing ceilings with input and display capabilities allows for a range of new single-user and multi-user applications such as status indicators, unobtrusive notifications, in-house navigation and collaborative work areas. However, ergonomic constraints limit the application space. To investigate such constraints we built a working prototype of an interactive ceiling. Currently, we are conducting a study investigating which areas on the ceiling may be used for displaying notifications and content.","GENESIS, The GEneral NEural SImulation System ","Canonical correlation analysis neural network for steady-state visual evoked potentials based brain-computer interfacesCanonical correlation analysis (CCA) is a promising feature extraction technique of steady state visual evoked potential (SSVEP)-based brain computer interface (BCI). Many researches have showed that CCA performs significantly better than the traditional methods. In this paper, the neural network implementation of CCA is used for the frequency detection and classification in SSVEP-based BCI. Results showed that the neural network implementation of CCA can achieve higher classification accuracy than the method of power spectral density analysis (PSDA), minimum energy combination (MEC) and similar performance to the standard CCA method.","Policy Chain for Securing Service Oriented Architectures ","Building a knowledge base of severe adverse drug events based on AERS reporting data using semantic web technologies. ","Exploring Adoption and Use of Agile Methods: A Comparative Case Study ","Effects of Network Structure Improvement on Distributed RDF Querying ","Looking for a Synergy between Human and Artificial CognitionContextually based reasoning is an essential aspect of human cognition, permeating language, memory, and reasoning capabilities. This integral process is developed over the lifetime through experiential learning. Given the goal of artificial intelligence to mimic human intelligence, it is essential to include such contextual considerations in system design and implementation. We compare selected computational architectures and cognitive paradigms on the basis of key elements in human intelligence understanding in order to illustrate the similarities and differences between the two viewpoints and highlight the potential effectiveness of context based computing. In the literature, we discover meaningful parallels between the assessment of context in cognition and computation which have implications for both fields of study.","Proposal of an Inference Engine Architecture for Business Rules and Processes ","Reasoning about probabilities in dynamic systems using goal regressionReasoning about degrees of belief in uncertain dynamic worlds is fundamental to many applications, such as robotics and planning, where actions modify state properties and sensors provide measurements, both of which are prone to noise. With the exception of limited cases such as Gaussian processes over linear phenomena, belief state evolution can be complex and hard to reason with in a general way. This paper proposes a framework with new results that allows the reduction of subjective probabilities after sensing and acting, both in discrete and continuous domains, to questions about the initial state only. We build on an expressive probabilistic first-order logical account by Bacchus, Halpern and Levesque, resulting in a methodology that, in principle, can be coupled with a variety of existing inference solutions.","Modeling business capabilities and context dependent delivery by cloud servicesContemporary business environments are changing rapidly, organizations are global, and cloud-based services have become a norm. Enterprises operating in these conditions need to have the capability to deliver their business in a variety of business contexts. Capability delivery thus has to be monitored and adjusted. Current Enterprise Modeling approaches do not address context-dependent capability design and do not explicitly support runtime adjustments. To address this challenge, a capability-driven approach is proposed to model business capabilities by using EM techniques, and to use model-based patterns to describe how software applications can adhere to changes in the execution context. A meta-model for capability design and delivery is presented with the consideration to delivering solutions as cloud services. The proposal is illustrated with an example case from an energy efficiency project. A supporting architecture for the capability development and the delivery in the cloud is also presented.","Managing Complex Data for Electrical/Electronic Components: Challenges and RequirementsIn the automotive domain, innovation is driven by the introduction and continuous improvement of electrical and electronic (E/E) components (e.g. sensors, actuators, and electronic control units). This trend is accompanied by increasing complexity and interdependencies between them. In addition, external impact factors (e.g. changes of regulations) demand for management of E/E product data (E/E-PDM). Since E/E product data is scattered over distributed heterogeneous IT systems, application-spanning use cases (e.g. consistency of artifacts, plausibility of logical connections between electronic control units) are difficult to realize. Consequently, the partial integration of the corresponding application data models becomes necessary. Changes of application data models are common in context of E/E-PDM, but they are not considered by existing application integration approaches. Furthermore, no methodology for creating application integration models exists. This paper elaborates challenges to be tackled when integrating applications containing E/E product data. It further presents properties of the IT landscape involved in E/E-PDM and reveals occurring problems. Finally, requirements for E/E-PDM are discussed.","PIC2LNT: model transformation for model checking an applied pi-calculusThe \u03c0-calculus [12] was proposed by Milner, Parrow, and Walker about twenty years ago for describing concurrent systems with mobile communication. The \u03c0-calculus is equipped with operational semantics defined in terms of Ltss (Labelled Transition Systems). Although a lot of theoretical results have been achieved on this language (see, e.g., [1, chapter 8] for a survey), only a few verification tools have been designed for analysing \u03c0-calculus specifications automatically. The two most famous examples are the Mobility Workbench (Mwb) [14] and Jack [5], which were developed in the 90s.","Assertion Prediction with Ontologies through Evidence Combination ","Simulative Model Checking of Steady State and Time-Unbounded Temporal Operators ","Architecture for transparent binary acceleration of loops with memory accessesThis paper presents an extension to a hardware/software system architecture in which repetitive instruction traces, called Megablocks, Reconfigurable Processing Unit (RPU). This scheme is supported by a custom toolchain able to automatically generate a RPU tailored for the execution of one or more Megablocks detected offline. Switching between hardware and software execution is done transparently, without modifications to source code or executable binaries. Our approach has been evaluated using an architecture with a MicroBlaze General Purpose Processor (GPP) softcore. By using a memory sharing mechanism, the RPU can access the GPP's data memory, allowing the acceleration of Megablocks with load/store operations. For a set of 21 embedded benchmarks, an average speedup of 1.43\u00d7 is achieved, and a potential speedup of 2.09\u00d7 is predicted for an implementation using a low overhead interface for communication between GPP and RPU.","Enhancing Biomedical Images Using the UFIR Filters with Recursive Responses ","Recommending Multimedia Objects in Cultural Heritage ApplicationsItaly's Cultural Heritage is the world's most diverse and rich patrimony and attracts millions of visitors every year to monuments, archaeological sites and museums. The valorization of cultural heritage represents nowadays one of the most important research challenges in the Italian scenario. In this paper, we present a general multimedia recommender system able to uniformly manage heterogeneous multimedia data and to provide context-aware recommendation techniques supporting intelligent multimedia services for the users. A specific application of our system within the cultural heritage domain is proposed by means of a real case study in the mobile environment related to an outdoor scenario, together with preliminary results on user's satisfaction.","Specification Design of Renewable Energy Management System for Recovery Planning of Japanese Coastal Community After Tsunami Disaster ","Design of a Team-Based Relocation Scheme in Electric Vehicle Sharing Systems ","User-state sensing for virtual health agents and telehealth applications. ","Engineering a Platform for Mission Planning of Autonomous and Resilient QuadrotorsQuadrotors and UAVs in general are becoming as attractive instru- ments to safely and efficiently perform environmental monitoring missions. In professional use, quadrotors are manually controlled by expert operators via a remote controller. In research, several projects provide various degrees of au- tomation for the execution of the mission; however, those projects are based on the use of programming languages which are too distant from the background of the stakeholders operating in the field (e.g., fire fighters, policemen, etc.). In this paper we propose FLYAQ, a platform enabling to (i) graphically define monitoring missions via a web interface, (ii) decompose the mission according to the number and nature of available quadrotors, and (iii) generate the implementa- tion code orchestrating all the quadrotors of the swarm to fulfil the common goal of the mission. The FLYAQ platform enables operators to focus on the mission itself, rather than on technical concerns arising from the use of quadrotors. A reconfiguration engine is specifically designed to make the swarm resilient to faults and external events that may compromise the mission. Moreover, under some limitations explained in the paper, the reconfiguration engine permits to change the mission at run-time. The FLYAQ platform will be distributed as an open-source product.","Evaluation Strategy and Translation of Environment Calculus ","Study on Research Challenges and Optimization for Internetworking of Hybrid MANET and Satellite Networks ","The Agulhas System in a Global ContextThe Agulhas is a convoluted and multifarious system [1]. It consists of a western boundary current, the Agulhas Current, which is arguably one of the most prominent current systems of the Southern Hemisphere (Fig.1). The Agulhas Current, roughly on par with its Northern Hemisphere counterpart, the Gulf Stream, carries vast amount of heat and salt towards the pole [2].","Edit Distance Comparison Confidence Measure for Speech Recognition ","Shortest Paths with Bundles and Non-additive Weights Is HardIn a standard path auction, all of the edges in a graph are sold as separate entities, each edge having a single cost. We consider a generalisation in which a graph is partitioned and each subset of edges has a unique owner. We show that if the owner is allowed to apply a non-additive pricing structure then the winner determination problem becomes NP-hard (in contrast with the quadratic time algorithm for the standard additive pricing model). We show that this holds even if the owners have subsets of only 2 edges. For subadditive pricing (e.g. volume discounts), there is a trivial approximation ratio of the size of the largest subset. Where the size of the subsets is unbounded then we show that approximation to within a \u03a9(log n) factor is hard. For the superadditive case we show that approximation with a factor of nfor any \ufffd&gt; 0i s hard even when the subsets are of size at most 2.","A Spectral Approach to Total VariationThe total variation (TV) functional is explored from a spec- tral perspective. We formulate a TV transform based on the second time derivative of the total variation flow, scaled by time. In the transforma- tion domain disks yield impulse responses. This transformation can be viewed as a spectral domain, with somewhat similar intuition of classical Fourier analysis. A simple reconstruction formula from the TV spectral domain to the spatial domain is given. We can then design low-pass, high-pass and band-pass TV filters and obtain a TV spectrum of signals and images.","Spatial Primitives from a Cognitive Perspective: Sensitivity to Changes in Various Geometric Properties ","Facilitating Teaching and Learning Capabilities in Social Learning Management Systems: Challenges, Issues, and Implications for DesignThe adoption of learning management systems LMSs and social networking technologies SNTs in higher education has begun to change the way learning and teaching take place. However, the adoption of these emerging tools as a means to support collaboration seems to be slow. This study seeks to identify issues and opportunities related to LMS and SNT utilization and combination to enhance learning and teaching capabilities in higher education. An illustrative study reports on student and instructor experiences of using these systems in two Norwegian universities. The empirical evidence gained is analysed in terms of current benefits and drawbacks, and future challenges and capabilities. This provides the basis for a brief assessment of some requirements for an integrated learning platform, taking organizational, social, and technical issues of LMS and SNT into account. This study has implications for the design of such a social learning management system SLMS, as it is termed, which can encompass the functionalities of both LMS and SNT.","Semi-Supervised Vector Quantization for proximity dataSemi-supervised learning (SSL) is focused on learning from labeled and unlabeled data by incorporating structural and statistical in- formation of the available unlabeled data. The amount of data is dra- matically increasing, but few of them are fully labeled, due to cost and time constraints. This is even more challenging for non-vectorial, proxim- ity data, given by pairwise proximity values. Only few methods provide SSL for this data, limited to positive-semi-definite (psd) data. They also lack interpretable models, which is a relevant aspect in life-sciences where most of these data are found. This paper provides a prototype based SSL approach for proximity data.","Three kinds of negation of fuzzy knowledge and their base of logicNegative information plays an important role in fuzzy knowledge representation and reasoning. This paper distinguish between contradictory negative relation and opposite negative relation for the fuzzy information, a characteristic of fuzzy information is discovered that if a pair of opposite concepts are fuzzy concepts, then there must exists a \"medium\" fuzzy concept between them; conversely, if there is a medium fuzzy concept between the two opposite concepts, then opposite concepts must be fuzzy concepts. We thus consider that negation of fuzzy information include contradictory negation, opposite negation and medium negation. In order to provide a logical basis for three kinds of negation in fuzzy information, we propose a fuzzy propositional logic with contradictory negation, opposite negation and medium negation (FLcom), discussed some interesting properties of FLcom, presented a semantic interpretation of FLcom, and proved the reliability theorem.","Estimating reference evapotranspiration for irrigation management in the texas high plainsAccurate estimates of daily crop evapotranspiration (ET) are needed for efficient irrigation management in regions where crop water demand exceeds rainfall. Daily grass or alfalfa reference ET values and crop coefficients are widely used to estimate crop water demand. Inaccurate reference ET estimates can hence have a tremendous impact on irrigation costs and the demands on freshwater resources. ET networks calculate reference ET using precise measurements of meteorological data. These networks are typically characterized by gaps in spatial coverage and lack of sufficient funding, creating an immediate need for alternative sources that can fill data gaps without high costs. Although non-agricultural weather stations provide publicly accessible meteorological data, there are concerns that the data may be unsuitable for estimating reference ET due to factors such as weather station siting, data formats and quality control issues. The objective of our research is to enable the use of alternative data sources, adapting sophisticated machine learning algorithms such as Gaussian process models and neural networks to discover and model the nonlinear relationships between non-ET weather station data and the reference ET computed by ET networks. Using data from the Texas High Plains region in the U.S., we demonstrate significant improvement in estimation accuracy in comparison with baseline regression models typically used for irrigation management applications.","Keyword-Matched Data Skyline in Peer-to-Peer SystemsData and storage management is turning to distributed due to the huge increase in data volumes. To satisfy users' requirements and preferences, advanced query operators, such as skyline, have been intro- duced and implemented. Skyline offers users with interesting objects, which has been explored in centralized, distributed and peer-to-peer (P2P) systems. However, keyword-matched skyline has not been con- sidered in distributed and P2P systems. This paper introduces keyword- matched data skyline algorithms in P2P systems. Differing from other operators, skyline algorithms are devised to exploit its properties to re- duce traversed peers for a query. By partitioning data space and using distributed hash tables (DHTs) and Bloom filters, we design new algo- rithms, Nk-sky and Ck-sky, to reduce the required traversed peers to answer keyword-matched data skyline queries. We apply the algorithms on Chord as an example of DHT overlay P2P systems. Experimental results show a significant reduction of traversed peers with the Cover-set tuples algorithm Ck-sky.","Executive Doctorate Programs and the Role of the Information Systems DisciplineOver the last few years, a new genre of doctoral programs has emerged. These programs are partly aimed at bridging the gap between academic research and practice. Although these programs tend to be interdisciplinary in nature in terms of content and research methods, several of the programs have significant IS discipline connections. The goal of this panel session is to share experiences from these executive doctoral programs and the lessons learned. We also want to explore the interesting phenomenon of IS scholars being tapped to launch, manage, and teach in these programs in a disproportionately high level as a reflection of the IS discipline\u2019s interdisciplinary nature.","QUALITY-ADJUSTED CONSUMER SURPLUS FOR ONLINE LABOR MARKETS WITH ASYMMETRIC INFORMATIONTraditional measures of consumer surplus (CS) have implicitly assumed that the quality expected is the same as the quality that is paid for ex ante. However, when product or service quality cannot be perfectly verified ex ante by consumers in markets with asymmetric information, and actual quality received may not necessarily equal quality expected, CS would not be precisely measured. In this paper, we propose a quality-adjusted measure of CS for IT outsourcing e-markets with asymmetric information. We first relax the assumption that consumers always receive the quality they expect ex ante. Second, we leverage expectationconfirmation theory to construct the utility function to derive the proposed quality-adjusted measure of CS. Measurement development is followed by an empirical study of the effects of different measures of CS. We found the quality-adjusted measure better predicts market outcomes, i.e., continuation, subsequent projects and payments."],"x":{"__ndarray__":"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","dtype":"float32","order":"little","shape":[5006]},"y":{"__ndarray__":"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","dtype":"float32","order":"little","shape":[5006]}},"selected":{"id":"2218"},"selection_policy":{"id":"2217"}},"id":"2171","type":"ColumnDataSource"},{"attributes":{"active_drag":"auto","active_inspect":"auto","active_multi":null,"active_scroll":"auto","active_tap":"auto","tools":[{"id":"2189"},{"id":"2190"},{"id":"2191"},{"id":"2192"},{"id":"2193"},{"id":"2194"},{"id":"2196"}]},"id":"2197","type":"Toolbar"},{"attributes":{},"id":"2177","type":"LinearScale"},{"attributes":{},"id":"2182","type":"BasicTicker"},{"attributes":{"formatter":{"id":"2212"},"ticker":{"id":"2182"},"visible":false},"id":"2181","type":"LinearAxis"},{"attributes":{},"id":"2194","type":"HelpTool"},{"attributes":{},"id":"2173","type":"DataRange1d"},{"attributes":{"fill_alpha":{"value":0.1},"fill_color":{"field":"color"},"line_alpha":{"value":0.1},"line_color":{"field":"color"},"size":{"units":"screen","value":2},"x":{"field":"x"},"y":{"field":"y"}},"id":"2207","type":"Circle"},{"attributes":{"source":{"id":"2171"}},"id":"2209","type":"CDSView"},{"attributes":{"axis":{"id":"2181"},"ticker":null,"visible":false},"id":"2184","type":"Grid"},{"attributes":{},"id":"2190","type":"WheelZoomTool"},{"attributes":{},"id":"2212","type":"BasicTickFormatter"},{"attributes":{"data_source":{"id":"2171"},"glyph":{"id":"2206"},"hover_glyph":null,"muted_glyph":null,"nonselection_glyph":{"id":"2207"},"selection_glyph":null,"view":{"id":"2209"}},"id":"2208","type":"GlyphRenderer"},{"attributes":{},"id":"2217","type":"UnionRenderers"},{"attributes":{"background_fill_color":"white","below":[{"id":"2181"}],"center":[{"id":"2184"},{"id":"2188"}],"left":[{"id":"2185"}],"plot_height":800,"plot_width":800,"renderers":[{"id":"2208"}],"title":{"id":"2211"},"toolbar":{"id":"2197"},"x_range":{"id":"2173"},"x_scale":{"id":"2177"},"y_range":{"id":"2175"},"y_scale":{"id":"2179"}},"id":"2172","subtype":"Figure","type":"Plot"},{"attributes":{"text":""},"id":"2211","type":"Title"},{"attributes":{"bottom_units":"screen","fill_alpha":0.5,"fill_color":"lightgrey","left_units":"screen","level":"overlay","line_alpha":1.0,"line_color":"black","line_dash":[4,4],"line_width":2,"right_units":"screen","top_units":"screen"},"id":"2195","type":"BoxAnnotation"},{"attributes":{},"id":"2218","type":"Selection"},{"attributes":{},"id":"2175","type":"DataRange1d"},{"attributes":{},"id":"2189","type":"PanTool"},{"attributes":{"fill_alpha":{"field":"alpha"},"fill_color":{"field":"color"},"line_alpha":{"field":"alpha"},"line_color":{"field":"color"},"size":{"units":"screen","value":2},"x":{"field":"x"},"y":{"field":"y"}},"id":"2206","type":"Circle"},{"attributes":{},"id":"2214","type":"BasicTickFormatter"},{"attributes":{},"id":"2186","type":"BasicTicker"},{"attributes":{"axis":{"id":"2185"},"dimension":1,"ticker":null,"visible":false},"id":"2188","type":"Grid"},{"attributes":{},"id":"2192","type":"SaveTool"}],"root_ids":["2172"]},"title":"Bokeh Application","version":"2.2.3"}}
        </script>
        <script type="text/javascript">
          (function() {
            var fn = function() {
              Bokeh.safely(function() {
                (function(root) {
                  function embed_document(root) {
                    
                  var docs_json = document.getElementById('2300').textContent;
                  var render_items = [{"docid":"17a79a35-419e-4724-b8dd-45a6605298e2","root_ids":["2172"],"roots":{"2172":"62ea5ea9-79ac-4d9a-a7a6-ddb12b567757"}}];
                  root.Bokeh.embed.embed_items(docs_json, render_items);
                
                  }
                  if (root.Bokeh !== undefined) {
                    embed_document(root);
                  } else {
                    var attempts = 0;
                    var timer = setInterval(function(root) {
                      if (root.Bokeh !== undefined) {
                        clearInterval(timer);
                        embed_document(root);
                      } else {
                        attempts++;
                        if (attempts > 100) {
                          clearInterval(timer);
                          console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
                        }
                      }
                    }, 10, root)
                  }
                })(window);
              });
            };
            if (document.readyState != "loading") fn();
            else document.addEventListener("DOMContentLoaded", fn);
          })();
        </script>
    
  </body>
  
</html>